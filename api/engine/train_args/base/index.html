
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../../dataset/transforms/">
      
      
        <link rel="next" href="../seq2seq/">
      
      
      <link rel="icon" href="../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.44">
    
    
      
        <title>base - MindNLP Docs</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#mindnlp.engine.train_args.OptimizerNames" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="MindNLP Docs" class="md-header__button md-logo" aria-label="MindNLP Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindNLP Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              base
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../../../zh/api/engine/train_args/base/" hreflang="zh" class="md-select__link">
              中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindnlp
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../tutorials/quick_start/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../supported_models/" class="md-tabs__link">
        
  
    
  
  Supported Models

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../contribute/" class="md-tabs__link">
        
  
    
  
  How-To Contribute

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../accelerate/" class="md-tabs__link">
          
  
    
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../notes/changelog/" class="md-tabs__link">
          
  
    
  
  Notes

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="MindNLP Docs" class="md-nav__button md-logo" aria-label="MindNLP Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    MindNLP Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindnlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/quick_start/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/data_preprocess/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Preprocess
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/use_trainer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Trainer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/use_mirror/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Mirror
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../supported_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supported Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contribute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How-To Contribute
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../accelerate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/load_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    load_dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/BaseMapFunction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BaseMapFunction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/transforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transforms
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" checked>
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Engine
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            Engine
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4_1" checked>
        
          
          <label class="md-nav__link" for="__nav_5_4_1" id="__nav_5_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    train_args
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_4_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_4_1">
            <span class="md-nav__icon md-icon"></span>
            train_args
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    base
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.OptimizerNames" class="md-nav__link">
    <span class="md-ellipsis">
      OptimizerNames
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments" class="md-nav__link">
    <span class="md-ellipsis">
      TrainingArguments
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TrainingArguments">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.ddp_timeout_delta" class="md-nav__link">
    <span class="md-ellipsis">
      ddp_timeout_delta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.eval_batch_size" class="md-nav__link">
    <span class="md-ellipsis">
      eval_batch_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.local_process_index" class="md-nav__link">
    <span class="md-ellipsis">
      local_process_index
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.n_device" class="md-nav__link">
    <span class="md-ellipsis">
      n_device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.parallel_mode" class="md-nav__link">
    <span class="md-ellipsis">
      parallel_mode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.process_index" class="md-nav__link">
    <span class="md-ellipsis">
      process_index
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.should_log" class="md-nav__link">
    <span class="md-ellipsis">
      should_log
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.should_save" class="md-nav__link">
    <span class="md-ellipsis">
      should_save
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.train_batch_size" class="md-nav__link">
    <span class="md-ellipsis">
      train_batch_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      world_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.__post_init__" class="md-nav__link">
    <span class="md-ellipsis">
      __post_init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.__str__" class="md-nav__link">
    <span class="md-ellipsis">
      __str__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.get_process_log_level" class="md-nav__link">
    <span class="md-ellipsis">
      get_process_log_level
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.get_warmup_steps" class="md-nav__link">
    <span class="md-ellipsis">
      get_warmup_steps
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.main_process_first" class="md-nav__link">
    <span class="md-ellipsis">
      main_process_first
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      set_dataloader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      set_evaluate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_logging" class="md-nav__link">
    <span class="md-ellipsis">
      set_logging
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_lr_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      set_lr_scheduler
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      set_optimizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_save" class="md-nav__link">
    <span class="md-ellipsis">
      set_save
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_testing" class="md-nav__link">
    <span class="md-ellipsis">
      set_testing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_training" class="md-nav__link">
    <span class="md-ellipsis">
      set_training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.to_dict" class="md-nav__link">
    <span class="md-ellipsis">
      to_dict
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.to_json_string" class="md-nav__link">
    <span class="md-ellipsis">
      to_json_string
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.to_sanitized_dict" class="md-nav__link">
    <span class="md-ellipsis">
      to_sanitized_dict
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.ParallelMode" class="md-nav__link">
    <span class="md-ellipsis">
      ParallelMode
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seq2seq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seq2seq
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4_2" >
        
          
          <label class="md-nav__link" for="__nav_5_4_2" id="__nav_5_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    trainer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4_2">
            <span class="md-nav__icon md-icon"></span>
            trainer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../trainer/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../trainer/default_func/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    default_func
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../callbacks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    callbacks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    export
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../modules/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modules
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../parallel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../peft/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            PEFT
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_2" >
        
          
          <label class="md-nav__link" for="__nav_5_7_2" id="__nav_5_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    tuners
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_2">
            <span class="md-nav__icon md-icon"></span>
            tuners
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/adalora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AdaLoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/adaption_prompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adaption_Prompt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/ia3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IA3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/lokr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoKr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/prompt_tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prompt tuning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_3" >
        
          
          <label class="md-nav__link" for="__nav_5_7_3" id="__nav_5_7_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_3">
            <span class="md-nav__icon md-icon"></span>
            utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/utils/merge_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    merge_utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/mapping/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mapping
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/peft_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    peft_model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sentence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../transformers/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_2" >
        
          
          <label class="md-nav__link" for="__nav_5_9_2" id="__nav_5_9_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    generation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_2">
            <span class="md-nav__icon md-icon"></span>
            generation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transforemrs/generation/index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/generation/beam_constraints/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_constraints
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/generation/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/generation/logits_process/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    logits_process
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/generation/stopping_criteria/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    stopping_criteria
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/generation/streamers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    streamers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/generation/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../transformers/models/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    models
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_9_3" id="__nav_5_9_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_3">
            <span class="md-nav__icon md-icon"></span>
            models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/albert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    albert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/align/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    align
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/altclip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    altclip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/audio_spectrogram_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    audio_spectrogram_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/auto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    auto
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    autoformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/baichuan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    baichuan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/barthez/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    barthez
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bartpho/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bartpho
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/beit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bert_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bert_japanese/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert_japanese
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bertweet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bertweet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bge_m3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bge_m3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/big_bird/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    big_bird
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bigbird_pegasus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bigbird_pegasus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/biogpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    biogpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/blenderbot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blenderbot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/blenderbot_small/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blenderbot_small
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/blip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/blip_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blip_2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bloom/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bloom
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bridgetower/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bridgetower
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/bros/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bros
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/byt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    byt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/camembert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    camembert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/canine/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    canine
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/chatglm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/chatglm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/chatglm3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    clip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/codegen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    codegen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/cogvlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cogvlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/cohere/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cohere
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/convbert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convbert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/convnext/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convnext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/cpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/cpmant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpmant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/cpmbee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpmbee
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/ctrl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctrl
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/cvt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cvt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/data2vec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data2vec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/deberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    deberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/deberta_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    deberta_v2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/decision_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decision_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/distilbert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    distilbert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/efficientformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    efficientformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/efficientnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    efficientnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/electra/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    electra
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/encodec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encodec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/ernie/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ernie
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/ernie_m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ernie_m
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/esm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    esm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/falcon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    falcon
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/flava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    flava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/funnel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    funnel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gemma
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/git/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    git
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gpt_bigcode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_bigcode
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gpt_neo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gpt_neox/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neox
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gpt_neox_japanese/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neox_japanese
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gpt_pangu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_pangu
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/gptj/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gptj
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/graphormer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    graphormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/groupvit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    groupvit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/hubert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hubert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/imagegpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    imagegpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/internlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    internlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/jamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/jetmoe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jetmoe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/layoutlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    layoutlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/layoutlmv2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    layoutlmv2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/led/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    led
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/llama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/llava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/llava_next/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llava_next
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/longformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    longformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/longt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    longt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/luke/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    luke
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/marian/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    marian
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/maskformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    maskformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mbart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mbart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/megatron_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    megatron_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/megatron_gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    megatron_gpt2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/minicpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    minicpm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/minigpt4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    minigpt4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mistral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mixtral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mixtral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mobilebert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mobilebert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mobilevit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mobilevit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/moss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    moss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mpnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mpnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/musicgen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    musicgen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/musicgen_melody/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    musicgen_melody
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/mvp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mvp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/nezha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nezha
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/nystromformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nystromformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/olmo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    olmo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/openelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    openelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/opt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    opt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/owlvit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    owlvit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/pegasus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pegasus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/phi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phi
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/phi3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phi3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/poolformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    poolformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/pop2piano/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pop2piano
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/qwen2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    qwen2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/qwen2_moe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    qwen2_moe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/reformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/regnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/rembert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rembert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/resnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    resnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/roberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/roc_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roc_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/rwkv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rwkv
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/sam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sam
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/seamless_m4t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seamless_m4t
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/seamless_m4t_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seamless_m4t_v2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/segformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    segformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/seggpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seggpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/speech_encoder_decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_encoder_decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/speech_to_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_to_text
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/squeezebert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    squeezebert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/stablelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    stablelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/starcoder2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    starcoder2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/swiftformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    swiftformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/switch_transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    switch_transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/t5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    t5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/table_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    table_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/timesformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    timesformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/tinybert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tinybert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/van/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    van
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/vipllava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vipllava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/vision_text_dual_encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vision_text_dual_encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/visual_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    visual_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/vit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/wav2vec2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/wav2vec2_conformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2_conformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/wav2vec2_with_lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2_with_lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/wavlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/whisper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    whisper
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/x_clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    x_clip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/xlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/xlm_roberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm_roberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/xlm_roberta_xl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm_roberta_xl
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/models/xlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlnet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_4" >
        
          
          <label class="md-nav__link" for="__nav_5_9_4" id="__nav_5_9_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_4">
            <span class="md-nav__icon md-icon"></span>
            pipeline
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transforemrs/pipeline/index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/automatic_speech_recognition/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    automatic_speech_recognition
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/document_question_answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    document_question_answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/fill_mask/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fill_mask
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/question_answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    question_answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/text2text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text2text_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/text_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/pipeline/zero_shot_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zero_shot_classification
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/configuration_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    configuration_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/modeling_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    modeling_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/tokenization_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/tokenization_utils_base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils_base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transformers/tokenization_utils_fast/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils_fast
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../trl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TRL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Notes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/changelog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Change Log
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/code_of_conduct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code of Conduct
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.OptimizerNames" class="md-nav__link">
    <span class="md-ellipsis">
      OptimizerNames
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments" class="md-nav__link">
    <span class="md-ellipsis">
      TrainingArguments
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TrainingArguments">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.ddp_timeout_delta" class="md-nav__link">
    <span class="md-ellipsis">
      ddp_timeout_delta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.eval_batch_size" class="md-nav__link">
    <span class="md-ellipsis">
      eval_batch_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.local_process_index" class="md-nav__link">
    <span class="md-ellipsis">
      local_process_index
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.n_device" class="md-nav__link">
    <span class="md-ellipsis">
      n_device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.parallel_mode" class="md-nav__link">
    <span class="md-ellipsis">
      parallel_mode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.process_index" class="md-nav__link">
    <span class="md-ellipsis">
      process_index
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.should_log" class="md-nav__link">
    <span class="md-ellipsis">
      should_log
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.should_save" class="md-nav__link">
    <span class="md-ellipsis">
      should_save
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.train_batch_size" class="md-nav__link">
    <span class="md-ellipsis">
      train_batch_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      world_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.__post_init__" class="md-nav__link">
    <span class="md-ellipsis">
      __post_init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.__str__" class="md-nav__link">
    <span class="md-ellipsis">
      __str__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.get_process_log_level" class="md-nav__link">
    <span class="md-ellipsis">
      get_process_log_level
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.get_warmup_steps" class="md-nav__link">
    <span class="md-ellipsis">
      get_warmup_steps
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.main_process_first" class="md-nav__link">
    <span class="md-ellipsis">
      main_process_first
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      set_dataloader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      set_evaluate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_logging" class="md-nav__link">
    <span class="md-ellipsis">
      set_logging
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_lr_scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      set_lr_scheduler
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      set_optimizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_save" class="md-nav__link">
    <span class="md-ellipsis">
      set_save
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_testing" class="md-nav__link">
    <span class="md-ellipsis">
      set_testing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.set_training" class="md-nav__link">
    <span class="md-ellipsis">
      set_training
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.to_dict" class="md-nav__link">
    <span class="md-ellipsis">
      to_dict
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.to_json_string" class="md-nav__link">
    <span class="md-ellipsis">
      to_json_string
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.TrainingArguments.to_sanitized_dict" class="md-nav__link">
    <span class="md-ellipsis">
      to_sanitized_dict
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.engine.train_args.ParallelMode" class="md-nav__link">
    <span class="md-ellipsis">
      ParallelMode
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/mindspore-lab/mindnlp/edit/master/docs/en/api/engine/train_args/base.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindnlp/raw/master/docs/en/api/engine/train_args/base.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


  <h1>base</h1>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.engine.train_args.OptimizerNames" class="doc doc-heading">
            <code>mindnlp.engine.train_args.OptimizerNames</code>


<a href="#mindnlp.engine.train_args.OptimizerNames" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.utils.ExplicitEnum">ExplicitEnum</span></code></p>


        <p>Stores the acceptable string identifiers for optimizers.</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">OptimizerNames</span><span class="p">(</span><span class="n">ExplicitEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Stores the acceptable string identifiers for optimizers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ADAMW</span> <span class="o">=</span> <span class="s2">&quot;adamw&quot;</span>
    <span class="n">SGD</span> <span class="o">=</span> <span class="s2">&quot;sgd&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.engine.train_args.TrainingArguments" class="doc doc-heading">
            <code>mindnlp.engine.train_args.TrainingArguments</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>TrainingArguments is the subset of the arguments we use in our example scripts <strong>which relate to the training loop
itself</strong>.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>output_dir</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The output directory where the model predictions and checkpoints will be written.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>overwrite_output_dir</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If <code>True</code>, overwrite the content of the output directory. Use this to continue training if <code>output_dir</code>
points to a checkpoint directory.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_train</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to run training or not. This argument is not directly used by [<code>Trainer</code>], it's intended to be used
by your training/evaluation scripts instead. See the <a href="https://github.com/huggingface/transformers/tree/main/examples">example
scripts</a> for more details.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_eval</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to run evaluation on the validation set or not. Will be set to <code>True</code> if <code>evaluation_strategy</code> is
different from <code>"no"</code>. This argument is not directly used by [<code>Trainer</code>], it's intended to be used by your
training/evaluation scripts instead. See the <a href="https://github.com/huggingface/transformers/tree/main/examples">example
scripts</a> for more details.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_predict</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to run predictions on the test set or not. This argument is not directly used by [<code>Trainer</code>], it's
intended to be used by your training/evaluation scripts instead. See the <a href="https://github.com/huggingface/transformers/tree/main/examples">example
scripts</a> for more details.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>evaluation_strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The evaluation strategy to adopt during training. Possible values are:</p>
<div class="highlight"><pre><span></span><code>- `&quot;no&quot;`: No evaluation is done during training.
- `&quot;steps&quot;`: Evaluation is done (and logged) every `eval_steps`.
- `&quot;epoch&quot;`: Evaluation is done at the end of each epoch.
</code></pre></div>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&#34;no&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;no&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prediction_loss_only</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When performing evaluation and generating predictions, only returns the loss.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>per_device_train_batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The batch size per GPU/XPU/TPU/MPS/NPU core/CPU for training.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>per_device_eval_batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The batch size per GPU/XPU/TPU/MPS/NPU core/CPU for evaluation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>gradient_accumulation_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of updates steps to accumulate the gradients for, before performing a backward/update pass.</p>
<p><Tip warning={true}></p>
<p>When using gradient accumulation, one step is counted as one step with backward pass. Therefore, logging,
evaluation, save will be conducted every <code>gradient_accumulation_steps * xxx_step</code> training examples.</p>
<p></Tip></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval_accumulation_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU. If
left unset, the whole predictions are accumulated on GPU/NPU/TPU before being moved to the CPU (faster but
requires more memory).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval_delay</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of epochs or steps to wait for before the first evaluation can be performed, depending on the
evaluation_strategy.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>learning_rate</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The initial learning rate for [<code>AdamW</code>] optimizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 5e-5</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>5e-05</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>weight_decay</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in [<code>AdamW</code>]
optimizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>adam_beta1</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The beta1 hyperparameter for the [<code>AdamW</code>] optimizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.9</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.9</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>adam_beta2</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The beta2 hyperparameter for the [<code>AdamW</code>] optimizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.999</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.999</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>adam_epsilon</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon hyperparameter for the [<code>AdamW</code>] optimizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1e-8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-08</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_grad_norm</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Maximum gradient norm (for gradient clipping).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_train_epochs(`float`,</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Total number of training epochs to perform (if not an integer, will perform the decimal part percents of
the last epoch before stopping training).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>*optional*, defaults to 3.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If set to a positive number, the total number of training steps to perform. Overrides <code>num_train_epochs</code>.
For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until
<code>max_steps</code> is reached.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to -1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>-1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lr_scheduler_type</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The scheduler type to use. See the documentation of [<code>SchedulerType</code>] for all possible values.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`SchedulerType`], *optional*, defaults to `&#34;linear&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;linear&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lr_scheduler_kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The extra arguments for the lr_scheduler. See the documentation of each scheduler for possible values.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>&#39;dict&#39;, *optional*, defaults to {}</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>dict()</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warmup_ratio</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ratio of total training steps used for a linear warmup from 0 to <code>learning_rate</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warmup_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of steps used for a linear warmup from 0 to <code>learning_rate</code>. Overrides any effect of <code>warmup_ratio</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>log_level</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logger log level to use on the main process. Possible choices are the log levels as strings: 'debug',
'info', 'warning', 'error' and 'critical', plus a 'passive' level which doesn't set anything and keeps the
current log level for the Transformers library (which will be <code>"warning"</code> by default).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `passive`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;passive&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>log_level_replica</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logger log level to use on replicas. Same choices as <code>log_level</code>"</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;warning&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;warning&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>log_on_each_node</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>In multinode distributed training, whether to log using <code>log_level</code> once per node, or only on the main
node.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logging_dir</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p><a href="https://www.tensorflow.org/tensorboard">TensorBoard</a> log directory. Will default to
<em>output_dir/runs/<strong>CURRENT_DATETIME_HOSTNAME</strong></em>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logging_strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The logging strategy to adopt during training. Possible values are:</p>
<div class="highlight"><pre><span></span><code>- `&quot;no&quot;`: No logging is done during training.
- `&quot;epoch&quot;`: Logging is done at the end of each epoch.
- `&quot;steps&quot;`: Logging is done every `logging_steps`.
</code></pre></div>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&#34;steps&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;steps&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logging_first_step</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to log the first <code>global_step</code> or not.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logging_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of update steps between two logs if <code>logging_strategy="steps"</code>. Should be an integer or a float in
range <code>[0,1)</code>. If smaller than 1, will be interpreted as ratio of total training steps.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` or `float`, *optional*, defaults to 500</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>500</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logging_nan_inf_filter</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to filter <code>nan</code> and <code>inf</code> losses for logging. If set to <code>True</code> the loss of every step that is <code>nan</code>
or <code>inf</code> is filtered and the average loss of the current logging window is taken instead.</p>
<p><Tip></p>
<p><code>logging_nan_inf_filter</code> only influences the logging of loss values, it does not change the behavior the
gradient is computed or applied to the model.</p>
<p></Tip></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The checkpoint save strategy to adopt during training. Possible values are:</p>
<div class="highlight"><pre><span></span><code>- `&quot;no&quot;`: No save is done during training.
- `&quot;epoch&quot;`: Save is done at the end of each epoch.
- `&quot;steps&quot;`: Save is done every `save_steps`.
</code></pre></div>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&#34;steps&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;steps&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of updates steps before two checkpoint saves if <code>save_strategy="steps"</code>. Should be an integer or a
float in range <code>[0,1)</code>. If smaller than 1, will be interpreted as ratio of total training steps.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` or `float`, *optional*, defaults to 500</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>500</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_total_limit</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in
<code>output_dir</code>. When <code>load_best_model_at_end</code> is enabled, the "best" checkpoint according to
<code>metric_for_best_model</code> will always be retained in addition to the most recent ones. For example, for
<code>save_total_limit=5</code> and <code>load_best_model_at_end</code>, the four last checkpoints will always be retained
alongside the best model. When <code>save_total_limit=1</code> and <code>load_best_model_at_end</code>, it is possible that two
checkpoints are saved: the last one and the best one (if they are different).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_safetensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Use <a href="https://huggingface.co/docs/safetensors">safetensors</a> saving and loading for state dicts instead of
default <code>mindspore.load_checkpoint</code> and <code>mindspore.save_checkpoint</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_on_each_node</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When doing multi-node distributed training, whether to save models and checkpoints on each node, or only on
the main one.</p>
<p>This should not be activated when the different nodes use the same storage as the files will be saved with
the same names for each node.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_only_model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When checkpointing, whether to only save the model, or also the optimizer, scheduler &amp; rng state.
Note that when this is true, you won't be able to resume training from checkpoint.
This enables you to save storage by not storing the optimizer, scheduler &amp; rng state.
You can only load the model using <code>from_pretrained</code> with this option set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_cpu</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to use cpu. If set to False, we will use cuda or mps device if available.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use the
[<code>~Trainer.model_init</code>] function to instantiate the model if it has some randomly initialized parameters.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 42</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>42</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>data_seed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Random seed to be used with data samplers. If not set, random generators for data sampling will use the
same seed as <code>seed</code>. This can be used to ensure reproducibility of data sampling, independent of the model
seed.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>jit_mode_eval</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to use MindSpore jit trace for inference.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_ipex</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Use Intel extension for MindSpore when it is available.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bf16</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use bf16 16-bit (mixed) precision training instead of 32-bit training. Requires Ampere or higher
NVIDIA architecture or using CPU (use_cpu) or Ascend NPU. This is an experimental API and it may change.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fp16</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use fp16 16-bit (mixed) precision training instead of 32-bit training.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fp16_opt_level</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>For <code>fp16</code> training, Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']. See details on
the <a href="https://nvidia.github.io/apex/amp">Apex documentation</a>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to &#39;O1&#39;</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;O1&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fp16_backend</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>This argument is deprecated. Use <code>half_precision_backend</code> instead.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;auto&#34;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>half_precision_backend</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The backend to use for mixed precision training. Must be one of <code>"auto", "apex", "cpu_amp"</code>. <code>"auto"</code> will
use CPU/CUDA AMP or APEX depending on the MindSpore version detected, while the other choices will force the
requested backend.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;auto&#34;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bf16_full_eval</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use full bfloat16 evaluation instead of 32-bit. This will be faster and save memory but can harm
metric values. This is an experimental API and it may change.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fp16_full_eval</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use full float16 evaluation instead of 32-bit. This will be faster and save memory but can harm
metric values.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>local_rank</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Rank of the process during distributed training.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to -1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>-1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ddp_backend</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The backend to use for distributed training. Must be one of <code>"nccl"</code>, <code>"mpi"</code>, <code>"ccl"</code>, <code>"gloo"</code>, <code>"hccl"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tpu_num_cores</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When training on TPU, the number of TPU cores (automatically passed by launcher script).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataloader_drop_last</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch size)
or not.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eval_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of update steps between two evaluations if <code>evaluation_strategy="steps"</code>. Will default to the same
value as <code>logging_steps</code> if not set. Should be an integer or a float in range <code>[0,1)</code>. If smaller than 1,
will be interpreted as ratio of total training steps.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` or `float`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataloader_num_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of subprocesses to use for data loading (MindSpore only). 0 means that the data will be loaded in the
main process.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>past_index</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Some models like <a href="../model_doc/transformerxl">TransformerXL</a> or <a href="../model_doc/xlnet">XLNet</a> can make use of
the past hidden states for their predictions. If this argument is set to a positive int, the <code>Trainer</code> will
use the corresponding output (usually index 2) as the past state and feed it to the model at the next
training step under the keyword argument <code>mems</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to -1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>-1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>run_name</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A descriptor for the run. Typically used for <a href="https://www.wandb.com/">wandb</a> and
<a href="https://www.mlflow.org/">mlflow</a> logging.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>disable_tqdm</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to disable the tqdm progress bars and table of metrics produced by
[<code>~notebook.NotebookTrainingTracker</code>] in Jupyter Notebooks. Will default to <code>True</code> if the logging level is
set to warn or lower (default), <code>False</code> otherwise.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>remove_unused_columns</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to automatically remove the columns unused by the model forward method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>label_names</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of keys in your dictionary of inputs that correspond to the labels.</p>
<p>Will eventually default to the list of argument names accepted by the model that contain the word "label",
except if the model used is one of the <code>XxxForQuestionAnswering</code> in which case it will also include the
<code>["start_positions", "end_positions"]</code> keys.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[str]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>load_best_model_at_end</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to load the best model found during training at the end of training. When this option is
enabled, the best checkpoint will always be saved. See
<a href="https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.save_total_limit"><code>save_total_limit</code></a>
for more.</p>
<p><Tip></p>
<p>When set to <code>True</code>, the parameters <code>save_strategy</code> needs to be the same as <code>evaluation_strategy</code>, and in
the case it is "steps", <code>save_steps</code> must be a round multiple of <code>eval_steps</code>.</p>
<p></Tip></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric_for_best_model</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Use in conjunction with <code>load_best_model_at_end</code> to specify the metric to use to compare two different
models. Must be the name of a metric returned by the evaluation with or without the prefix <code>"eval_"</code>. Will
default to <code>"loss"</code> if unspecified and <code>load_best_model_at_end=True</code> (to use the evaluation loss).</p>
<p>If you set this value, <code>greater_is_better</code> will default to <code>True</code>. Don't forget to set it to <code>False</code> if
your metric is better when lower.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>greater_is_better</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Use in conjunction with <code>load_best_model_at_end</code> and <code>metric_for_best_model</code> to specify if better models
should have a greater metric or not. Will default to:</p>
<ul>
<li><code>True</code> if <code>metric_for_best_model</code> is set to a value that isn't <code>"loss"</code> or <code>"eval_loss"</code>.</li>
<li><code>False</code> if <code>metric_for_best_model</code> is not set, or set to <code>"loss"</code> or <code>"eval_loss"</code>.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ignore_data_skip</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When resuming training, whether or not to skip the epochs and batches to get the data loading at the same
stage as in the previous training. If set to <code>True</code>, the training will begin faster (as that skipping step
can take a long time) but will not yield the same results as the interrupted training would have.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fsdp</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Use MindSpore Distributed Parallel Training (in distributed training only).</p>
<p>A list of options along the following:</p>
<ul>
<li><code>"full_shard"</code>: Shard parameters, gradients and optimizer states.</li>
<li><code>"shard_grad_op"</code>: Shard optimizer states and gradients.</li>
<li><code>"hybrid_shard"</code>: Apply <code>FULL_SHARD</code> within a node, and replicate parameters across nodes.</li>
<li><code>"hybrid_shard_zero2"</code>: Apply <code>SHARD_GRAD_OP</code> within a node, and replicate parameters across nodes.</li>
<li><code>"offload"</code>: Offload parameters and gradients to CPUs (only compatible with <code>"full_shard"</code> and
  <code>"shard_grad_op"</code>).</li>
<li><code>"auto_wrap"</code>: Automatically recursively wrap layers with FSDP using <code>default_auto_wrap_policy</code>.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, `str` or list of [`~trainer_utils.FSDPOption`], *optional*, defaults to `&#39;&#39;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fsdp_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Config to be used with fsdp (MindSpore Distributed Parallel Training). The value is either a location of
fsdp json config file (e.g., <code>fsdp_config.json</code>) or an already loaded json file as <code>dict</code>.</p>
<p>A List of config and its options:
    - min_num_params (<code>int</code>, <em>optional</em>, defaults to <code>0</code>):
        FSDP's minimum number of parameters for Default Auto Wrapping. (useful only when <code>fsdp</code> field is
        passed).
    - transformer_layer_cls_to_wrap (<code>List[str]</code>, <em>optional</em>):
        List of transformer layer class names (case-sensitive) to wrap, e.g, <code>BertLayer</code>, <code>GPTJBlock</code>,
        <code>T5Block</code> .... (useful only when <code>fsdp</code> flag is passed).
    - backward_prefetch (<code>str</code>, <em>optional</em>)
        FSDP's backward prefetch mode. Controls when to prefetch next set of parameters (useful only when
        <code>fsdp</code> field is passed).</p>
<div class="highlight"><pre><span></span><code>    A list of options along the following:

    - `&quot;backward_pre&quot;` : Prefetches the next set of parameters before the current set of parameter&#39;s
      gradient
        computation.
    - `&quot;backward_post&quot;` : This prefetches the next set of parameters after the current set of
      parameter’s
        gradient computation.
- forward_prefetch (`bool`, *optional*, defaults to `False`)
    FSDP&#39;s forward prefetch mode (useful only when `fsdp` field is passed).
     If `&quot;True&quot;`, then FSDP explicitly prefetches the next upcoming all-gather while executing in the
     forward pass.
- limit_all_gathers (`bool`, *optional*, defaults to `False`)
    FSDP&#39;s limit_all_gathers (useful only when `fsdp` field is passed).
     If `&quot;True&quot;`, FSDP explicitly synchronizes the CPU thread to prevent too many in-flight
     all-gathers.
- use_orig_params (`bool`, *optional*, defaults to `True`)
    If `&quot;True&quot;`, allows non-uniform `requires_grad` during init, which means support for interspersed
    frozen and trainable paramteres. Useful in cases such as parameter-efficient fine-tuning.
- sync_module_states (`bool`, *optional*, defaults to `True`)
    If `&quot;True&quot;`, each individually wrapped FSDP unit will broadcast module parameters from rank 0 to
    ensure they are the same across all ranks after initialization
- activation_checkpointing (`bool`, *optional*, defaults to `False`):
    If `&quot;True&quot;`, activation checkpointing is a technique to reduce memory usage by clearing activations of
    certain layers and recomputing them during a backward pass. Effectively, this trades extra
    computation time for reduced memory usage.
- xla (`bool`, *optional*, defaults to `False`):
    Whether to use MindSpore/XLA Fully Sharded Data Parallel Training. This is an experimental feature
    and its API may evolve in the future.
- xla_fsdp_settings (`dict`, *optional*)
    The value is a dictionary which stores the XLA FSDP wrapping parameters.
- xla_fsdp_grad_ckpt (`bool`, *optional*, defaults to `False`):
    Will use gradient checkpointing over each nested XLA FSDP wrapped layer. This setting can only be
    used when the xla flag is set to true, and an auto wrapping policy is specified through
    fsdp_min_num_params or fsdp_transformer_layer_cls_to_wrap.
</code></pre></div>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `dict`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>deepspeed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Use <a href="https://github.com/microsoft/deepspeed">Deepspeed</a>. This is an experimental feature and its API may
evolve in the future. The value is either the location of DeepSpeed json config file (e.g.,
<code>ds_config.json</code>) or an already loaded json file as a <code>dict</code>"</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `dict`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>accelerator_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Config to be used with the internal <code>Accelerator</code> implementation. The value is either a location of
accelerator json config file (e.g., <code>accelerator_config.json</code>), an already loaded json file as <code>dict</code>,
or an instance of [<code>~trainer_pt_utils.AcceleratorConfig</code>].</p>
<p>A list of config and its options:
    - split_batches (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
        Whether or not the accelerator should split the batches yielded by the dataloaders across the devices. If
        <code>True</code> the actual batch size used will be the same on any kind of distributed processes, but it must be a
        round multiple of the <code>num_processes</code> you are using. If <code>False</code>, actual batch size used will be the one set
        in your script multiplied by the number of processes.
    - dispatch_batches (<code>bool</code>, <em>optional</em>):
        If set to <code>True</code>, the dataloader prepared by the Accelerator is only iterated through on the main process
        and then the batches are split and broadcast to each process. Will default to <code>True</code> for <code>DataLoader</code> whose
        underlying dataset is an <code>IterableDataset</code>, <code>False</code> otherwise.
    - even_batches (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):
        If set to <code>True</code>, in cases where the total batch size across all processes does not exactly divide the
        dataset, samples at the start of the dataset will be duplicated so the batch can be divided equally among
        all workers.
    - use_seedable_sampler (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>):
        Whether or not use a fully seedable random sampler ([<code>accelerate.data_loader.SeedableRandomSampler</code>]). Ensures
        training results are fully reproducable using a different sampling technique. While seed-to-seed results
        may differ, on average the differences are neglible when using multiple different seeds to compare. Should
        also be ran with [<code>~utils.set_seed</code>] for the best results.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, `dict`, or `AcceleratorConfig`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>label_smoothing_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The label smoothing factor to use. Zero means no label smoothing, otherwise the underlying onehot-encoded
labels are changed from 0s and 1s to <code>label_smoothing_factor/num_labels</code> and <code>1 - label_smoothing_factor +
label_smoothing_factor/num_labels</code> respectively.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>debug</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Enable one or more debug features. This is an experimental feature.</p>
<p>Possible options are:</p>
<ul>
<li><code>"underflow_overflow"</code>: detects overflow in model's input/outputs and reports the last frames that led to
  the event</li>
<li><code>"tpu_metrics_debug"</code>: print debug metrics on TPU</li>
</ul>
<p>The options should be separated by whitespaces.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or list of [`~debug_utils.DebugOption`], *optional*, defaults to `&#34;&#34;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>optim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The optimizer to use: adamw, sgd.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`training_args.OptimizerNames`], *optional*, defaults to `&#34;adamw&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.engine.train_args.base.TrainingArguments.default_optim">default_optim</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>optim_args</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional arguments that are supplied to AnyPrecisionAdamW.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>group_by_length</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to group together samples of roughly the same length in the training dataset (to minimize
padding applied and be more efficient). Only useful if applying dynamic padding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>length_column_name</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Column name for precomputed lengths. If the column exists, grouping by length will use these values rather
than computing them on train startup. Ignored unless <code>group_by_length</code> is <code>True</code> and the dataset is an
instance of <code>Dataset</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;length&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;length&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>report_to</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of integrations to report the results and logs to. Supported platforms are <code>"azure_ml"</code>,
<code>"clearml"</code>, <code>"codecarbon"</code>, <code>"comet_ml"</code>, <code>"dagshub"</code>, <code>"dvclive"</code>, <code>"flyte"</code>, <code>"mlflow"</code>, <code>"neptune"</code>,
<code>"tensorboard"</code>, and <code>"wandb"</code>. Use <code>"all"</code> to report to all integrations installed, <code>"none"</code> for no
integrations.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*, defaults to `&#34;all&#34;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ddp_find_unused_parameters</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When using distributed training, the value of the flag <code>find_unused_parameters</code> passed to
<code>DistributedDataParallel</code>. Will default to <code>False</code> if gradient checkpointing is used, <code>True</code> otherwise.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ddp_bucket_cap_mb</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When using distributed training, the value of the flag <code>bucket_cap_mb</code> passed to <code>DistributedDataParallel</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ddp_broadcast_buffers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When using distributed training, the value of the flag <code>broadcast_buffers</code> passed to
<code>DistributedDataParallel</code>. Will default to <code>False</code> if gradient checkpointing is used, <code>True</code> otherwise.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataloader_persistent_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If True, the data loader will not shut down the worker processes after a dataset has been consumed once.
This allows to maintain the workers Dataset instances alive. Can potentially speed up training, but will
increase RAM usage. Will default to <code>False</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dataloader_prefetch_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of batches loaded in advance by each worker.
2 means there will be a total of 2 * num_workers batches prefetched across all workers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>skip_memory_metrics</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to skip adding of memory profiler reports to metrics. This is skipped by default because it slows
down the training and evaluation speed.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>push_to_hub</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to push the model to the Hub every time the model is saved. If this is activated,
<code>output_dir</code> will begin a git directory synced with the repo (determined by <code>hub_model_id</code>) and the content
will be pushed each time a save is triggered (depending on your <code>save_strategy</code>). Calling
[<code>~Trainer.save_model</code>] will also trigger a push.</p>
<p><Tip warning={true}></p>
<p>If <code>output_dir</code> exists, it needs to be a local clone of the repository to which the [<code>Trainer</code>] will be
pushed.</p>
<p></Tip></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resume_from_checkpoint</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The path to a folder with a valid checkpoint for your model. This argument is not directly used by
[<code>Trainer</code>], it's intended to be used by your training/evaluation scripts instead. See the <a href="https://github.com/huggingface/transformers/tree/main/examples">example
scripts</a> for more details.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hub_model_id</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The name of the repository to keep in sync with the local <em>output_dir</em>. It can be a simple model ID in
which case the model will be pushed in your namespace. Otherwise it should be the whole repository name,
for instance <code>"user_name/model"</code>, which allows you to push to an organization you are a member of with
<code>"organization_name/model"</code>. Will default to <code>user_name/output_dir_name</code> with <em>output_dir_name</em> being the
name of <code>output_dir</code>.</p>
<p>Will default to the name of <code>output_dir</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hub_strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Defines the scope of what is pushed to the Hub and when. Possible values are:</p>
<ul>
<li><code>"end"</code>: push the model, its configuration, the tokenizer (if passed along to the [<code>Trainer</code>]) and a
  draft of a model card when the [<code>~Trainer.save_model</code>] method is called.</li>
<li><code>"every_save"</code>: push the model, its configuration, the tokenizer (if passed along to the [<code>Trainer</code>]) and
  a draft of a model card each time there is a model save. The pushes are asynchronous to not block
  training, and in case the save are very frequent, a new push is only attempted if the previous one is
  finished. A last push is made with the final model at the end of training.</li>
<li><code>"checkpoint"</code>: like <code>"every_save"</code> but the latest checkpoint is also pushed in a subfolder named
  last-checkpoint, allowing you to resume training easily with
  <code>trainer.train(resume_from_checkpoint="last-checkpoint")</code>.</li>
<li><code>"all_checkpoints"</code>: like <code>"checkpoint"</code> but all checkpoints are pushed like they appear in the output
  folder (so you will get one checkpoint folder per folder in your final repository)</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~trainer_utils.HubStrategy`], *optional*, defaults to `&#34;every_save&#34;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hub_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The token to use to push the model to the Hub. Will default to the token in the cache folder obtained with
<code>huggingface-cli login</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hub_private_repo</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If True, the Hub repo will be set to private.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hub_always_push</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Unless this is <code>True</code>, the <code>Trainer</code> will skip pushing a checkpoint when the previous push is not finished.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>recompute</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If True, use gradient checkpointing to save memory at the expense of slower backward pass.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>recompute_kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Key word arguments to be passed to the <code>recompute_enable</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*, defaults to `None`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>include_inputs_for_metrics</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not the inputs will be passed to the <code>compute_metrics</code> function. This is intended for metrics
that need inputs, predictions and references for scoring calculation in Metric class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ray_scope</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The scope to use when doing hyperparameter search with Ray. By default, <code>"last"</code> will be used. Ray will
then use the last checkpoint of all trials, compare those, and select the best one. However, other options
are also available. See the <a href="https://docs.ray.io/en/latest/tune/api_docs/analysis.html#ray.tune.ExperimentAnalysis.get_best_trial">Ray documentation</a> for
more options.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;last&#34;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ddp_timeout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The timeout for <code>mindspore.communication.init</code> calls, used to avoid GPU socket timeouts when
performing slow operations in distributed runnings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1800</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1800</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_mps_device</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>This argument is deprecated.<code>mps</code> device will be used if it is available similar to <code>cuda</code> device.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nn_compile</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>This will use the best defaults for the [<code>mindspore.nn.Module.compile</code>]
You can customize the defaults with the argument <code>nn_compile_backend</code> and <code>nn_compile_mode</code> but we
don't guarantee any of them will work as the support is progressively rolled in in MindSpore.</p>
<p>This flag and the whole compile API is experimental and subject to change in future releases.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nn_compile_backend</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The backend to use in <code>mindspore.nn.Module.compile</code>. If set to any value, <code>mindspore.nn.Module.compile</code> will be set to <code>True</code>.</p>
<p>Refer to the MindSpore doc for possible values and note that they may change across MindSpore versions.</p>
<p>This flag is experimental and subject to change in future releases.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nn_compile_mode</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The mode to use in <code>mindspore.nn.Module.compile</code>. If set to any value, <code>mindspore.nn.Module.compile</code> will be set to <code>True</code>.</p>
<p>Refer to the MindSpore doc for possible values and note that they may change across MindSpore versions.</p>
<p>This flag is experimental and subject to change in future releases.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>split_batches</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not the accelerator should split the batches yielded by the dataloaders across the devices
during distributed training. If</p>
<p>set to <code>True</code>, the actual batch size used will be the same on any kind of distributed processes, but it
must be a</p>
<p>round multiple of the number of processes you are using (such as GPUs).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>include_tokens_per_second</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to compute the number of tokens per second per device for training speed metrics.</p>
<p>This will iterate over the entire training dataloader once beforehand,</p>
<p>and will slow down the entire process.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>include_num_input_tokens_seen</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to track the number of input tokens seen throughout training.</p>
<p>May be slower in distributed training as gather operations must be called.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>neftune_noise_alpha</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If not <code>None</code>, this will activate NEFTune noise embeddings. This can drastically improve model performance
for instruction fine-tuning. Check out the <a href="https://arxiv.org/abs/2310.05914">original paper</a> and the
<a href="https://github.com/neelsjain/NEFTune">original code</a>. Support transformers <code>PreTrainedModel</code> and also
<code>PeftModel</code> from peft.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[float]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TrainingArguments</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    TrainingArguments is the subset of the arguments we use in our example scripts **which relate to the training loop</span>
<span class="sd">    itself**.</span>


<span class="sd">    Parameters:</span>
<span class="sd">        output_dir (`str`):</span>
<span class="sd">            The output directory where the model predictions and checkpoints will be written.</span>
<span class="sd">        overwrite_output_dir (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            If `True`, overwrite the content of the output directory. Use this to continue training if `output_dir`</span>
<span class="sd">            points to a checkpoint directory.</span>
<span class="sd">        do_train (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to run training or not. This argument is not directly used by [`Trainer`], it&#39;s intended to be used</span>
<span class="sd">            by your training/evaluation scripts instead. See the [example</span>
<span class="sd">            scripts](https://github.com/huggingface/transformers/tree/main/examples) for more details.</span>
<span class="sd">        do_eval (`bool`, *optional*):</span>
<span class="sd">            Whether to run evaluation on the validation set or not. Will be set to `True` if `evaluation_strategy` is</span>
<span class="sd">            different from `&quot;no&quot;`. This argument is not directly used by [`Trainer`], it&#39;s intended to be used by your</span>
<span class="sd">            training/evaluation scripts instead. See the [example</span>
<span class="sd">            scripts](https://github.com/huggingface/transformers/tree/main/examples) for more details.</span>
<span class="sd">        do_predict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to run predictions on the test set or not. This argument is not directly used by [`Trainer`], it&#39;s</span>
<span class="sd">            intended to be used by your training/evaluation scripts instead. See the [example</span>
<span class="sd">            scripts](https://github.com/huggingface/transformers/tree/main/examples) for more details.</span>
<span class="sd">        evaluation_strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;no&quot;`):</span>
<span class="sd">            The evaluation strategy to adopt during training. Possible values are:</span>

<span class="sd">                - `&quot;no&quot;`: No evaluation is done during training.</span>
<span class="sd">                - `&quot;steps&quot;`: Evaluation is done (and logged) every `eval_steps`.</span>
<span class="sd">                - `&quot;epoch&quot;`: Evaluation is done at the end of each epoch.</span>

<span class="sd">        prediction_loss_only (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            When performing evaluation and generating predictions, only returns the loss.</span>
<span class="sd">        per_device_train_batch_size (`int`, *optional*, defaults to 8):</span>
<span class="sd">            The batch size per GPU/XPU/TPU/MPS/NPU core/CPU for training.</span>
<span class="sd">        per_device_eval_batch_size (`int`, *optional*, defaults to 8):</span>
<span class="sd">            The batch size per GPU/XPU/TPU/MPS/NPU core/CPU for evaluation.</span>
<span class="sd">        gradient_accumulation_steps (`int`, *optional*, defaults to 1):</span>
<span class="sd">            Number of updates steps to accumulate the gradients for, before performing a backward/update pass.</span>

<span class="sd">            &lt;Tip warning={true}&gt;</span>

<span class="sd">            When using gradient accumulation, one step is counted as one step with backward pass. Therefore, logging,</span>
<span class="sd">            evaluation, save will be conducted every `gradient_accumulation_steps * xxx_step` training examples.</span>

<span class="sd">            &lt;/Tip&gt;</span>

<span class="sd">        eval_accumulation_steps (`int`, *optional*):</span>
<span class="sd">            Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU. If</span>
<span class="sd">            left unset, the whole predictions are accumulated on GPU/NPU/TPU before being moved to the CPU (faster but</span>
<span class="sd">            requires more memory).</span>
<span class="sd">        eval_delay (`float`, *optional*):</span>
<span class="sd">            Number of epochs or steps to wait for before the first evaluation can be performed, depending on the</span>
<span class="sd">            evaluation_strategy.</span>
<span class="sd">        learning_rate (`float`, *optional*, defaults to 5e-5):</span>
<span class="sd">            The initial learning rate for [`AdamW`] optimizer.</span>
<span class="sd">        weight_decay (`float`, *optional*, defaults to 0):</span>
<span class="sd">            The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in [`AdamW`]</span>
<span class="sd">            optimizer.</span>
<span class="sd">        adam_beta1 (`float`, *optional*, defaults to 0.9):</span>
<span class="sd">            The beta1 hyperparameter for the [`AdamW`] optimizer.</span>
<span class="sd">        adam_beta2 (`float`, *optional*, defaults to 0.999):</span>
<span class="sd">            The beta2 hyperparameter for the [`AdamW`] optimizer.</span>
<span class="sd">        adam_epsilon (`float`, *optional*, defaults to 1e-8):</span>
<span class="sd">            The epsilon hyperparameter for the [`AdamW`] optimizer.</span>
<span class="sd">        max_grad_norm (`float`, *optional*, defaults to 1.0):</span>
<span class="sd">            Maximum gradient norm (for gradient clipping).</span>
<span class="sd">        num_train_epochs(`float`, *optional*, defaults to 3.0):</span>
<span class="sd">            Total number of training epochs to perform (if not an integer, will perform the decimal part percents of</span>
<span class="sd">            the last epoch before stopping training).</span>
<span class="sd">        max_steps (`int`, *optional*, defaults to -1):</span>
<span class="sd">            If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.</span>
<span class="sd">            For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until</span>
<span class="sd">            `max_steps` is reached.</span>
<span class="sd">        lr_scheduler_type (`str` or [`SchedulerType`], *optional*, defaults to `&quot;linear&quot;`):</span>
<span class="sd">            The scheduler type to use. See the documentation of [`SchedulerType`] for all possible values.</span>
<span class="sd">        lr_scheduler_kwargs (&#39;dict&#39;, *optional*, defaults to {}):</span>
<span class="sd">            The extra arguments for the lr_scheduler. See the documentation of each scheduler for possible values.</span>
<span class="sd">        warmup_ratio (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            Ratio of total training steps used for a linear warmup from 0 to `learning_rate`.</span>
<span class="sd">        warmup_steps (`int`, *optional*, defaults to 0):</span>
<span class="sd">            Number of steps used for a linear warmup from 0 to `learning_rate`. Overrides any effect of `warmup_ratio`.</span>
<span class="sd">        log_level (`str`, *optional*, defaults to `passive`):</span>
<span class="sd">            Logger log level to use on the main process. Possible choices are the log levels as strings: &#39;debug&#39;,</span>
<span class="sd">            &#39;info&#39;, &#39;warning&#39;, &#39;error&#39; and &#39;critical&#39;, plus a &#39;passive&#39; level which doesn&#39;t set anything and keeps the</span>
<span class="sd">            current log level for the Transformers library (which will be `&quot;warning&quot;` by default).</span>
<span class="sd">        log_level_replica (`str`, *optional*, defaults to `&quot;warning&quot;`):</span>
<span class="sd">            Logger log level to use on replicas. Same choices as `log_level`&quot;</span>
<span class="sd">        log_on_each_node (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            In multinode distributed training, whether to log using `log_level` once per node, or only on the main</span>
<span class="sd">            node.</span>
<span class="sd">        logging_dir (`str`, *optional*):</span>
<span class="sd">            [TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to</span>
<span class="sd">            *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.</span>
<span class="sd">        logging_strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;steps&quot;`):</span>
<span class="sd">            The logging strategy to adopt during training. Possible values are:</span>

<span class="sd">                - `&quot;no&quot;`: No logging is done during training.</span>
<span class="sd">                - `&quot;epoch&quot;`: Logging is done at the end of each epoch.</span>
<span class="sd">                - `&quot;steps&quot;`: Logging is done every `logging_steps`.</span>

<span class="sd">        logging_first_step (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to log the first `global_step` or not.</span>
<span class="sd">        logging_steps (`int` or `float`, *optional*, defaults to 500):</span>
<span class="sd">            Number of update steps between two logs if `logging_strategy=&quot;steps&quot;`. Should be an integer or a float in</span>
<span class="sd">            range `[0,1)`. If smaller than 1, will be interpreted as ratio of total training steps.</span>
<span class="sd">        logging_nan_inf_filter (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to filter `nan` and `inf` losses for logging. If set to `True` the loss of every step that is `nan`</span>
<span class="sd">            or `inf` is filtered and the average loss of the current logging window is taken instead.</span>

<span class="sd">            &lt;Tip&gt;</span>

<span class="sd">            `logging_nan_inf_filter` only influences the logging of loss values, it does not change the behavior the</span>
<span class="sd">            gradient is computed or applied to the model.</span>

<span class="sd">            &lt;/Tip&gt;</span>

<span class="sd">        save_strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;steps&quot;`):</span>
<span class="sd">            The checkpoint save strategy to adopt during training. Possible values are:</span>

<span class="sd">                - `&quot;no&quot;`: No save is done during training.</span>
<span class="sd">                - `&quot;epoch&quot;`: Save is done at the end of each epoch.</span>
<span class="sd">                - `&quot;steps&quot;`: Save is done every `save_steps`.</span>
<span class="sd">        save_steps (`int` or `float`, *optional*, defaults to 500):</span>
<span class="sd">            Number of updates steps before two checkpoint saves if `save_strategy=&quot;steps&quot;`. Should be an integer or a</span>
<span class="sd">            float in range `[0,1)`. If smaller than 1, will be interpreted as ratio of total training steps.</span>
<span class="sd">        save_total_limit (`int`, *optional*):</span>
<span class="sd">            If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in</span>
<span class="sd">            `output_dir`. When `load_best_model_at_end` is enabled, the &quot;best&quot; checkpoint according to</span>
<span class="sd">            `metric_for_best_model` will always be retained in addition to the most recent ones. For example, for</span>
<span class="sd">            `save_total_limit=5` and `load_best_model_at_end`, the four last checkpoints will always be retained</span>
<span class="sd">            alongside the best model. When `save_total_limit=1` and `load_best_model_at_end`, it is possible that two</span>
<span class="sd">            checkpoints are saved: the last one and the best one (if they are different).</span>
<span class="sd">        save_safetensors (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Use [safetensors](https://huggingface.co/docs/safetensors) saving and loading for state dicts instead of</span>
<span class="sd">            default `mindspore.load_checkpoint` and `mindspore.save_checkpoint`.</span>
<span class="sd">        save_on_each_node (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            When doing multi-node distributed training, whether to save models and checkpoints on each node, or only on</span>
<span class="sd">            the main one.</span>

<span class="sd">            This should not be activated when the different nodes use the same storage as the files will be saved with</span>
<span class="sd">            the same names for each node.</span>
<span class="sd">        save_only_model (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            When checkpointing, whether to only save the model, or also the optimizer, scheduler &amp; rng state.</span>
<span class="sd">            Note that when this is true, you won&#39;t be able to resume training from checkpoint.</span>
<span class="sd">            This enables you to save storage by not storing the optimizer, scheduler &amp; rng state.</span>
<span class="sd">            You can only load the model using `from_pretrained` with this option set to `True`.</span>
<span class="sd">        use_cpu (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to use cpu. If set to False, we will use cuda or mps device if available.</span>
<span class="sd">        seed (`int`, *optional*, defaults to 42):</span>
<span class="sd">            Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use the</span>
<span class="sd">            [`~Trainer.model_init`] function to instantiate the model if it has some randomly initialized parameters.</span>
<span class="sd">        data_seed (`int`, *optional*):</span>
<span class="sd">            Random seed to be used with data samplers. If not set, random generators for data sampling will use the</span>
<span class="sd">            same seed as `seed`. This can be used to ensure reproducibility of data sampling, independent of the model</span>
<span class="sd">            seed.</span>
<span class="sd">        jit_mode_eval (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to use MindSpore jit trace for inference.</span>
<span class="sd">        use_ipex (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Use Intel extension for MindSpore when it is available.</span>
<span class="sd">        bf16 (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to use bf16 16-bit (mixed) precision training instead of 32-bit training. Requires Ampere or higher</span>
<span class="sd">            NVIDIA architecture or using CPU (use_cpu) or Ascend NPU. This is an experimental API and it may change.</span>
<span class="sd">        fp16 (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to use fp16 16-bit (mixed) precision training instead of 32-bit training.</span>
<span class="sd">        fp16_opt_level (`str`, *optional*, defaults to &#39;O1&#39;):</span>
<span class="sd">            For `fp16` training, Apex AMP optimization level selected in [&#39;O0&#39;, &#39;O1&#39;, &#39;O2&#39;, and &#39;O3&#39;]. See details on</span>
<span class="sd">            the [Apex documentation](https://nvidia.github.io/apex/amp).</span>
<span class="sd">        fp16_backend (`str`, *optional*, defaults to `&quot;auto&quot;`):</span>
<span class="sd">            This argument is deprecated. Use `half_precision_backend` instead.</span>
<span class="sd">        half_precision_backend (`str`, *optional*, defaults to `&quot;auto&quot;`):</span>
<span class="sd">            The backend to use for mixed precision training. Must be one of `&quot;auto&quot;, &quot;apex&quot;, &quot;cpu_amp&quot;`. `&quot;auto&quot;` will</span>
<span class="sd">            use CPU/CUDA AMP or APEX depending on the MindSpore version detected, while the other choices will force the</span>
<span class="sd">            requested backend.</span>
<span class="sd">        bf16_full_eval (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to use full bfloat16 evaluation instead of 32-bit. This will be faster and save memory but can harm</span>
<span class="sd">            metric values. This is an experimental API and it may change.</span>
<span class="sd">        fp16_full_eval (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to use full float16 evaluation instead of 32-bit. This will be faster and save memory but can harm</span>
<span class="sd">            metric values.</span>
<span class="sd">        local_rank (`int`, *optional*, defaults to -1):</span>
<span class="sd">            Rank of the process during distributed training.</span>
<span class="sd">        ddp_backend (`str`, *optional*):</span>
<span class="sd">            The backend to use for distributed training. Must be one of `&quot;nccl&quot;`, `&quot;mpi&quot;`, `&quot;ccl&quot;`, `&quot;gloo&quot;`, `&quot;hccl&quot;`.</span>
<span class="sd">        tpu_num_cores (`int`, *optional*):</span>
<span class="sd">            When training on TPU, the number of TPU cores (automatically passed by launcher script).</span>
<span class="sd">        dataloader_drop_last (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch size)</span>
<span class="sd">            or not.</span>
<span class="sd">        eval_steps (`int` or `float`, *optional*):</span>
<span class="sd">            Number of update steps between two evaluations if `evaluation_strategy=&quot;steps&quot;`. Will default to the same</span>
<span class="sd">            value as `logging_steps` if not set. Should be an integer or a float in range `[0,1)`. If smaller than 1,</span>
<span class="sd">            will be interpreted as ratio of total training steps.</span>
<span class="sd">        dataloader_num_workers (`int`, *optional*, defaults to 0):</span>
<span class="sd">            Number of subprocesses to use for data loading (MindSpore only). 0 means that the data will be loaded in the</span>
<span class="sd">            main process.</span>
<span class="sd">        past_index (`int`, *optional*, defaults to -1):</span>
<span class="sd">            Some models like [TransformerXL](../model_doc/transformerxl) or [XLNet](../model_doc/xlnet) can make use of</span>
<span class="sd">            the past hidden states for their predictions. If this argument is set to a positive int, the `Trainer` will</span>
<span class="sd">            use the corresponding output (usually index 2) as the past state and feed it to the model at the next</span>
<span class="sd">            training step under the keyword argument `mems`.</span>
<span class="sd">        run_name (`str`, *optional*):</span>
<span class="sd">            A descriptor for the run. Typically used for [wandb](https://www.wandb.com/) and</span>
<span class="sd">            [mlflow](https://www.mlflow.org/) logging.</span>
<span class="sd">        disable_tqdm (`bool`, *optional*):</span>
<span class="sd">            Whether or not to disable the tqdm progress bars and table of metrics produced by</span>
<span class="sd">            [`~notebook.NotebookTrainingTracker`] in Jupyter Notebooks. Will default to `True` if the logging level is</span>
<span class="sd">            set to warn or lower (default), `False` otherwise.</span>
<span class="sd">        remove_unused_columns (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether or not to automatically remove the columns unused by the model forward method.</span>
<span class="sd">        label_names (`List[str]`, *optional*):</span>
<span class="sd">            The list of keys in your dictionary of inputs that correspond to the labels.</span>

<span class="sd">            Will eventually default to the list of argument names accepted by the model that contain the word &quot;label&quot;,</span>
<span class="sd">            except if the model used is one of the `XxxForQuestionAnswering` in which case it will also include the</span>
<span class="sd">            `[&quot;start_positions&quot;, &quot;end_positions&quot;]` keys.</span>
<span class="sd">        load_best_model_at_end (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to load the best model found during training at the end of training. When this option is</span>
<span class="sd">            enabled, the best checkpoint will always be saved. See</span>
<span class="sd">            [`save_total_limit`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.save_total_limit)</span>
<span class="sd">            for more.</span>

<span class="sd">            &lt;Tip&gt;</span>

<span class="sd">            When set to `True`, the parameters `save_strategy` needs to be the same as `evaluation_strategy`, and in</span>
<span class="sd">            the case it is &quot;steps&quot;, `save_steps` must be a round multiple of `eval_steps`.</span>

<span class="sd">            &lt;/Tip&gt;</span>

<span class="sd">        metric_for_best_model (`str`, *optional*):</span>
<span class="sd">            Use in conjunction with `load_best_model_at_end` to specify the metric to use to compare two different</span>
<span class="sd">            models. Must be the name of a metric returned by the evaluation with or without the prefix `&quot;eval_&quot;`. Will</span>
<span class="sd">            default to `&quot;loss&quot;` if unspecified and `load_best_model_at_end=True` (to use the evaluation loss).</span>

<span class="sd">            If you set this value, `greater_is_better` will default to `True`. Don&#39;t forget to set it to `False` if</span>
<span class="sd">            your metric is better when lower.</span>
<span class="sd">        greater_is_better (`bool`, *optional*):</span>
<span class="sd">            Use in conjunction with `load_best_model_at_end` and `metric_for_best_model` to specify if better models</span>
<span class="sd">            should have a greater metric or not. Will default to:</span>

<span class="sd">            - `True` if `metric_for_best_model` is set to a value that isn&#39;t `&quot;loss&quot;` or `&quot;eval_loss&quot;`.</span>
<span class="sd">            - `False` if `metric_for_best_model` is not set, or set to `&quot;loss&quot;` or `&quot;eval_loss&quot;`.</span>
<span class="sd">        ignore_data_skip (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            When resuming training, whether or not to skip the epochs and batches to get the data loading at the same</span>
<span class="sd">            stage as in the previous training. If set to `True`, the training will begin faster (as that skipping step</span>
<span class="sd">            can take a long time) but will not yield the same results as the interrupted training would have.</span>
<span class="sd">        fsdp (`bool`, `str` or list of [`~trainer_utils.FSDPOption`], *optional*, defaults to `&#39;&#39;`):</span>
<span class="sd">            Use MindSpore Distributed Parallel Training (in distributed training only).</span>

<span class="sd">            A list of options along the following:</span>

<span class="sd">            - `&quot;full_shard&quot;`: Shard parameters, gradients and optimizer states.</span>
<span class="sd">            - `&quot;shard_grad_op&quot;`: Shard optimizer states and gradients.</span>
<span class="sd">            - `&quot;hybrid_shard&quot;`: Apply `FULL_SHARD` within a node, and replicate parameters across nodes.</span>
<span class="sd">            - `&quot;hybrid_shard_zero2&quot;`: Apply `SHARD_GRAD_OP` within a node, and replicate parameters across nodes.</span>
<span class="sd">            - `&quot;offload&quot;`: Offload parameters and gradients to CPUs (only compatible with `&quot;full_shard&quot;` and</span>
<span class="sd">              `&quot;shard_grad_op&quot;`).</span>
<span class="sd">            - `&quot;auto_wrap&quot;`: Automatically recursively wrap layers with FSDP using `default_auto_wrap_policy`.</span>
<span class="sd">        fsdp_config (`str` or `dict`, *optional*):</span>
<span class="sd">            Config to be used with fsdp (MindSpore Distributed Parallel Training). The value is either a location of</span>
<span class="sd">            fsdp json config file (e.g., `fsdp_config.json`) or an already loaded json file as `dict`.</span>

<span class="sd">            A List of config and its options:</span>
<span class="sd">                - min_num_params (`int`, *optional*, defaults to `0`):</span>
<span class="sd">                    FSDP&#39;s minimum number of parameters for Default Auto Wrapping. (useful only when `fsdp` field is</span>
<span class="sd">                    passed).</span>
<span class="sd">                - transformer_layer_cls_to_wrap (`List[str]`, *optional*):</span>
<span class="sd">                    List of transformer layer class names (case-sensitive) to wrap, e.g, `BertLayer`, `GPTJBlock`,</span>
<span class="sd">                    `T5Block` .... (useful only when `fsdp` flag is passed).</span>
<span class="sd">                - backward_prefetch (`str`, *optional*)</span>
<span class="sd">                    FSDP&#39;s backward prefetch mode. Controls when to prefetch next set of parameters (useful only when</span>
<span class="sd">                    `fsdp` field is passed).</span>

<span class="sd">                    A list of options along the following:</span>

<span class="sd">                    - `&quot;backward_pre&quot;` : Prefetches the next set of parameters before the current set of parameter&#39;s</span>
<span class="sd">                      gradient</span>
<span class="sd">                        computation.</span>
<span class="sd">                    - `&quot;backward_post&quot;` : This prefetches the next set of parameters after the current set of</span>
<span class="sd">                      parameter’s</span>
<span class="sd">                        gradient computation.</span>
<span class="sd">                - forward_prefetch (`bool`, *optional*, defaults to `False`)</span>
<span class="sd">                    FSDP&#39;s forward prefetch mode (useful only when `fsdp` field is passed).</span>
<span class="sd">                     If `&quot;True&quot;`, then FSDP explicitly prefetches the next upcoming all-gather while executing in the</span>
<span class="sd">                     forward pass.</span>
<span class="sd">                - limit_all_gathers (`bool`, *optional*, defaults to `False`)</span>
<span class="sd">                    FSDP&#39;s limit_all_gathers (useful only when `fsdp` field is passed).</span>
<span class="sd">                     If `&quot;True&quot;`, FSDP explicitly synchronizes the CPU thread to prevent too many in-flight</span>
<span class="sd">                     all-gathers.</span>
<span class="sd">                - use_orig_params (`bool`, *optional*, defaults to `True`)</span>
<span class="sd">                    If `&quot;True&quot;`, allows non-uniform `requires_grad` during init, which means support for interspersed</span>
<span class="sd">                    frozen and trainable paramteres. Useful in cases such as parameter-efficient fine-tuning.</span>
<span class="sd">                - sync_module_states (`bool`, *optional*, defaults to `True`)</span>
<span class="sd">                    If `&quot;True&quot;`, each individually wrapped FSDP unit will broadcast module parameters from rank 0 to</span>
<span class="sd">                    ensure they are the same across all ranks after initialization</span>
<span class="sd">                - activation_checkpointing (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                    If `&quot;True&quot;`, activation checkpointing is a technique to reduce memory usage by clearing activations of</span>
<span class="sd">                    certain layers and recomputing them during a backward pass. Effectively, this trades extra</span>
<span class="sd">                    computation time for reduced memory usage.</span>
<span class="sd">                - xla (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                    Whether to use MindSpore/XLA Fully Sharded Data Parallel Training. This is an experimental feature</span>
<span class="sd">                    and its API may evolve in the future.</span>
<span class="sd">                - xla_fsdp_settings (`dict`, *optional*)</span>
<span class="sd">                    The value is a dictionary which stores the XLA FSDP wrapping parameters.</span>
<span class="sd">                - xla_fsdp_grad_ckpt (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                    Will use gradient checkpointing over each nested XLA FSDP wrapped layer. This setting can only be</span>
<span class="sd">                    used when the xla flag is set to true, and an auto wrapping policy is specified through</span>
<span class="sd">                    fsdp_min_num_params or fsdp_transformer_layer_cls_to_wrap.</span>

<span class="sd">        deepspeed (`str` or `dict`, *optional*):</span>
<span class="sd">            Use [Deepspeed](https://github.com/microsoft/deepspeed). This is an experimental feature and its API may</span>
<span class="sd">            evolve in the future. The value is either the location of DeepSpeed json config file (e.g.,</span>
<span class="sd">            `ds_config.json`) or an already loaded json file as a `dict`&quot;</span>

<span class="sd">        accelerator_config (`str`, `dict`, or `AcceleratorConfig`, *optional*):</span>
<span class="sd">            Config to be used with the internal `Accelerator` implementation. The value is either a location of</span>
<span class="sd">            accelerator json config file (e.g., `accelerator_config.json`), an already loaded json file as `dict`,</span>
<span class="sd">            or an instance of [`~trainer_pt_utils.AcceleratorConfig`].</span>

<span class="sd">            A list of config and its options:</span>
<span class="sd">                - split_batches (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                    Whether or not the accelerator should split the batches yielded by the dataloaders across the devices. If</span>
<span class="sd">                    `True` the actual batch size used will be the same on any kind of distributed processes, but it must be a</span>
<span class="sd">                    round multiple of the `num_processes` you are using. If `False`, actual batch size used will be the one set</span>
<span class="sd">                    in your script multiplied by the number of processes.</span>
<span class="sd">                - dispatch_batches (`bool`, *optional*):</span>
<span class="sd">                    If set to `True`, the dataloader prepared by the Accelerator is only iterated through on the main process</span>
<span class="sd">                    and then the batches are split and broadcast to each process. Will default to `True` for `DataLoader` whose</span>
<span class="sd">                    underlying dataset is an `IterableDataset`, `False` otherwise.</span>
<span class="sd">                - even_batches (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                    If set to `True`, in cases where the total batch size across all processes does not exactly divide the</span>
<span class="sd">                    dataset, samples at the start of the dataset will be duplicated so the batch can be divided equally among</span>
<span class="sd">                    all workers.</span>
<span class="sd">                - use_seedable_sampler (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                    Whether or not use a fully seedable random sampler ([`accelerate.data_loader.SeedableRandomSampler`]). Ensures</span>
<span class="sd">                    training results are fully reproducable using a different sampling technique. While seed-to-seed results</span>
<span class="sd">                    may differ, on average the differences are neglible when using multiple different seeds to compare. Should</span>
<span class="sd">                    also be ran with [`~utils.set_seed`] for the best results.</span>

<span class="sd">        label_smoothing_factor (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            The label smoothing factor to use. Zero means no label smoothing, otherwise the underlying onehot-encoded</span>
<span class="sd">            labels are changed from 0s and 1s to `label_smoothing_factor/num_labels` and `1 - label_smoothing_factor +</span>
<span class="sd">            label_smoothing_factor/num_labels` respectively.</span>
<span class="sd">        debug (`str` or list of [`~debug_utils.DebugOption`], *optional*, defaults to `&quot;&quot;`):</span>
<span class="sd">            Enable one or more debug features. This is an experimental feature.</span>

<span class="sd">            Possible options are:</span>

<span class="sd">            - `&quot;underflow_overflow&quot;`: detects overflow in model&#39;s input/outputs and reports the last frames that led to</span>
<span class="sd">              the event</span>
<span class="sd">            - `&quot;tpu_metrics_debug&quot;`: print debug metrics on TPU</span>

<span class="sd">            The options should be separated by whitespaces.</span>
<span class="sd">        optim (`str` or [`training_args.OptimizerNames`], *optional*, defaults to `&quot;adamw&quot;`):</span>
<span class="sd">            The optimizer to use: adamw, sgd.</span>
<span class="sd">        optim_args (`str`, *optional*):</span>
<span class="sd">            Optional arguments that are supplied to AnyPrecisionAdamW.</span>
<span class="sd">        group_by_length (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to group together samples of roughly the same length in the training dataset (to minimize</span>
<span class="sd">            padding applied and be more efficient). Only useful if applying dynamic padding.</span>
<span class="sd">        length_column_name (`str`, *optional*, defaults to `&quot;length&quot;`):</span>
<span class="sd">            Column name for precomputed lengths. If the column exists, grouping by length will use these values rather</span>
<span class="sd">            than computing them on train startup. Ignored unless `group_by_length` is `True` and the dataset is an</span>
<span class="sd">            instance of `Dataset`.</span>
<span class="sd">        report_to (`str` or `List[str]`, *optional*, defaults to `&quot;all&quot;`):</span>
<span class="sd">            The list of integrations to report the results and logs to. Supported platforms are `&quot;azure_ml&quot;`,</span>
<span class="sd">            `&quot;clearml&quot;`, `&quot;codecarbon&quot;`, `&quot;comet_ml&quot;`, `&quot;dagshub&quot;`, `&quot;dvclive&quot;`, `&quot;flyte&quot;`, `&quot;mlflow&quot;`, `&quot;neptune&quot;`,</span>
<span class="sd">            `&quot;tensorboard&quot;`, and `&quot;wandb&quot;`. Use `&quot;all&quot;` to report to all integrations installed, `&quot;none&quot;` for no</span>
<span class="sd">            integrations.</span>
<span class="sd">        ddp_find_unused_parameters (`bool`, *optional*):</span>
<span class="sd">            When using distributed training, the value of the flag `find_unused_parameters` passed to</span>
<span class="sd">            `DistributedDataParallel`. Will default to `False` if gradient checkpointing is used, `True` otherwise.</span>
<span class="sd">        ddp_bucket_cap_mb (`int`, *optional*):</span>
<span class="sd">            When using distributed training, the value of the flag `bucket_cap_mb` passed to `DistributedDataParallel`.</span>
<span class="sd">        ddp_broadcast_buffers (`bool`, *optional*):</span>
<span class="sd">            When using distributed training, the value of the flag `broadcast_buffers` passed to</span>
<span class="sd">            `DistributedDataParallel`. Will default to `False` if gradient checkpointing is used, `True` otherwise.</span>
<span class="sd">        dataloader_persistent_workers (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            If True, the data loader will not shut down the worker processes after a dataset has been consumed once.</span>
<span class="sd">            This allows to maintain the workers Dataset instances alive. Can potentially speed up training, but will</span>
<span class="sd">            increase RAM usage. Will default to `False`.</span>
<span class="sd">        dataloader_prefetch_factor (`int`, *optional*):</span>
<span class="sd">            Number of batches loaded in advance by each worker.</span>
<span class="sd">            2 means there will be a total of 2 * num_workers batches prefetched across all workers.</span>
<span class="sd">        skip_memory_metrics (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to skip adding of memory profiler reports to metrics. This is skipped by default because it slows</span>
<span class="sd">            down the training and evaluation speed.</span>
<span class="sd">        push_to_hub (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to push the model to the Hub every time the model is saved. If this is activated,</span>
<span class="sd">            `output_dir` will begin a git directory synced with the repo (determined by `hub_model_id`) and the content</span>
<span class="sd">            will be pushed each time a save is triggered (depending on your `save_strategy`). Calling</span>
<span class="sd">            [`~Trainer.save_model`] will also trigger a push.</span>

<span class="sd">            &lt;Tip warning={true}&gt;</span>

<span class="sd">            If `output_dir` exists, it needs to be a local clone of the repository to which the [`Trainer`] will be</span>
<span class="sd">            pushed.</span>

<span class="sd">            &lt;/Tip&gt;</span>

<span class="sd">        resume_from_checkpoint (`str`, *optional*):</span>
<span class="sd">            The path to a folder with a valid checkpoint for your model. This argument is not directly used by</span>
<span class="sd">            [`Trainer`], it&#39;s intended to be used by your training/evaluation scripts instead. See the [example</span>
<span class="sd">            scripts](https://github.com/huggingface/transformers/tree/main/examples) for more details.</span>
<span class="sd">        hub_model_id (`str`, *optional*):</span>
<span class="sd">            The name of the repository to keep in sync with the local *output_dir*. It can be a simple model ID in</span>
<span class="sd">            which case the model will be pushed in your namespace. Otherwise it should be the whole repository name,</span>
<span class="sd">            for instance `&quot;user_name/model&quot;`, which allows you to push to an organization you are a member of with</span>
<span class="sd">            `&quot;organization_name/model&quot;`. Will default to `user_name/output_dir_name` with *output_dir_name* being the</span>
<span class="sd">            name of `output_dir`.</span>

<span class="sd">            Will default to the name of `output_dir`.</span>
<span class="sd">        hub_strategy (`str` or [`~trainer_utils.HubStrategy`], *optional*, defaults to `&quot;every_save&quot;`):</span>
<span class="sd">            Defines the scope of what is pushed to the Hub and when. Possible values are:</span>

<span class="sd">            - `&quot;end&quot;`: push the model, its configuration, the tokenizer (if passed along to the [`Trainer`]) and a</span>
<span class="sd">              draft of a model card when the [`~Trainer.save_model`] method is called.</span>
<span class="sd">            - `&quot;every_save&quot;`: push the model, its configuration, the tokenizer (if passed along to the [`Trainer`]) and</span>
<span class="sd">              a draft of a model card each time there is a model save. The pushes are asynchronous to not block</span>
<span class="sd">              training, and in case the save are very frequent, a new push is only attempted if the previous one is</span>
<span class="sd">              finished. A last push is made with the final model at the end of training.</span>
<span class="sd">            - `&quot;checkpoint&quot;`: like `&quot;every_save&quot;` but the latest checkpoint is also pushed in a subfolder named</span>
<span class="sd">              last-checkpoint, allowing you to resume training easily with</span>
<span class="sd">              `trainer.train(resume_from_checkpoint=&quot;last-checkpoint&quot;)`.</span>
<span class="sd">            - `&quot;all_checkpoints&quot;`: like `&quot;checkpoint&quot;` but all checkpoints are pushed like they appear in the output</span>
<span class="sd">              folder (so you will get one checkpoint folder per folder in your final repository)</span>

<span class="sd">        hub_token (`str`, *optional*):</span>
<span class="sd">            The token to use to push the model to the Hub. Will default to the token in the cache folder obtained with</span>
<span class="sd">            `huggingface-cli login`.</span>
<span class="sd">        hub_private_repo (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            If True, the Hub repo will be set to private.</span>
<span class="sd">        hub_always_push (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Unless this is `True`, the `Trainer` will skip pushing a checkpoint when the previous push is not finished.</span>
<span class="sd">        recompute (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            If True, use gradient checkpointing to save memory at the expense of slower backward pass.</span>
<span class="sd">        recompute_kwargs (`dict`, *optional*, defaults to `None`):</span>
<span class="sd">            Key word arguments to be passed to the `recompute_enable` method.</span>
<span class="sd">        include_inputs_for_metrics (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not the inputs will be passed to the `compute_metrics` function. This is intended for metrics</span>
<span class="sd">            that need inputs, predictions and references for scoring calculation in Metric class.</span>
<span class="sd">        auto_find_batch_size (`bool`, *optional*, defaults to `False`)</span>
<span class="sd">            Whether to find a batch size that will fit into memory automatically through exponential decay, avoiding</span>
<span class="sd">            CUDA Out-of-Memory errors. Requires accelerate to be installed (`pip install accelerate`)</span>
<span class="sd">        full_determinism (`bool`, *optional*, defaults to `False`)</span>
<span class="sd">            If `True`, [`enable_full_determinism`] is called instead of [`set_seed`] to ensure reproducible results in</span>
<span class="sd">            distributed training. Important: this will negatively impact the performance, so only use it for debugging.</span>
<span class="sd">        ray_scope (`str`, *optional*, defaults to `&quot;last&quot;`):</span>
<span class="sd">            The scope to use when doing hyperparameter search with Ray. By default, `&quot;last&quot;` will be used. Ray will</span>
<span class="sd">            then use the last checkpoint of all trials, compare those, and select the best one. However, other options</span>
<span class="sd">            are also available. See the [Ray documentation](</span>
<span class="sd">            https://docs.ray.io/en/latest/tune/api_docs/analysis.html#ray.tune.ExperimentAnalysis.get_best_trial) for</span>
<span class="sd">            more options.</span>
<span class="sd">        ddp_timeout (`int`, *optional*, defaults to 1800):</span>
<span class="sd">            The timeout for `mindspore.communication.init` calls, used to avoid GPU socket timeouts when</span>
<span class="sd">            performing slow operations in distributed runnings.</span>
<span class="sd">        use_mps_device (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            This argument is deprecated.`mps` device will be used if it is available similar to `cuda` device.</span>
<span class="sd">        nn_compile (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            This will use the best defaults for the [`mindspore.nn.Module.compile`]</span>
<span class="sd">            You can customize the defaults with the argument `nn_compile_backend` and `nn_compile_mode` but we</span>
<span class="sd">            don&#39;t guarantee any of them will work as the support is progressively rolled in in MindSpore.</span>

<span class="sd">            This flag and the whole compile API is experimental and subject to change in future releases.</span>
<span class="sd">        nn_compile_backend (`str`, *optional*):</span>
<span class="sd">            The backend to use in `mindspore.nn.Module.compile`. If set to any value, `mindspore.nn.Module.compile` will be set to `True`.</span>

<span class="sd">            Refer to the MindSpore doc for possible values and note that they may change across MindSpore versions.</span>

<span class="sd">            This flag is experimental and subject to change in future releases.</span>
<span class="sd">        nn_compile_mode (`str`, *optional*):</span>
<span class="sd">            The mode to use in `mindspore.nn.Module.compile`. If set to any value, `mindspore.nn.Module.compile` will be set to `True`.</span>

<span class="sd">            Refer to the MindSpore doc for possible values and note that they may change across MindSpore versions.</span>

<span class="sd">            This flag is experimental and subject to change in future releases.</span>
<span class="sd">        split_batches (`bool`, *optional*):</span>
<span class="sd">            Whether or not the accelerator should split the batches yielded by the dataloaders across the devices</span>
<span class="sd">            during distributed training. If</span>

<span class="sd">            set to `True`, the actual batch size used will be the same on any kind of distributed processes, but it</span>
<span class="sd">            must be a</span>

<span class="sd">            round multiple of the number of processes you are using (such as GPUs).</span>
<span class="sd">        include_tokens_per_second (`bool`, *optional*):</span>
<span class="sd">            Whether or not to compute the number of tokens per second per device for training speed metrics.</span>

<span class="sd">            This will iterate over the entire training dataloader once beforehand,</span>

<span class="sd">            and will slow down the entire process.</span>

<span class="sd">        include_num_input_tokens_seen (`bool`, *optional*):</span>
<span class="sd">            Whether or not to track the number of input tokens seen throughout training.</span>

<span class="sd">            May be slower in distributed training as gather operations must be called.</span>

<span class="sd">        neftune_noise_alpha (`Optional[float]`):</span>
<span class="sd">            If not `None`, this will activate NEFTune noise embeddings. This can drastically improve model performance</span>
<span class="sd">            for instruction fine-tuning. Check out the [original paper](https://arxiv.org/abs/2310.05914) and the</span>
<span class="sd">            [original code](https://github.com/neelsjain/NEFTune). Support transformers `PreTrainedModel` and also</span>
<span class="sd">            `PeftModel` from peft.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The output directory where the model predictions and checkpoints will be written.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">overwrite_output_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Overwrite the content of the output directory. &quot;</span>
                <span class="s2">&quot;Use this to continue training if output_dir points to a checkpoint directory.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>

    <span class="n">do_train</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to run training.&quot;</span><span class="p">})</span>
    <span class="n">do_eval</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to run eval on the dev set.&quot;</span><span class="p">})</span>
    <span class="n">do_predict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to run predictions on the test set.&quot;</span><span class="p">})</span>
    <span class="n">evaluation_strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IntervalStrategy</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;no&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The evaluation strategy to use.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">prediction_loss_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;When performing evaluation and predictions, only returns the loss.&quot;</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="n">per_device_train_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Batch size per GPU/TPU/MPS/NPU core/CPU for training.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">per_device_eval_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Batch size per GPU/TPU/MPS/NPU core/CPU for evaluation.&quot;</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="n">gradient_accumulation_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Number of updates steps to accumulate before performing a backward/update pass.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">eval_accumulation_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Number of predictions steps to accumulate before moving the tensors to the CPU.&quot;</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="n">eval_delay</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Number of epochs or steps to wait for before the first evaluation can be performed, depending on the&quot;</span>
                <span class="s2">&quot; evaluation_strategy.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>

    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The initial learning rate for AdamW.&quot;</span><span class="p">})</span>
    <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Weight decay for AdamW if we apply some.&quot;</span><span class="p">})</span>
    <span class="n">adam_beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Beta1 for AdamW optimizer&quot;</span><span class="p">})</span>
    <span class="n">adam_beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Beta2 for AdamW optimizer&quot;</span><span class="p">})</span>
    <span class="n">adam_epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Epsilon for AdamW optimizer.&quot;</span><span class="p">})</span>
    <span class="n">max_grad_norm</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Max gradient norm.&quot;</span><span class="p">})</span>

    <span class="n">num_train_epochs</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Total number of training epochs to perform.&quot;</span><span class="p">})</span>
    <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;If &gt; 0: set total number of training steps to perform. Override num_train_epochs.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">lr_scheduler_type</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">SchedulerType</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The scheduler type to use.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">lr_scheduler_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="nb">dict</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Extra parameters for the lr_scheduler such as {&#39;num_cycles&#39;: 1} for the cosine with hard restarts&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">warmup_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Linear warmup over warmup_ratio fraction of total steps.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">warmup_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Linear warmup over warmup_steps.&quot;</span><span class="p">})</span>

    <span class="n">log_level</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;passive&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Logger log level to use on the main node. Possible choices are the log levels as strings: &#39;debug&#39;,&quot;</span>
                <span class="s2">&quot; &#39;info&#39;, &#39;warning&#39;, &#39;error&#39; and &#39;critical&#39;, plus a &#39;passive&#39; level which doesn&#39;t set anything and&quot;</span>
                <span class="s2">&quot; lets the application set the level. Defaults to &#39;passive&#39;.&quot;</span>
            <span class="p">),</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="n">trainer_log_levels</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">log_level_replica</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;warning&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Logger log level to use on replica nodes. Same choices and defaults as ``log_level``&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="n">trainer_log_levels</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">log_on_each_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;When doing a multinode distributed training, whether to log once per node or just once on the main&quot;</span>
                <span class="s2">&quot; node.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">logging_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Tensorboard log dir.&quot;</span><span class="p">})</span>
    <span class="n">logging_strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IntervalStrategy</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The logging strategy to use.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">logging_first_step</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Log the first global_step&quot;</span><span class="p">})</span>
    <span class="n">logging_steps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Log every X updates steps. Should be an integer or a float in range `[0,1)`. &quot;</span>
                <span class="s2">&quot;If smaller than 1, will be interpreted as ratio of total training steps.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">logging_nan_inf_filter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Filter nan and inf losses for logging.&quot;</span><span class="p">})</span>
    <span class="n">save_strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IntervalStrategy</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The checkpoint save strategy to use.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">save_steps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Save checkpoint every X updates steps. Should be an integer or a float in range `[0,1)`. &quot;</span>
                <span class="s2">&quot;If smaller than 1, will be interpreted as ratio of total training steps.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">save_total_limit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in&quot;</span>
                <span class="s2">&quot; `output_dir`. When `load_best_model_at_end` is enabled, the &#39;best&#39; checkpoint according to&quot;</span>
                <span class="s2">&quot; `metric_for_best_model` will always be retained in addition to the most recent ones. For example,&quot;</span>
                <span class="s2">&quot; for `save_total_limit=5` and `load_best_model_at_end=True`, the four last checkpoints will always be&quot;</span>
                <span class="s2">&quot; retained alongside the best model. When `save_total_limit=1` and `load_best_model_at_end=True`,&quot;</span>
                <span class="s2">&quot; it is possible that two checkpoints are saved: the last one and the best one (if they are different).&quot;</span>
                <span class="s2">&quot; Default is unlimited checkpoints&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">save_safetensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Use safetensors saving and loading for state dicts instead of default mindspore.load_checkpoint and mindspore.save_checkpoint.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">save_on_each_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;When doing multi-node distributed training, whether to save models and checkpoints on each node, or&quot;</span>
                <span class="s2">&quot; only on the main one&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">save_only_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;When checkpointing, whether to only save the model, or also the optimizer, scheduler &amp; rng state.&quot;</span>
                <span class="s2">&quot;Note that when this is true, you won&#39;t be able to resume training from checkpoint.&quot;</span>
                <span class="s2">&quot;This enables you to save storage by not storing the optimizer, scheduler &amp; rng state.&quot;</span>
                <span class="s2">&quot;You can only load the model using from_pretrained with this option set to True.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">use_cpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot; Whether or not to use cpu. If set to False, we will use cuda/tpu/mps/npu device if available.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Random seed that will be set at the beginning of training.&quot;</span><span class="p">})</span>
    <span class="n">data_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Random seed to be used with data samplers.&quot;</span><span class="p">})</span>
    <span class="n">jit_mode_eval</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether or not to use MindSpore jit trace for inference&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">bf16</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Whether to use bf16 (mixed) precision instead of 32-bit. Requires Ampere or higher NVIDIA&quot;</span>
                <span class="s2">&quot; architecture or using CPU (use_cpu) or Ascend NPU. This is an experimental API and it may change.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">fp16</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use fp16 (mixed) precision instead of 32-bit&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">fp16_opt_level</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;O1&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;For fp16: Apex AMP optimization level selected in [&#39;O0&#39;, &#39;O1&#39;, &#39;O2&#39;, and &#39;O3&#39;]. &quot;</span>
                <span class="s2">&quot;See details at https://nvidia.github.io/apex/amp.html&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">bf16_full_eval</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Whether to use full bfloat16 evaluation instead of 32-bit. This is an experimental API and it may&quot;</span>
                <span class="s2">&quot; change.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">fp16_full_eval</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use full float16 evaluation instead of 32-bit&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;For distributed training: local_rank&quot;</span><span class="p">})</span>
    <span class="n">ddp_backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The backend to be used for distributed training&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span> <span class="s2">&quot;gloo&quot;</span><span class="p">,</span> <span class="s2">&quot;mpi&quot;</span><span class="p">,</span> <span class="s2">&quot;ccl&quot;</span><span class="p">,</span> <span class="s2">&quot;hccl&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span>

    <span class="n">dataset_drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Drop the last incomplete batch if it is not divisible by the batch size.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">eval_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Run an evaluation every X steps. Should be an integer or a float in range `[0,1)`. &quot;</span>
                <span class="s2">&quot;If smaller than 1, will be interpreted as ratio of total training steps.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">dataset_num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Number of subprocesses to use for data loading (MindSpore only). 0 means that the data will be loaded&quot;</span>
                <span class="s2">&quot; in the main process.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">dataset_prefetch_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Number of batches loaded in advance by each worker. &quot;</span>
                <span class="s2">&quot;2 means there will be a total of 2 * num_workers batches prefetched across all workers. &quot;</span>
                <span class="s2">&quot;Default is unset&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">past_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;If &gt;=0, uses the corresponding part of the output as the past state for next step.&quot;</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="n">run_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;An optional descriptor for the run. Notably used for wandb logging.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether or not to disable the tqdm progress bars.&quot;</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="n">remove_unused_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Remove columns not required by the model when using an nlp.Dataset.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">label_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The list of keys in your dictionary of inputs that correspond to the labels.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">load_best_model_at_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Whether or not to load the best model found during training at the end of training. When this option&quot;</span>
                <span class="s2">&quot; is enabled, the best checkpoint will always be saved. See `save_total_limit` for more.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">metric_for_best_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The metric to use to compare two different models.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">greater_is_better</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether the `metric_for_best_model` should be maximized or not.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">ignore_data_skip</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;When resuming training, whether or not to skip the first epochs and batches to get to the same&quot;</span>
                <span class="s2">&quot; training data.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">label_smoothing_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The label smoothing epsilon to apply (zero means no label smoothing).&quot;</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="n">default_optim</span> <span class="o">=</span> <span class="s2">&quot;adamw&quot;</span>
    <span class="n">optim</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">OptimizerNames</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="n">default_optim</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The optimizer to use.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">optim_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Optional arguments to supply to optimizer.&quot;</span><span class="p">})</span>
    <span class="n">group_by_length</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether or not to group samples of roughly the same length together when batching.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">length_column_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;length&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Column name with precomputed lengths to use when grouping by length.&quot;</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="n">resume_from_checkpoint</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The path to a folder with a valid checkpoint for your model.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">recompute</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;If True, use gradient checkpointing to save memory at the expense of slower backward pass.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">recompute_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Gradient checkpointing key word arguments such as `use_reentrant`. Will be passed to `mindspore.nn.Module.recompute` through `model.recompute_enable`.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">include_inputs_for_metrics</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether or not the inputs will be passed to the `compute_metrics` function.&quot;</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="n">mp_parameters</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Used by the SageMaker launcher to send mp-specific args. Ignored in Trainer&quot;</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="n">auto_find_batch_size</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Whether to automatically decrease the batch size in half and rerun the training loop again each time&quot;</span>
                <span class="s2">&quot; a CUDA Out-of-Memory was reached&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">full_determinism</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Whether to call enable_full_determinism instead of set_seed for reproducibility in distributed&quot;</span>
                <span class="s2">&quot; training. Important: this will negatively impact the performance, so only use it for debugging.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>

    <span class="n">ddp_timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1800</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Overrides the default timeout for distributed training (value should be given in seconds).&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>

    <span class="n">include_tokens_per_second</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;If set to `True`, the speed metrics will include `tgs` (tokens per second per device).&quot;</span><span class="p">},</span>
    <span class="p">)</span>

    <span class="n">include_num_input_tokens_seen</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;If set to `True`, will track the number of input tokens seen throughout training. (May be slower in distributed training)&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>

    <span class="n">neftune_noise_alpha</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Activates neftune noise embeddings into the model.&quot;</span>
                    <span class="s2">&quot;NEFTune has been proven to drastically improve model performances for instrcution fine-tuning. &quot;</span>
                    <span class="s2">&quot;Check out the original paper here: https://arxiv.org/abs/2310.05914 and the original code here: https://github.com/neelsjain/NEFTune. &quot;</span>
                    <span class="s2">&quot;Only supported for `PreTrainedModel` and `PeftModel` classes.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method initializes the TrainingArguments class instance after its creation.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: An instance of the TrainingArguments class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None. This method does not return any value.</span>

<span class="sd">        Raises:</span>
<span class="sd">            - ValueError: If the evaluation strategy requires non-zero evaluation steps or logging steps are zero.</span>
<span class="sd">            - FutureWarning: If using `EvaluationStrategy` for `evaluation_strategy` is deprecated.</span>
<span class="sd">            - ValueError: If the logging strategy requires non-zero logging steps or steps are not an integer.</span>
<span class="sd">            - ValueError: If the saving steps are not an integer when required.</span>
<span class="sd">            - ValueError: If `load_best_model_at_end` is enabled but save and evaluation strategies do not match.</span>
<span class="sd">            - ValueError: If the saving steps are not a multiple of evaluation steps for `load_best_model_at_end`.</span>
<span class="sd">            - ValueError: If `save_safetensors` is enabled but safetensors are not installed.</span>
<span class="sd">            - ValueError: If both `fp16` and `bf16` are set to True.</span>
<span class="sd">            - ValueError: If both `fp16_full_eval` and `bf16_full_eval` are set to True.</span>
<span class="sd">            - ValueError: If lr_scheduler_type is reduce_lr_on_plateau but eval strategy or mindspore is not available.</span>
<span class="sd">            - ValueError: If warmup_ratio is not in the range [0,1] or if both warmup_ratio and warmup_steps are provided.</span>
<span class="sd">            - ValueError: If dataset_prefetch_factor is set without dataset_num_workers &gt; 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># expand paths, if not os.makedirs(&quot;~/bar&quot;) will make directory</span>
        <span class="c1"># in the current directory instead of the actual home</span>
        <span class="c1"># see https://github.com/huggingface/transformers/issues/10628</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">default_logdir</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">getEffectiveLevel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">logging</span><span class="o">.</span><span class="n">WARN</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="p">,</span> <span class="n">EvaluationStrategy</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;using `EvaluationStrategy` for `evaluation_strategy` is deprecated and will be removed in version 5&quot;</span>
                <span class="s2">&quot; of 🤗 Transformers. Use `IntervalStrategy` instead&quot;</span><span class="p">,</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Go back to the underlying string or we won&#39;t be able to instantiate `IntervalStrategy` on it.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="o">.</span><span class="n">value</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="n">SchedulerType</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">!=</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">NO</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># eval_steps has to be defined and non-zero, fallbacks to logging_steps if the latter is non-zero</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using `logging_steps` to initialize `eval_steps` to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;evaluation strategy </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="si">}</span><span class="s2"> requires either non-zero --eval_steps or&quot;</span>
                    <span class="s2">&quot; --logging_steps&quot;</span>
                <span class="p">)</span>

        <span class="c1"># logging_steps must be non-zero for logging_strategy that is other than &#39;no&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;logging strategy </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span><span class="si">}</span><span class="s2"> requires non-zero --logging_steps&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">!=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--logging_steps must be an integer if bigger than 1: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">!=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--eval_steps must be an integer if bigger than 1: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">!=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--save_steps must be an integer if bigger than 1: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="p">)</span>

        <span class="c1"># Sanity checks for load_best_model_at_end: we require save and eval strategies to be compatible.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_best_model_at_end</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;--load_best_model_at_end requires the save and eval strategy to match, but found</span><span class="se">\n</span><span class="s2">- Evaluation &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;strategy: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="si">}</span><span class="se">\n</span><span class="s2">- Save strategy: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="s2">&quot;--load_best_model_at_end requires the saving steps to be a multiple of the evaluation &quot;</span>
                            <span class="s2">&quot;steps, which cannot get guaranteed when mixing ratio and absolute steps for save_steps &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="si">}</span><span class="s2"> and eval_steps </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span>
                    <span class="c1"># Work around floating point precision issues</span>
                    <span class="n">LARGE_MULTIPLIER</span> <span class="o">=</span> <span class="mi">1_000_000</span>
                    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">*</span> <span class="n">LARGE_MULTIPLIER</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">*</span> <span class="n">LARGE_MULTIPLIER</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="s2">&quot;--load_best_model_at_end requires the saving steps to be a multiple of the evaluation &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;steps, but found </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="si">}</span><span class="s2">, which is not a multiple of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;--load_best_model_at_end requires the saving steps to be a round multiple of the evaluation &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;steps, but found </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="si">}</span><span class="s2">, which is not a round multiple of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

        <span class="n">safetensors_available</span> <span class="o">=</span> <span class="n">is_safetensors_available</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_safetensors</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">safetensors_available</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--save_safetensors=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_safetensors</span><span class="si">}</span><span class="s2"> requires safetensors to be installed!&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_safetensors</span> <span class="ow">and</span> <span class="n">safetensors_available</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Found safetensors installation, but --save_safetensors=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_safetensors</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Safetensors should be a preferred weights saving format due to security and performance reasons. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;If your model cannot be saved by safetensors please feel free to open an issue at &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;https://github.com/huggingface/safetensors!&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_best_model_at_end</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span> <span class="o">==</span> <span class="n">SchedulerType</span><span class="o">.</span><span class="n">REDUCE_ON_PLATEAU</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_for_best_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="s2">&quot;loss&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">greater_is_better</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_for_best_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_for_best_model</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;eval_loss&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">run_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp16</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bf16</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At most one of fp16 and bf16 can be True, but not both&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp16_full_eval</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bf16_full_eval</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At most one of fp16 and bf16 can be True for full eval, but not both&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span> <span class="o">==</span> <span class="n">SchedulerType</span><span class="o">.</span><span class="n">REDUCE_ON_PLATEAU</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">NO</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;lr_scheduler_type reduce_lr_on_plateau requires an eval strategy&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_mindspore_available</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;lr_scheduler_type reduce_lr_on_plateau requires mindspore&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">OptimizerNames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="p">)</span>

        <span class="c1"># if training args is specified, it will override the one specified in the accelerate config</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp16</span><span class="p">:</span>
            <span class="n">mixed_precision_dtype</span> <span class="o">=</span> <span class="s2">&quot;fp16&quot;</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">bf16</span><span class="p">:</span>
            <span class="n">mixed_precision_dtype</span> <span class="o">=</span> <span class="s2">&quot;bf16&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;warmup_ratio must lie in range [0,1]&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Both warmup_ratio and warmup_steps given, warmup_steps will override any effect of warmup_ratio&quot;</span>
                <span class="s2">&quot; during training&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_num_workers</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_prefetch_factor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;--dataset_prefetch_factor can only be set when data is loaded in a different process, i.e.&quot;</span>
                <span class="s2">&quot; when --dataset_num_workers &gt; 1.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method returns a string representation of the TrainingArguments object.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (TrainingArguments): The instance of the TrainingArguments class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None: This method returns a string representation of the TrainingArguments object.</span>

<span class="sd">        Raises:</span>
<span class="sd">            No specific exceptions are documented to be raised by this method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">self_as_dict</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># Remove deprecated arguments. That code should be removed once</span>
        <span class="c1"># those deprecated arguments are removed from TrainingArguments. (TODO: v5)</span>
        <span class="k">del</span> <span class="n">self_as_dict</span><span class="p">[</span><span class="s2">&quot;per_gpu_train_batch_size&quot;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">self_as_dict</span><span class="p">[</span><span class="s2">&quot;per_gpu_eval_batch_size&quot;</span><span class="p">]</span>

        <span class="n">self_as_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;&lt;</span><span class="si">{</span><span class="n">k</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">&gt;&quot;</span> <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_token&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">self_as_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="n">attrs_as_str</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">self_as_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attrs_as_str</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span>

    <span class="fm">__repr__</span> <span class="o">=</span> <span class="fm">__str__</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the number of devices used for training.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (TrainingArguments): The object instance.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None: This method does not return a value.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None: This method does not raise any exceptions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">train_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The actual batch size for training (may differ from `per_gpu_train_batch_size` in distributed training).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">per_device_train_batch_size</span>
        <span class="n">train_batch_size</span> <span class="o">=</span> <span class="n">per_device_batch_size</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">train_batch_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">eval_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The actual batch size for evaluation (may differ from `per_gpu_eval_batch_size` in distributed training).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">per_device_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span>
        <span class="n">eval_batch_size</span> <span class="o">=</span> <span class="n">per_device_batch_size</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eval_batch_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">ddp_timeout_delta</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">timedelta</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The actual timeout for mindspore.communication.init since it expects a timedelta variable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ddp_timeout</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">parallel_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The current mode used for parallelism if multiple GPUs/TPU cores are available. One of:</span>

<span class="sd">        - `ParallelMode.NOT_PARALLEL`: no parallelism (CPU or one GPU).</span>
<span class="sd">        - `ParallelMode.NOT_DISTRIBUTED`: several GPUs in one single process (uses `nn.DataParallel`).</span>
<span class="sd">        - `ParallelMode.DISTRIBUTED`: several GPUs, each having its own process (uses</span>
<span class="sd">          `nn.DistributedDataParallel`).</span>
<span class="sd">        - `ParallelMode.TPU`: several TPU cores.</span>
<span class="sd">        &quot;&quot;&quot;</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">world_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The number of processes used in parallel.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">process_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The index of the current process used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">local_process_index</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The index of the local process used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">should_log</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Whether or not the current process should produce log.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_on_each_node</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_process_index</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_index</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">should_save</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Whether or not the current process should write to disk, e.g., to save models and checkpoints.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_on_each_node</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_process_index</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_index</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">get_process_log_level</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the log level to be used depending on whether this process is the main process of node 0, main process</span>
<span class="sd">        of node non-0, or a non-main process.</span>

<span class="sd">        For the main process the log level defaults to the logging level set (`logging.WARNING` if you didn&#39;t do</span>
<span class="sd">        anything) unless overridden by `log_level` argument.</span>

<span class="sd">        For the replica processes the log level defaults to `logging.WARNING` unless overridden by `log_level_replica`</span>
<span class="sd">        argument.</span>

<span class="sd">        The choice between the main and replica process settings is made according to the return value of `should_log`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># convert to int</span>
        <span class="n">log_level</span> <span class="o">=</span> <span class="n">trainer_log_levels</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">log_level</span><span class="p">]</span>
        <span class="n">log_level_replica</span> <span class="o">=</span> <span class="n">trainer_log_levels</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">log_level_replica</span><span class="p">]</span>

        <span class="n">log_level_main_node</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_verbosity</span><span class="p">()</span> <span class="k">if</span> <span class="n">log_level</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">log_level</span>
        <span class="n">log_level_replica_node</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_verbosity</span><span class="p">()</span> <span class="k">if</span> <span class="n">log_level_replica</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">log_level_replica</span>
        <span class="k">return</span> <span class="n">log_level_main_node</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">should_log</span> <span class="k">else</span> <span class="n">log_level_replica_node</span>

    <span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
    <span class="k">def</span> <span class="nf">main_process_first</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;work&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A context manager for MindSpore distributed environment where on needs to do something on the main process, while</span>
<span class="sd">        blocking replicas, and when it&#39;s finished releasing the replicas.</span>

<span class="sd">        One such use is for `datasets`&#39;s `map` feature which to be efficient should be run once on the main process,</span>
<span class="sd">        which upon completion saves a cached version of results and which then automatically gets loaded by the</span>
<span class="sd">        replicas.</span>

<span class="sd">        Args:</span>
<span class="sd">            local (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                if `True` first means process of rank 0 of each node if `False` first means process of rank 0 of node</span>
<span class="sd">                rank 0 In multi-node environment with a shared filesystem you most likely will want to use</span>
<span class="sd">                `local=False` so that only the main process of the first node will do the processing. If however, the</span>
<span class="sd">                filesystem is not shared, then the main process of each node will need to do the processing, which is</span>
<span class="sd">                the default behavior.</span>
<span class="sd">            desc (`str`, *optional*, defaults to `&quot;work&quot;`):</span>
<span class="sd">                a work description to be used in debug logs</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_mindspore_available</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">main_process_desc</span> <span class="o">=</span> <span class="s2">&quot;main local process&quot;</span> <span class="k">if</span> <span class="n">local</span> <span class="k">else</span> <span class="s2">&quot;main process&quot;</span>
            <span class="n">is_main_process</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">communication</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">is_main_process</span><span class="p">:</span>
                    <span class="c1"># tell all replicas to wait</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">process_index</span><span class="si">}</span><span class="s2">: waiting for the </span><span class="si">{</span><span class="n">main_process_desc</span><span class="si">}</span><span class="s2"> to perform </span><span class="si">{</span><span class="n">desc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="k">yield</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">is_main_process</span><span class="p">:</span>
                    <span class="c1"># the wait is over</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">process_index</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">main_process_desc</span><span class="si">}</span><span class="s2"> completed </span><span class="si">{</span><span class="n">desc</span><span class="si">}</span><span class="s2">, releasing all replicas&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">yield</span>

    <span class="k">def</span> <span class="nf">get_warmup_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get number of steps used for a linear warmup.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_training_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">warmup_steps</span>

    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates</span>
<span class="sd">        the token values by removing their value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># filter out fields that are defined as field(init=False)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="k">if</span> <span class="n">field</span><span class="o">.</span><span class="n">init</span><span class="p">}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
                <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">value</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Enum</span><span class="p">):</span>
                <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_token&quot;</span><span class="p">):</span>
                <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&lt;</span><span class="si">{</span><span class="n">k</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">&gt;&quot;</span>
        <span class="k">return</span> <span class="n">d</span>

    <span class="k">def</span> <span class="nf">to_json_string</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Serializes this instance to a JSON string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_sanitized_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sanitized serialization to use with TensorBoard’s hparams</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">d</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size</span><span class="p">,</span> <span class="s2">&quot;eval_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_batch_size</span><span class="p">}}</span>

        <span class="n">valid_types</span> <span class="o">=</span> <span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">is_mindspore_available</span><span class="p">():</span>
            <span class="n">valid_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">valid_types</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="c1"># The following methods are there to simplify the instantiation of `TrainingArguments`</span>
    <span class="k">def</span> <span class="nf">set_training</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-5</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
        <span class="n">recompute</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that regroups all basic arguments linked to the training.</span>

<span class="sd">        &lt;Tip&gt;</span>

<span class="sd">        Calling this method will automatically set `self.do_train` to `True`.</span>

<span class="sd">        &lt;/Tip&gt;</span>

<span class="sd">        Args:</span>
<span class="sd">            learning_rate (`float`, *optional*, defaults to 5e-5):</span>
<span class="sd">                The initial learning rate for the optimizer.</span>
<span class="sd">            batch_size (`int` *optional*, defaults to 8):</span>
<span class="sd">                The batch size per device (GPU/TPU core/CPU...) used for training.</span>
<span class="sd">            weight_decay (`float`, *optional*, defaults to 0):</span>
<span class="sd">                The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in the</span>
<span class="sd">                optimizer.</span>
<span class="sd">            num_train_epochs(`float`, *optional*, defaults to 3.0):</span>
<span class="sd">                Total number of training epochs to perform (if not an integer, will perform the decimal part percents</span>
<span class="sd">                of the last epoch before stopping training).</span>
<span class="sd">            max_steps (`int`, *optional*, defaults to -1):</span>
<span class="sd">                If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.</span>
<span class="sd">                For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until</span>
<span class="sd">                `max_steps` is reached.</span>
<span class="sd">            gradient_accumulation_steps (`int`, *optional*, defaults to 1):</span>
<span class="sd">                Number of updates steps to accumulate the gradients for, before performing a backward/update pass.</span>

<span class="sd">                &lt;Tip warning={true}&gt;</span>

<span class="sd">                When using gradient accumulation, one step is counted as one step with backward pass. Therefore,</span>
<span class="sd">                logging, evaluation, save will be conducted every `gradient_accumulation_steps * xxx_step` training</span>
<span class="sd">                examples.</span>

<span class="sd">                &lt;/Tip&gt;</span>

<span class="sd">            seed (`int`, *optional*, defaults to 42):</span>
<span class="sd">                Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use</span>
<span class="sd">                the [`~Trainer.model_init`] function to instantiate the model if it has some randomly initialized</span>
<span class="sd">                parameters.</span>
<span class="sd">            recompute (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                If True, use gradient checkpointing to save memory at the expense of slower backward pass.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">        &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">        &gt;&gt;&gt; args = args.set_training(learning_rate=1e-4, batch_size=32)</span>
<span class="sd">        &gt;&gt;&gt; args.learning_rate</span>
<span class="sd">        1e-4</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_train</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">=</span> <span class="n">num_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="n">gradient_accumulation_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recompute</span> <span class="o">=</span> <span class="n">recompute</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">IntervalStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">accumulation_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">delay</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">loss_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">jit_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that regroups all arguments linked to evaluation.</span>

<span class="sd">        Args:</span>
<span class="sd">            strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;no&quot;`):</span>
<span class="sd">                The evaluation strategy to adopt during training. Possible values are:</span>

<span class="sd">                    - `&quot;no&quot;`: No evaluation is done during training.</span>
<span class="sd">                    - `&quot;steps&quot;`: Evaluation is done (and logged) every `steps`.</span>
<span class="sd">                    - `&quot;epoch&quot;`: Evaluation is done at the end of each epoch.</span>

<span class="sd">                Setting a `strategy` different from `&quot;no&quot;` will set `self.do_eval` to `True`.</span>
<span class="sd">            steps (`int`, *optional*, defaults to 500):</span>
<span class="sd">                Number of update steps between two evaluations if `strategy=&quot;steps&quot;`.</span>
<span class="sd">            batch_size (`int` *optional*, defaults to 8):</span>
<span class="sd">                The batch size per device (GPU/TPU core/CPU...) used for evaluation.</span>
<span class="sd">            accumulation_steps (`int`, *optional*):</span>
<span class="sd">                Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU.</span>
<span class="sd">                If left unset, the whole predictions are accumulated on GPU/TPU before being moved to the CPU (faster</span>
<span class="sd">                but requires more memory).</span>
<span class="sd">            delay (`float`, *optional*):</span>
<span class="sd">                Number of epochs or steps to wait for before the first evaluation can be performed, depending on the</span>
<span class="sd">                evaluation_strategy.</span>
<span class="sd">            loss_only (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Ignores all outputs except the loss.</span>
<span class="sd">            jit_mode (`bool`, *optional*):</span>
<span class="sd">                Whether or not to use MindSpore jit trace for inference.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">        &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">        &gt;&gt;&gt; args = args.set_evaluate(strategy=&quot;steps&quot;, steps=100)</span>
<span class="sd">        &gt;&gt;&gt; args.eval_steps</span>
<span class="sd">        100</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Setting `strategy` as &#39;steps&#39; requires a positive value for `steps`.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">!=</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">NO</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">=</span> <span class="n">steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_accumulation_steps</span> <span class="o">=</span> <span class="n">accumulation_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_delay</span> <span class="o">=</span> <span class="n">delay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prediction_loss_only</span> <span class="o">=</span> <span class="n">loss_only</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">jit_mode_eval</span> <span class="o">=</span> <span class="n">jit_mode</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_testing</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">loss_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">jit_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that regroups all basic arguments linked to testing on a held-out dataset.</span>

<span class="sd">        &lt;Tip&gt;</span>

<span class="sd">        Calling this method will automatically set `self.do_predict` to `True`.</span>

<span class="sd">        &lt;/Tip&gt;</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size (`int` *optional*, defaults to 8):</span>
<span class="sd">                The batch size per device (GPU/TPU core/CPU...) used for testing.</span>
<span class="sd">            loss_only (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Ignores all outputs except the loss.</span>
<span class="sd">            jit_mode (`bool`, *optional*):</span>
<span class="sd">                Whether or not to use MindSpore jit trace for inference.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">        &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">        &gt;&gt;&gt; args = args.set_testing(batch_size=32)</span>
<span class="sd">        &gt;&gt;&gt; args.per_device_eval_batch_size</span>
<span class="sd">        32</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_predict</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prediction_loss_only</span> <span class="o">=</span> <span class="n">loss_only</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">jit_mode_eval</span> <span class="o">=</span> <span class="n">jit_mode</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_save</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">IntervalStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
        <span class="n">total_limit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">on_each_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that regroups all arguments linked to checkpoint saving.</span>

<span class="sd">        Args:</span>
<span class="sd">            strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;steps&quot;`):</span>
<span class="sd">                The checkpoint save strategy to adopt during training. Possible values are:</span>

<span class="sd">                    - `&quot;no&quot;`: No save is done during training.</span>
<span class="sd">                    - `&quot;epoch&quot;`: Save is done at the end of each epoch.</span>
<span class="sd">                    - `&quot;steps&quot;`: Save is done every `save_steps`.</span>

<span class="sd">            steps (`int`, *optional*, defaults to 500):</span>
<span class="sd">                Number of updates steps before two checkpoint saves if `strategy=&quot;steps&quot;`.</span>
<span class="sd">            total_limit (`int`, *optional*):</span>
<span class="sd">                If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in</span>
<span class="sd">                `output_dir`.</span>
<span class="sd">            on_each_node (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                When doing multi-node distributed training, whether to save models and checkpoints on each node, or</span>
<span class="sd">                only on the main one.</span>

<span class="sd">                This should not be activated when the different nodes use the same storage as the files will be saved</span>
<span class="sd">                with the same names for each node.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">        &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">        &gt;&gt;&gt; args = args.set_save(strategy=&quot;steps&quot;, steps=100)</span>
<span class="sd">        &gt;&gt;&gt; args.save_steps</span>
<span class="sd">        100</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Setting `strategy` as &#39;steps&#39; requires a positive value for `steps`.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">=</span> <span class="n">steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_total_limit</span> <span class="o">=</span> <span class="n">total_limit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_on_each_node</span> <span class="o">=</span> <span class="n">on_each_node</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_logging</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">IntervalStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
        <span class="n">report_to</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
        <span class="n">level</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;passive&quot;</span><span class="p">,</span>
        <span class="n">first_step</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">nan_inf_filter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">on_each_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">replica_level</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;passive&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that regroups all arguments linked to logging.</span>

<span class="sd">        Args:</span>
<span class="sd">            strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;steps&quot;`):</span>
<span class="sd">                The logging strategy to adopt during training. Possible values are:</span>

<span class="sd">                    - `&quot;no&quot;`: No logging is done during training.</span>
<span class="sd">                    - `&quot;epoch&quot;`: Logging is done at the end of each epoch.</span>
<span class="sd">                    - `&quot;steps&quot;`: Logging is done every `logging_steps`.</span>

<span class="sd">            steps (`int`, *optional*, defaults to 500):</span>
<span class="sd">                Number of update steps between two logs if `strategy=&quot;steps&quot;`.</span>
<span class="sd">            level (`str`, *optional*, defaults to `&quot;passive&quot;`):</span>
<span class="sd">                Logger log level to use on the main process. Possible choices are the log levels as strings: `&quot;debug&quot;`,</span>
<span class="sd">                `&quot;info&quot;`, `&quot;warning&quot;`, `&quot;error&quot;` and `&quot;critical&quot;`, plus a `&quot;passive&quot;` level which doesn&#39;t set anything</span>
<span class="sd">                and lets the application set the level.</span>
<span class="sd">            report_to (`str` or `List[str]`, *optional*, defaults to `&quot;all&quot;`):</span>
<span class="sd">                The list of integrations to report the results and logs to. Supported platforms are `&quot;azure_ml&quot;`,</span>
<span class="sd">                `&quot;clearml&quot;`, `&quot;codecarbon&quot;`, `&quot;comet_ml&quot;`, `&quot;dagshub&quot;`, `&quot;dvclive&quot;`, `&quot;flyte&quot;`, `&quot;mlflow&quot;`,</span>
<span class="sd">                `&quot;neptune&quot;`, `&quot;tensorboard&quot;`, and `&quot;wandb&quot;`. Use `&quot;all&quot;` to report to all integrations installed,</span>
<span class="sd">                `&quot;none&quot;` for no integrations.</span>
<span class="sd">            first_step (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether to log and evaluate the first `global_step` or not.</span>
<span class="sd">            nan_inf_filter (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                Whether to filter `nan` and `inf` losses for logging. If set to `True` the loss of every step that is</span>
<span class="sd">                `nan` or `inf` is filtered and the average loss of the current logging window is taken instead.</span>

<span class="sd">                &lt;Tip&gt;</span>

<span class="sd">                `nan_inf_filter` only influences the logging of loss values, it does not change the behavior the</span>
<span class="sd">                gradient is computed or applied to the model.</span>

<span class="sd">                &lt;/Tip&gt;</span>

<span class="sd">            on_each_node (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                In multinode distributed training, whether to log using `log_level` once per node, or only on the main</span>
<span class="sd">                node.</span>
<span class="sd">            replica_level (`str`, *optional*, defaults to `&quot;passive&quot;`):</span>
<span class="sd">                Logger log level to use on replicas. Same choices as `log_level`</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">        &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">        &gt;&gt;&gt; args = args.set_logging(strategy=&quot;steps&quot;, steps=100)</span>
<span class="sd">        &gt;&gt;&gt; args.logging_steps</span>
<span class="sd">        100</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Setting `strategy` as &#39;steps&#39; requires a positive value for `steps`.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">=</span> <span class="n">steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report_to</span> <span class="o">=</span> <span class="n">report_to</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_level</span> <span class="o">=</span> <span class="n">level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_first_step</span> <span class="o">=</span> <span class="n">first_step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_nan_inf_filter</span> <span class="o">=</span> <span class="n">nan_inf_filter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_on_each_node</span> <span class="o">=</span> <span class="n">on_each_node</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_level_replica</span> <span class="o">=</span> <span class="n">replica_level</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_optimizer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">OptimizerNames</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;adamw_torch&quot;</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-5</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>
        <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that regroups all arguments linked to the optimizer and its hyperparameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (`str` or [`training_args.OptimizerNames`], *optional*, defaults to `&quot;adamw&quot;`):</span>
<span class="sd">                The optimizer to use: `&quot;adamw&quot;`, `&quot;sgd&quot;`.</span>
<span class="sd">            learning_rate (`float`, *optional*, defaults to 5e-5):</span>
<span class="sd">                The initial learning rate.</span>
<span class="sd">            weight_decay (`float`, *optional*, defaults to 0):</span>
<span class="sd">                The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights.</span>
<span class="sd">            beta1 (`float`, *optional*, defaults to 0.9):</span>
<span class="sd">                The beta1 hyperparameter for the adam optimizer or its variants.</span>
<span class="sd">            beta2 (`float`, *optional*, defaults to 0.999):</span>
<span class="sd">                The beta2 hyperparameter for the adam optimizer or its variants.</span>
<span class="sd">            epsilon (`float`, *optional*, defaults to 1e-8):</span>
<span class="sd">                The epsilon hyperparameter for the adam optimizer or its variants.</span>
<span class="sd">            args (`str`, *optional*):</span>
<span class="sd">                Optional arguments that are supplied to AnyPrecisionAdamW (only useful when</span>
<span class="sd">                `optim=&quot;adamw_anyprecision&quot;`).</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">        &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">        &gt;&gt;&gt; args = args.set_optimizer(name=&quot;adamw&quot;, beta1=0.8)</span>
<span class="sd">        &gt;&gt;&gt; args.optim</span>
<span class="sd">        &#39;adamw&#39;</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">OptimizerNames</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adam_beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adam_beta2</span> <span class="o">=</span> <span class="n">beta2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adam_epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim_args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_lr_scheduler</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">SchedulerType</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">3.0</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">warmup_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">warmup_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that regroups all arguments linked to the learning rate scheduler and its hyperparameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (`str` or [`SchedulerType`], *optional*, defaults to `&quot;linear&quot;`):</span>
<span class="sd">                The scheduler type to use. See the documentation of [`SchedulerType`] for all possible values.</span>
<span class="sd">            num_epochs(`float`, *optional*, defaults to 3.0):</span>
<span class="sd">                Total number of training epochs to perform (if not an integer, will perform the decimal part percents</span>
<span class="sd">                of the last epoch before stopping training).</span>
<span class="sd">            max_steps (`int`, *optional*, defaults to -1):</span>
<span class="sd">                If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.</span>
<span class="sd">                For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until</span>
<span class="sd">                `max_steps` is reached.</span>
<span class="sd">            warmup_ratio (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">                Ratio of total training steps used for a linear warmup from 0 to `learning_rate`.</span>
<span class="sd">            warmup_steps (`int`, *optional*, defaults to 0):</span>
<span class="sd">                Number of steps used for a linear warmup from 0 to `learning_rate`. Overrides any effect of</span>
<span class="sd">                `warmup_ratio`.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">        &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">        &gt;&gt;&gt; args = args.set_lr_scheduler(name=&quot;cosine&quot;, warmup_ratio=0.05)</span>
<span class="sd">        &gt;&gt;&gt; args.warmup_ratio</span>
<span class="sd">        0.05</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="n">SchedulerType</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">=</span> <span class="n">num_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="n">warmup_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">set_dataloader</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">eval_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">persistent_workers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">prefetch_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">auto_find_batch_size</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">ignore_data_skip</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">sampler_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method that regroups all arguments linked to the dataloaders creation.</span>

<span class="sd">        Args:</span>
<span class="sd">            drop_last (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch</span>
<span class="sd">                size) or not.</span>
<span class="sd">            num_workers (`int`, *optional*, defaults to 0):</span>
<span class="sd">                Number of subprocesses to use for data loading (MindSpore only). 0 means that the data will be loaded in</span>
<span class="sd">                the main process.</span>
<span class="sd">            pin_memory (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                Whether you want to pin memory in data loaders or not. Will default to `True`.</span>
<span class="sd">            persistent_workers (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                If True, the data loader will not shut down the worker processes after a dataset has been consumed</span>
<span class="sd">                once. This allows to maintain the workers Dataset instances alive. Can potentially speed up training,</span>
<span class="sd">                but will increase RAM usage. Will default to `False`.</span>
<span class="sd">            prefetch_factor (`int`, *optional*):</span>
<span class="sd">                Number of batches loaded in advance by each worker.</span>
<span class="sd">                2 means there will be a total of 2 * num_workers batches prefetched across all workers.</span>
<span class="sd">            auto_find_batch_size (`bool`, *optional*, defaults to `False`)</span>
<span class="sd">                Whether to find a batch size that will fit into memory automatically through exponential decay,</span>
<span class="sd">                avoiding CUDA Out-of-Memory errors. Requires accelerate to be installed (`pip install accelerate`)</span>
<span class="sd">            ignore_data_skip (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                When resuming training, whether or not to skip the epochs and batches to get the data loading at the</span>
<span class="sd">                same stage as in the previous training. If set to `True`, the training will begin faster (as that</span>
<span class="sd">                skipping step can take a long time) but will not yield the same results as the interrupted training</span>
<span class="sd">                would have.</span>
<span class="sd">            sampler_seed (`int`, *optional*):</span>
<span class="sd">                Random seed to be used with data samplers. If not set, random generators for data sampling will use the</span>
<span class="sd">                same seed as `self.seed`. This can be used to ensure reproducibility of data sampling, independent of</span>
<span class="sd">                the model seed.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">        &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">        &gt;&gt;&gt; args = args.set_dataloader(train_batch_size=16, eval_batch_size=64)</span>
<span class="sd">        &gt;&gt;&gt; args.per_device_train_batch_size</span>
<span class="sd">        16</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="n">train_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="n">eval_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_drop_last</span> <span class="o">=</span> <span class="n">drop_last</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_persistent_workers</span> <span class="o">=</span> <span class="n">persistent_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_prefetch_factor</span> <span class="o">=</span> <span class="n">prefetch_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">auto_find_batch_size</span> <span class="o">=</span> <span class="n">auto_find_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_data_skip</span> <span class="o">=</span> <span class="n">ignore_data_skip</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_seed</span> <span class="o">=</span> <span class="n">sampler_seed</span>
        <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.ddp_timeout_delta" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">ddp_timeout_delta</span><span class="p">:</span> <span class="n">timedelta</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.ddp_timeout_delta" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The actual timeout for mindspore.communication.init since it expects a timedelta variable.</p>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.eval_batch_size" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">eval_batch_size</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.eval_batch_size" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The actual batch size for evaluation (may differ from <code>per_gpu_eval_batch_size</code> in distributed training).</p>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.local_process_index" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">local_process_index</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.local_process_index" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The index of the local process used.</p>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.n_device" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">n_device</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.n_device" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Returns the number of devices used for training.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The object instance.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.engine.train_args.base.TrainingArguments" href="#mindnlp.engine.train_args.TrainingArguments">TrainingArguments</a></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>None</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>This method does not return a value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>None</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>This method does not raise any exceptions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.parallel_mode" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">parallel_mode</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.parallel_mode" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The current mode used for parallelism if multiple GPUs/TPU cores are available. One of:</p>
<ul>
<li><code>ParallelMode.NOT_PARALLEL</code>: no parallelism (CPU or one GPU).</li>
<li><code>ParallelMode.NOT_DISTRIBUTED</code>: several GPUs in one single process (uses <code>nn.DataParallel</code>).</li>
<li><code>ParallelMode.DISTRIBUTED</code>: several GPUs, each having its own process (uses
  <code>nn.DistributedDataParallel</code>).</li>
<li><code>ParallelMode.TPU</code>: several TPU cores.</li>
</ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.process_index" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">process_index</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.process_index" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The index of the current process used.</p>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.should_log" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">should_log</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.should_log" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Whether or not the current process should produce log.</p>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.should_save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">should_save</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.should_save" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Whether or not the current process should write to disk, e.g., to save models and checkpoints.</p>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.train_batch_size" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">train_batch_size</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.train_batch_size" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The actual batch size for training (may differ from <code>per_gpu_train_batch_size</code> in distributed training).</p>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.engine.train_args.TrainingArguments.world_size" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">world_size</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.engine.train_args.TrainingArguments.world_size" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The number of processes used in parallel.</p>
    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.__post_init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">__post_init__</span><span class="p">()</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.__post_init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method initializes the TrainingArguments class instance after its creation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An instance of the TrainingArguments class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None. This method does not return any value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the evaluation strategy requires non-zero evaluation steps or logging steps are zero.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-FutureWarning</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If using <code>EvaluationStrategy</code> for <code>evaluation_strategy</code> is deprecated.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the logging strategy requires non-zero logging steps or steps are not an integer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the saving steps are not an integer when required.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If <code>load_best_model_at_end</code> is enabled but save and evaluation strategies do not match.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the saving steps are not a multiple of evaluation steps for <code>load_best_model_at_end</code>.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If <code>save_safetensors</code> is enabled but safetensors are not installed.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If both <code>fp16</code> and <code>bf16</code> are set to True.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If both <code>fp16_full_eval</code> and <code>bf16_full_eval</code> are set to True.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If lr_scheduler_type is reduce_lr_on_plateau but eval strategy or mindspore is not available.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If warmup_ratio is not in the range [0,1] or if both warmup_ratio and warmup_steps are provided.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>-ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If dataset_prefetch_factor is set without dataset_num_workers &gt; 1.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method initializes the TrainingArguments class instance after its creation.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: An instance of the TrainingArguments class.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. This method does not return any value.</span>

<span class="sd">    Raises:</span>
<span class="sd">        - ValueError: If the evaluation strategy requires non-zero evaluation steps or logging steps are zero.</span>
<span class="sd">        - FutureWarning: If using `EvaluationStrategy` for `evaluation_strategy` is deprecated.</span>
<span class="sd">        - ValueError: If the logging strategy requires non-zero logging steps or steps are not an integer.</span>
<span class="sd">        - ValueError: If the saving steps are not an integer when required.</span>
<span class="sd">        - ValueError: If `load_best_model_at_end` is enabled but save and evaluation strategies do not match.</span>
<span class="sd">        - ValueError: If the saving steps are not a multiple of evaluation steps for `load_best_model_at_end`.</span>
<span class="sd">        - ValueError: If `save_safetensors` is enabled but safetensors are not installed.</span>
<span class="sd">        - ValueError: If both `fp16` and `bf16` are set to True.</span>
<span class="sd">        - ValueError: If both `fp16_full_eval` and `bf16_full_eval` are set to True.</span>
<span class="sd">        - ValueError: If lr_scheduler_type is reduce_lr_on_plateau but eval strategy or mindspore is not available.</span>
<span class="sd">        - ValueError: If warmup_ratio is not in the range [0,1] or if both warmup_ratio and warmup_steps are provided.</span>
<span class="sd">        - ValueError: If dataset_prefetch_factor is set without dataset_num_workers &gt; 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># expand paths, if not os.makedirs(&quot;~/bar&quot;) will make directory</span>
    <span class="c1"># in the current directory instead of the actual home</span>
    <span class="c1"># see https://github.com/huggingface/transformers/issues/10628</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">default_logdir</span><span class="p">())</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_dir</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">logger</span><span class="o">.</span><span class="n">getEffectiveLevel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">logging</span><span class="o">.</span><span class="n">WARN</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="p">,</span> <span class="n">EvaluationStrategy</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;using `EvaluationStrategy` for `evaluation_strategy` is deprecated and will be removed in version 5&quot;</span>
            <span class="s2">&quot; of 🤗 Transformers. Use `IntervalStrategy` instead&quot;</span><span class="p">,</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Go back to the underlying string or we won&#39;t be able to instantiate `IntervalStrategy` on it.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="o">.</span><span class="n">value</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="n">SchedulerType</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">!=</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">NO</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># eval_steps has to be defined and non-zero, fallbacks to logging_steps if the latter is non-zero</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using `logging_steps` to initialize `eval_steps` to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;evaluation strategy </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="si">}</span><span class="s2"> requires either non-zero --eval_steps or&quot;</span>
                <span class="s2">&quot; --logging_steps&quot;</span>
            <span class="p">)</span>

    <span class="c1"># logging_steps must be non-zero for logging_strategy that is other than &#39;no&#39;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;logging strategy </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span><span class="si">}</span><span class="s2"> requires non-zero --logging_steps&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">!=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--logging_steps must be an integer if bigger than 1: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">!=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--eval_steps must be an integer if bigger than 1: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">!=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--save_steps must be an integer if bigger than 1: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="p">)</span>

    <span class="c1"># Sanity checks for load_best_model_at_end: we require save and eval strategies to be compatible.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_best_model_at_end</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;--load_best_model_at_end requires the save and eval strategy to match, but found</span><span class="se">\n</span><span class="s2">- Evaluation &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;strategy: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span><span class="si">}</span><span class="se">\n</span><span class="s2">- Save strategy: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;--load_best_model_at_end requires the saving steps to be a multiple of the evaluation &quot;</span>
                        <span class="s2">&quot;steps, which cannot get guaranteed when mixing ratio and absolute steps for save_steps &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="si">}</span><span class="s2"> and eval_steps </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="c1"># Work around floating point precision issues</span>
                <span class="n">LARGE_MULTIPLIER</span> <span class="o">=</span> <span class="mi">1_000_000</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">*</span> <span class="n">LARGE_MULTIPLIER</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">*</span> <span class="n">LARGE_MULTIPLIER</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;--load_best_model_at_end requires the saving steps to be a multiple of the evaluation &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;steps, but found </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="si">}</span><span class="s2">, which is not a multiple of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;--load_best_model_at_end requires the saving steps to be a round multiple of the evaluation &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;steps, but found </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span><span class="si">}</span><span class="s2">, which is not a round multiple of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="n">safetensors_available</span> <span class="o">=</span> <span class="n">is_safetensors_available</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_safetensors</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">safetensors_available</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--save_safetensors=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_safetensors</span><span class="si">}</span><span class="s2"> requires safetensors to be installed!&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_safetensors</span> <span class="ow">and</span> <span class="n">safetensors_available</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Found safetensors installation, but --save_safetensors=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_safetensors</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Safetensors should be a preferred weights saving format due to security and performance reasons. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;If your model cannot be saved by safetensors please feel free to open an issue at &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;https://github.com/huggingface/safetensors!&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_best_model_at_end</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span> <span class="o">==</span> <span class="n">SchedulerType</span><span class="o">.</span><span class="n">REDUCE_ON_PLATEAU</span>
    <span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_for_best_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_for_best_model</span> <span class="o">=</span> <span class="s2">&quot;loss&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">greater_is_better</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_for_best_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_for_best_model</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;eval_loss&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dir</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp16</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bf16</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At most one of fp16 and bf16 can be True, but not both&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp16_full_eval</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bf16_full_eval</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At most one of fp16 and bf16 can be True for full eval, but not both&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span> <span class="o">==</span> <span class="n">SchedulerType</span><span class="o">.</span><span class="n">REDUCE_ON_PLATEAU</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">NO</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;lr_scheduler_type reduce_lr_on_plateau requires an eval strategy&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_mindspore_available</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;lr_scheduler_type reduce_lr_on_plateau requires mindspore&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">OptimizerNames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="p">)</span>

    <span class="c1"># if training args is specified, it will override the one specified in the accelerate config</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp16</span><span class="p">:</span>
        <span class="n">mixed_precision_dtype</span> <span class="o">=</span> <span class="s2">&quot;fp16&quot;</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">bf16</span><span class="p">:</span>
        <span class="n">mixed_precision_dtype</span> <span class="o">=</span> <span class="s2">&quot;bf16&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;warmup_ratio must lie in range [0,1]&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Both warmup_ratio and warmup_steps given, warmup_steps will override any effect of warmup_ratio&quot;</span>
            <span class="s2">&quot; during training&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_num_workers</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_prefetch_factor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;--dataset_prefetch_factor can only be set when data is loaded in a different process, i.e.&quot;</span>
            <span class="s2">&quot; when --dataset_num_workers &gt; 1.&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.__str__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="fm">__str__</span><span class="p">()</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.__str__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method returns a string representation of the TrainingArguments object.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the TrainingArguments class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.engine.train_args.base.TrainingArguments" href="#mindnlp.engine.train_args.TrainingArguments">TrainingArguments</a></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>None</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>This method returns a string representation of the TrainingArguments object.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method returns a string representation of the TrainingArguments object.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (TrainingArguments): The instance of the TrainingArguments class.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None: This method returns a string representation of the TrainingArguments object.</span>

<span class="sd">    Raises:</span>
<span class="sd">        No specific exceptions are documented to be raised by this method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">self_as_dict</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="c1"># Remove deprecated arguments. That code should be removed once</span>
    <span class="c1"># those deprecated arguments are removed from TrainingArguments. (TODO: v5)</span>
    <span class="k">del</span> <span class="n">self_as_dict</span><span class="p">[</span><span class="s2">&quot;per_gpu_train_batch_size&quot;</span><span class="p">]</span>
    <span class="k">del</span> <span class="n">self_as_dict</span><span class="p">[</span><span class="s2">&quot;per_gpu_eval_batch_size&quot;</span><span class="p">]</span>

    <span class="n">self_as_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;&lt;</span><span class="si">{</span><span class="n">k</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">&gt;&quot;</span> <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_token&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">self_as_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="n">attrs_as_str</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">self_as_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span>
    <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attrs_as_str</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.get_process_log_level" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">get_process_log_level</span><span class="p">()</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.get_process_log_level" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Returns the log level to be used depending on whether this process is the main process of node 0, main process
of node non-0, or a non-main process.</p>
<p>For the main process the log level defaults to the logging level set (<code>logging.WARNING</code> if you didn't do
anything) unless overridden by <code>log_level</code> argument.</p>
<p>For the replica processes the log level defaults to <code>logging.WARNING</code> unless overridden by <code>log_level_replica</code>
argument.</p>
<p>The choice between the main and replica process settings is made according to the return value of <code>should_log</code>.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_process_log_level</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the log level to be used depending on whether this process is the main process of node 0, main process</span>
<span class="sd">    of node non-0, or a non-main process.</span>

<span class="sd">    For the main process the log level defaults to the logging level set (`logging.WARNING` if you didn&#39;t do</span>
<span class="sd">    anything) unless overridden by `log_level` argument.</span>

<span class="sd">    For the replica processes the log level defaults to `logging.WARNING` unless overridden by `log_level_replica`</span>
<span class="sd">    argument.</span>

<span class="sd">    The choice between the main and replica process settings is made according to the return value of `should_log`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># convert to int</span>
    <span class="n">log_level</span> <span class="o">=</span> <span class="n">trainer_log_levels</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">log_level</span><span class="p">]</span>
    <span class="n">log_level_replica</span> <span class="o">=</span> <span class="n">trainer_log_levels</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">log_level_replica</span><span class="p">]</span>

    <span class="n">log_level_main_node</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_verbosity</span><span class="p">()</span> <span class="k">if</span> <span class="n">log_level</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">log_level</span>
    <span class="n">log_level_replica_node</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_verbosity</span><span class="p">()</span> <span class="k">if</span> <span class="n">log_level_replica</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">log_level_replica</span>
    <span class="k">return</span> <span class="n">log_level_main_node</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">should_log</span> <span class="k">else</span> <span class="n">log_level_replica_node</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.get_warmup_steps" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">get_warmup_steps</span><span class="p">(</span><span class="n">num_training_steps</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.get_warmup_steps" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Get number of steps used for a linear warmup.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_warmup_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get number of steps used for a linear warmup.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">warmup_steps</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_training_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">warmup_steps</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.main_process_first" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">main_process_first</span><span class="p">(</span><span class="n">local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;work&#39;</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.main_process_first" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A context manager for MindSpore distributed environment where on needs to do something on the main process, while
blocking replicas, and when it's finished releasing the replicas.</p>
<p>One such use is for <code>datasets</code>'s <code>map</code> feature which to be efficient should be run once on the main process,
which upon completion saves a cached version of results and which then automatically gets loaded by the
replicas.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>local</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>if <code>True</code> first means process of rank 0 of each node if <code>False</code> first means process of rank 0 of node
rank 0 In multi-node environment with a shared filesystem you most likely will want to use
<code>local=False</code> so that only the main process of the first node will do the processing. If however, the
filesystem is not shared, then the main process of each node will need to do the processing, which is
the default behavior.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>desc</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>a work description to be used in debug logs</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;work&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;work&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">main_process_first</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;work&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A context manager for MindSpore distributed environment where on needs to do something on the main process, while</span>
<span class="sd">    blocking replicas, and when it&#39;s finished releasing the replicas.</span>

<span class="sd">    One such use is for `datasets`&#39;s `map` feature which to be efficient should be run once on the main process,</span>
<span class="sd">    which upon completion saves a cached version of results and which then automatically gets loaded by the</span>
<span class="sd">    replicas.</span>

<span class="sd">    Args:</span>
<span class="sd">        local (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            if `True` first means process of rank 0 of each node if `False` first means process of rank 0 of node</span>
<span class="sd">            rank 0 In multi-node environment with a shared filesystem you most likely will want to use</span>
<span class="sd">            `local=False` so that only the main process of the first node will do the processing. If however, the</span>
<span class="sd">            filesystem is not shared, then the main process of each node will need to do the processing, which is</span>
<span class="sd">            the default behavior.</span>
<span class="sd">        desc (`str`, *optional*, defaults to `&quot;work&quot;`):</span>
<span class="sd">            a work description to be used in debug logs</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_mindspore_available</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">main_process_desc</span> <span class="o">=</span> <span class="s2">&quot;main local process&quot;</span> <span class="k">if</span> <span class="n">local</span> <span class="k">else</span> <span class="s2">&quot;main process&quot;</span>
        <span class="n">is_main_process</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">communication</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_main_process</span><span class="p">:</span>
                <span class="c1"># tell all replicas to wait</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">process_index</span><span class="si">}</span><span class="s2">: waiting for the </span><span class="si">{</span><span class="n">main_process_desc</span><span class="si">}</span><span class="s2"> to perform </span><span class="si">{</span><span class="n">desc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_main_process</span><span class="p">:</span>
                <span class="c1"># the wait is over</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">process_index</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">main_process_desc</span><span class="si">}</span><span class="s2"> completed </span><span class="si">{</span><span class="n">desc</span><span class="si">}</span><span class="s2">, releasing all replicas&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">yield</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.set_dataloader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">set_dataloader</span><span class="p">(</span><span class="n">train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">eval_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">persistent_workers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prefetch_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">auto_find_batch_size</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ignore_data_skip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sampler_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.set_dataloader" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A method that regroups all arguments linked to the dataloaders creation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>drop_last</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch
size) or not.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of subprocesses to use for data loading (MindSpore only). 0 means that the data will be loaded in
the main process.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pin_memory</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether you want to pin memory in data loaders or not. Will default to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>persistent_workers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If True, the data loader will not shut down the worker processes after a dataset has been consumed
once. This allows to maintain the workers Dataset instances alive. Can potentially speed up training,
but will increase RAM usage. Will default to <code>False</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prefetch_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of batches loaded in advance by each worker.
2 means there will be a total of 2 * num_workers batches prefetched across all workers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ignore_data_skip</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When resuming training, whether or not to skip the epochs and batches to get the data loading at the
same stage as in the previous training. If set to <code>True</code>, the training will begin faster (as that
skipping step can take a long time) but will not yield the same results as the interrupted training
would have.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sampler_seed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Random seed to be used with data samplers. If not set, random generators for data sampling will use the
same seed as <code>self.seed</code>. This can be used to ensure reproducibility of data sampling, independent of
the model seed.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="s2">&quot;working_dir&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">set_dataloader</span><span class="p">(</span><span class="n">train_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">eval_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">per_device_train_batch_size</span>
<span class="mi">16</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_dataloader</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">eval_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">persistent_workers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">prefetch_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">auto_find_batch_size</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">ignore_data_skip</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">sampler_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A method that regroups all arguments linked to the dataloaders creation.</span>

<span class="sd">    Args:</span>
<span class="sd">        drop_last (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to drop the last incomplete batch (if the length of the dataset is not divisible by the batch</span>
<span class="sd">            size) or not.</span>
<span class="sd">        num_workers (`int`, *optional*, defaults to 0):</span>
<span class="sd">            Number of subprocesses to use for data loading (MindSpore only). 0 means that the data will be loaded in</span>
<span class="sd">            the main process.</span>
<span class="sd">        pin_memory (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether you want to pin memory in data loaders or not. Will default to `True`.</span>
<span class="sd">        persistent_workers (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            If True, the data loader will not shut down the worker processes after a dataset has been consumed</span>
<span class="sd">            once. This allows to maintain the workers Dataset instances alive. Can potentially speed up training,</span>
<span class="sd">            but will increase RAM usage. Will default to `False`.</span>
<span class="sd">        prefetch_factor (`int`, *optional*):</span>
<span class="sd">            Number of batches loaded in advance by each worker.</span>
<span class="sd">            2 means there will be a total of 2 * num_workers batches prefetched across all workers.</span>
<span class="sd">        auto_find_batch_size (`bool`, *optional*, defaults to `False`)</span>
<span class="sd">            Whether to find a batch size that will fit into memory automatically through exponential decay,</span>
<span class="sd">            avoiding CUDA Out-of-Memory errors. Requires accelerate to be installed (`pip install accelerate`)</span>
<span class="sd">        ignore_data_skip (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            When resuming training, whether or not to skip the epochs and batches to get the data loading at the</span>
<span class="sd">            same stage as in the previous training. If set to `True`, the training will begin faster (as that</span>
<span class="sd">            skipping step can take a long time) but will not yield the same results as the interrupted training</span>
<span class="sd">            would have.</span>
<span class="sd">        sampler_seed (`int`, *optional*):</span>
<span class="sd">            Random seed to be used with data samplers. If not set, random generators for data sampling will use the</span>
<span class="sd">            same seed as `self.seed`. This can be used to ensure reproducibility of data sampling, independent of</span>
<span class="sd">            the model seed.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">    &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">    &gt;&gt;&gt; args = args.set_dataloader(train_batch_size=16, eval_batch_size=64)</span>
<span class="sd">    &gt;&gt;&gt; args.per_device_train_batch_size</span>
<span class="sd">    16</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="n">train_batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="n">eval_batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_drop_last</span> <span class="o">=</span> <span class="n">drop_last</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_persistent_workers</span> <span class="o">=</span> <span class="n">persistent_workers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dataset_prefetch_factor</span> <span class="o">=</span> <span class="n">prefetch_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">auto_find_batch_size</span> <span class="o">=</span> <span class="n">auto_find_batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ignore_data_skip</span> <span class="o">=</span> <span class="n">ignore_data_skip</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data_seed</span> <span class="o">=</span> <span class="n">sampler_seed</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.set_evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">set_evaluate</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;no&#39;</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">accumulation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">jit_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.set_evaluate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A method that regroups all arguments linked to evaluation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The evaluation strategy to adopt during training. Possible values are:</p>
<div class="highlight"><pre><span></span><code>- `&quot;no&quot;`: No evaluation is done during training.
- `&quot;steps&quot;`: Evaluation is done (and logged) every `steps`.
- `&quot;epoch&quot;`: Evaluation is done at the end of each epoch.
</code></pre></div>
<p>Setting a <code>strategy</code> different from <code>"no"</code> will set <code>self.do_eval</code> to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&#34;no&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;no&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of update steps between two evaluations if <code>strategy="steps"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 500</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>500</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The batch size per device (GPU/TPU core/CPU...) used for evaluation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` *optional*, defaults to 8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>accumulation_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU.
If left unset, the whole predictions are accumulated on GPU/TPU before being moved to the CPU (faster
but requires more memory).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delay</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of epochs or steps to wait for before the first evaluation can be performed, depending on the
evaluation_strategy.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>loss_only</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignores all outputs except the loss.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>jit_mode</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to use MindSpore jit trace for inference.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="s2">&quot;working_dir&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">set_evaluate</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">eval_steps</span>
<span class="mi">100</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">IntervalStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">accumulation_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">jit_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A method that regroups all arguments linked to evaluation.</span>

<span class="sd">    Args:</span>
<span class="sd">        strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;no&quot;`):</span>
<span class="sd">            The evaluation strategy to adopt during training. Possible values are:</span>

<span class="sd">                - `&quot;no&quot;`: No evaluation is done during training.</span>
<span class="sd">                - `&quot;steps&quot;`: Evaluation is done (and logged) every `steps`.</span>
<span class="sd">                - `&quot;epoch&quot;`: Evaluation is done at the end of each epoch.</span>

<span class="sd">            Setting a `strategy` different from `&quot;no&quot;` will set `self.do_eval` to `True`.</span>
<span class="sd">        steps (`int`, *optional*, defaults to 500):</span>
<span class="sd">            Number of update steps between two evaluations if `strategy=&quot;steps&quot;`.</span>
<span class="sd">        batch_size (`int` *optional*, defaults to 8):</span>
<span class="sd">            The batch size per device (GPU/TPU core/CPU...) used for evaluation.</span>
<span class="sd">        accumulation_steps (`int`, *optional*):</span>
<span class="sd">            Number of predictions steps to accumulate the output tensors for, before moving the results to the CPU.</span>
<span class="sd">            If left unset, the whole predictions are accumulated on GPU/TPU before being moved to the CPU (faster</span>
<span class="sd">            but requires more memory).</span>
<span class="sd">        delay (`float`, *optional*):</span>
<span class="sd">            Number of epochs or steps to wait for before the first evaluation can be performed, depending on the</span>
<span class="sd">            evaluation_strategy.</span>
<span class="sd">        loss_only (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Ignores all outputs except the loss.</span>
<span class="sd">        jit_mode (`bool`, *optional*):</span>
<span class="sd">            Whether or not to use MindSpore jit trace for inference.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">    &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">    &gt;&gt;&gt; args = args.set_evaluate(strategy=&quot;steps&quot;, steps=100)</span>
<span class="sd">    &gt;&gt;&gt; args.eval_steps</span>
<span class="sd">    100</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Setting `strategy` as &#39;steps&#39; requires a positive value for `steps`.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_strategy</span> <span class="o">!=</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">NO</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_steps</span> <span class="o">=</span> <span class="n">steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_accumulation_steps</span> <span class="o">=</span> <span class="n">accumulation_steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">eval_delay</span> <span class="o">=</span> <span class="n">delay</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prediction_loss_only</span> <span class="o">=</span> <span class="n">loss_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">jit_mode_eval</span> <span class="o">=</span> <span class="n">jit_mode</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.set_logging" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">set_logging</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">report_to</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s1">&#39;passive&#39;</span><span class="p">,</span> <span class="n">first_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nan_inf_filter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">on_each_node</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">replica_level</span><span class="o">=</span><span class="s1">&#39;passive&#39;</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.set_logging" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A method that regroups all arguments linked to logging.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The logging strategy to adopt during training. Possible values are:</p>
<div class="highlight"><pre><span></span><code>- `&quot;no&quot;`: No logging is done during training.
- `&quot;epoch&quot;`: Logging is done at the end of each epoch.
- `&quot;steps&quot;`: Logging is done every `logging_steps`.
</code></pre></div>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&#34;steps&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;steps&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of update steps between two logs if <code>strategy="steps"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 500</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>500</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>level</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logger log level to use on the main process. Possible choices are the log levels as strings: <code>"debug"</code>,
<code>"info"</code>, <code>"warning"</code>, <code>"error"</code> and <code>"critical"</code>, plus a <code>"passive"</code> level which doesn't set anything
and lets the application set the level.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;passive&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;passive&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>report_to</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of integrations to report the results and logs to. Supported platforms are <code>"azure_ml"</code>,
<code>"clearml"</code>, <code>"codecarbon"</code>, <code>"comet_ml"</code>, <code>"dagshub"</code>, <code>"dvclive"</code>, <code>"flyte"</code>, <code>"mlflow"</code>,
<code>"neptune"</code>, <code>"tensorboard"</code>, and <code>"wandb"</code>. Use <code>"all"</code> to report to all integrations installed,
<code>"none"</code> for no integrations.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*, defaults to `&#34;all&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;none&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>first_step</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to log and evaluate the first <code>global_step</code> or not.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nan_inf_filter</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to filter <code>nan</code> and <code>inf</code> losses for logging. If set to <code>True</code> the loss of every step that is
<code>nan</code> or <code>inf</code> is filtered and the average loss of the current logging window is taken instead.</p>
<p><Tip></p>
<p><code>nan_inf_filter</code> only influences the logging of loss values, it does not change the behavior the
gradient is computed or applied to the model.</p>
<p></Tip></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>on_each_node</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>In multinode distributed training, whether to log using <code>log_level</code> once per node, or only on the main
node.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>replica_level</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logger log level to use on replicas. Same choices as <code>log_level</code></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;passive&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;passive&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="s2">&quot;working_dir&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">set_logging</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">logging_steps</span>
<span class="mi">100</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_logging</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">IntervalStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
    <span class="n">report_to</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;passive&quot;</span><span class="p">,</span>
    <span class="n">first_step</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">nan_inf_filter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">on_each_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">replica_level</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;passive&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A method that regroups all arguments linked to logging.</span>

<span class="sd">    Args:</span>
<span class="sd">        strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;steps&quot;`):</span>
<span class="sd">            The logging strategy to adopt during training. Possible values are:</span>

<span class="sd">                - `&quot;no&quot;`: No logging is done during training.</span>
<span class="sd">                - `&quot;epoch&quot;`: Logging is done at the end of each epoch.</span>
<span class="sd">                - `&quot;steps&quot;`: Logging is done every `logging_steps`.</span>

<span class="sd">        steps (`int`, *optional*, defaults to 500):</span>
<span class="sd">            Number of update steps between two logs if `strategy=&quot;steps&quot;`.</span>
<span class="sd">        level (`str`, *optional*, defaults to `&quot;passive&quot;`):</span>
<span class="sd">            Logger log level to use on the main process. Possible choices are the log levels as strings: `&quot;debug&quot;`,</span>
<span class="sd">            `&quot;info&quot;`, `&quot;warning&quot;`, `&quot;error&quot;` and `&quot;critical&quot;`, plus a `&quot;passive&quot;` level which doesn&#39;t set anything</span>
<span class="sd">            and lets the application set the level.</span>
<span class="sd">        report_to (`str` or `List[str]`, *optional*, defaults to `&quot;all&quot;`):</span>
<span class="sd">            The list of integrations to report the results and logs to. Supported platforms are `&quot;azure_ml&quot;`,</span>
<span class="sd">            `&quot;clearml&quot;`, `&quot;codecarbon&quot;`, `&quot;comet_ml&quot;`, `&quot;dagshub&quot;`, `&quot;dvclive&quot;`, `&quot;flyte&quot;`, `&quot;mlflow&quot;`,</span>
<span class="sd">            `&quot;neptune&quot;`, `&quot;tensorboard&quot;`, and `&quot;wandb&quot;`. Use `&quot;all&quot;` to report to all integrations installed,</span>
<span class="sd">            `&quot;none&quot;` for no integrations.</span>
<span class="sd">        first_step (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to log and evaluate the first `global_step` or not.</span>
<span class="sd">        nan_inf_filter (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to filter `nan` and `inf` losses for logging. If set to `True` the loss of every step that is</span>
<span class="sd">            `nan` or `inf` is filtered and the average loss of the current logging window is taken instead.</span>

<span class="sd">            &lt;Tip&gt;</span>

<span class="sd">            `nan_inf_filter` only influences the logging of loss values, it does not change the behavior the</span>
<span class="sd">            gradient is computed or applied to the model.</span>

<span class="sd">            &lt;/Tip&gt;</span>

<span class="sd">        on_each_node (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            In multinode distributed training, whether to log using `log_level` once per node, or only on the main</span>
<span class="sd">            node.</span>
<span class="sd">        replica_level (`str`, *optional*, defaults to `&quot;passive&quot;`):</span>
<span class="sd">            Logger log level to use on replicas. Same choices as `log_level`</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">    &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">    &gt;&gt;&gt; args = args.set_logging(strategy=&quot;steps&quot;, steps=100)</span>
<span class="sd">    &gt;&gt;&gt; args.logging_steps</span>
<span class="sd">    100</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Setting `strategy` as &#39;steps&#39; requires a positive value for `steps`.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logging_steps</span> <span class="o">=</span> <span class="n">steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">report_to</span> <span class="o">=</span> <span class="n">report_to</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_level</span> <span class="o">=</span> <span class="n">level</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logging_first_step</span> <span class="o">=</span> <span class="n">first_step</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logging_nan_inf_filter</span> <span class="o">=</span> <span class="n">nan_inf_filter</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_on_each_node</span> <span class="o">=</span> <span class="n">on_each_node</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_level_replica</span> <span class="o">=</span> <span class="n">replica_level</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.set_lr_scheduler" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">set_lr_scheduler</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">warmup_ratio</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.set_lr_scheduler" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A method that regroups all arguments linked to the learning rate scheduler and its hyperparameters.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The scheduler type to use. See the documentation of [<code>SchedulerType</code>] for all possible values.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`SchedulerType`], *optional*, defaults to `&#34;linear&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;linear&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_epochs(`float`,</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Total number of training epochs to perform (if not an integer, will perform the decimal part percents
of the last epoch before stopping training).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>*optional*, defaults to 3.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If set to a positive number, the total number of training steps to perform. Overrides <code>num_train_epochs</code>.
For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until
<code>max_steps</code> is reached.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to -1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>-1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warmup_ratio</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ratio of total training steps used for a linear warmup from 0 to <code>learning_rate</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>warmup_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of steps used for a linear warmup from 0 to <code>learning_rate</code>. Overrides any effect of
<code>warmup_ratio</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="s2">&quot;working_dir&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">set_lr_scheduler</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span> <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">warmup_ratio</span>
<span class="mf">0.05</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_lr_scheduler</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">SchedulerType</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">3.0</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">warmup_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">warmup_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A method that regroups all arguments linked to the learning rate scheduler and its hyperparameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        name (`str` or [`SchedulerType`], *optional*, defaults to `&quot;linear&quot;`):</span>
<span class="sd">            The scheduler type to use. See the documentation of [`SchedulerType`] for all possible values.</span>
<span class="sd">        num_epochs(`float`, *optional*, defaults to 3.0):</span>
<span class="sd">            Total number of training epochs to perform (if not an integer, will perform the decimal part percents</span>
<span class="sd">            of the last epoch before stopping training).</span>
<span class="sd">        max_steps (`int`, *optional*, defaults to -1):</span>
<span class="sd">            If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.</span>
<span class="sd">            For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until</span>
<span class="sd">            `max_steps` is reached.</span>
<span class="sd">        warmup_ratio (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            Ratio of total training steps used for a linear warmup from 0 to `learning_rate`.</span>
<span class="sd">        warmup_steps (`int`, *optional*, defaults to 0):</span>
<span class="sd">            Number of steps used for a linear warmup from 0 to `learning_rate`. Overrides any effect of</span>
<span class="sd">            `warmup_ratio`.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">    &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">    &gt;&gt;&gt; args = args.set_lr_scheduler(name=&quot;cosine&quot;, warmup_ratio=0.05)</span>
<span class="sd">    &gt;&gt;&gt; args.warmup_ratio</span>
<span class="sd">    0.05</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="n">SchedulerType</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">=</span> <span class="n">num_epochs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">warmup_ratio</span> <span class="o">=</span> <span class="n">warmup_ratio</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.set_optimizer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">set_optimizer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;adamw_torch&#39;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-05</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.set_optimizer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A method that regroups all arguments linked to the optimizer and its hyperparameters.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The optimizer to use: <code>"adamw"</code>, <code>"sgd"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`training_args.OptimizerNames`], *optional*, defaults to `&#34;adamw&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;adamw_torch&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>learning_rate</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The initial learning rate.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 5e-5</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>5e-05</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>weight_decay</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>beta1</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The beta1 hyperparameter for the adam optimizer or its variants.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.9</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.9</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>beta2</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The beta2 hyperparameter for the adam optimizer or its variants.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.999</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.999</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epsilon</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon hyperparameter for the adam optimizer or its variants.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1e-8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-08</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>args</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional arguments that are supplied to AnyPrecisionAdamW (only useful when
<code>optim="adamw_anyprecision"</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="s2">&quot;working_dir&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">set_optimizer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;adamw&quot;</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">optim</span>
<span class="s1">&#39;adamw&#39;</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_optimizer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">OptimizerNames</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;adamw_torch&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-5</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span>
    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A method that regroups all arguments linked to the optimizer and its hyperparameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        name (`str` or [`training_args.OptimizerNames`], *optional*, defaults to `&quot;adamw&quot;`):</span>
<span class="sd">            The optimizer to use: `&quot;adamw&quot;`, `&quot;sgd&quot;`.</span>
<span class="sd">        learning_rate (`float`, *optional*, defaults to 5e-5):</span>
<span class="sd">            The initial learning rate.</span>
<span class="sd">        weight_decay (`float`, *optional*, defaults to 0):</span>
<span class="sd">            The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights.</span>
<span class="sd">        beta1 (`float`, *optional*, defaults to 0.9):</span>
<span class="sd">            The beta1 hyperparameter for the adam optimizer or its variants.</span>
<span class="sd">        beta2 (`float`, *optional*, defaults to 0.999):</span>
<span class="sd">            The beta2 hyperparameter for the adam optimizer or its variants.</span>
<span class="sd">        epsilon (`float`, *optional*, defaults to 1e-8):</span>
<span class="sd">            The epsilon hyperparameter for the adam optimizer or its variants.</span>
<span class="sd">        args (`str`, *optional*):</span>
<span class="sd">            Optional arguments that are supplied to AnyPrecisionAdamW (only useful when</span>
<span class="sd">            `optim=&quot;adamw_anyprecision&quot;`).</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">    &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">    &gt;&gt;&gt; args = args.set_optimizer(name=&quot;adamw&quot;, beta1=0.8)</span>
<span class="sd">    &gt;&gt;&gt; args.optim</span>
<span class="sd">    &#39;adamw&#39;</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">OptimizerNames</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">adam_beta1</span> <span class="o">=</span> <span class="n">beta1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">adam_beta2</span> <span class="o">=</span> <span class="n">beta2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">adam_epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optim_args</span> <span class="o">=</span> <span class="n">args</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.set_save" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">set_save</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">total_limit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">on_each_node</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.set_save" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A method that regroups all arguments linked to checkpoint saving.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>strategy</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The checkpoint save strategy to adopt during training. Possible values are:</p>
<div class="highlight"><pre><span></span><code>- `&quot;no&quot;`: No save is done during training.
- `&quot;epoch&quot;`: Save is done at the end of each epoch.
- `&quot;steps&quot;`: Save is done every `save_steps`.
</code></pre></div>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&#34;steps&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;steps&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of updates steps before two checkpoint saves if <code>strategy="steps"</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 500</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>500</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>total_limit</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in
<code>output_dir</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>on_each_node</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>When doing multi-node distributed training, whether to save models and checkpoints on each node, or
only on the main one.</p>
<p>This should not be activated when the different nodes use the same storage as the files will be saved
with the same names for each node.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="s2">&quot;working_dir&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">set_save</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">save_steps</span>
<span class="mi">100</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">strategy</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">IntervalStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
    <span class="n">total_limit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">on_each_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A method that regroups all arguments linked to checkpoint saving.</span>

<span class="sd">    Args:</span>
<span class="sd">        strategy (`str` or [`~trainer_utils.IntervalStrategy`], *optional*, defaults to `&quot;steps&quot;`):</span>
<span class="sd">            The checkpoint save strategy to adopt during training. Possible values are:</span>

<span class="sd">                - `&quot;no&quot;`: No save is done during training.</span>
<span class="sd">                - `&quot;epoch&quot;`: Save is done at the end of each epoch.</span>
<span class="sd">                - `&quot;steps&quot;`: Save is done every `save_steps`.</span>

<span class="sd">        steps (`int`, *optional*, defaults to 500):</span>
<span class="sd">            Number of updates steps before two checkpoint saves if `strategy=&quot;steps&quot;`.</span>
<span class="sd">        total_limit (`int`, *optional*):</span>
<span class="sd">            If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in</span>
<span class="sd">            `output_dir`.</span>
<span class="sd">        on_each_node (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            When doing multi-node distributed training, whether to save models and checkpoints on each node, or</span>
<span class="sd">            only on the main one.</span>

<span class="sd">            This should not be activated when the different nodes use the same storage as the files will be saved</span>
<span class="sd">            with the same names for each node.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">    &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">    &gt;&gt;&gt; args = args.set_save(strategy=&quot;steps&quot;, steps=100)</span>
<span class="sd">    &gt;&gt;&gt; args.save_steps</span>
<span class="sd">    100</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span> <span class="o">=</span> <span class="n">IntervalStrategy</span><span class="p">(</span><span class="n">strategy</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_strategy</span> <span class="o">==</span> <span class="n">IntervalStrategy</span><span class="o">.</span><span class="n">STEPS</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Setting `strategy` as &#39;steps&#39; requires a positive value for `steps`.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_steps</span> <span class="o">=</span> <span class="n">steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_total_limit</span> <span class="o">=</span> <span class="n">total_limit</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_on_each_node</span> <span class="o">=</span> <span class="n">on_each_node</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.set_testing" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">set_testing</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">loss_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">jit_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.set_testing" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A method that regroups all basic arguments linked to testing on a held-out dataset.</p>
<p><Tip></p>
<p>Calling this method will automatically set <code>self.do_predict</code> to <code>True</code>.</p>
<p></Tip></p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The batch size per device (GPU/TPU core/CPU...) used for testing.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` *optional*, defaults to 8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>loss_only</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ignores all outputs except the loss.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>jit_mode</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to use MindSpore jit trace for inference.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="s2">&quot;working_dir&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">set_testing</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span>
<span class="mi">32</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_testing</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">loss_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">jit_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A method that regroups all basic arguments linked to testing on a held-out dataset.</span>

<span class="sd">    &lt;Tip&gt;</span>

<span class="sd">    Calling this method will automatically set `self.do_predict` to `True`.</span>

<span class="sd">    &lt;/Tip&gt;</span>

<span class="sd">    Args:</span>
<span class="sd">        batch_size (`int` *optional*, defaults to 8):</span>
<span class="sd">            The batch size per device (GPU/TPU core/CPU...) used for testing.</span>
<span class="sd">        loss_only (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Ignores all outputs except the loss.</span>
<span class="sd">        jit_mode (`bool`, *optional*):</span>
<span class="sd">            Whether or not to use MindSpore jit trace for inference.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">    &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">    &gt;&gt;&gt; args = args.set_testing(batch_size=32)</span>
<span class="sd">    &gt;&gt;&gt; args.per_device_eval_batch_size</span>
<span class="sd">    32</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_predict</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prediction_loss_only</span> <span class="o">=</span> <span class="n">loss_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">jit_mode_eval</span> <span class="o">=</span> <span class="n">jit_mode</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.set_training" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">set_training</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">5e-05</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">recompute</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.set_training" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>A method that regroups all basic arguments linked to the training.</p>
<p><Tip></p>
<p>Calling this method will automatically set <code>self.do_train</code> to <code>True</code>.</p>
<p></Tip></p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>learning_rate</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The initial learning rate for the optimizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 5e-5</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>5e-05</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The batch size per device (GPU/TPU core/CPU...) used for training.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` *optional*, defaults to 8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>weight_decay</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in the
optimizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_train_epochs(`float`,</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Total number of training epochs to perform (if not an integer, will perform the decimal part percents
of the last epoch before stopping training).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>*optional*, defaults to 3.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If set to a positive number, the total number of training steps to perform. Overrides <code>num_train_epochs</code>.
For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until
<code>max_steps</code> is reached.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to -1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>-1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>gradient_accumulation_steps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of updates steps to accumulate the gradients for, before performing a backward/update pass.</p>
<p><Tip warning={true}></p>
<p>When using gradient accumulation, one step is counted as one step with backward pass. Therefore,
logging, evaluation, save will be conducted every <code>gradient_accumulation_steps * xxx_step</code> training
examples.</p>
<p></Tip></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use
the [<code>~Trainer.model_init</code>] function to instantiate the model if it has some randomly initialized
parameters.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 42</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>42</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>recompute</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If True, use gradient checkpointing to save memory at the expense of slower backward pass.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="s2">&quot;working_dir&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">set_training</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span>
<span class="mf">1e-4</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_training</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-5</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="n">recompute</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A method that regroups all basic arguments linked to the training.</span>

<span class="sd">    &lt;Tip&gt;</span>

<span class="sd">    Calling this method will automatically set `self.do_train` to `True`.</span>

<span class="sd">    &lt;/Tip&gt;</span>

<span class="sd">    Args:</span>
<span class="sd">        learning_rate (`float`, *optional*, defaults to 5e-5):</span>
<span class="sd">            The initial learning rate for the optimizer.</span>
<span class="sd">        batch_size (`int` *optional*, defaults to 8):</span>
<span class="sd">            The batch size per device (GPU/TPU core/CPU...) used for training.</span>
<span class="sd">        weight_decay (`float`, *optional*, defaults to 0):</span>
<span class="sd">            The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights in the</span>
<span class="sd">            optimizer.</span>
<span class="sd">        num_train_epochs(`float`, *optional*, defaults to 3.0):</span>
<span class="sd">            Total number of training epochs to perform (if not an integer, will perform the decimal part percents</span>
<span class="sd">            of the last epoch before stopping training).</span>
<span class="sd">        max_steps (`int`, *optional*, defaults to -1):</span>
<span class="sd">            If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.</span>
<span class="sd">            For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until</span>
<span class="sd">            `max_steps` is reached.</span>
<span class="sd">        gradient_accumulation_steps (`int`, *optional*, defaults to 1):</span>
<span class="sd">            Number of updates steps to accumulate the gradients for, before performing a backward/update pass.</span>

<span class="sd">            &lt;Tip warning={true}&gt;</span>

<span class="sd">            When using gradient accumulation, one step is counted as one step with backward pass. Therefore,</span>
<span class="sd">            logging, evaluation, save will be conducted every `gradient_accumulation_steps * xxx_step` training</span>
<span class="sd">            examples.</span>

<span class="sd">            &lt;/Tip&gt;</span>

<span class="sd">        seed (`int`, *optional*, defaults to 42):</span>
<span class="sd">            Random seed that will be set at the beginning of training. To ensure reproducibility across runs, use</span>
<span class="sd">            the [`~Trainer.model_init`] function to instantiate the model if it has some randomly initialized</span>
<span class="sd">            parameters.</span>
<span class="sd">        recompute (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            If True, use gradient checkpointing to save memory at the expense of slower backward pass.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    &gt;&gt;&gt; from transformers import TrainingArguments</span>

<span class="sd">    &gt;&gt;&gt; args = TrainingArguments(&quot;working_dir&quot;)</span>
<span class="sd">    &gt;&gt;&gt; args = args.set_training(learning_rate=1e-4, batch_size=32)</span>
<span class="sd">    &gt;&gt;&gt; args.learning_rate</span>
<span class="sd">    1e-4</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_train</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_train_epochs</span> <span class="o">=</span> <span class="n">num_epochs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="n">gradient_accumulation_steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">recompute</span> <span class="o">=</span> <span class="n">recompute</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.to_dict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.to_dict" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Serializes this instance while replace <code>Enum</code> by their values (for JSON serialization support). It obfuscates
the token values by removing their value.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates</span>
<span class="sd">    the token values by removing their value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># filter out fields that are defined as field(init=False)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="k">if</span> <span class="n">field</span><span class="o">.</span><span class="n">init</span><span class="p">}</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">value</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Enum</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_token&quot;</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&lt;</span><span class="si">{</span><span class="n">k</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2">&gt;&quot;</span>
    <span class="k">return</span> <span class="n">d</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.to_json_string" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">to_json_string</span><span class="p">()</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.to_json_string" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Serializes this instance to a JSON string.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">to_json_string</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Serializes this instance to a JSON string.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.engine.train_args.TrainingArguments.to_sanitized_dict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">train_args</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">to_sanitized_dict</span><span class="p">()</span></code>

<a href="#mindnlp.engine.train_args.TrainingArguments.to_sanitized_dict" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Sanitized serialization to use with TensorBoard’s hparams</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">to_sanitized_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sanitized serialization to use with TensorBoard’s hparams</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">d</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size</span><span class="p">,</span> <span class="s2">&quot;eval_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_batch_size</span><span class="p">}}</span>

    <span class="n">valid_types</span> <span class="o">=</span> <span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">is_mindspore_available</span><span class="p">():</span>
        <span class="n">valid_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">valid_types</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.engine.train_args.ParallelMode" class="doc doc-heading">
            <code>mindnlp.engine.train_args.ParallelMode</code>


<a href="#mindnlp.engine.train_args.ParallelMode" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="enum.Enum">Enum</span></code></p>


        <div class="highlight"><pre><span></span><code>Represents the different modes of parallel processing supported by the system.

This class defines an enumeration for the various modes of parallel processing that can be utilized by the system. It inherits from the Enum class, providing a structured way to define and work with
</code></pre></div>
<p>parallel processing modes within the system.</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\engine\train_args\base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ParallelMode</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>

<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents the different modes of parallel processing supported by the system.</span>

<span class="sd">    This class defines an enumeration for the various modes of parallel processing that can be utilized by the system. It inherits from the Enum class, providing a structured way to define and work with</span>
<span class="sd">parallel processing modes within the system.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">NOT_PARALLEL</span> <span class="o">=</span> <span class="s2">&quot;not_parallel&quot;</span>
    <span class="n">NOT_DISTRIBUTED</span> <span class="o">=</span> <span class="s2">&quot;not_distributed&quot;</span>
    <span class="n">DISTRIBUTED</span> <span class="o">=</span> <span class="s2">&quot;distributed&quot;</span>
    <span class="n">SAGEMAKER_MODEL_PARALLEL</span> <span class="o">=</span> <span class="s2">&quot;sagemaker_model_parallel&quot;</span>
    <span class="n">SAGEMAKER_DATA_PARALLEL</span> <span class="o">=</span> <span class="s2">&quot;sagemaker_data_parallel&quot;</span>
    <span class="n">TPU</span> <span class="o">=</span> <span class="s2">&quot;tpu&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../../../dataset/transforms/" class="md-footer__link md-footer__link--prev" aria-label="Previous: transforms">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                transforms
              </div>
            </div>
          </a>
        
        
          
          <a href="../seq2seq/" class="md-footer__link md-footer__link--next" aria-label="Next: seq2seq">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                seq2seq
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 - 2024 MindSpore Lab and CQU NLP Team.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:lvyufeng@cqu.edu.cn" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindnlp" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/lu-yu-feng-46-1" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top", "navigation.footer", "navigation.path", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>