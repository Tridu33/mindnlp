
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../baichuan/">
      
      
        <link rel="next" href="../bart/">
      
      
      <link rel="icon" href="../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.44">
    
    
      
        <title>bark - MindNLP Docs</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="MindNLP Docs" class="md-header__button md-logo" aria-label="MindNLP Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindNLP Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              bark
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../../../zh/api/transformers/models/bark/" hreflang="zh" class="md-select__link">
              中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindnlp
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../tutorials/quick_start/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../supported_models/" class="md-tabs__link">
        
  
    
  
  Supported Models

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../contribute/" class="md-tabs__link">
        
  
    
  
  How-To Contribute

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../accelerate/" class="md-tabs__link">
          
  
    
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../notes/changelog/" class="md-tabs__link">
          
  
    
  
  Notes

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="MindNLP Docs" class="md-nav__button md-logo" aria-label="MindNLP Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    MindNLP Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindnlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/quick_start/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/data_preprocess/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Preprocess
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/use_trainer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Trainer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/use_mirror/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Mirror
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../supported_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supported Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contribute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How-To Contribute
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../accelerate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/load_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    load_dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/BaseMapFunction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BaseMapFunction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/transforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transforms
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Engine
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            Engine
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4_1" >
        
          
          <label class="md-nav__link" for="__nav_5_4_1" id="__nav_5_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    train_args
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4_1">
            <span class="md-nav__icon md-icon"></span>
            train_args
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/train_args/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/train_args/seq2seq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seq2seq
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4_2" >
        
          
          <label class="md-nav__link" for="__nav_5_4_2" id="__nav_5_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    trainer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4_2">
            <span class="md-nav__icon md-icon"></span>
            trainer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/trainer/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/trainer/default_func/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    default_func
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/callbacks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    callbacks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    export
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../modules/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modules
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../parallel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../peft/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            PEFT
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_2" >
        
          
          <label class="md-nav__link" for="__nav_5_7_2" id="__nav_5_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    tuners
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_2">
            <span class="md-nav__icon md-icon"></span>
            tuners
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/adalora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AdaLoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/adaption_prompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adaption_Prompt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/ia3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IA3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/lokr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoKr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/prompt_tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prompt tuning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_3" >
        
          
          <label class="md-nav__link" for="__nav_5_7_3" id="__nav_5_7_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_3">
            <span class="md-nav__icon md-icon"></span>
            utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/utils/merge_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    merge_utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/mapping/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mapping
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/peft_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    peft_model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sentence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_2" >
        
          
          <label class="md-nav__link" for="__nav_5_9_2" id="__nav_5_9_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    generation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_2">
            <span class="md-nav__icon md-icon"></span>
            generation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transforemrs/generation/index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/beam_constraints/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_constraints
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/logits_process/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    logits_process
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/stopping_criteria/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    stopping_criteria
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/streamers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    streamers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    models
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_9_3" id="__nav_5_9_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_9_3">
            <span class="md-nav__icon md-icon"></span>
            models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../albert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    albert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../align/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    align
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../altclip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    altclip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../audio_spectrogram_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    audio_spectrogram_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../auto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    auto
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    autoformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../baichuan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    baichuan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    bark
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    bark
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkCoarseConfig
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig.from_sub_model_configs" class="md-nav__link">
    <span class="md-ellipsis">
      from_sub_model_configs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkFineConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkFineConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkSemanticConfig
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkGenerationConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkGenerationConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.from_sub_model_configs" class="md-nav__link">
    <span class="md-ellipsis">
      from_sub_model_configs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.to_dict" class="md-nav__link">
    <span class="md-ellipsis">
      to_dict
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkFineModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkFineModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_input_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_input_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_output_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_output_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.resize_token_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      resize_token_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_input_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      set_input_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_output_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      set_output_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.tie_weights" class="md-nav__link">
    <span class="md-ellipsis">
      tie_weights
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkSemanticModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkSemanticModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkCoarseModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkCoarseModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.preprocess_histories" class="md-nav__link">
    <span class="md-ellipsis">
      preprocess_histories
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.codec_decode" class="md-nav__link">
    <span class="md-ellipsis">
      codec_decode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkPreTrainedModel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkCausalModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkCausalModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.get_input_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_input_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.prepare_inputs_for_generation" class="md-nav__link">
    <span class="md-ellipsis">
      prepare_inputs_for_generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.set_input_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      set_input_embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      BarkProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.from_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      from_pretrained
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.save_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      save_pretrained
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../barthez/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    barthez
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bartpho/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bartpho
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../beit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert_japanese/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert_japanese
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bertweet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bertweet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bge_m3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bge_m3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../big_bird/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    big_bird
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bigbird_pegasus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bigbird_pegasus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../biogpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    biogpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blenderbot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blenderbot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blenderbot_small/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blenderbot_small
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blip_2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bloom
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bridgetower/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bridgetower
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bros/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bros
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../byt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    byt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../camembert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    camembert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../canine/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    canine
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    clip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../codegen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    codegen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cogvlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cogvlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cohere/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cohere
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convbert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convbert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convnext/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convnext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpmant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpmant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpmbee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpmbee
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ctrl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctrl
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cvt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cvt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data2vec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data2vec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    deberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deberta_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    deberta_v2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../decision_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decision_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distilbert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    distilbert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../efficientformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    efficientformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../efficientnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    efficientnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../electra/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    electra
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encodec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encodec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ernie/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ernie
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ernie_m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ernie_m
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../esm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    esm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    falcon
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../flava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    flava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../funnel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    funnel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gemma
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../git/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    git
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_bigcode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_bigcode
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neox/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neox
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neox_japanese/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neox_japanese
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_pangu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_pangu
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gptj/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gptj
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../graphormer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    graphormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../groupvit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    groupvit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hubert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hubert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../imagegpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    imagegpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../internlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    internlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jetmoe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jetmoe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../layoutlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    layoutlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../layoutlmv2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    layoutlmv2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../led/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    led
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llava_next/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llava_next
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../longformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    longformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../longt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    longt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../luke/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    luke
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../marian/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    marian
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../maskformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    maskformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mbart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mbart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    megatron_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron_gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    megatron_gpt2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../minicpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    minicpm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../minigpt4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    minigpt4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mistral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mixtral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mixtral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mobilebert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mobilebert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mobilevit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mobilevit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../moss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    moss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mpnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mpnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../musicgen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    musicgen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../musicgen_melody/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    musicgen_melody
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mvp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mvp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nezha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nezha
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nystromformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nystromformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../olmo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    olmo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../openelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    openelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../opt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    opt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../owlvit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    owlvit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pegasus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pegasus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phi
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phi3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../poolformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    poolformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pop2piano/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pop2piano
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../qwen2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    qwen2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../qwen2_moe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    qwen2_moe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rembert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rembert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../resnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    resnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roc_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roc_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rwkv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rwkv
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sam
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seamless_m4t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seamless_m4t
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seamless_m4t_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seamless_m4t_v2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../segformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    segformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seggpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seggpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speech_encoder_decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_encoder_decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speech_to_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_to_text
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../squeezebert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    squeezebert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stablelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    stablelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    starcoder2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../swiftformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    swiftformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../switch_transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    switch_transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    t5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../table_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    table_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../timesformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    timesformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tinybert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tinybert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../van/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    van
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vipllava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vipllava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vision_text_dual_encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vision_text_dual_encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../visual_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    visual_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2_conformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2_conformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2_with_lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2_with_lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wavlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../whisper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    whisper
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x_clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    x_clip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm_roberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm_roberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm_roberta_xl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm_roberta_xl
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlnet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_4" >
        
          
          <label class="md-nav__link" for="__nav_5_9_4" id="__nav_5_9_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_4">
            <span class="md-nav__icon md-icon"></span>
            pipeline
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transforemrs/pipeline/index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/automatic_speech_recognition/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    automatic_speech_recognition
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/document_question_answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    document_question_answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/fill_mask/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fill_mask
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/question_answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    question_answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text2text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text2text_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/zero_shot_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zero_shot_classification
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../configuration_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    configuration_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modeling_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    modeling_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils_base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils_base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils_fast/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils_fast
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../trl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TRL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Notes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/changelog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Change Log
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/code_of_conduct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code of Conduct
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkCoarseConfig
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig.from_sub_model_configs" class="md-nav__link">
    <span class="md-ellipsis">
      from_sub_model_configs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkFineConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkFineConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkSemanticConfig
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig" class="md-nav__link">
    <span class="md-ellipsis">
      BarkGenerationConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkGenerationConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.from_sub_model_configs" class="md-nav__link">
    <span class="md-ellipsis">
      from_sub_model_configs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.to_dict" class="md-nav__link">
    <span class="md-ellipsis">
      to_dict
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkFineModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkFineModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_input_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_input_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_output_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_output_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.resize_token_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      resize_token_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_input_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      set_input_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_output_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      set_output_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.tie_weights" class="md-nav__link">
    <span class="md-ellipsis">
      tie_weights
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkSemanticModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkSemanticModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkCoarseModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkCoarseModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.preprocess_histories" class="md-nav__link">
    <span class="md-ellipsis">
      preprocess_histories
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.codec_decode" class="md-nav__link">
    <span class="md-ellipsis">
      codec_decode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkPreTrainedModel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel" class="md-nav__link">
    <span class="md-ellipsis">
      BarkCausalModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkCausalModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.get_input_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_input_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.prepare_inputs_for_generation" class="md-nav__link">
    <span class="md-ellipsis">
      prepare_inputs_for_generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.set_input_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      set_input_embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      BarkProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BarkProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.from_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      from_pretrained
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.save_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      save_pretrained
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/mindspore-lab/mindnlp/edit/master/docs/en/api/transformers/models/bark.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindnlp/raw/master/docs/en/api/transformers/models/bark.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


  <h1>bark</h1>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig</code>


<a href="#mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSubModelConfig">BarkSubModelConfig</span></code></p>


        <p>BarkCoarseConfig is a Python class that represents the configuration settings for the coarse behavior model
in the Bark autonomous driving simulation framework.
This class inherits from the BarkSubModelConfig class.</p>
<p>The BarkCoarseConfig class provides a set of parameters and options that can be used to configure the behavior of the coarse model.
These parameters include settings related to the behavior model itself, such as the desired velocity,
acceleration limits, and time horizons, as well as settings for the perception model,
such as sensor range and field of view.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.desired_velocity">desired_velocity</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The desired velocity of the ego vehicle.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.max_acceleration">max_acceleration</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The maximum acceleration limit for the ego vehicle.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.min_acceleration">min_acceleration</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The minimum acceleration limit for the ego vehicle.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.horizon_time">horizon_time</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The time horizon for the behavior planning.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.perception_range">perception_range</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The range of the perception sensor.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.field_of_view">field_of_view</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The field of view of the perception sensor.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">METHOD</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.__init__">__init__</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Initializes a new instance of the BarkCoarseConfig class with the specified parameters.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.get_desired_velocity">get_desired_velocity</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the desired velocity of the ego vehicle.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.set_desired_velocity">set_desired_velocity</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the desired velocity of the ego vehicle.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.get_max_acceleration">get_max_acceleration</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the maximum acceleration limit for the ego vehicle.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.set_max_acceleration">set_max_acceleration</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the maximum acceleration limit for the ego vehicle.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.get_min_acceleration">get_min_acceleration</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the minimum acceleration limit for the ego vehicle.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.set_min_acceleration">set_min_acceleration</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the minimum acceleration limit for the ego vehicle.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.get_horizon_time">get_horizon_time</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the time horizon for the behavior planning.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.set_horizon_time">set_horizon_time</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the time horizon for the behavior planning.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.get_perception_range">get_perception_range</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the range of the perception sensor.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.set_perception_range">set_perception_range</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the range of the perception sensor.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.get_field_of_view">get_field_of_view</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the field of view of the perception sensor.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkCoarseConfig.set_field_of_view">set_field_of_view</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the field of view of the perception sensor.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\configuration_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkCoarseConfig</span><span class="p">(</span><span class="n">BarkSubModelConfig</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BarkCoarseConfig is a Python class that represents the configuration settings for the coarse behavior model</span>
<span class="sd">    in the Bark autonomous driving simulation framework.</span>
<span class="sd">    This class inherits from the BarkSubModelConfig class.</span>

<span class="sd">    The BarkCoarseConfig class provides a set of parameters and options that can be used to configure the behavior of the coarse model.</span>
<span class="sd">    These parameters include settings related to the behavior model itself, such as the desired velocity,</span>
<span class="sd">    acceleration limits, and time horizons, as well as settings for the perception model,</span>
<span class="sd">    such as sensor range and field of view.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        desired_velocity (float): The desired velocity of the ego vehicle.</span>
<span class="sd">        max_acceleration (float): The maximum acceleration limit for the ego vehicle.</span>
<span class="sd">        min_acceleration (float): The minimum acceleration limit for the ego vehicle.</span>
<span class="sd">        horizon_time (float): The time horizon for the behavior planning.</span>
<span class="sd">        perception_range (float): The range of the perception sensor.</span>
<span class="sd">        field_of_view (float): The field of view of the perception sensor.</span>

<span class="sd">    Methods:</span>
<span class="sd">        __init__(self, desired_velocity, max_acceleration, min_acceleration, horizon_time, perception_range, field_of_view):</span>
<span class="sd">            Initializes a new instance of the BarkCoarseConfig class with the specified parameters.</span>
<span class="sd">        get_desired_velocity(self): Returns the desired velocity of the ego vehicle.</span>
<span class="sd">        set_desired_velocity(self, desired_velocity): Sets the desired velocity of the ego vehicle.</span>
<span class="sd">        get_max_acceleration(self): Returns the maximum acceleration limit for the ego vehicle.</span>
<span class="sd">        set_max_acceleration(self, max_acceleration): Sets the maximum acceleration limit for the ego vehicle.</span>
<span class="sd">        get_min_acceleration(self): Returns the minimum acceleration limit for the ego vehicle.</span>
<span class="sd">        set_min_acceleration(self, min_acceleration): Sets the minimum acceleration limit for the ego vehicle.</span>
<span class="sd">        get_horizon_time(self): Returns the time horizon for the behavior planning.</span>
<span class="sd">        set_horizon_time(self, horizon_time): Sets the time horizon for the behavior planning.</span>
<span class="sd">        get_perception_range(self): Returns the range of the perception sensor.</span>
<span class="sd">        set_perception_range(self, perception_range): Sets the range of the perception sensor.</span>
<span class="sd">        get_field_of_view(self): Returns the field of view of the perception sensor.</span>
<span class="sd">        set_field_of_view(self, field_of_view): Sets the field of view of the perception sensor.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;coarse_acoustics&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.configuration_bark.BarkConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.configuration_bark.BarkConfig</code>


<a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code></p>


        <p>This is the configuration class to store the configuration of a [<code>BarkModel</code>]. It is used to instantiate a Bark
model according to the specified sub-models configurations, defining the model architecture.</p>
<p>Instantiating a configuration with the defaults will yield a similar configuration to that of the Bark
<a href="https://hf-mirror.com/suno/bark">suno/bark</a> architecture.</p>
<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the
documentation from [<code>PretrainedConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>semantic_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Configuration of the underlying semantic sub-model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`BarkSemanticConfig`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>coarse_acoustics_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Configuration of the underlying coarse acoustics sub-model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`BarkCoarseConfig`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fine_acoustics_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Configuration of the underlying fine acoustics sub-model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`BarkFineConfig`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>codec_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Configuration of the underlying codec sub-model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`AutoConfig`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
<span class="o">...</span>     <span class="n">BarkSemanticConfig</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">BarkCoarseConfig</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">BarkFineConfig</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">BarkModel</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">BarkConfig</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">AutoConfig</span><span class="p">,</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing Bark sub-modules configurations.</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">semantic_config</span> <span class="o">=</span> <span class="n">BarkSemanticConfig</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="n">BarkCoarseConfig</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="n">BarkFineConfig</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">codec_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/encodec_24khz&quot;</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a Bark module style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">BarkConfig</span><span class="o">.</span><span class="n">from_sub_model_configs</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">semantic_config</span><span class="p">,</span> <span class="n">coarse_acoustics_config</span><span class="p">,</span> <span class="n">fine_acoustics_config</span><span class="p">,</span> <span class="n">codec_config</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a model (with random weights)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">BarkModel</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Accessing the model configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
</code></pre></div>
</details>





              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\configuration_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the configuration class to store the configuration of a [`BarkModel`]. It is used to instantiate a Bark</span>
<span class="sd">    model according to the specified sub-models configurations, defining the model architecture.</span>

<span class="sd">    Instantiating a configuration with the defaults will yield a similar configuration to that of the Bark</span>
<span class="sd">    [suno/bark](https://hf-mirror.com/suno/bark) architecture.</span>

<span class="sd">    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the</span>
<span class="sd">    documentation from [`PretrainedConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        semantic_config ([`BarkSemanticConfig`], *optional*):</span>
<span class="sd">            Configuration of the underlying semantic sub-model.</span>
<span class="sd">        coarse_acoustics_config ([`BarkCoarseConfig`], *optional*):</span>
<span class="sd">            Configuration of the underlying coarse acoustics sub-model.</span>
<span class="sd">        fine_acoustics_config ([`BarkFineConfig`], *optional*):</span>
<span class="sd">            Configuration of the underlying fine acoustics sub-model.</span>
<span class="sd">        codec_config ([`AutoConfig`], *optional*):</span>
<span class="sd">            Configuration of the underlying codec sub-model.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import (</span>
<span class="sd">        ...     BarkSemanticConfig,</span>
<span class="sd">        ...     BarkCoarseConfig,</span>
<span class="sd">        ...     BarkFineConfig,</span>
<span class="sd">        ...     BarkModel,</span>
<span class="sd">        ...     BarkConfig,</span>
<span class="sd">        ...     AutoConfig,</span>
<span class="sd">        ... )</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing Bark sub-modules configurations.</span>
<span class="sd">        &gt;&gt;&gt; semantic_config = BarkSemanticConfig()</span>
<span class="sd">        &gt;&gt;&gt; coarse_acoustics_config = BarkCoarseConfig()</span>
<span class="sd">        &gt;&gt;&gt; fine_acoustics_config = BarkFineConfig()</span>
<span class="sd">        &gt;&gt;&gt; codec_config = AutoConfig.from_pretrained(&quot;facebook/encodec_24khz&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a Bark module style configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = BarkConfig.from_sub_model_configs(</span>
<span class="sd">        ...     semantic_config, coarse_acoustics_config, fine_acoustics_config, codec_config</span>
<span class="sd">        ... )</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a model (with random weights)</span>
<span class="sd">        &gt;&gt;&gt; model = BarkModel(configuration)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Accessing the model configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = model.config</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;bark&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">semantic_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">coarse_acoustics_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fine_acoustics_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">codec_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a BarkConfig object with the provided configurations.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the BarkConfig class.</span>
<span class="sd">            semantic_config (Dict): Dictionary containing configuration for the semantic model. Defaults to None.</span>
<span class="sd">            coarse_acoustics_config (Dict): Dictionary containing configuration for the coarse acoustics model. Defaults to None.</span>
<span class="sd">            fine_acoustics_config (Dict): Dictionary containing configuration for the fine acoustics model. Defaults to None.</span>
<span class="sd">            codec_config (Dict): Dictionary containing configuration for the codec model. Defaults to None.</span>
<span class="sd">            initializer_range (float): Range for weight initialization. Defaults to 0.02.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">semantic_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">semantic_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;semantic_config is None. initializing the semantic model with default values.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">coarse_acoustics_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;coarse_acoustics_config is None. initializing the coarse model with default values.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fine_acoustics_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;fine_acoustics_config is None. initializing the fine model with default values.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">codec_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">codec_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;codec_config is None. initializing the codec model with default values.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">semantic_config</span> <span class="o">=</span> <span class="n">BarkSemanticConfig</span><span class="p">(</span><span class="o">**</span><span class="n">semantic_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="n">BarkCoarseConfig</span><span class="p">(</span><span class="o">**</span><span class="n">coarse_acoustics_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="n">BarkFineConfig</span><span class="p">(</span><span class="o">**</span><span class="n">fine_acoustics_config</span><span class="p">)</span>
        <span class="n">codec_model_type</span> <span class="o">=</span> <span class="n">codec_config</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;model_type&quot;</span> <span class="ow">in</span> <span class="n">codec_config</span> <span class="k">else</span> <span class="s2">&quot;encodec&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">codec_config</span> <span class="o">=</span> <span class="n">CONFIG_MAPPING</span><span class="p">[</span><span class="n">codec_model_type</span><span class="p">](</span><span class="o">**</span><span class="n">codec_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_sub_model_configs</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">semantic_config</span><span class="p">:</span> <span class="n">BarkSemanticConfig</span><span class="p">,</span>
        <span class="n">coarse_acoustics_config</span><span class="p">:</span> <span class="n">BarkCoarseConfig</span><span class="p">,</span>
        <span class="n">fine_acoustics_config</span><span class="p">:</span> <span class="n">BarkFineConfig</span><span class="p">,</span>
        <span class="n">codec_config</span><span class="p">:</span> <span class="n">PretrainedConfig</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate a [`BarkConfig`] (or a derived class) from bark sub-models configuration.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`BarkConfig`]: An instance of a configuration object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">semantic_config</span><span class="o">=</span><span class="n">semantic_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
            <span class="n">coarse_acoustics_config</span><span class="o">=</span><span class="n">coarse_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
            <span class="n">fine_acoustics_config</span><span class="o">=</span><span class="n">fine_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
            <span class="n">codec_config</span><span class="o">=</span><span class="n">codec_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.configuration_bark.BarkConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">configuration_bark</span><span class="o">.</span><span class="n">BarkConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">semantic_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">coarse_acoustics_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fine_acoustics_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">codec_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initializes a BarkConfig object with the provided configurations.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the BarkConfig class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>semantic_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary containing configuration for the semantic model. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Dict">Dict</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>coarse_acoustics_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary containing configuration for the coarse acoustics model. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Dict">Dict</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fine_acoustics_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary containing configuration for the fine acoustics model. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Dict">Dict</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>codec_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary containing configuration for the codec model. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Dict">Dict</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_range</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Range for weight initialization. Defaults to 0.02.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.02</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\configuration_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">semantic_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">coarse_acoustics_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fine_acoustics_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">codec_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a BarkConfig object with the provided configurations.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The instance of the BarkConfig class.</span>
<span class="sd">        semantic_config (Dict): Dictionary containing configuration for the semantic model. Defaults to None.</span>
<span class="sd">        coarse_acoustics_config (Dict): Dictionary containing configuration for the coarse acoustics model. Defaults to None.</span>
<span class="sd">        fine_acoustics_config (Dict): Dictionary containing configuration for the fine acoustics model. Defaults to None.</span>
<span class="sd">        codec_config (Dict): Dictionary containing configuration for the codec model. Defaults to None.</span>
<span class="sd">        initializer_range (float): Range for weight initialization. Defaults to 0.02.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">semantic_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">semantic_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;semantic_config is None. initializing the semantic model with default values.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">coarse_acoustics_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;coarse_acoustics_config is None. initializing the coarse model with default values.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">fine_acoustics_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;fine_acoustics_config is None. initializing the fine model with default values.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">codec_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">codec_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;codec_config is None. initializing the codec model with default values.&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">semantic_config</span> <span class="o">=</span> <span class="n">BarkSemanticConfig</span><span class="p">(</span><span class="o">**</span><span class="n">semantic_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="n">BarkCoarseConfig</span><span class="p">(</span><span class="o">**</span><span class="n">coarse_acoustics_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="n">BarkFineConfig</span><span class="p">(</span><span class="o">**</span><span class="n">fine_acoustics_config</span><span class="p">)</span>
    <span class="n">codec_model_type</span> <span class="o">=</span> <span class="n">codec_config</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;model_type&quot;</span> <span class="ow">in</span> <span class="n">codec_config</span> <span class="k">else</span> <span class="s2">&quot;encodec&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">codec_config</span> <span class="o">=</span> <span class="n">CONFIG_MAPPING</span><span class="p">[</span><span class="n">codec_model_type</span><span class="p">](</span><span class="o">**</span><span class="n">codec_config</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.configuration_bark.BarkConfig.from_sub_model_configs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">configuration_bark</span><span class="o">.</span><span class="n">BarkConfig</span><span class="o">.</span><span class="n">from_sub_model_configs</span><span class="p">(</span><span class="n">semantic_config</span><span class="p">,</span> <span class="n">coarse_acoustics_config</span><span class="p">,</span> <span class="n">fine_acoustics_config</span><span class="p">,</span> <span class="n">codec_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#mindnlp.transformers.models.bark.configuration_bark.BarkConfig.from_sub_model_configs" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Instantiate a [<code>BarkConfig</code>] (or a derived class) from bark sub-models configuration.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>BarkConfig</code>]: An instance of a configuration object</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\configuration_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_sub_model_configs</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">semantic_config</span><span class="p">:</span> <span class="n">BarkSemanticConfig</span><span class="p">,</span>
    <span class="n">coarse_acoustics_config</span><span class="p">:</span> <span class="n">BarkCoarseConfig</span><span class="p">,</span>
    <span class="n">fine_acoustics_config</span><span class="p">:</span> <span class="n">BarkFineConfig</span><span class="p">,</span>
    <span class="n">codec_config</span><span class="p">:</span> <span class="n">PretrainedConfig</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Instantiate a [`BarkConfig`] (or a derived class) from bark sub-models configuration.</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`BarkConfig`]: An instance of a configuration object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
        <span class="n">semantic_config</span><span class="o">=</span><span class="n">semantic_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
        <span class="n">coarse_acoustics_config</span><span class="o">=</span><span class="n">coarse_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
        <span class="n">fine_acoustics_config</span><span class="o">=</span><span class="n">fine_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
        <span class="n">codec_config</span><span class="o">=</span><span class="n">codec_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig</code>


<a href="#mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSubModelConfig">BarkSubModelConfig</span></code></p>


        <p>BarkFineConfig represents the configuration settings for a fine-tuning model within the Bark framework.
This class inherits from BarkSubModelConfig and provides parameters for configuring the fine-tuning process,
including options for tying word embeddings, specifying the total number of codes, and the number of codes given.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tie_word_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Flag indicating whether to tie word embeddings during fine-tuning.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_codes_total</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The total number of codes used in the fine-tuning model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_codes_given</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of codes given as input to the fine-tuning model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Inherits from BarkSubModelConfig and initializes the configuration settings for the fine-tuning model based on the provided parameters.</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\configuration_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkFineConfig</span><span class="p">(</span><span class="n">BarkSubModelConfig</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BarkFineConfig represents the configuration settings for a fine-tuning model within the Bark framework.</span>
<span class="sd">    This class inherits from BarkSubModelConfig and provides parameters for configuring the fine-tuning process,</span>
<span class="sd">    including options for tying word embeddings, specifying the total number of codes, and the number of codes given.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        tie_word_embeddings (bool): Flag indicating whether to tie word embeddings during fine-tuning.</span>
<span class="sd">        n_codes_total (int): The total number of codes used in the fine-tuning model.</span>
<span class="sd">        n_codes_given (int): The number of codes given as input to the fine-tuning model.</span>

<span class="sd">    Inherits from BarkSubModelConfig and initializes the configuration settings for the fine-tuning model based on the provided parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;fine_acoustics&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tie_word_embeddings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_codes_total</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_codes_given</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes a new instance of the BarkFineConfig class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkFineConfig): The object instance.</span>
<span class="sd">            tie_word_embeddings (bool): Whether to tie the word embeddings of the model. Defaults to True.</span>
<span class="sd">            n_codes_total (int): The total number of codes. Defaults to 8.</span>
<span class="sd">            n_codes_given (int): The number of given codes. Defaults to 1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_codes_total</span> <span class="o">=</span> <span class="n">n_codes_total</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_codes_given</span> <span class="o">=</span> <span class="n">n_codes_given</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">tie_word_embeddings</span><span class="o">=</span><span class="n">tie_word_embeddings</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">configuration_bark</span><span class="o">.</span><span class="n">BarkFineConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">tie_word_embeddings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_codes_total</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_codes_given</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initializes a new instance of the BarkFineConfig class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The object instance.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig" href="#mindnlp.transformers.models.bark.configuration_bark.BarkFineConfig">BarkFineConfig</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tie_word_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to tie the word embeddings of the model. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_codes_total</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The total number of codes. Defaults to 8.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_codes_given</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of given codes. Defaults to 1.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\configuration_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tie_word_embeddings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_codes_total</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_codes_given</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes a new instance of the BarkFineConfig class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkFineConfig): The object instance.</span>
<span class="sd">        tie_word_embeddings (bool): Whether to tie the word embeddings of the model. Defaults to True.</span>
<span class="sd">        n_codes_total (int): The total number of codes. Defaults to 8.</span>
<span class="sd">        n_codes_given (int): The number of given codes. Defaults to 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_codes_total</span> <span class="o">=</span> <span class="n">n_codes_total</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_codes_given</span> <span class="o">=</span> <span class="n">n_codes_given</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">tie_word_embeddings</span><span class="o">=</span><span class="n">tie_word_embeddings</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig</code>


<a href="#mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSubModelConfig">BarkSubModelConfig</span></code></p>


        <p>Represents a configuration class for semantic segmentation models in the Bark framework.
This class inherits properties and methods from the BarkSubModelConfig class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.model_name">model_name</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The name of the semantic segmentation model.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.num_classes">num_classes</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The number of classes in the semantic segmentation task.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.input_shape">input_shape</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The input shape of the model in the format (height, width, channels).</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>tuple</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.backbone">backbone</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The backbone architecture used in the model.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.pretrained_backbone">pretrained_backbone</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Indicates if a pretrained backbone is used.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.normalization">normalization</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The type of normalization applied to the input data.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.loss_function">loss_function</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The loss function used for training the model.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.optimizer">optimizer</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The optimizer used during model training.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">METHOD</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.set_model_name">set_model_name</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the name of the semantic segmentation model.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.set_num_classes">set_num_classes</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the number of classes in the semantic segmentation task.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.set_input_shape">set_input_shape</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the input shape of the model.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.set_backbone">set_backbone</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the backbone architecture used in the model.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.set_pretrained_backbone">set_pretrained_backbone</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets whether a pretrained backbone is used.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.set_normalization">set_normalization</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the type of normalization applied to the input data.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.set_loss_function">set_loss_function</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the loss function used for training the model.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.configuration_bark.BarkSemanticConfig.set_optimizer">set_optimizer</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the optimizer used during model training.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\configuration_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkSemanticConfig</span><span class="p">(</span><span class="n">BarkSubModelConfig</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a configuration class for semantic segmentation models in the Bark framework.</span>
<span class="sd">    This class inherits properties and methods from the BarkSubModelConfig class.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        model_name (str): The name of the semantic segmentation model.</span>
<span class="sd">        num_classes (int): The number of classes in the semantic segmentation task.</span>
<span class="sd">        input_shape (tuple): The input shape of the model in the format (height, width, channels).</span>
<span class="sd">        backbone (str): The backbone architecture used in the model.</span>
<span class="sd">        pretrained_backbone (bool): Indicates if a pretrained backbone is used.</span>
<span class="sd">        normalization (str): The type of normalization applied to the input data.</span>
<span class="sd">        loss_function (str): The loss function used for training the model.</span>
<span class="sd">        optimizer (str): The optimizer used during model training.</span>

<span class="sd">    Methods:</span>
<span class="sd">        set_model_name:</span>
<span class="sd">            Sets the name of the semantic segmentation model.</span>

<span class="sd">        set_num_classes:</span>
<span class="sd">            Sets the number of classes in the semantic segmentation task.</span>

<span class="sd">        set_input_shape:</span>
<span class="sd">            Sets the input shape of the model.</span>

<span class="sd">        set_backbone:</span>
<span class="sd">            Sets the backbone architecture used in the model.</span>

<span class="sd">        set_pretrained_backbone:</span>
<span class="sd">            Sets whether a pretrained backbone is used.</span>

<span class="sd">        set_normalization:</span>
<span class="sd">            Sets the type of normalization applied to the input data.</span>

<span class="sd">        set_loss_function:</span>
<span class="sd">            Sets the loss function used for training the model.</span>

<span class="sd">        set_optimizer:</span>
<span class="sd">            Sets the optimizer used during model training.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;semantic&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig</code>


<a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.generation.configuration_utils.GenerationConfig">GenerationConfig</span></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\generation_configuration_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkGenerationConfig</span><span class="p">(</span><span class="n">GenerationConfig</span><span class="p">):</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;bark&quot;</span>
    <span class="n">is_composition</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># TODO (joao): nested from_dict</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">semantic_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">coarse_acoustics_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fine_acoustics_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="o">=</span><span class="mi">24_000</span><span class="p">,</span>
        <span class="n">codebook_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Class that holds a generation configuration for [`BarkModel`].</span>

<span class="sd">        The [`BarkModel`] does not have a `generate` method, but uses this class to generate speeches with a nested</span>
<span class="sd">        [`BarkGenerationConfig`] which uses [`BarkSemanticGenerationConfig`], [`BarkCoarseGenerationConfig`],</span>
<span class="sd">        [`BarkFineGenerationConfig`].</span>

<span class="sd">        This configuration inherit from [`GenerationConfig`] and can be used to control the model generation. Read the</span>
<span class="sd">        documentation from [`GenerationConfig`] for more information.</span>

<span class="sd">        Args:</span>
<span class="sd">            semantic_config (`Dict`, *optional*):</span>
<span class="sd">                Semantic generation configuration.</span>
<span class="sd">            coarse_acoustics_config (`Dict`, *optional*):</span>
<span class="sd">                Coarse generation configuration.</span>
<span class="sd">            fine_acoustics_config (`Dict`, *optional*):</span>
<span class="sd">                Fine generation configuration.</span>
<span class="sd">            sample_rate (`int`, *optional*, defaults to 24_000):</span>
<span class="sd">                Sample rate.</span>
<span class="sd">            codebook_size (`int`, *optional*, defaults to 1024):</span>
<span class="sd">                Vector length for each codebook.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">semantic_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">semantic_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;semantic_config is None. initializing the semantic model with default values.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">coarse_acoustics_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;coarse_acoustics_config is None. initializing the coarse model with default values.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fine_acoustics_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;fine_acoustics_config is None. initializing the fine model with default values.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">semantic_config</span> <span class="o">=</span> <span class="n">BarkSemanticGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="n">semantic_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="n">BarkCoarseGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="n">coarse_acoustics_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="n">BarkFineGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="n">fine_acoustics_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">codebook_size</span> <span class="o">=</span> <span class="n">codebook_size</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_sub_model_configs</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">semantic_config</span><span class="p">:</span> <span class="n">BarkSemanticGenerationConfig</span><span class="p">,</span>
        <span class="n">coarse_acoustics_config</span><span class="p">:</span> <span class="n">BarkCoarseGenerationConfig</span><span class="p">,</span>
        <span class="n">fine_acoustics_config</span><span class="p">:</span> <span class="n">BarkFineGenerationConfig</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate a [`BarkGenerationConfig`] (or a derived class) from bark sub-models generation configuration.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`BarkGenerationConfig`]: An instance of a configuration object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">semantic_config</span><span class="o">=</span><span class="n">semantic_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
            <span class="n">coarse_acoustics_config</span><span class="o">=</span><span class="n">coarse_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
            <span class="n">fine_acoustics_config</span><span class="o">=</span><span class="n">fine_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Serializes this instance to a Python dictionary. Override the default [`~PretrainedConfig.to_dict`].</span>

<span class="sd">        Returns:</span>
<span class="sd">            `Dict[str, any]`: Dictionary of all the attributes that make up this configuration instance,</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>

        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;semantic_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">semantic_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;coarse_acoustics_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;fine_acoustics_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">model_type</span>
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">generation_configuration_bark</span><span class="o">.</span><span class="n">BarkGenerationConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">semantic_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">coarse_acoustics_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fine_acoustics_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">24000</span><span class="p">,</span> <span class="n">codebook_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Class that holds a generation configuration for [<code>BarkModel</code>].</p>
<p>The [<code>BarkModel</code>] does not have a <code>generate</code> method, but uses this class to generate speeches with a nested
[<code>BarkGenerationConfig</code>] which uses [<code>BarkSemanticGenerationConfig</code>], [<code>BarkCoarseGenerationConfig</code>],
[<code>BarkFineGenerationConfig</code>].</p>
<p>This configuration inherit from [<code>GenerationConfig</code>] and can be used to control the model generation. Read the
documentation from [<code>GenerationConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>semantic_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Semantic generation configuration.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>coarse_acoustics_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Coarse generation configuration.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fine_acoustics_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Fine generation configuration.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sample_rate</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Sample rate.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 24_000</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>24000</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>codebook_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Vector length for each codebook.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1024</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\generation_configuration_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">semantic_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">coarse_acoustics_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fine_acoustics_config</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="o">=</span><span class="mi">24_000</span><span class="p">,</span>
    <span class="n">codebook_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class that holds a generation configuration for [`BarkModel`].</span>

<span class="sd">    The [`BarkModel`] does not have a `generate` method, but uses this class to generate speeches with a nested</span>
<span class="sd">    [`BarkGenerationConfig`] which uses [`BarkSemanticGenerationConfig`], [`BarkCoarseGenerationConfig`],</span>
<span class="sd">    [`BarkFineGenerationConfig`].</span>

<span class="sd">    This configuration inherit from [`GenerationConfig`] and can be used to control the model generation. Read the</span>
<span class="sd">    documentation from [`GenerationConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        semantic_config (`Dict`, *optional*):</span>
<span class="sd">            Semantic generation configuration.</span>
<span class="sd">        coarse_acoustics_config (`Dict`, *optional*):</span>
<span class="sd">            Coarse generation configuration.</span>
<span class="sd">        fine_acoustics_config (`Dict`, *optional*):</span>
<span class="sd">            Fine generation configuration.</span>
<span class="sd">        sample_rate (`int`, *optional*, defaults to 24_000):</span>
<span class="sd">            Sample rate.</span>
<span class="sd">        codebook_size (`int`, *optional*, defaults to 1024):</span>
<span class="sd">            Vector length for each codebook.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">semantic_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">semantic_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;semantic_config is None. initializing the semantic model with default values.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">coarse_acoustics_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;coarse_acoustics_config is None. initializing the coarse model with default values.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">fine_acoustics_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;fine_acoustics_config is None. initializing the fine model with default values.&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">semantic_config</span> <span class="o">=</span> <span class="n">BarkSemanticGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="n">semantic_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics_config</span> <span class="o">=</span> <span class="n">BarkCoarseGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="n">coarse_acoustics_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics_config</span> <span class="o">=</span> <span class="n">BarkFineGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="n">fine_acoustics_config</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">codebook_size</span> <span class="o">=</span> <span class="n">codebook_size</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.from_sub_model_configs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">generation_configuration_bark</span><span class="o">.</span><span class="n">BarkGenerationConfig</span><span class="o">.</span><span class="n">from_sub_model_configs</span><span class="p">(</span><span class="n">semantic_config</span><span class="p">,</span> <span class="n">coarse_acoustics_config</span><span class="p">,</span> <span class="n">fine_acoustics_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.from_sub_model_configs" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Instantiate a [<code>BarkGenerationConfig</code>] (or a derived class) from bark sub-models generation configuration.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>BarkGenerationConfig</code>]: An instance of a configuration object</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\generation_configuration_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_sub_model_configs</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">semantic_config</span><span class="p">:</span> <span class="n">BarkSemanticGenerationConfig</span><span class="p">,</span>
    <span class="n">coarse_acoustics_config</span><span class="p">:</span> <span class="n">BarkCoarseGenerationConfig</span><span class="p">,</span>
    <span class="n">fine_acoustics_config</span><span class="p">:</span> <span class="n">BarkFineGenerationConfig</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Instantiate a [`BarkGenerationConfig`] (or a derived class) from bark sub-models generation configuration.</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`BarkGenerationConfig`]: An instance of a configuration object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
        <span class="n">semantic_config</span><span class="o">=</span><span class="n">semantic_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
        <span class="n">coarse_acoustics_config</span><span class="o">=</span><span class="n">coarse_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
        <span class="n">fine_acoustics_config</span><span class="o">=</span><span class="n">fine_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.to_dict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">generation_configuration_bark</span><span class="o">.</span><span class="n">BarkGenerationConfig</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span></code>

<a href="#mindnlp.transformers.models.bark.generation_configuration_bark.BarkGenerationConfig.to_dict" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Serializes this instance to a Python dictionary. Override the default [<code>~PretrainedConfig.to_dict</code>].</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>Dict[str, any]</code>: Dictionary of all the attributes that make up this configuration instance,</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\generation_configuration_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Serializes this instance to a Python dictionary. Override the default [`~PretrainedConfig.to_dict`].</span>

<span class="sd">    Returns:</span>
<span class="sd">        `Dict[str, any]`: Dictionary of all the attributes that make up this configuration instance,</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>

    <span class="n">output</span><span class="p">[</span><span class="s2">&quot;semantic_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">semantic_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="n">output</span><span class="p">[</span><span class="s2">&quot;coarse_acoustics_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="n">output</span><span class="p">[</span><span class="s2">&quot;fine_acoustics_config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

    <span class="n">output</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">model_type</span>
    <span class="k">return</span> <span class="n">output</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.modeling_bark.BarkFineModel</code>


<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel">BarkPreTrainedModel</a></code></p>


        <p>BarkFineModel is a model for generating fine acoustics tokens from input coarse acoustics tokens and optional prompts,
building on the BarkPreTrainedModel base class.</p>
<p>This class provides methods for resizing token embeddings, tying weights between input and output embeddings, and
generating fine acoustics tokens based on input coarse acoustics tokens and generation configurations.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.config">config</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Configuration object containing model settings.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">METHOD</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.resize_token_embeddings" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.resize_token_embeddings">resize_token_embeddings</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Resizes the input token embeddings matrix of the model, taking care of tying weights embeddings afterwards
if necessary.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.tie_weights" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.tie_weights">tie_weights</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Ties the weights between the input embeddings list and the output embeddings list.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.generate" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.generate">generate</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Generates fine acoustics tokens from input coarse acoustics tokens and optional speaker prompts,
following specified generation configurations.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel._resize_token_embeddings">_resize_token_embeddings</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Helper method to resize the token embeddings matrix.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_input_embeddings" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_input_embeddings">get_input_embeddings</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the input embeddings layers.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_input_embeddings" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_input_embeddings">set_input_embeddings</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets new input embeddings layers.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_output_embeddings" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_output_embeddings">get_output_embeddings</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the output embeddings layers.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_output_embeddings" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_output_embeddings">set_output_embeddings</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets new output embeddings layers.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.forward" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.forward">forward</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>forwards the model for a specific codebook index, handling input tokens, masks, and labels accordingly.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span>
<span class="normal">1568</span>
<span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkFineModel</span><span class="p">(</span><span class="n">BarkPreTrainedModel</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BarkFineModel is a model for generating fine acoustics tokens from input coarse acoustics tokens and optional prompts,</span>
<span class="sd">    building on the BarkPreTrainedModel base class.</span>

<span class="sd">    This class provides methods for resizing token embeddings, tying weights between input and output embeddings, and</span>
<span class="sd">    generating fine acoustics tokens based on input coarse acoustics tokens and generation configurations.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        config: Configuration object containing model settings.</span>

<span class="sd">    Methods:</span>
<span class="sd">        resize_token_embeddings:</span>
<span class="sd">            Resizes the input token embeddings matrix of the model, taking care of tying weights embeddings afterwards</span>
<span class="sd">            if necessary.</span>

<span class="sd">        tie_weights():</span>
<span class="sd">            Ties the weights between the input embeddings list and the output embeddings list.</span>

<span class="sd">        generate:</span>
<span class="sd">            Generates fine acoustics tokens from input coarse acoustics tokens and optional speaker prompts,</span>
<span class="sd">            following specified generation configurations.</span>

<span class="sd">        _resize_token_embeddings:</span>
<span class="sd">            Helper method to resize the token embeddings matrix.</span>

<span class="sd">        get_input_embeddings() -&gt; nn.ModuleList:</span>
<span class="sd">            Returns the input embeddings layers.</span>

<span class="sd">        set_input_embeddings(new_embeddings):</span>
<span class="sd">            Sets new input embeddings layers.</span>

<span class="sd">        get_output_embeddings() -&gt; nn.ModuleList:</span>
<span class="sd">            Returns the output embeddings layers.</span>

<span class="sd">        set_output_embeddings(new_output_embeddings):</span>
<span class="sd">            Sets new output embeddings layers.</span>

<span class="sd">        forward:</span>
<span class="sd">            forwards the model for a specific codebook index, handling input tokens, masks, and labels accordingly.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base_model_prefix</span> <span class="o">=</span> <span class="s2">&quot;fine_acoustics&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">BarkFineConfig</span>
    <span class="n">main_input_name</span> <span class="o">=</span> <span class="s2">&quot;codebook_idx&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a BarkFineModel object.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">            config (Config):</span>
<span class="sd">                An object containing configuration parameters for the model.</span>
<span class="sd">                Parameters:</span>

<span class="sd">                - input_vocab_size (int): The size of the input vocabulary.</span>
<span class="sd">                - hidden_size (int): The size of the hidden layers.</span>
<span class="sd">                - block_size (int): The size of the blocks in the model.</span>
<span class="sd">                - dropout (float): The dropout rate.</span>
<span class="sd">                - num_layers (int): The number of layers in the model.</span>
<span class="sd">                - output_vocab_size (int): The size of the output vocabulary.</span>
<span class="sd">                - n_codes_total (int): The total number of codes used.</span>
<span class="sd">                - n_codes_given (int): The number of codes given.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># non-causal gpt-like model with one embedding layer and one lm_head for each codebook of Encodec</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

        <span class="c1"># initialize a modified non causal GPT-like model</span>
        <span class="c1"># note that for there is one embedding layer and one lm_head for each codebook of Encodec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_total</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embeds_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">BarkBlock</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">is_causal</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layernorm_final</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lm_heads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">output_vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_given</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_codes_total</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_codes_total</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">n_codes_total</span>

        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method retrieves the input embeddings for the BarkFineModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkFineModel): The instance of the BarkFineModel class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None: This method returns the input embeddings layers for the BarkFineModel.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># one embedding layers for each codebook</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layers</span>

    <span class="k">def</span> <span class="nf">set_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_embeddings</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the input embeddings for the BarkFineModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">            new_embeddings (object): The new embeddings to set for the input_embeds_layers attribute.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># one embedding layers for each codebook</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layers</span> <span class="o">=</span> <span class="n">new_embeddings</span>

    <span class="k">def</span> <span class="nf">get_output_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method is defined in the class &#39;BarkFineModel&#39; and is used to retrieve the output embeddings of the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: An instance of the &#39;BarkFineModel&#39; class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># one lm_head for each codebook</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_heads</span>

    <span class="k">def</span> <span class="nf">set_output_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_output_embeddings</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to set new output embeddings for the BarkFineModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">            new_output_embeddings (object): New output embeddings to be set for the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># one lm_head for each codebook</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_heads</span> <span class="o">=</span> <span class="n">new_output_embeddings</span>

    <span class="k">def</span> <span class="nf">_resize_token_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Resize the token embeddings for the BarkFineModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">            new_num_tokens (int): The new number of tokens to resize the embeddings to.</span>
<span class="sd">            pad_to_multiple_of (int or None): If provided, the embeddings will be padded to be a multiple of this value.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None: The method updates the token embeddings of the model in place.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If new_num_tokens is not an integer.</span>
<span class="sd">            ValueError: If new_num_tokens is less than or equal to 0.</span>
<span class="sd">            ValueError: If pad_to_multiple_of is provided but is not an integer.</span>
<span class="sd">            ValueError: If pad_to_multiple_of is less than or equal to 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">old_embeddings_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>
        <span class="n">new_embeddings_list</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_get_resized_embeddings</span><span class="p">(</span><span class="n">old_embeddings</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">old_embeddings</span> <span class="ow">in</span> <span class="n">old_embeddings_list</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_input_embeddings</span><span class="p">(</span><span class="n">new_embeddings_list</span><span class="p">)</span>
        <span class="n">new_num_tokens</span> <span class="o">=</span> <span class="n">new_embeddings_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># if word embeddings are not tied, make sure that lm head is resized as well</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">tie_word_embeddings</span><span class="p">:</span>
            <span class="n">old_lm_head_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span>
            <span class="n">new_lm_head_list</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
                <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_resized_lm_head</span><span class="p">(</span><span class="n">old_lm_head</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">)</span> <span class="k">for</span> <span class="n">old_lm_head</span> <span class="ow">in</span> <span class="n">old_lm_head_list</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_output_embeddings</span><span class="p">(</span><span class="n">new_lm_head_list</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">resize_token_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Resizes input token embeddings matrix of the model if `new_num_tokens != config.vocab_size`.</span>

<span class="sd">        Takes care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            new_num_tokens (`int`, *optional*):</span>
<span class="sd">                The number of new tokens in the embedding matrix. Increasing the size will add newly initialized</span>
<span class="sd">                vectors at the end. Reducing the size will remove vectors from the end. If not provided or `None`, just</span>
<span class="sd">                returns a pointer to the input tokens `nn.Embedding` module of the model without doing anything.</span>
<span class="sd">            pad_to_multiple_of (`int`, *optional*):</span>
<span class="sd">                If set will pad the embedding matrix to a multiple of the provided value.</span>

<span class="sd">                This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability</span>
<span class="sd">                `&gt;= 7.5` (Volta), or on TPUs which benefit from having sequence lengths be a multiple of 128. For more</span>
<span class="sd">                details about this, or help on choosing the correct value for resizing, refer to this guide:</span>
<span class="sd">                https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc</span>

<span class="sd">        Returns:</span>
<span class="sd">            `nn.Embedding`: Pointer to the input tokens Embeddings Module of the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resize_token_embeddings</span><span class="p">(</span><span class="n">new_num_tokens</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_num_tokens</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">pad_to_multiple_of</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">model_embeds</span>

        <span class="c1"># Update base model and current model config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_vocab_size</span> <span class="o">=</span> <span class="n">model_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_vocab_size</span> <span class="o">=</span> <span class="n">model_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Tie weights again if needed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tie_weights</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">model_embeds</span>

    <span class="k">def</span> <span class="nf">tie_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tie the weights between the input embeddings list and the output embeddings list.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;tie_word_embeddings&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tied_weights_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">output_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span>
            <span class="n">input_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_total</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_given</span><span class="p">):</span>
                <span class="c1"># self.input_embeds_layers[i + 1].weight = self.lm_heads[i].weight</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_tie_or_clone_weights</span><span class="p">(</span><span class="n">output_embeddings</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">input_embeddings</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_tied_weights_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;lm_heads.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.weight&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s2">&quot;_tie_weights&quot;</span><span class="p">):</span>
                <span class="n">module</span><span class="o">.</span><span class="n">_tie_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">codebook_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>  <span class="c1"># an additionnal idx corresponding to the id of the codebook that will be predicted</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">head_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">MaskedLMOutput</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        forward and process the input data for the BarkFineModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">            codebook_idx (int): Index of the codebook to predict.</span>
<span class="sd">            input_ids (Optional[mindspore.Tensor], optional): Input tensor containing the tokenized input sequence. Defaults to None.</span>
<span class="sd">            attention_mask (Optional[mindspore.Tensor], optional): Tensor indicating which tokens should be attended to. Defaults to None.</span>
<span class="sd">            position_ids (Optional[mindspore.Tensor], optional): Tensor containing the position indices of each input token. Defaults to None.</span>
<span class="sd">            head_mask (Optional[mindspore.Tensor], optional): Tensor specifying which attention heads to mask. Defaults to None.</span>
<span class="sd">            labels (Optional[mindspore.Tensor], optional): Tensor containing the labels for the masked language modeling task. Defaults to None.</span>
<span class="sd">            input_embeds (Optional[mindspore.Tensor], optional): Tensor containing the input embeddings. Defaults to None.</span>
<span class="sd">            output_attentions (Optional[bool], optional): Whether to output attention weights. Defaults to None.</span>
<span class="sd">            output_hidden_states (Optional[bool], optional): Whether to output hidden states. Defaults to None.</span>
<span class="sd">            return_dict (Optional[bool], optional): Whether to return a dictionary instead of a tuple. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[Tuple[mindspore.Tensor], MaskedLMOutput]:</span>
<span class="sd">                If `return_dict` is False, returns a tuple containing the following:</span>

<span class="sd">                - None: Placeholder for loss value (None for this method).</span>
<span class="sd">                - logits (mindspore.Tensor): Predicted logits for masked language modeling task.</span>
<span class="sd">                - all_hidden_states (Tuple[mindspore.Tensor]): Tuple of hidden states for each layer.</span>
<span class="sd">                - all_self_attentions (Tuple[mindspore.Tensor]): Tuple of attention weights for each layer.</span>

<span class="sd">            If `return_dict` is True, returns a MaskedLMOutput object containing the following attributes:</span>

<span class="sd">                - loss (None): Placeholder for loss value (None for this method).</span>
<span class="sd">                - logits (mindspore.Tensor): Predicted logits for masked language modeling task.</span>
<span class="sd">                - hidden_states (Tuple[mindspore.Tensor]): Tuple of hidden states for each layer.</span>
<span class="sd">                - attentions (Tuple[mindspore.Tensor]): Tuple of attention weights for each layer.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If codebook_idx is 0, as it should be predicted by the coarse model.</span>
<span class="sd">            ValueError: If both input_ids and input_embeds are specified.</span>
<span class="sd">            ValueError: If neither input_ids nor input_embeds are specified.</span>
<span class="sd">            ValueError: If batch_size is not defined or less than or equal to 0.</span>
<span class="sd">            NotImplementedError: If labels are provided, as training is not implemented yet.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="k">if</span> <span class="n">codebook_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot predict 0th codebook - 0th codebook should be predicted by the coarse model&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You cannot specify both input_ids and input_embeds at the same time&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You have to specify either input_ids or input_embeds&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># the input_embeddings are the sum of the j previous codebooks embeddings before</span>
            <span class="c1"># the current codebook_idx codebook</span>

            <span class="c1"># forward the GPT model itself</span>
            <span class="n">input_embeds</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">input_embeds_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layers</span><span class="p">)</span>
            <span class="p">]</span>  <span class="c1"># token embeddings of shape (b, t, n_embd)</span>
            <span class="n">input_embeds</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">input_embeds</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span> <span class="n">codebook_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">seq_length</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># shape (1, seq_length)</span>

        <span class="n">position_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeds_layer</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>  <span class="c1"># position embeddings of shape (1, t, n_embd)</span>

        <span class="c1"># Attention mask.</span>
        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;batch_size has to be defined and &gt; 0&quot;</span><span class="p">)</span>
            <span class="c1"># [bsz, to_seq_length] -&gt; [bsz, 1, 1, to_seq_length]</span>
            <span class="c1"># from_seq_length is 1 to easily broadcast</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">_prepare_4d_attention_mask</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">head_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_head_mask</span><span class="p">(</span><span class="n">head_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">input_embeds</span> <span class="o">+</span> <span class="n">position_embeds</span><span class="p">)</span>
        <span class="n">output_shape</span> <span class="o">=</span> <span class="n">input_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>

        <span class="n">all_self_attentions</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">block</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
                <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="n">all_hidden_states</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span>
                <span class="n">hidden_states</span><span class="p">,</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">head_mask</span><span class="o">=</span><span class="n">head_mask</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
                <span class="n">all_self_attentions</span> <span class="o">=</span> <span class="n">all_self_attentions</span> <span class="o">+</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm_final</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>

        <span class="c1"># Add last hidden state</span>
        <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
            <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="n">all_hidden_states</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_heads</span><span class="p">[</span><span class="n">codebook_idx</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_given</span><span class="p">](</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Training is not implemented yet&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">all_hidden_states</span><span class="p">,</span> <span class="n">all_self_attentions</span><span class="p">]</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MaskedLMOutput</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">all_hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">all_self_attentions</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">coarse_output</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">semantic_generation_config</span><span class="p">:</span> <span class="n">BarkSemanticGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">coarse_generation_config</span><span class="p">:</span> <span class="n">BarkCoarseGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fine_generation_config</span><span class="p">:</span> <span class="n">BarkFineGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">codebook_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates fine acoustics tokens from input coarse acoustics tokens and an additional optional `Bark` speaker</span>
<span class="sd">        prompt.</span>

<span class="sd">        Args:</span>
<span class="sd">            coarse_output (`mindspore.Tensor` of shape (batch_size, seq_len)):</span>
<span class="sd">                Input coarse acoustics ids, i.e the output of `BarkCoarseModel.generate`.</span>
<span class="sd">            semantic_generation_config (`BarkSemanticGenerationConfig`):</span>
<span class="sd">                Generation config indicating how to generate the semantic tokens.</span>
<span class="sd">            coarse_generation_config (`BarkCoarseGenerationConfig`):</span>
<span class="sd">                Generation config indicating how to generate the coarse tokens.</span>
<span class="sd">            fine_generation_config (`BarkFineGenerationConfig`):</span>
<span class="sd">                Generation config indicating how to generate the fine tokens.</span>
<span class="sd">            codebook_size (`int`, *optional*, defaults to 1024):</span>
<span class="sd">                Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</span>
<span class="sd">            history_prompt (`Optional[Dict[str,mindspore.Tensor]]`, *optional*):</span>
<span class="sd">                Optional `Bark` speaker prompt.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mindspore.Tensor: Output fine acoustics tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">semantic_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`semantic_generation_config` has to be provided&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">coarse_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`coarse_generation_config` has to be provided&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fine_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`fine_generation_config` has to be provided&quot;</span><span class="p">)</span>

        <span class="c1"># since we don&#39;t really use GenerationConfig through the fine model (autoencoder)</span>
        <span class="c1"># and since only temperature is used from the classic GenerationConfig parameters</span>
        <span class="c1"># manually impose the kwargs priority over the generation config</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>

        <span class="n">max_fine_history_length</span> <span class="o">=</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">max_fine_history_length</span>
        <span class="n">max_fine_input_length</span> <span class="o">=</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">max_fine_input_length</span>

        <span class="c1"># shape: (batch, n_coarse_codebooks * seq_len)</span>
        <span class="c1"># new_shape: (batch, seq_len, n_coarse_codebooks)</span>
        <span class="n">coarse_output</span> <span class="o">=</span> <span class="n">coarse_output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">coarse_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span><span class="p">)</span>

        <span class="c1"># brings ids into the range [0, codebook_size -1]</span>
        <span class="n">coarse_output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">coarse_output</span> <span class="o">-</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_vocab_size</span><span class="p">,</span> <span class="n">codebook_size</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">coarse_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">history_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x_fine_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">history_prompt</span><span class="p">[</span><span class="s2">&quot;fine_prompt&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="c1"># swapaxes to get to shape (seq_len, n_fine_codebooks)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_fine_history</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">n_coarse</span> <span class="o">=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span>

        <span class="c1"># pad the last 6th codebooks</span>
        <span class="n">fine_input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">coarse_output</span><span class="p">,</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">n_fine_codebooks</span> <span class="o">-</span> <span class="n">n_coarse</span><span class="p">),</span>
            <span class="s2">&quot;constant&quot;</span><span class="p">,</span>
            <span class="n">codebook_size</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># prepend history if available (max max_fine_history_length)</span>
        <span class="k">if</span> <span class="n">x_fine_history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fine_input</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_fine_history</span><span class="p">[:,</span> <span class="o">-</span><span class="n">max_fine_history_length</span><span class="p">:,</span> <span class="p">:],</span> <span class="n">fine_input</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># len of the fine_history that has been added to fine_input</span>
            <span class="n">n_history</span> <span class="o">=</span> <span class="n">x_fine_history</span><span class="p">[:,</span> <span class="o">-</span><span class="n">max_fine_history_length</span><span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_history</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">n_remove_from_end</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># need to pad if too short (since non-causal model)</span>
        <span class="k">if</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">max_fine_input_length</span><span class="p">:</span>
            <span class="n">n_remove_from_end</span> <span class="o">=</span> <span class="n">max_fine_input_length</span> <span class="o">-</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">fine_input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">fine_input</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">n_remove_from_end</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">codebook_size</span><span class="p">)</span>

        <span class="c1"># we can be lazy about fractional loop and just keep overwriting codebooks.</span>
        <span class="c1"># seems that coarse_output.shape[1] - (max_fine_input_length - n_history) is equal to minus n_remove_from_end</span>
        <span class="c1"># So if we needed to pad because too short, n_loops is always 1 (because n_remove_from_end &gt; 0)</span>
        <span class="c1"># If not, we loop over at least twice.</span>

        <span class="n">n_loops</span> <span class="o">=</span> <span class="p">(</span><span class="n">coarse_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">max_fine_input_length</span> <span class="o">-</span> <span class="n">n_history</span><span class="p">))</span> <span class="o">/</span> <span class="n">max_fine_history_length</span>
        <span class="n">n_loops</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_loops</span><span class="p">))</span>
        <span class="n">n_loops</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_loops</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">n_outer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_loops</span><span class="p">):</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="n">n_outer</span> <span class="o">*</span> <span class="n">max_fine_history_length</span><span class="p">,</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_fine_input_length</span><span class="p">])</span>

            <span class="n">start_fill_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                <span class="p">[</span><span class="n">n_history</span> <span class="o">+</span> <span class="n">n_outer</span> <span class="o">*</span> <span class="n">max_fine_history_length</span><span class="p">,</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_fine_history_length</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">rel_start_fill_idx</span> <span class="o">=</span> <span class="n">start_fill_idx</span> <span class="o">-</span> <span class="n">start_idx</span>
            <span class="n">input_buffer</span> <span class="o">=</span> <span class="n">fine_input</span><span class="p">[:,</span> <span class="n">start_idx</span> <span class="p">:</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">max_fine_input_length</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">for</span> <span class="n">n_inner</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coarse</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">n_fine_codebooks</span><span class="p">):</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">n_inner</span><span class="p">,</span> <span class="n">input_buffer</span><span class="p">)</span><span class="o">.</span><span class="n">logits</span>
                <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">temperature</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
                    <span class="n">relevant_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="n">rel_start_fill_idx</span><span class="p">:,</span> <span class="p">:</span><span class="n">codebook_size</span><span class="p">]</span>
                    <span class="n">codebook_preds</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">relevant_logits</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">relevant_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">codebook_size</span><span class="p">]</span> <span class="o">/</span> <span class="n">temperature</span>
                    <span class="c1"># apply softmax</span>
                    <span class="n">probs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">relevant_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">rel_start_fill_idx</span><span class="p">:</span><span class="n">max_fine_input_length</span><span class="p">]</span>
                    <span class="c1"># reshape to 2D: (batch_size, seq_len, codebook_size) -&gt; (batch_size*seq_len, codebook_size)</span>
                    <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">codebook_size</span><span class="p">))</span>
                    <span class="c1"># multinomial then reshape : (batch_size*seq_len)-&gt; (batch_size,seq_len)</span>
                    <span class="n">codebook_preds</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">codebook_preds</span> <span class="o">=</span> <span class="n">codebook_preds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
                <span class="n">input_buffer</span><span class="p">[:,</span> <span class="n">rel_start_fill_idx</span><span class="p">:,</span> <span class="n">n_inner</span><span class="p">]</span> <span class="o">=</span> <span class="n">codebook_preds</span>
                <span class="k">del</span> <span class="n">logits</span><span class="p">,</span> <span class="n">codebook_preds</span>

            <span class="c1"># transfer into fine_input</span>
            <span class="k">for</span> <span class="n">n_inner</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coarse</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">n_fine_codebooks</span><span class="p">):</span>
                <span class="n">fine_input</span><span class="p">[</span>
                    <span class="p">:,</span> <span class="n">start_fill_idx</span> <span class="p">:</span> <span class="n">start_fill_idx</span> <span class="o">+</span> <span class="p">(</span><span class="n">max_fine_input_length</span> <span class="o">-</span> <span class="n">rel_start_fill_idx</span><span class="p">),</span> <span class="n">n_inner</span>
                <span class="p">]</span> <span class="o">=</span> <span class="n">input_buffer</span><span class="p">[:,</span> <span class="n">rel_start_fill_idx</span><span class="p">:,</span> <span class="n">n_inner</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">input_buffer</span>

        <span class="n">fine_input</span> <span class="o">=</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="n">n_history</span><span class="p">:]</span>
        <span class="k">if</span> <span class="n">n_remove_from_end</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">fine_input</span> <span class="o">=</span> <span class="n">fine_input</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="n">n_remove_from_end</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">coarse_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;input and output should have the same seq_len&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fine_input</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initializes a BarkFineModel object.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the BarkFineModel class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel">BarkFineModel</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An object containing configuration parameters for the model.
Parameters:</p>
<ul>
<li>input_vocab_size (int): The size of the input vocabulary.</li>
<li>hidden_size (int): The size of the hidden layers.</li>
<li>block_size (int): The size of the blocks in the model.</li>
<li>dropout (float): The dropout rate.</li>
<li>num_layers (int): The number of layers in the model.</li>
<li>output_vocab_size (int): The size of the output vocabulary.</li>
<li>n_codes_total (int): The total number of codes used.</li>
<li>n_codes_given (int): The number of codes given.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>Config</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a BarkFineModel object.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">        config (Config):</span>
<span class="sd">            An object containing configuration parameters for the model.</span>
<span class="sd">            Parameters:</span>

<span class="sd">            - input_vocab_size (int): The size of the input vocabulary.</span>
<span class="sd">            - hidden_size (int): The size of the hidden layers.</span>
<span class="sd">            - block_size (int): The size of the blocks in the model.</span>
<span class="sd">            - dropout (float): The dropout rate.</span>
<span class="sd">            - num_layers (int): The number of layers in the model.</span>
<span class="sd">            - output_vocab_size (int): The size of the output vocabulary.</span>
<span class="sd">            - n_codes_total (int): The total number of codes used.</span>
<span class="sd">            - n_codes_given (int): The number of codes given.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># non-causal gpt-like model with one embedding layer and one lm_head for each codebook of Encodec</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

    <span class="c1"># initialize a modified non causal GPT-like model</span>
    <span class="c1"># note that for there is one embedding layer and one lm_head for each codebook of Encodec</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
        <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_total</span><span class="p">)]</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">position_embeds_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">BarkBlock</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">is_causal</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)])</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm_final</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">lm_heads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">output_vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_given</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_codes_total</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_codes_total</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">n_codes_total</span>

    <span class="c1"># Initialize weights and apply final processing</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">codebook_idx</span><span class="p">,</span> <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">head_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>forward and process the input data for the BarkFineModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the BarkFineModel class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel">BarkFineModel</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>codebook_idx</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Index of the codebook to predict.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_ids</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input tensor containing the tokenized input sequence. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor indicating which tokens should be attended to. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>position_ids</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor containing the position indices of each input token. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>head_mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor specifying which attention heads to mask. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>labels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor containing the labels for the masked language modeling task. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_embeds</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tensor containing the input embeddings. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_attentions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to output attention weights. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[bool]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_hidden_states</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to output hidden states. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[bool]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_dict</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to return a dictionary instead of a tuple. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[bool]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Union">Union</span>[<span title="typing.Tuple">Tuple</span>[<span title="mindspore.Tensor">Tensor</span>], <span title="mindnlp.transformers.modeling_outputs.MaskedLMOutput">MaskedLMOutput</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Union[Tuple[mindspore.Tensor], MaskedLMOutput]:
If <code>return_dict</code> is False, returns a tuple containing the following:</p>
<ul>
<li>None: Placeholder for loss value (None for this method).</li>
<li>logits (mindspore.Tensor): Predicted logits for masked language modeling task.</li>
<li>all_hidden_states (Tuple[mindspore.Tensor]): Tuple of hidden states for each layer.</li>
<li>all_self_attentions (Tuple[mindspore.Tensor]): Tuple of attention weights for each layer.</li>
</ul>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Union">Union</span>[<span title="typing.Tuple">Tuple</span>[<span title="mindspore.Tensor">Tensor</span>], <span title="mindnlp.transformers.modeling_outputs.MaskedLMOutput">MaskedLMOutput</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>If <code>return_dict</code> is True, returns a MaskedLMOutput object containing the following attributes:</p>
<ul>
<li>loss (None): Placeholder for loss value (None for this method).</li>
<li>logits (mindspore.Tensor): Predicted logits for masked language modeling task.</li>
<li>hidden_states (Tuple[mindspore.Tensor]): Tuple of hidden states for each layer.</li>
<li>attentions (Tuple[mindspore.Tensor]): Tuple of attention weights for each layer.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If codebook_idx is 0, as it should be predicted by the coarse model.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If both input_ids and input_embeds are specified.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If neither input_ids nor input_embeds are specified.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If batch_size is not defined or less than or equal to 0.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>NotImplementedError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If labels are provided, as training is not implemented yet.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1569</span>
<span class="normal">1570</span>
<span class="normal">1571</span>
<span class="normal">1572</span>
<span class="normal">1573</span>
<span class="normal">1574</span>
<span class="normal">1575</span>
<span class="normal">1576</span>
<span class="normal">1577</span>
<span class="normal">1578</span>
<span class="normal">1579</span>
<span class="normal">1580</span>
<span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">codebook_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>  <span class="c1"># an additionnal idx corresponding to the id of the codebook that will be predicted</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">head_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">MaskedLMOutput</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    forward and process the input data for the BarkFineModel.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">        codebook_idx (int): Index of the codebook to predict.</span>
<span class="sd">        input_ids (Optional[mindspore.Tensor], optional): Input tensor containing the tokenized input sequence. Defaults to None.</span>
<span class="sd">        attention_mask (Optional[mindspore.Tensor], optional): Tensor indicating which tokens should be attended to. Defaults to None.</span>
<span class="sd">        position_ids (Optional[mindspore.Tensor], optional): Tensor containing the position indices of each input token. Defaults to None.</span>
<span class="sd">        head_mask (Optional[mindspore.Tensor], optional): Tensor specifying which attention heads to mask. Defaults to None.</span>
<span class="sd">        labels (Optional[mindspore.Tensor], optional): Tensor containing the labels for the masked language modeling task. Defaults to None.</span>
<span class="sd">        input_embeds (Optional[mindspore.Tensor], optional): Tensor containing the input embeddings. Defaults to None.</span>
<span class="sd">        output_attentions (Optional[bool], optional): Whether to output attention weights. Defaults to None.</span>
<span class="sd">        output_hidden_states (Optional[bool], optional): Whether to output hidden states. Defaults to None.</span>
<span class="sd">        return_dict (Optional[bool], optional): Whether to return a dictionary instead of a tuple. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[Tuple[mindspore.Tensor], MaskedLMOutput]:</span>
<span class="sd">            If `return_dict` is False, returns a tuple containing the following:</span>

<span class="sd">            - None: Placeholder for loss value (None for this method).</span>
<span class="sd">            - logits (mindspore.Tensor): Predicted logits for masked language modeling task.</span>
<span class="sd">            - all_hidden_states (Tuple[mindspore.Tensor]): Tuple of hidden states for each layer.</span>
<span class="sd">            - all_self_attentions (Tuple[mindspore.Tensor]): Tuple of attention weights for each layer.</span>

<span class="sd">        If `return_dict` is True, returns a MaskedLMOutput object containing the following attributes:</span>

<span class="sd">            - loss (None): Placeholder for loss value (None for this method).</span>
<span class="sd">            - logits (mindspore.Tensor): Predicted logits for masked language modeling task.</span>
<span class="sd">            - hidden_states (Tuple[mindspore.Tensor]): Tuple of hidden states for each layer.</span>
<span class="sd">            - attentions (Tuple[mindspore.Tensor]): Tuple of attention weights for each layer.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If codebook_idx is 0, as it should be predicted by the coarse model.</span>
<span class="sd">        ValueError: If both input_ids and input_embeds are specified.</span>
<span class="sd">        ValueError: If neither input_ids nor input_embeds are specified.</span>
<span class="sd">        ValueError: If batch_size is not defined or less than or equal to 0.</span>
<span class="sd">        NotImplementedError: If labels are provided, as training is not implemented yet.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
    <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
    <span class="p">)</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="k">if</span> <span class="n">codebook_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot predict 0th codebook - 0th codebook should be predicted by the coarse model&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You cannot specify both input_ids and input_embeds at the same time&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You have to specify either input_ids or input_embeds&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># the input_embeddings are the sum of the j previous codebooks embeddings before</span>
        <span class="c1"># the current codebook_idx codebook</span>

        <span class="c1"># forward the GPT model itself</span>
        <span class="n">input_embeds</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">input_embeds_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layers</span><span class="p">)</span>
        <span class="p">]</span>  <span class="c1"># token embeddings of shape (b, t, n_embd)</span>
        <span class="n">input_embeds</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">input_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">input_embeds</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span> <span class="n">codebook_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">seq_length</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># shape (1, seq_length)</span>

    <span class="n">position_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeds_layer</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>  <span class="c1"># position embeddings of shape (1, t, n_embd)</span>

    <span class="c1"># Attention mask.</span>
    <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;batch_size has to be defined and &gt; 0&quot;</span><span class="p">)</span>
        <span class="c1"># [bsz, to_seq_length] -&gt; [bsz, 1, 1, to_seq_length]</span>
        <span class="c1"># from_seq_length is 1 to easily broadcast</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">_prepare_4d_attention_mask</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">head_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_head_mask</span><span class="p">(</span><span class="n">head_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">input_embeds</span> <span class="o">+</span> <span class="n">position_embeds</span><span class="p">)</span>
    <span class="n">output_shape</span> <span class="o">=</span> <span class="n">input_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>

    <span class="n">all_self_attentions</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">block</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
            <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="n">all_hidden_states</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span>
            <span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">head_mask</span><span class="o">=</span><span class="n">head_mask</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
            <span class="n">all_self_attentions</span> <span class="o">=</span> <span class="n">all_self_attentions</span> <span class="o">+</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm_final</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>

    <span class="c1"># Add last hidden state</span>
    <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
        <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="n">all_hidden_states</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_heads</span><span class="p">[</span><span class="n">codebook_idx</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_given</span><span class="p">](</span><span class="n">hidden_states</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Training is not implemented yet&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">all_hidden_states</span><span class="p">,</span> <span class="n">all_self_attentions</span><span class="p">]</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">MaskedLMOutput</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
        <span class="n">hidden_states</span><span class="o">=</span><span class="n">all_hidden_states</span><span class="p">,</span>
        <span class="n">attentions</span><span class="o">=</span><span class="n">all_self_attentions</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.generate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">coarse_output</span><span class="p">,</span> <span class="n">semantic_generation_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">coarse_generation_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">codebook_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">history_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.generate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generates fine acoustics tokens from input coarse acoustics tokens and an additional optional <code>Bark</code> speaker
prompt.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>coarse_output</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input coarse acoustics ids, i.e the output of <code>BarkCoarseModel.generate</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape (batch_size, seq_len</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>semantic_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config indicating how to generate the semantic tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`BarkSemanticGenerationConfig`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>coarse_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config indicating how to generate the coarse tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`BarkCoarseGenerationConfig`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fine_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config indicating how to generate the fine tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`BarkFineGenerationConfig`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>codebook_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1024</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>history_prompt</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional <code>Bark</code> speaker prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[Dict[str,mindspore.Tensor]]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindspore.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>mindspore.Tensor: Output fine acoustics tokens.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1713</span>
<span class="normal">1714</span>
<span class="normal">1715</span>
<span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span>
<span class="normal">1747</span>
<span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span>
<span class="normal">1840</span>
<span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">coarse_output</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">semantic_generation_config</span><span class="p">:</span> <span class="n">BarkSemanticGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">coarse_generation_config</span><span class="p">:</span> <span class="n">BarkCoarseGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fine_generation_config</span><span class="p">:</span> <span class="n">BarkFineGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">codebook_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates fine acoustics tokens from input coarse acoustics tokens and an additional optional `Bark` speaker</span>
<span class="sd">    prompt.</span>

<span class="sd">    Args:</span>
<span class="sd">        coarse_output (`mindspore.Tensor` of shape (batch_size, seq_len)):</span>
<span class="sd">            Input coarse acoustics ids, i.e the output of `BarkCoarseModel.generate`.</span>
<span class="sd">        semantic_generation_config (`BarkSemanticGenerationConfig`):</span>
<span class="sd">            Generation config indicating how to generate the semantic tokens.</span>
<span class="sd">        coarse_generation_config (`BarkCoarseGenerationConfig`):</span>
<span class="sd">            Generation config indicating how to generate the coarse tokens.</span>
<span class="sd">        fine_generation_config (`BarkFineGenerationConfig`):</span>
<span class="sd">            Generation config indicating how to generate the fine tokens.</span>
<span class="sd">        codebook_size (`int`, *optional*, defaults to 1024):</span>
<span class="sd">            Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</span>
<span class="sd">        history_prompt (`Optional[Dict[str,mindspore.Tensor]]`, *optional*):</span>
<span class="sd">            Optional `Bark` speaker prompt.</span>

<span class="sd">    Returns:</span>
<span class="sd">        mindspore.Tensor: Output fine acoustics tokens.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">semantic_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`semantic_generation_config` has to be provided&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">coarse_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`coarse_generation_config` has to be provided&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">fine_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`fine_generation_config` has to be provided&quot;</span><span class="p">)</span>

    <span class="c1"># since we don&#39;t really use GenerationConfig through the fine model (autoencoder)</span>
    <span class="c1"># and since only temperature is used from the classic GenerationConfig parameters</span>
    <span class="c1"># manually impose the kwargs priority over the generation config</span>
    <span class="n">temperature</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">temperature</span><span class="p">)</span>

    <span class="n">max_fine_history_length</span> <span class="o">=</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">max_fine_history_length</span>
    <span class="n">max_fine_input_length</span> <span class="o">=</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">max_fine_input_length</span>

    <span class="c1"># shape: (batch, n_coarse_codebooks * seq_len)</span>
    <span class="c1"># new_shape: (batch, seq_len, n_coarse_codebooks)</span>
    <span class="n">coarse_output</span> <span class="o">=</span> <span class="n">coarse_output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">coarse_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span><span class="p">)</span>

    <span class="c1"># brings ids into the range [0, codebook_size -1]</span>
    <span class="n">coarse_output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">coarse_output</span> <span class="o">-</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_vocab_size</span><span class="p">,</span> <span class="n">codebook_size</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">coarse_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">history_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x_fine_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">history_prompt</span><span class="p">[</span><span class="s2">&quot;fine_prompt&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="c1"># swapaxes to get to shape (seq_len, n_fine_codebooks)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_fine_history</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">n_coarse</span> <span class="o">=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span>

    <span class="c1"># pad the last 6th codebooks</span>
    <span class="n">fine_input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
        <span class="n">coarse_output</span><span class="p">,</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">n_fine_codebooks</span> <span class="o">-</span> <span class="n">n_coarse</span><span class="p">),</span>
        <span class="s2">&quot;constant&quot;</span><span class="p">,</span>
        <span class="n">codebook_size</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># prepend history if available (max max_fine_history_length)</span>
    <span class="k">if</span> <span class="n">x_fine_history</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fine_input</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_fine_history</span><span class="p">[:,</span> <span class="o">-</span><span class="n">max_fine_history_length</span><span class="p">:,</span> <span class="p">:],</span> <span class="n">fine_input</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># len of the fine_history that has been added to fine_input</span>
        <span class="n">n_history</span> <span class="o">=</span> <span class="n">x_fine_history</span><span class="p">[:,</span> <span class="o">-</span><span class="n">max_fine_history_length</span><span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_history</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">n_remove_from_end</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># need to pad if too short (since non-causal model)</span>
    <span class="k">if</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">max_fine_input_length</span><span class="p">:</span>
        <span class="n">n_remove_from_end</span> <span class="o">=</span> <span class="n">max_fine_input_length</span> <span class="o">-</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">fine_input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">fine_input</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">n_remove_from_end</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">codebook_size</span><span class="p">)</span>

    <span class="c1"># we can be lazy about fractional loop and just keep overwriting codebooks.</span>
    <span class="c1"># seems that coarse_output.shape[1] - (max_fine_input_length - n_history) is equal to minus n_remove_from_end</span>
    <span class="c1"># So if we needed to pad because too short, n_loops is always 1 (because n_remove_from_end &gt; 0)</span>
    <span class="c1"># If not, we loop over at least twice.</span>

    <span class="n">n_loops</span> <span class="o">=</span> <span class="p">(</span><span class="n">coarse_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">max_fine_input_length</span> <span class="o">-</span> <span class="n">n_history</span><span class="p">))</span> <span class="o">/</span> <span class="n">max_fine_history_length</span>
    <span class="n">n_loops</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_loops</span><span class="p">))</span>
    <span class="n">n_loops</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_loops</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">for</span> <span class="n">n_outer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_loops</span><span class="p">):</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="n">n_outer</span> <span class="o">*</span> <span class="n">max_fine_history_length</span><span class="p">,</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_fine_input_length</span><span class="p">])</span>

        <span class="n">start_fill_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="p">[</span><span class="n">n_history</span> <span class="o">+</span> <span class="n">n_outer</span> <span class="o">*</span> <span class="n">max_fine_history_length</span><span class="p">,</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">max_fine_history_length</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">rel_start_fill_idx</span> <span class="o">=</span> <span class="n">start_fill_idx</span> <span class="o">-</span> <span class="n">start_idx</span>
        <span class="n">input_buffer</span> <span class="o">=</span> <span class="n">fine_input</span><span class="p">[:,</span> <span class="n">start_idx</span> <span class="p">:</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">max_fine_input_length</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">n_inner</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coarse</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">n_fine_codebooks</span><span class="p">):</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">n_inner</span><span class="p">,</span> <span class="n">input_buffer</span><span class="p">)</span><span class="o">.</span><span class="n">logits</span>
            <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">temperature</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="n">relevant_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="n">rel_start_fill_idx</span><span class="p">:,</span> <span class="p">:</span><span class="n">codebook_size</span><span class="p">]</span>
                <span class="n">codebook_preds</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">relevant_logits</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">relevant_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">codebook_size</span><span class="p">]</span> <span class="o">/</span> <span class="n">temperature</span>
                <span class="c1"># apply softmax</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">relevant_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">rel_start_fill_idx</span><span class="p">:</span><span class="n">max_fine_input_length</span><span class="p">]</span>
                <span class="c1"># reshape to 2D: (batch_size, seq_len, codebook_size) -&gt; (batch_size*seq_len, codebook_size)</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">codebook_size</span><span class="p">))</span>
                <span class="c1"># multinomial then reshape : (batch_size*seq_len)-&gt; (batch_size,seq_len)</span>
                <span class="n">codebook_preds</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">codebook_preds</span> <span class="o">=</span> <span class="n">codebook_preds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">input_buffer</span><span class="p">[:,</span> <span class="n">rel_start_fill_idx</span><span class="p">:,</span> <span class="n">n_inner</span><span class="p">]</span> <span class="o">=</span> <span class="n">codebook_preds</span>
            <span class="k">del</span> <span class="n">logits</span><span class="p">,</span> <span class="n">codebook_preds</span>

        <span class="c1"># transfer into fine_input</span>
        <span class="k">for</span> <span class="n">n_inner</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_coarse</span><span class="p">,</span> <span class="n">fine_generation_config</span><span class="o">.</span><span class="n">n_fine_codebooks</span><span class="p">):</span>
            <span class="n">fine_input</span><span class="p">[</span>
                <span class="p">:,</span> <span class="n">start_fill_idx</span> <span class="p">:</span> <span class="n">start_fill_idx</span> <span class="o">+</span> <span class="p">(</span><span class="n">max_fine_input_length</span> <span class="o">-</span> <span class="n">rel_start_fill_idx</span><span class="p">),</span> <span class="n">n_inner</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">input_buffer</span><span class="p">[:,</span> <span class="n">rel_start_fill_idx</span><span class="p">:,</span> <span class="n">n_inner</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">input_buffer</span>

    <span class="n">fine_input</span> <span class="o">=</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="n">n_history</span><span class="p">:]</span>
    <span class="k">if</span> <span class="n">n_remove_from_end</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">fine_input</span> <span class="o">=</span> <span class="n">fine_input</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="n">n_remove_from_end</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">fine_input</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">coarse_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;input and output should have the same seq_len&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fine_input</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_input_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_input_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method retrieves the input embeddings for the BarkFineModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the BarkFineModel class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel">BarkFineModel</a></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>None</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>This method returns the input embeddings layers for the BarkFineModel.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method retrieves the input embeddings for the BarkFineModel.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkFineModel): The instance of the BarkFineModel class.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None: This method returns the input embeddings layers for the BarkFineModel.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># one embedding layers for each codebook</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layers</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_output_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.get_output_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method is defined in the class 'BarkFineModel' and is used to retrieve the output embeddings of the model.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An instance of the 'BarkFineModel' class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method is defined in the class &#39;BarkFineModel&#39; and is used to retrieve the output embeddings of the model.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: An instance of the &#39;BarkFineModel&#39; class.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># one lm_head for each codebook</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_heads</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.resize_token_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="n">new_num_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.resize_token_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Resizes input token embeddings matrix of the model if <code>new_num_tokens != config.vocab_size</code>.</p>
<p>Takes care of tying weights embeddings afterwards if the model class has a <code>tie_weights()</code> method.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>new_num_tokens</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of new tokens in the embedding matrix. Increasing the size will add newly initialized
vectors at the end. Reducing the size will remove vectors from the end. If not provided or <code>None</code>, just
returns a pointer to the input tokens <code>nn.Embedding</code> module of the model without doing anything.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_to_multiple_of</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If set will pad the embedding matrix to a multiple of the provided value.</p>
<p>This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability
<code>&gt;= 7.5</code> (Volta), or on TPUs which benefit from having sequence lengths be a multiple of 128. For more
details about this, or help on choosing the correct value for resizing, refer to this guide:
https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindnlp.core.nn.Embedding">Embedding</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>nn.Embedding</code>: Pointer to the input tokens Embeddings Module of the model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">resize_token_embeddings</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">new_num_tokens</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resizes input token embeddings matrix of the model if `new_num_tokens != config.vocab_size`.</span>

<span class="sd">    Takes care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        new_num_tokens (`int`, *optional*):</span>
<span class="sd">            The number of new tokens in the embedding matrix. Increasing the size will add newly initialized</span>
<span class="sd">            vectors at the end. Reducing the size will remove vectors from the end. If not provided or `None`, just</span>
<span class="sd">            returns a pointer to the input tokens `nn.Embedding` module of the model without doing anything.</span>
<span class="sd">        pad_to_multiple_of (`int`, *optional*):</span>
<span class="sd">            If set will pad the embedding matrix to a multiple of the provided value.</span>

<span class="sd">            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability</span>
<span class="sd">            `&gt;= 7.5` (Volta), or on TPUs which benefit from having sequence lengths be a multiple of 128. For more</span>
<span class="sd">            details about this, or help on choosing the correct value for resizing, refer to this guide:</span>
<span class="sd">            https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc</span>

<span class="sd">    Returns:</span>
<span class="sd">        `nn.Embedding`: Pointer to the input tokens Embeddings Module of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resize_token_embeddings</span><span class="p">(</span><span class="n">new_num_tokens</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">new_num_tokens</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">pad_to_multiple_of</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">model_embeds</span>

    <span class="c1"># Update base model and current model config</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_vocab_size</span> <span class="o">=</span> <span class="n">model_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_vocab_size</span> <span class="o">=</span> <span class="n">model_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">model_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Tie weights again if needed</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tie_weights</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">model_embeds</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_input_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="n">set_input_embeddings</span><span class="p">(</span><span class="n">new_embeddings</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_input_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Sets the input embeddings for the BarkFineModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the BarkFineModel class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel">BarkFineModel</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>new_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The new embeddings to set for the input_embeds_layers attribute.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_embeddings</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sets the input embeddings for the BarkFineModel.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">        new_embeddings (object): The new embeddings to set for the input_embeds_layers attribute.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># one embedding layers for each codebook</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layers</span> <span class="o">=</span> <span class="n">new_embeddings</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_output_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="n">set_output_embeddings</span><span class="p">(</span><span class="n">new_output_embeddings</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.set_output_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Method to set new output embeddings for the BarkFineModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the BarkFineModel class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel">BarkFineModel</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>new_output_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>New output embeddings to be set for the model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_output_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_output_embeddings</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to set new output embeddings for the BarkFineModel.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkFineModel): The instance of the BarkFineModel class.</span>
<span class="sd">        new_output_embeddings (object): New output embeddings to be set for the model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># one lm_head for each codebook</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lm_heads</span> <span class="o">=</span> <span class="n">new_output_embeddings</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.tie_weights" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkFineModel</span><span class="o">.</span><span class="n">tie_weights</span><span class="p">()</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkFineModel.tie_weights" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Tie the weights between the input embeddings list and the output embeddings list.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span>
<span class="normal">1565</span>
<span class="normal">1566</span>
<span class="normal">1567</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">tie_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tie the weights between the input embeddings list and the output embeddings list.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;tie_word_embeddings&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tied_weights_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span>
        <span class="n">input_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_total</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_codes_given</span><span class="p">):</span>
            <span class="c1"># self.input_embeds_layers[i + 1].weight = self.lm_heads[i].weight</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tie_or_clone_weights</span><span class="p">(</span><span class="n">output_embeddings</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">input_embeddings</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tied_weights_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;lm_heads.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.weight&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s2">&quot;_tie_weights&quot;</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_tie_weights</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel</code>


<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel">BarkCausalModel</a></code></p>


        <p>Represents a semantic model for generating text semantic tokens from an input prompt and an optional <code>Bark</code> speaker prompt.</p>
<p>This class inherits from BarkCausalModel and provides a method to generate output semantic tokens
based on the input prompt and generation configuration.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel.input_embeds_layer">input_embeds_layer</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The layer used for input embeddings.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>Layer</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel.config">config</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>Configuration settings for the semantic model.</p>
              </div>
              <p>
                  <span class="doc-attribute-annotation">
                    <b>TYPE:</b>
                      <code>Config</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkSemanticModel</span><span class="p">(</span><span class="n">BarkCausalModel</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Represents a semantic model for generating text semantic tokens from an input prompt and an optional `Bark` speaker prompt.</span>

<span class="sd">        This class inherits from BarkCausalModel and provides a method to generate output semantic tokens</span>
<span class="sd">        based on the input prompt and generation configuration.</span>

<span class="sd">        Attributes:</span>
<span class="sd">            input_embeds_layer (Layer): The layer used for input embeddings.</span>
<span class="sd">            config (Config): Configuration settings for the semantic model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
    <span class="n">base_model_prefix</span> <span class="o">=</span> <span class="s2">&quot;semantic&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">BarkSemanticConfig</span>

    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">semantic_generation_config</span><span class="p">:</span> <span class="n">BarkSemanticGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates text semantic tokens from an input prompt and an additional optional `Bark` speaker prompt.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_ids (`Optional[mindspore.Tensor]` of shape (batch_size, seq_len), *optional*):</span>
<span class="sd">                Input ids, i.e tokenized input sentences. Will be truncated up to</span>
<span class="sd">                semantic_generation_config.max_input_semantic_length tokens. Note that the output audios will be as</span>
<span class="sd">                long as the longest generation among the batch.</span>
<span class="sd">            semantic_generation_config (`BarkSemanticGenerationConfig`):</span>
<span class="sd">                Generation config indicating how to generate the semantic tokens.</span>
<span class="sd">            history_prompt (`Optional[Dict[str,mindspore.Tensor]]`, *optional*):</span>
<span class="sd">                Optional `Bark` speaker prompt.</span>
<span class="sd">            attention_mask (`Optional[mindspore.Tensor]`, *optional*):</span>
<span class="sd">                Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:</span>

<span class="sd">                - 1 for tokens that are **not masked**,</span>
<span class="sd">                - 0 for tokens that are **masked**.</span>

<span class="sd">                [What are attention masks?](../glossary#attention-mask)</span>

<span class="sd">        Returns:</span>
<span class="sd">            mindspore.Tensor: Output semantic tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">semantic_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`semantic_generation_config` has to be provided&quot;</span><span class="p">)</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">max_input_semantic_length</span> <span class="o">=</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">max_input_semantic_length</span>

        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span> <span class="o">+</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">text_encoding_offset</span>

        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">attention_mask</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">text_pad_token</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">history_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">semantic_history</span> <span class="o">=</span> <span class="n">history_prompt</span><span class="p">[</span><span class="s2">&quot;semantic_prompt&quot;</span><span class="p">][</span><span class="o">-</span><span class="n">max_input_semantic_length</span><span class="p">:]</span>
            <span class="n">semantic_history</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                <span class="n">semantic_history</span><span class="p">,</span>
                <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_input_semantic_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">semantic_history</span><span class="p">)),</span>
                <span class="n">value</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">semantic_history</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span>
                <span class="p">[</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_input_semantic_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span>
            <span class="p">)</span>

        <span class="n">semantic_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">semantic_history</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">infer_array</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span>
            <span class="p">[[</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_infer_token</span><span class="p">]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span>
        <span class="p">)</span>

        <span class="n">input_embeds</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_input_semantic_length</span><span class="p">])</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">semantic_history</span><span class="p">[:,</span> <span class="p">:</span> <span class="n">max_input_semantic_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">infer_array</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">tokens_to_suppress</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="nb">range</span><span class="p">(</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_vocab_size</span><span class="p">,</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">tokens_to_suppress</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_vocab_size</span><span class="p">))</span>
        <span class="p">)</span>

        <span class="n">suppress_tokens_logits_processor</span> <span class="o">=</span> <span class="n">SuppressTokensLogitsProcessor</span><span class="p">(</span><span class="n">tokens_to_suppress</span><span class="p">)</span>

        <span class="n">min_eos_p</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;min_eos_p&quot;</span><span class="p">,</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">min_eos_p</span><span class="p">)</span>
        <span class="n">early_stopping_logits_processor</span> <span class="o">=</span> <span class="n">BarkEosPrioritizerLogitsProcessor</span><span class="p">(</span>
            <span class="n">eos_token_id</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span> <span class="n">min_eos_p</span><span class="o">=</span><span class="n">min_eos_p</span>
        <span class="p">)</span>

        <span class="c1"># pass input_ids in order to stay consistent with the transformers generate method even though it is not used</span>
        <span class="c1"># (except to get the input seq_len - that&#39;s why we keep the first 257 tokens)</span>
        <span class="n">semantic_output</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">ops</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_input_semantic_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
            <span class="n">input_embeds</span><span class="o">=</span><span class="n">input_embeds</span><span class="p">,</span>
            <span class="n">logits_processor</span><span class="o">=</span><span class="p">[</span><span class="n">suppress_tokens_logits_processor</span><span class="p">,</span> <span class="n">early_stopping_logits_processor</span><span class="p">],</span>
            <span class="n">generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>  <span class="c1"># size: 10048</span>

        <span class="c1"># take the generated semantic tokens</span>
        <span class="n">semantic_output</span> <span class="o">=</span> <span class="n">semantic_output</span><span class="p">[:,</span> <span class="n">max_input_semantic_length</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span>

        <span class="k">return</span> <span class="n">semantic_output</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel.generate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkSemanticModel</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">semantic_generation_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">history_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkSemanticModel.generate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generates text semantic tokens from an input prompt and an additional optional <code>Bark</code> speaker prompt.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_ids</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input ids, i.e tokenized input sentences. Will be truncated up to
semantic_generation_config.max_input_semantic_length tokens. Note that the output audios will be as
long as the longest generation among the batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[mindspore.Tensor]` of shape (batch_size, seq_len), *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>semantic_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config indicating how to generate the semantic tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`BarkSemanticGenerationConfig`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>history_prompt</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional <code>Bark</code> speaker prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[Dict[str,mindspore.Tensor]]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Mask to avoid performing attention on padding token indices. Mask values selected in <code>[0, 1]</code>:</p>
<ul>
<li>1 for tokens that are <strong>not masked</strong>,</li>
<li>0 for tokens that are <strong>masked</strong>.</li>
</ul>
<p><a href="../glossary#attention-mask">What are attention masks?</a></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[mindspore.Tensor]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindspore.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>mindspore.Tensor: Output semantic tokens.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">semantic_generation_config</span><span class="p">:</span> <span class="n">BarkSemanticGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates text semantic tokens from an input prompt and an additional optional `Bark` speaker prompt.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_ids (`Optional[mindspore.Tensor]` of shape (batch_size, seq_len), *optional*):</span>
<span class="sd">            Input ids, i.e tokenized input sentences. Will be truncated up to</span>
<span class="sd">            semantic_generation_config.max_input_semantic_length tokens. Note that the output audios will be as</span>
<span class="sd">            long as the longest generation among the batch.</span>
<span class="sd">        semantic_generation_config (`BarkSemanticGenerationConfig`):</span>
<span class="sd">            Generation config indicating how to generate the semantic tokens.</span>
<span class="sd">        history_prompt (`Optional[Dict[str,mindspore.Tensor]]`, *optional*):</span>
<span class="sd">            Optional `Bark` speaker prompt.</span>
<span class="sd">        attention_mask (`Optional[mindspore.Tensor]`, *optional*):</span>
<span class="sd">            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:</span>

<span class="sd">            - 1 for tokens that are **not masked**,</span>
<span class="sd">            - 0 for tokens that are **masked**.</span>

<span class="sd">            [What are attention masks?](../glossary#attention-mask)</span>

<span class="sd">    Returns:</span>
<span class="sd">        mindspore.Tensor: Output semantic tokens.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">semantic_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`semantic_generation_config` has to be provided&quot;</span><span class="p">)</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">max_input_semantic_length</span> <span class="o">=</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">max_input_semantic_length</span>

    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span> <span class="o">+</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">text_encoding_offset</span>

    <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">attention_mask</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">(),</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">text_pad_token</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">history_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">semantic_history</span> <span class="o">=</span> <span class="n">history_prompt</span><span class="p">[</span><span class="s2">&quot;semantic_prompt&quot;</span><span class="p">][</span><span class="o">-</span><span class="n">max_input_semantic_length</span><span class="p">:]</span>
        <span class="n">semantic_history</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">semantic_history</span><span class="p">,</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_input_semantic_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">semantic_history</span><span class="p">)),</span>
            <span class="n">value</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">semantic_history</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span>
            <span class="p">[</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_input_semantic_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span>
        <span class="p">)</span>

    <span class="n">semantic_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">semantic_history</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">infer_array</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_infer_token</span><span class="p">]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span>
    <span class="p">)</span>

    <span class="n">input_embeds</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_input_semantic_length</span><span class="p">])</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">semantic_history</span><span class="p">[:,</span> <span class="p">:</span> <span class="n">max_input_semantic_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">infer_array</span><span class="p">),</span>
        <span class="p">],</span>
        <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">tokens_to_suppress</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
        <span class="nb">range</span><span class="p">(</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_vocab_size</span><span class="p">,</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">tokens_to_suppress</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
        <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_vocab_size</span><span class="p">))</span>
    <span class="p">)</span>

    <span class="n">suppress_tokens_logits_processor</span> <span class="o">=</span> <span class="n">SuppressTokensLogitsProcessor</span><span class="p">(</span><span class="n">tokens_to_suppress</span><span class="p">)</span>

    <span class="n">min_eos_p</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;min_eos_p&quot;</span><span class="p">,</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">min_eos_p</span><span class="p">)</span>
    <span class="n">early_stopping_logits_processor</span> <span class="o">=</span> <span class="n">BarkEosPrioritizerLogitsProcessor</span><span class="p">(</span>
        <span class="n">eos_token_id</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span> <span class="n">min_eos_p</span><span class="o">=</span><span class="n">min_eos_p</span>
    <span class="p">)</span>

    <span class="c1"># pass input_ids in order to stay consistent with the transformers generate method even though it is not used</span>
    <span class="c1"># (except to get the input seq_len - that&#39;s why we keep the first 257 tokens)</span>
    <span class="n">semantic_output</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">ops</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_input_semantic_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">input_embeds</span><span class="o">=</span><span class="n">input_embeds</span><span class="p">,</span>
        <span class="n">logits_processor</span><span class="o">=</span><span class="p">[</span><span class="n">suppress_tokens_logits_processor</span><span class="p">,</span> <span class="n">early_stopping_logits_processor</span><span class="p">],</span>
        <span class="n">generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>  <span class="c1"># size: 10048</span>

    <span class="c1"># take the generated semantic tokens</span>
    <span class="n">semantic_output</span> <span class="o">=</span> <span class="n">semantic_output</span><span class="p">[:,</span> <span class="n">max_input_semantic_length</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span>

    <span class="k">return</span> <span class="n">semantic_output</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel</code>


<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel">BarkCausalModel</a></code></p>


        <p>Represents a model for generating coarse acoustics tokens from input text semantic tokens and an optional <code>Bark</code> speaker prompt.</p>
<p>This class inherits from BarkCausalModel and includes methods for preprocessing histories and generating coarse acoustics tokens based on provided configurations and inputs.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">METHOD</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.preprocess_histories" href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.preprocess_histories">preprocess_histories</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Preprocesses optional <code>Bark</code> speaker prompts before generating coarse acoustics tokens. Returns processed semantic and coarse speaker prompts.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.generate" href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.generate">generate</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Generates coarse acoustics tokens based on input text semantic tokens, generation configurations, and optional speaker prompts. Returns the output coarse acoustics tokens.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>semantic_output</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input text semantic ids.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>semantic_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config for semantic tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindnlp.transformers.models.bark.generation_configuration_bark.BarkSemanticGenerationConfig">BarkSemanticGenerationConfig</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>coarse_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config for coarse tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindnlp.transformers.models.bark.generation_configuration_bark.BarkCoarseGenerationConfig">BarkCoarseGenerationConfig</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>codebook_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the output vocabulary per codebook channel.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>history_prompt</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional <code>Bark</code> speaker prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[str, <span title="mindspore.Tensor">Tensor</span>]]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_output_lengths</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to return the output lengths.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Conditional return:
By default:</p>
<ul>
<li>mindspore.Tensor: Output coarse acoustics tokens.</li>
</ul>
<p>If return_output_lengths=True:</p>
<ul>
<li>Tuple(mindspore.Tensor, mindspore.Tensor):
Output coarse acoustics tokens and the length of each sample in the batch.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkCoarseModel</span><span class="p">(</span><span class="n">BarkCausalModel</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a model for generating coarse acoustics tokens from input text semantic tokens and an optional `Bark` speaker prompt.</span>

<span class="sd">    This class inherits from BarkCausalModel and includes methods for preprocessing histories and generating coarse acoustics tokens based on provided configurations and inputs.</span>

<span class="sd">    Methods:</span>
<span class="sd">        preprocess_histories(max_coarse_history, semantic_to_coarse_ratio, batch_size, semantic_generation_config, codebook_size, history_prompt=None):</span>
<span class="sd">            Preprocesses optional `Bark` speaker prompts before generating coarse acoustics tokens. Returns processed semantic and coarse speaker prompts.</span>

<span class="sd">        generate(semantic_output, semantic_generation_config, coarse_generation_config, codebook_size=1024, history_prompt=None, return_output_lengths=None, **kwargs):</span>
<span class="sd">            Generates coarse acoustics tokens based on input text semantic tokens, generation configurations, and optional speaker prompts. Returns the output coarse acoustics tokens.</span>

<span class="sd">    Args:</span>
<span class="sd">        semantic_output (mindspore.Tensor): Input text semantic ids.</span>
<span class="sd">        semantic_generation_config (BarkSemanticGenerationConfig): Generation config for semantic tokens.</span>
<span class="sd">        coarse_generation_config (BarkCoarseGenerationConfig): Generation config for coarse tokens.</span>
<span class="sd">        codebook_size (int, optional): Size of the output vocabulary per codebook channel.</span>
<span class="sd">        history_prompt (Optional[Dict[str, mindspore.Tensor]], optional): Optional `Bark` speaker prompt.</span>
<span class="sd">        return_output_lengths (bool, optional): Whether to return the output lengths.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Conditional return:</span>
<span class="sd">            By default:</span>

<span class="sd">            - mindspore.Tensor: Output coarse acoustics tokens.</span>

<span class="sd">            If return_output_lengths=True:</span>

<span class="sd">            - Tuple(mindspore.Tensor, mindspore.Tensor):</span>
<span class="sd">            Output coarse acoustics tokens and the length of each sample in the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base_model_prefix</span> <span class="o">=</span> <span class="s2">&quot;coarse_acoustics&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">BarkCoarseConfig</span>

    <span class="k">def</span> <span class="nf">preprocess_histories</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_coarse_history</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">semantic_to_coarse_ratio</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">semantic_generation_config</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">codebook_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Preprocess the optional `Bark` speaker prompts before `self.generate`.</span>

<span class="sd">        Args:</span>
<span class="sd">            max_coarse_history (`int`):</span>
<span class="sd">                Maximum size of coarse tokens used.</span>
<span class="sd">            semantic_to_coarse_ratio (`int`):</span>
<span class="sd">                Ratio of semantic to coarse frequency</span>
<span class="sd">            batch_size (`int`):</span>
<span class="sd">                Batch size, i.e the number of samples.</span>
<span class="sd">            semantic_generation_config (`BarkSemanticGenerationConfig`):</span>
<span class="sd">                Generation config indicating how to generate the semantic tokens.</span>
<span class="sd">            codebook_size (`int`):</span>
<span class="sd">                Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</span>
<span class="sd">            history_prompt (`Optional[Dict[str,mindspore.Tensor]]`):</span>
<span class="sd">                Optional `Bark` speaker prompt.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `tuple(mindspore.Tensor)`:</span>

<span class="sd">                - **x_semantic_history** (`mindspore.Tensor` -- Processed semantic speaker prompt.</span>
<span class="sd">                - **x_coarse_history** (`mindspore.Tensor`) -- Processed coarse speaker prompt.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">history_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x_semantic_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">history_prompt</span><span class="p">[</span><span class="s2">&quot;semantic_prompt&quot;</span><span class="p">][</span><span class="kc">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># clone to avoid modifying history_prompt.coarse_prompt</span>
            <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">history_prompt</span><span class="p">[</span><span class="s2">&quot;coarse_prompt&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

            <span class="c1"># offset x_coarse_history</span>
            <span class="k">if</span> <span class="n">codebook_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x_coarse_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="c1"># offset</span>
                    <span class="n">x_coarse_history</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">codebook_size</span> <span class="o">*</span> <span class="n">n</span>

            <span class="c1"># flatten x_coarse_history</span>
            <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">x_coarse_history</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">x_coarse_history</span> <span class="o">+</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_vocab_size</span>

            <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">x_coarse_history</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># e.g: after SEMANTIC_VOCAB_SIZE (10000), 1024 tokens dedicated to first codebook, 1024 next tokens</span>
            <span class="c1"># dedicated to second codebook.</span>

            <span class="n">max_semantic_history</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">max_coarse_history</span> <span class="o">/</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">))</span>
            <span class="c1"># trim histories correctly</span>
            <span class="n">n_semantic_hist_provided</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">max_semantic_history</span><span class="p">,</span>
                    <span class="n">x_semantic_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x_semantic_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">x_coarse_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">)),</span>
                <span class="p">]</span>
            <span class="p">)</span>

            <span class="n">n_coarse_hist_provided</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">n_semantic_hist_provided</span> <span class="o">*</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">))</span>

            <span class="n">x_semantic_history</span> <span class="o">=</span> <span class="n">x_semantic_history</span><span class="p">[:,</span> <span class="o">-</span><span class="n">n_semantic_hist_provided</span><span class="p">:]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">x_coarse_history</span><span class="p">[:,</span> <span class="o">-</span><span class="n">n_coarse_hist_provided</span><span class="p">:]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="c1"># bit of a hack for time alignment (sounds better) - from Bark original implementation</span>
            <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">x_coarse_history</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># shape: (batch_size, 0)</span>
            <span class="n">x_semantic_history</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">_c_expression</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
            <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">_c_expression</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x_semantic_history</span><span class="p">,</span> <span class="n">x_coarse_history</span>

    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">semantic_output</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">semantic_generation_config</span><span class="p">:</span> <span class="n">BarkSemanticGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">coarse_generation_config</span><span class="p">:</span> <span class="n">BarkCoarseGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">codebook_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_output_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates coarse acoustics tokens from input text semantic tokens and an additional optional `Bark` speaker</span>
<span class="sd">        prompt.</span>

<span class="sd">        Args:</span>
<span class="sd">            semantic_output (`mindspore.Tensor` of shape (batch_size, seq_len), *optional*):</span>
<span class="sd">                Input text semantic ids, i.e the output of `BarkSemanticModel.generate`.</span>
<span class="sd">            semantic_generation_config (`BarkSemanticGenerationConfig`):</span>
<span class="sd">                Generation config indicating how to generate the semantic tokens.</span>
<span class="sd">            coarse_generation_config (`BarkCoarseGenerationConfig`):</span>
<span class="sd">                Generation config indicating how to generate the coarse tokens.</span>
<span class="sd">            codebook_size (`int`, *optional*, defaults to 1024):</span>
<span class="sd">                Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</span>
<span class="sd">            history_prompt (`Optional[Dict[str,mindspore.Tensor]]`, *optional*):</span>
<span class="sd">                Optional `Bark` speaker prompt.</span>
<span class="sd">            return_output_lengths (`bool`, *optional*):</span>
<span class="sd">                Whether or not to return the output lengths. Useful when batching.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Conditional return:</span>
<span class="sd">                By default:</span>

<span class="sd">                - mindspore.Tensor: Output coarse acoustics tokens.</span>
<span class="sd">                If `return_output_lengths=True`:</span>

<span class="sd">                - `Tuple(mindspore.Tensor, mindspore.Tensor): The output coarse acoustics tokens, and the</span>
<span class="sd">                length of each sample of the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">semantic_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`semantic_generation_config` has to be provided&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">coarse_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`coarse_generation_config` has to be provided&quot;</span><span class="p">)</span>

        <span class="n">max_coarse_input_length</span> <span class="o">=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">max_coarse_input_length</span>
        <span class="n">max_coarse_history</span> <span class="o">=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">max_coarse_history</span>
        <span class="n">sliding_window_len</span> <span class="o">=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">sliding_window_len</span>

        <span class="c1"># replace semantic_pad_token (eos_tok and pad_tok here) with coarse_semantic_pad_token i.e the pad_token</span>
        <span class="c1"># used in the next model</span>
        <span class="n">semantic_output</span> <span class="o">=</span> <span class="n">semantic_output</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span>
            <span class="n">semantic_output</span> <span class="o">==</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span><span class="p">,</span>
            <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_semantic_pad_token</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">semantic_to_coarse_ratio</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_rate_hz</span>
            <span class="o">/</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_rate_hz</span>
            <span class="o">*</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span>
        <span class="p">)</span>
        <span class="n">max_semantic_history</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">max_coarse_history</span> <span class="o">/</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">))</span>

        <span class="n">output_lengths</span> <span class="o">=</span> <span class="p">(</span><span class="n">semantic_output</span> <span class="o">!=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_semantic_pad_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">output_lengths</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span>
            <span class="n">output_lengths</span> <span class="o">*</span> <span class="n">semantic_to_coarse_ratio</span> <span class="o">/</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span>
        <span class="p">)</span>
        <span class="n">output_lengths</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">output_lengths</span> <span class="o">*</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>

        <span class="n">max_generated_len</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output_lengths</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">semantic_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">x_semantic_history</span><span class="p">,</span> <span class="n">x_coarse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_histories</span><span class="p">(</span>
            <span class="n">history_prompt</span><span class="o">=</span><span class="n">history_prompt</span><span class="p">,</span>
            <span class="n">max_coarse_history</span><span class="o">=</span><span class="n">max_coarse_history</span><span class="p">,</span>
            <span class="n">semantic_to_coarse_ratio</span><span class="o">=</span><span class="n">semantic_to_coarse_ratio</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">semantic_generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
            <span class="n">codebook_size</span><span class="o">=</span><span class="n">codebook_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">base_semantic_idx</span> <span class="o">=</span> <span class="n">x_semantic_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">semantic_output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x_semantic_history</span><span class="p">,</span> <span class="n">semantic_output</span><span class="p">])</span>

        <span class="n">n_window_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">max_generated_len</span> <span class="o">/</span> <span class="n">sliding_window_len</span><span class="p">))</span>

        <span class="n">total_generated_len</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">len_coarse_history</span> <span class="o">=</span> <span class="n">x_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_window_steps</span><span class="p">):</span>
            <span class="n">semantic_idx</span> <span class="o">=</span> <span class="n">base_semantic_idx</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">total_generated_len</span> <span class="o">/</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">))</span>

            <span class="c1"># pad from right side</span>
            <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">semantic_output</span><span class="p">[:,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">semantic_idx</span> <span class="o">-</span> <span class="n">max_semantic_history</span><span class="p">]))</span> <span class="p">:]</span>
            <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">input_coarse</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_coarse_input_length</span><span class="p">]</span>
            <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                <span class="n">input_coarse</span><span class="p">,</span>
                <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_coarse_input_length</span> <span class="o">-</span> <span class="n">input_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                <span class="s2">&quot;constant&quot;</span><span class="p">,</span>
                <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_semantic_pad_token</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="mi">0</span> <span class="ow">in</span> <span class="n">x_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">input_coarse</span><span class="p">,</span>
                        <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_infer_token</span><span class="p">]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">input_coarse</span><span class="p">,</span>
                        <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_infer_token</span><span class="p">]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">),</span>
                        <span class="n">x_coarse</span><span class="p">[:,</span> <span class="o">-</span><span class="n">max_coarse_history</span><span class="p">:],</span>
                    <span class="p">]</span>
                <span class="p">)</span>

            <span class="n">alternatingLogitsProcessor</span> <span class="o">=</span> <span class="n">AlternatingCodebooksLogitsProcessor</span><span class="p">(</span>
                <span class="n">input_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_vocab_size</span><span class="p">,</span>
                <span class="n">codebook_size</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">output_coarse</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">input_coarse</span><span class="p">,</span>
                <span class="n">logits_processor</span><span class="o">=</span><span class="p">[</span><span class="n">alternatingLogitsProcessor</span><span class="p">],</span>
                <span class="n">max_new_tokens</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">sliding_window_len</span><span class="p">,</span> <span class="n">max_generated_len</span> <span class="o">-</span> <span class="n">total_generated_len</span><span class="p">),</span>
                <span class="n">generation_config</span><span class="o">=</span><span class="n">coarse_generation_config</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">input_coarse_len</span> <span class="o">=</span> <span class="n">input_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">x_coarse</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x_coarse</span><span class="p">,</span> <span class="n">output_coarse</span><span class="p">[:,</span> <span class="n">input_coarse_len</span><span class="p">:]])</span>
            <span class="n">total_generated_len</span> <span class="o">=</span> <span class="n">x_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">len_coarse_history</span>

            <span class="k">del</span> <span class="n">output_coarse</span>

        <span class="n">coarse_output</span> <span class="o">=</span> <span class="n">x_coarse</span><span class="p">[:,</span> <span class="n">len_coarse_history</span><span class="p">:]</span>

        <span class="k">if</span> <span class="n">return_output_lengths</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">coarse_output</span><span class="p">,</span> <span class="n">output_lengths</span>

        <span class="k">return</span> <span class="n">coarse_output</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.generate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkCoarseModel</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">semantic_output</span><span class="p">,</span> <span class="n">semantic_generation_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">coarse_generation_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">codebook_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">history_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_output_lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.generate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generates coarse acoustics tokens from input text semantic tokens and an additional optional <code>Bark</code> speaker
prompt.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>semantic_output</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input text semantic ids, i.e the output of <code>BarkSemanticModel.generate</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape (batch_size, seq_len), *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>semantic_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config indicating how to generate the semantic tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`BarkSemanticGenerationConfig`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>coarse_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config indicating how to generate the coarse tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`BarkCoarseGenerationConfig`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>codebook_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1024</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>history_prompt</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional <code>Bark</code> speaker prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[Dict[str,mindspore.Tensor]]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_output_lengths</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return the output lengths. Useful when batching.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Union">Union</span>[<span title="mindspore.Tensor">Tensor</span>, <span title="typing.Tuple">Tuple</span>[<span title="mindspore.Tensor">Tensor</span>, <span title="mindspore.Tensor">Tensor</span>]]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Conditional return:
By default:</p>
<ul>
<li>
<p>mindspore.Tensor: Output coarse acoustics tokens.
If <code>return_output_lengths=True</code>:</p>
</li>
<li>
<p>`Tuple(mindspore.Tensor, mindspore.Tensor): The output coarse acoustics tokens, and the
length of each sample of the batch.</p>
</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">semantic_output</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">semantic_generation_config</span><span class="p">:</span> <span class="n">BarkSemanticGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">coarse_generation_config</span><span class="p">:</span> <span class="n">BarkCoarseGenerationConfig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">codebook_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_output_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates coarse acoustics tokens from input text semantic tokens and an additional optional `Bark` speaker</span>
<span class="sd">    prompt.</span>

<span class="sd">    Args:</span>
<span class="sd">        semantic_output (`mindspore.Tensor` of shape (batch_size, seq_len), *optional*):</span>
<span class="sd">            Input text semantic ids, i.e the output of `BarkSemanticModel.generate`.</span>
<span class="sd">        semantic_generation_config (`BarkSemanticGenerationConfig`):</span>
<span class="sd">            Generation config indicating how to generate the semantic tokens.</span>
<span class="sd">        coarse_generation_config (`BarkCoarseGenerationConfig`):</span>
<span class="sd">            Generation config indicating how to generate the coarse tokens.</span>
<span class="sd">        codebook_size (`int`, *optional*, defaults to 1024):</span>
<span class="sd">            Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</span>
<span class="sd">        history_prompt (`Optional[Dict[str,mindspore.Tensor]]`, *optional*):</span>
<span class="sd">            Optional `Bark` speaker prompt.</span>
<span class="sd">        return_output_lengths (`bool`, *optional*):</span>
<span class="sd">            Whether or not to return the output lengths. Useful when batching.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Conditional return:</span>
<span class="sd">            By default:</span>

<span class="sd">            - mindspore.Tensor: Output coarse acoustics tokens.</span>
<span class="sd">            If `return_output_lengths=True`:</span>

<span class="sd">            - `Tuple(mindspore.Tensor, mindspore.Tensor): The output coarse acoustics tokens, and the</span>
<span class="sd">            length of each sample of the batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">semantic_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`semantic_generation_config` has to be provided&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">coarse_generation_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`coarse_generation_config` has to be provided&quot;</span><span class="p">)</span>

    <span class="n">max_coarse_input_length</span> <span class="o">=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">max_coarse_input_length</span>
    <span class="n">max_coarse_history</span> <span class="o">=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">max_coarse_history</span>
    <span class="n">sliding_window_len</span> <span class="o">=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">sliding_window_len</span>

    <span class="c1"># replace semantic_pad_token (eos_tok and pad_tok here) with coarse_semantic_pad_token i.e the pad_token</span>
    <span class="c1"># used in the next model</span>
    <span class="n">semantic_output</span> <span class="o">=</span> <span class="n">semantic_output</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span>
        <span class="n">semantic_output</span> <span class="o">==</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_pad_token</span><span class="p">,</span>
        <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_semantic_pad_token</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">semantic_to_coarse_ratio</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_rate_hz</span>
        <span class="o">/</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_rate_hz</span>
        <span class="o">*</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span>
    <span class="p">)</span>
    <span class="n">max_semantic_history</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">max_coarse_history</span> <span class="o">/</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">))</span>

    <span class="n">output_lengths</span> <span class="o">=</span> <span class="p">(</span><span class="n">semantic_output</span> <span class="o">!=</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_semantic_pad_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">output_lengths</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span>
        <span class="n">output_lengths</span> <span class="o">*</span> <span class="n">semantic_to_coarse_ratio</span> <span class="o">/</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span>
    <span class="p">)</span>
    <span class="n">output_lengths</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">output_lengths</span> <span class="o">*</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>

    <span class="n">max_generated_len</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output_lengths</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">semantic_output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">x_semantic_history</span><span class="p">,</span> <span class="n">x_coarse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_histories</span><span class="p">(</span>
        <span class="n">history_prompt</span><span class="o">=</span><span class="n">history_prompt</span><span class="p">,</span>
        <span class="n">max_coarse_history</span><span class="o">=</span><span class="n">max_coarse_history</span><span class="p">,</span>
        <span class="n">semantic_to_coarse_ratio</span><span class="o">=</span><span class="n">semantic_to_coarse_ratio</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">semantic_generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
        <span class="n">codebook_size</span><span class="o">=</span><span class="n">codebook_size</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">base_semantic_idx</span> <span class="o">=</span> <span class="n">x_semantic_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">semantic_output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x_semantic_history</span><span class="p">,</span> <span class="n">semantic_output</span><span class="p">])</span>

    <span class="n">n_window_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">max_generated_len</span> <span class="o">/</span> <span class="n">sliding_window_len</span><span class="p">))</span>

    <span class="n">total_generated_len</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">len_coarse_history</span> <span class="o">=</span> <span class="n">x_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_window_steps</span><span class="p">):</span>
        <span class="n">semantic_idx</span> <span class="o">=</span> <span class="n">base_semantic_idx</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">total_generated_len</span> <span class="o">/</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">))</span>

        <span class="c1"># pad from right side</span>
        <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">semantic_output</span><span class="p">[:,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">semantic_idx</span> <span class="o">-</span> <span class="n">max_semantic_history</span><span class="p">]))</span> <span class="p">:]</span>
        <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">input_coarse</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_coarse_input_length</span><span class="p">]</span>
        <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">input_coarse</span><span class="p">,</span>
            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_coarse_input_length</span> <span class="o">-</span> <span class="n">input_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
            <span class="s2">&quot;constant&quot;</span><span class="p">,</span>
            <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_semantic_pad_token</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="mi">0</span> <span class="ow">in</span> <span class="n">x_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">input_coarse</span><span class="p">,</span>
                    <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_infer_token</span><span class="p">]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_coarse</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">input_coarse</span><span class="p">,</span>
                    <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">coarse_infer_token</span><span class="p">]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">),</span>
                    <span class="n">x_coarse</span><span class="p">[:,</span> <span class="o">-</span><span class="n">max_coarse_history</span><span class="p">:],</span>
                <span class="p">]</span>
            <span class="p">)</span>

        <span class="n">alternatingLogitsProcessor</span> <span class="o">=</span> <span class="n">AlternatingCodebooksLogitsProcessor</span><span class="p">(</span>
            <span class="n">input_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_vocab_size</span><span class="p">,</span>
            <span class="n">codebook_size</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">output_coarse</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">input_coarse</span><span class="p">,</span>
            <span class="n">logits_processor</span><span class="o">=</span><span class="p">[</span><span class="n">alternatingLogitsProcessor</span><span class="p">],</span>
            <span class="n">max_new_tokens</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">sliding_window_len</span><span class="p">,</span> <span class="n">max_generated_len</span> <span class="o">-</span> <span class="n">total_generated_len</span><span class="p">),</span>
            <span class="n">generation_config</span><span class="o">=</span><span class="n">coarse_generation_config</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">input_coarse_len</span> <span class="o">=</span> <span class="n">input_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">x_coarse</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x_coarse</span><span class="p">,</span> <span class="n">output_coarse</span><span class="p">[:,</span> <span class="n">input_coarse_len</span><span class="p">:]])</span>
        <span class="n">total_generated_len</span> <span class="o">=</span> <span class="n">x_coarse</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">len_coarse_history</span>

        <span class="k">del</span> <span class="n">output_coarse</span>

    <span class="n">coarse_output</span> <span class="o">=</span> <span class="n">x_coarse</span><span class="p">[:,</span> <span class="n">len_coarse_history</span><span class="p">:]</span>

    <span class="k">if</span> <span class="n">return_output_lengths</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">coarse_output</span><span class="p">,</span> <span class="n">output_lengths</span>

    <span class="k">return</span> <span class="n">coarse_output</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.preprocess_histories" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkCoarseModel</span><span class="o">.</span><span class="n">preprocess_histories</span><span class="p">(</span><span class="n">max_coarse_history</span><span class="p">,</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">semantic_generation_config</span><span class="p">,</span> <span class="n">codebook_size</span><span class="p">,</span> <span class="n">history_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCoarseModel.preprocess_histories" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Preprocess the optional <code>Bark</code> speaker prompts before <code>self.generate</code>.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>max_coarse_history</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Maximum size of coarse tokens used.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>semantic_to_coarse_ratio</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ratio of semantic to coarse frequency</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batch size, i.e the number of samples.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>semantic_generation_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generation config indicating how to generate the semantic tokens.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`BarkSemanticGenerationConfig`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>codebook_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>history_prompt</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional <code>Bark</code> speaker prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[Dict[str,mindspore.Tensor]]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>tuple(mindspore.Tensor)</code>:</p>
<ul>
<li><strong>x_semantic_history</strong> (<code>mindspore.Tensor</code> -- Processed semantic speaker prompt.</li>
<li><strong>x_coarse_history</strong> (<code>mindspore.Tensor</code>) -- Processed coarse speaker prompt.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">preprocess_histories</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">max_coarse_history</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">semantic_to_coarse_ratio</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">semantic_generation_config</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">codebook_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess the optional `Bark` speaker prompts before `self.generate`.</span>

<span class="sd">    Args:</span>
<span class="sd">        max_coarse_history (`int`):</span>
<span class="sd">            Maximum size of coarse tokens used.</span>
<span class="sd">        semantic_to_coarse_ratio (`int`):</span>
<span class="sd">            Ratio of semantic to coarse frequency</span>
<span class="sd">        batch_size (`int`):</span>
<span class="sd">            Batch size, i.e the number of samples.</span>
<span class="sd">        semantic_generation_config (`BarkSemanticGenerationConfig`):</span>
<span class="sd">            Generation config indicating how to generate the semantic tokens.</span>
<span class="sd">        codebook_size (`int`):</span>
<span class="sd">            Codebook channel size, i.e. the size of the output vocabulary per codebook channel.</span>
<span class="sd">        history_prompt (`Optional[Dict[str,mindspore.Tensor]]`):</span>
<span class="sd">            Optional `Bark` speaker prompt.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `tuple(mindspore.Tensor)`:</span>

<span class="sd">            - **x_semantic_history** (`mindspore.Tensor` -- Processed semantic speaker prompt.</span>
<span class="sd">            - **x_coarse_history** (`mindspore.Tensor`) -- Processed coarse speaker prompt.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">history_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x_semantic_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">history_prompt</span><span class="p">[</span><span class="s2">&quot;semantic_prompt&quot;</span><span class="p">][</span><span class="kc">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># clone to avoid modifying history_prompt.coarse_prompt</span>
        <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">history_prompt</span><span class="p">[</span><span class="s2">&quot;coarse_prompt&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="c1"># offset x_coarse_history</span>
        <span class="k">if</span> <span class="n">codebook_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x_coarse_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="c1"># offset</span>
                <span class="n">x_coarse_history</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">codebook_size</span> <span class="o">*</span> <span class="n">n</span>

        <span class="c1"># flatten x_coarse_history</span>
        <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">x_coarse_history</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">x_coarse_history</span> <span class="o">+</span> <span class="n">semantic_generation_config</span><span class="o">.</span><span class="n">semantic_vocab_size</span>

        <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">x_coarse_history</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># e.g: after SEMANTIC_VOCAB_SIZE (10000), 1024 tokens dedicated to first codebook, 1024 next tokens</span>
        <span class="c1"># dedicated to second codebook.</span>

        <span class="n">max_semantic_history</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">max_coarse_history</span> <span class="o">/</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">))</span>
        <span class="c1"># trim histories correctly</span>
        <span class="n">n_semantic_hist_provided</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">max_semantic_history</span><span class="p">,</span>
                <span class="n">x_semantic_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x_semantic_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="mi">2</span><span class="p">,</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">x_coarse_history</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">)),</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">n_coarse_hist_provided</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">n_semantic_hist_provided</span> <span class="o">*</span> <span class="n">semantic_to_coarse_ratio</span><span class="p">))</span>

        <span class="n">x_semantic_history</span> <span class="o">=</span> <span class="n">x_semantic_history</span><span class="p">[:,</span> <span class="o">-</span><span class="n">n_semantic_hist_provided</span><span class="p">:]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">x_coarse_history</span><span class="p">[:,</span> <span class="o">-</span><span class="n">n_coarse_hist_provided</span><span class="p">:]</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="c1"># bit of a hack for time alignment (sounds better) - from Bark original implementation</span>
        <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">x_coarse_history</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># shape: (batch_size, 0)</span>
        <span class="n">x_semantic_history</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">_c_expression</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
        <span class="n">x_coarse_history</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">_c_expression</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[]]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">x_semantic_history</span><span class="p">,</span> <span class="n">x_coarse_history</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.modeling_bark.BarkModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.modeling_bark.BarkModel</code>


<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel">BarkPreTrainedModel</a></code></p>


        <p>BarkModel</p>
<p>This class represents a Bark model that is used for generating audio from an input prompt and an optional speaker prompt. It is a subclass of BarkPreTrainedModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">METHOD</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkModel.__init__" href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.__init__">__init__</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Initializes the BarkModel instance.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkModel.codec_decode" href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.codec_decode">codec_decode</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Turns quantized audio codes into an audio array using the encodec.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkModel.generate" href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.generate">generate</a></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Generates audio from an input prompt and an optional speaker prompt.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkModel.semantic">semantic</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>An instance of BarkSemanticModel.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkModel.coarse_acoustics">coarse_acoustics</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>An instance of BarkCoarseModel.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkModel.fine_acoustics">fine_acoustics</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>An instance of BarkFineModel.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkModel.codec_model">codec_model</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>An instance of the AutoModel class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkModel.config">config</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>The configuration object for the BarkModel.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">BarkModel</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;suno/bark-small&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">BarkModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;suno/bark-small&quot;</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># To add a voice preset, you can pass `voice_preset` to `BarkProcessor.__call__(...)`</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">voice_preset</span> <span class="o">=</span> <span class="s2">&quot;v2/en_speaker_6&quot;</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="s2">&quot;Hello, my dog is cute, I need him in my life&quot;</span><span class="p">,</span> <span class="n">voice_preset</span><span class="o">=</span><span class="n">voice_preset</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">audio_array</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">semantic_max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">audio_array</span> <span class="o">=</span> <span class="n">audio_array</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</code></pre></div>
</details>





              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span>
<span class="normal">1884</span>
<span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkModel</span><span class="p">(</span><span class="n">BarkPreTrainedModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BarkModel</span>

<span class="sd">    This class represents a Bark model that is used for generating audio from an input prompt and an optional speaker prompt. It is a subclass of BarkPreTrainedModel.</span>

<span class="sd">    Methods:</span>
<span class="sd">        __init__: Initializes the BarkModel instance.</span>
<span class="sd">        codec_decode: Turns quantized audio codes into an audio array using the encodec.</span>
<span class="sd">        generate:</span>
<span class="sd">            Generates audio from an input prompt and an optional speaker prompt.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        semantic: An instance of BarkSemanticModel.</span>
<span class="sd">        coarse_acoustics: An instance of BarkCoarseModel.</span>
<span class="sd">        fine_acoustics: An instance of BarkFineModel.</span>
<span class="sd">        codec_model: An instance of the AutoModel class.</span>
<span class="sd">        config: The configuration object for the BarkModel.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoProcessor, BarkModel</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;suno/bark-small&quot;)</span>
<span class="sd">        &gt;&gt;&gt; model = BarkModel.from_pretrained(&quot;suno/bark-small&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # To add a voice preset, you can pass `voice_preset` to `BarkProcessor.__call__(...)`</span>
<span class="sd">        &gt;&gt;&gt; voice_preset = &quot;v2/en_speaker_6&quot;</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; inputs = processor(&quot;Hello, my dog is cute, I need him in my life&quot;, voice_preset=voice_preset)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; audio_array = model.generate(**inputs, semantic_max_new_tokens=100)</span>
<span class="sd">        &gt;&gt;&gt; audio_array = audio_array.cpu().numpy().squeeze()</span>
<span class="sd">        ```</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">BarkConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a new instance of BarkModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkModel): The current instance of the BarkModel class.</span>
<span class="sd">            config (dict): A dictionary containing configuration settings for the BarkModel.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">semantic</span> <span class="o">=</span> <span class="n">BarkSemanticModel</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">semantic_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics</span> <span class="o">=</span> <span class="n">BarkCoarseModel</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">coarse_acoustics_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics</span> <span class="o">=</span> <span class="n">BarkFineModel</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">fine_acoustics_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">codec_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

    <span class="k">def</span> <span class="nf">codec_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fine_output</span><span class="p">,</span> <span class="n">output_lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Turn quantized audio codes into audio array using encodec.&quot;&quot;&quot;</span>
        <span class="n">fine_output</span> <span class="o">=</span> <span class="n">fine_output</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">fine_output</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">output_lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># encodec uses LSTMs which behaves differently with appended padding</span>
            <span class="c1"># decoding with encodec takes around 0.1% of the total generation time</span>
            <span class="c1"># to keep generation quality, we break batching</span>
            <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[:,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">output_lengths</span><span class="p">)]</span>
            <span class="n">audio_arr</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">out</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span>
            <span class="n">audio_arr</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># squeeze the codebook dimension</span>

        <span class="k">return</span> <span class="n">audio_arr</span>

    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_output_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates audio from an input prompt and an additional optional `Bark` speaker prompt.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_ids (`Optional[mindspore.Tensor]` of shape (batch_size, seq_len), *optional*):</span>
<span class="sd">                Input ids. Will be truncated up to 256 tokens. Note that the output audios will be as long as the</span>
<span class="sd">                longest generation among the batch.</span>
<span class="sd">            history_prompt (`Optional[Dict[str,mindspore.Tensor]]`, *optional*):</span>
<span class="sd">                Optional `Bark` speaker prompt. Note that for now, this model takes only one speaker prompt per batch.</span>
<span class="sd">            kwargs (*optional*):</span>
<span class="sd">                Remaining dictionary of keyword arguments. Keyword arguments are of two types:</span>

<span class="sd">                - Without a prefix, they will be entered as `**kwargs` for the `generate` method of each sub-model.</span>
<span class="sd">                - With a *semantic_*, *coarse_*, *fine_* prefix, they will be input for the `generate` method of the</span>
<span class="sd">                semantic, coarse and fine respectively. It has the priority over the keywords without a prefix.</span>

<span class="sd">                This means you can, for example, specify a generation strategy for all sub-models except one.</span>
<span class="sd">            return_output_lengths (`bool`, *optional*):</span>
<span class="sd">                Whether or not to return the waveform lengths. Useful when batching.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mindspore.Tensor:</span>
<span class="sd">                By default:</span>

<span class="sd">                - **audio_waveform** (`mindspore.Tensor` of shape (batch_size, seq_len)): Generated audio waveform.</span>

<span class="sd">                When `return_output_lengths=True`:</span>

<span class="sd">                - Returns a tuple made of:</span>
<span class="sd">                - **audio_waveform** (`mindspore.Tensor` of shape (batch_size, seq_len)): Generated audio waveform.</span>
<span class="sd">                - **output_lengths** (`mindspore.Tensor` of shape (batch_size)): The length of each waveform in the batch</span>

<span class="sd">        Example:</span>
<span class="sd">            ```python</span>
<span class="sd">            &gt;&gt;&gt; from transformers import AutoProcessor, BarkModel</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;suno/bark-small&quot;)</span>
<span class="sd">            &gt;&gt;&gt; model = BarkModel.from_pretrained(&quot;suno/bark-small&quot;)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; # To add a voice preset, you can pass `voice_preset` to `BarkProcessor.__call__(...)`</span>
<span class="sd">            &gt;&gt;&gt; voice_preset = &quot;v2/en_speaker_6&quot;</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; inputs = processor(&quot;Hello, my dog is cute, I need him in my life&quot;, voice_preset=voice_preset)</span>
<span class="sd">            ...</span>
<span class="sd">            &gt;&gt;&gt; audio_array = model.generate(**inputs, semantic_max_new_tokens=100)</span>
<span class="sd">            &gt;&gt;&gt; audio_array = audio_array.cpu().numpy().squeeze()</span>
<span class="sd">            ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO (joao):workaround until nested generation config is compatible with PreTrained Model</span>
        <span class="c1"># todo: dict</span>
        <span class="n">semantic_generation_config</span> <span class="o">=</span> <span class="n">BarkSemanticGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">semantic_config</span><span class="p">)</span>
        <span class="n">coarse_generation_config</span> <span class="o">=</span> <span class="n">BarkCoarseGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">coarse_acoustics_config</span><span class="p">)</span>
        <span class="n">fine_generation_config</span> <span class="o">=</span> <span class="n">BarkFineGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">fine_acoustics_config</span><span class="p">)</span>

        <span class="n">kwargs_semantic</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># if &quot;attention_mask&quot; is set, it should not be passed to CoarseModel and FineModel</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="s2">&quot;min_eos_p&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;min_eos_p&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="n">kwargs_coarse</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">kwargs_fine</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;semantic_&quot;</span><span class="p">):</span>
                <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;semantic_&quot;</span><span class="p">)</span> <span class="p">:]</span>
                <span class="n">kwargs_semantic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">elif</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;coarse_&quot;</span><span class="p">):</span>
                <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;coarse_&quot;</span><span class="p">)</span> <span class="p">:]</span>
                <span class="n">kwargs_coarse</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">elif</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;fine_&quot;</span><span class="p">):</span>
                <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;fine_&quot;</span><span class="p">)</span> <span class="p">:]</span>
                <span class="n">kwargs_fine</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># If the key is already in a specific config, then it&#39;s been set with a</span>
                <span class="c1"># submodules specific value and we don&#39;t override</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs_semantic</span><span class="p">:</span>
                    <span class="n">kwargs_semantic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs_coarse</span><span class="p">:</span>
                    <span class="n">kwargs_coarse</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs_fine</span><span class="p">:</span>
                    <span class="n">kwargs_fine</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="c1"># 1. Generate from the semantic model</span>
        <span class="n">semantic_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">semantic</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="p">,</span>
            <span class="n">history_prompt</span><span class="o">=</span><span class="n">history_prompt</span><span class="p">,</span>
            <span class="n">semantic_generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs_semantic</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 2. Generate from the coarse model</span>
        <span class="n">coarse_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">semantic_output</span><span class="p">,</span>
            <span class="n">history_prompt</span><span class="o">=</span><span class="n">history_prompt</span><span class="p">,</span>
            <span class="n">semantic_generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
            <span class="n">coarse_generation_config</span><span class="o">=</span><span class="n">coarse_generation_config</span><span class="p">,</span>
            <span class="n">codebook_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">codebook_size</span><span class="p">,</span>
            <span class="n">return_output_lengths</span><span class="o">=</span><span class="n">return_output_lengths</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs_coarse</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">output_lengths</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">return_output_lengths</span><span class="p">:</span>
            <span class="n">coarse_output</span><span class="p">,</span> <span class="n">output_lengths</span> <span class="o">=</span> <span class="n">coarse_output</span>
            <span class="c1"># (batch_size, seq_len*coarse_codebooks) -&gt; (batch_size, seq_len)</span>
            <span class="n">output_lengths</span> <span class="o">=</span> <span class="n">output_lengths</span> <span class="o">//</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span>

        <span class="c1"># 3. &quot;generate&quot; from the fine model</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">coarse_output</span><span class="p">,</span>
            <span class="n">history_prompt</span><span class="o">=</span><span class="n">history_prompt</span><span class="p">,</span>
            <span class="n">semantic_generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
            <span class="n">coarse_generation_config</span><span class="o">=</span><span class="n">coarse_generation_config</span><span class="p">,</span>
            <span class="n">fine_generation_config</span><span class="o">=</span><span class="n">fine_generation_config</span><span class="p">,</span>
            <span class="n">codebook_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">codebook_size</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs_fine</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;fine_acoustics_hook&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Manually offload fine_acoustics to CPU</span>
            <span class="c1"># and load codec_model to GPU</span>
            <span class="c1"># since bark doesn&#39;t use codec_model forward pass</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics_hook</span><span class="o">.</span><span class="n">offload</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span>

        <span class="c1"># 4. Decode the output and generate audio array</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">codec_decode</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">output_lengths</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;codec_model_hook&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Offload codec_model to CPU</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">codec_model_hook</span><span class="o">.</span><span class="n">offload</span><span class="p">()</span>

        <span class="c1"># if return_output_lengths:</span>
        <span class="c1">#     output_lengths = [len(sample) for sample in audio]</span>
        <span class="c1">#     audio = nn.utils.rnn.pad_sequence(audio, batch_first=True, padding_value=0)</span>
        <span class="c1">#     return audio, output_lengths</span>

        <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkModel.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkModel</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initializes a new instance of BarkModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The current instance of the BarkModel class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel">BarkModel</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A dictionary containing configuration settings for the BarkModel.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>dict</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span>
<span class="normal">1897</span>
<span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a new instance of BarkModel.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkModel): The current instance of the BarkModel class.</span>
<span class="sd">        config (dict): A dictionary containing configuration settings for the BarkModel.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">semantic</span> <span class="o">=</span> <span class="n">BarkSemanticModel</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">semantic_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics</span> <span class="o">=</span> <span class="n">BarkCoarseModel</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">coarse_acoustics_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics</span> <span class="o">=</span> <span class="n">BarkFineModel</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">fine_acoustics_config</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">codec_config</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkModel.codec_decode" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkModel</span><span class="o">.</span><span class="n">codec_decode</span><span class="p">(</span><span class="n">fine_output</span><span class="p">,</span> <span class="n">output_lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.codec_decode" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Turn quantized audio codes into audio array using encodec.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span>
<span class="normal">1917</span>
<span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">codec_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fine_output</span><span class="p">,</span> <span class="n">output_lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Turn quantized audio codes into audio array using encodec.&quot;&quot;&quot;</span>
    <span class="n">fine_output</span> <span class="o">=</span> <span class="n">fine_output</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">fine_output</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># encodec uses LSTMs which behaves differently with appended padding</span>
        <span class="c1"># decoding with encodec takes around 0.1% of the total generation time</span>
        <span class="c1"># to keep generation quality, we break batching</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="p">[:,</span> <span class="p">:</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">output_lengths</span><span class="p">)]</span>
        <span class="n">audio_arr</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">out</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span>
        <span class="n">audio_arr</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># squeeze the codebook dimension</span>

    <span class="k">return</span> <span class="n">audio_arr</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkModel.generate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkModel</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">history_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_output_lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkModel.generate" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Generates audio from an input prompt and an additional optional <code>Bark</code> speaker prompt.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_ids</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input ids. Will be truncated up to 256 tokens. Note that the output audios will be as long as the
longest generation among the batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[mindspore.Tensor]` of shape (batch_size, seq_len), *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>history_prompt</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional <code>Bark</code> speaker prompt. Note that for now, this model takes only one speaker prompt per batch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Optional[Dict[str,mindspore.Tensor]]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Remaining dictionary of keyword arguments. Keyword arguments are of two types:</p>
<ul>
<li>Without a prefix, they will be entered as <code>**kwargs</code> for the <code>generate</code> method of each sub-model.</li>
<li>With a <em>semantic_</em>, <em>coarse_</em>, <em>fine_</em> prefix, they will be input for the <code>generate</code> method of the
semantic, coarse and fine respectively. It has the priority over the keywords without a prefix.</li>
</ul>
<p>This means you can, for example, specify a generation strategy for all sub-models except one.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>*optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_output_lengths</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return the waveform lengths. Useful when batching.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindspore.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>mindspore.Tensor:
By default:</p>
<ul>
<li><strong>audio_waveform</strong> (<code>mindspore.Tensor</code> of shape (batch_size, seq_len)): Generated audio waveform.</li>
</ul>
<p>When <code>return_output_lengths=True</code>:</p>
<ul>
<li>Returns a tuple made of:</li>
<li><strong>audio_waveform</strong> (<code>mindspore.Tensor</code> of shape (batch_size, seq_len)): Generated audio waveform.</li>
<li><strong>output_lengths</strong> (<code>mindspore.Tensor</code> of shape (batch_size)): The length of each waveform in the batch</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">BarkModel</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;suno/bark-small&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">BarkModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;suno/bark-small&quot;</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># To add a voice preset, you can pass `voice_preset` to `BarkProcessor.__call__(...)`</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">voice_preset</span> <span class="o">=</span> <span class="s2">&quot;v2/en_speaker_6&quot;</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="s2">&quot;Hello, my dog is cute, I need him in my life&quot;</span><span class="p">,</span> <span class="n">voice_preset</span><span class="o">=</span><span class="n">voice_preset</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">audio_array</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">semantic_max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">audio_array</span> <span class="o">=</span> <span class="n">audio_array</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</code></pre></div>
</details>
            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span>
<span class="normal">1937</span>
<span class="normal">1938</span>
<span class="normal">1939</span>
<span class="normal">1940</span>
<span class="normal">1941</span>
<span class="normal">1942</span>
<span class="normal">1943</span>
<span class="normal">1944</span>
<span class="normal">1945</span>
<span class="normal">1946</span>
<span class="normal">1947</span>
<span class="normal">1948</span>
<span class="normal">1949</span>
<span class="normal">1950</span>
<span class="normal">1951</span>
<span class="normal">1952</span>
<span class="normal">1953</span>
<span class="normal">1954</span>
<span class="normal">1955</span>
<span class="normal">1956</span>
<span class="normal">1957</span>
<span class="normal">1958</span>
<span class="normal">1959</span>
<span class="normal">1960</span>
<span class="normal">1961</span>
<span class="normal">1962</span>
<span class="normal">1963</span>
<span class="normal">1964</span>
<span class="normal">1965</span>
<span class="normal">1966</span>
<span class="normal">1967</span>
<span class="normal">1968</span>
<span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span>
<span class="normal">2043</span>
<span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span>
<span class="normal">2063</span>
<span class="normal">2064</span>
<span class="normal">2065</span>
<span class="normal">2066</span>
<span class="normal">2067</span>
<span class="normal">2068</span>
<span class="normal">2069</span>
<span class="normal">2070</span>
<span class="normal">2071</span>
<span class="normal">2072</span>
<span class="normal">2073</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">history_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_output_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates audio from an input prompt and an additional optional `Bark` speaker prompt.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_ids (`Optional[mindspore.Tensor]` of shape (batch_size, seq_len), *optional*):</span>
<span class="sd">            Input ids. Will be truncated up to 256 tokens. Note that the output audios will be as long as the</span>
<span class="sd">            longest generation among the batch.</span>
<span class="sd">        history_prompt (`Optional[Dict[str,mindspore.Tensor]]`, *optional*):</span>
<span class="sd">            Optional `Bark` speaker prompt. Note that for now, this model takes only one speaker prompt per batch.</span>
<span class="sd">        kwargs (*optional*):</span>
<span class="sd">            Remaining dictionary of keyword arguments. Keyword arguments are of two types:</span>

<span class="sd">            - Without a prefix, they will be entered as `**kwargs` for the `generate` method of each sub-model.</span>
<span class="sd">            - With a *semantic_*, *coarse_*, *fine_* prefix, they will be input for the `generate` method of the</span>
<span class="sd">            semantic, coarse and fine respectively. It has the priority over the keywords without a prefix.</span>

<span class="sd">            This means you can, for example, specify a generation strategy for all sub-models except one.</span>
<span class="sd">        return_output_lengths (`bool`, *optional*):</span>
<span class="sd">            Whether or not to return the waveform lengths. Useful when batching.</span>

<span class="sd">    Returns:</span>
<span class="sd">        mindspore.Tensor:</span>
<span class="sd">            By default:</span>

<span class="sd">            - **audio_waveform** (`mindspore.Tensor` of shape (batch_size, seq_len)): Generated audio waveform.</span>

<span class="sd">            When `return_output_lengths=True`:</span>

<span class="sd">            - Returns a tuple made of:</span>
<span class="sd">            - **audio_waveform** (`mindspore.Tensor` of shape (batch_size, seq_len)): Generated audio waveform.</span>
<span class="sd">            - **output_lengths** (`mindspore.Tensor` of shape (batch_size)): The length of each waveform in the batch</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoProcessor, BarkModel</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;suno/bark-small&quot;)</span>
<span class="sd">        &gt;&gt;&gt; model = BarkModel.from_pretrained(&quot;suno/bark-small&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # To add a voice preset, you can pass `voice_preset` to `BarkProcessor.__call__(...)`</span>
<span class="sd">        &gt;&gt;&gt; voice_preset = &quot;v2/en_speaker_6&quot;</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; inputs = processor(&quot;Hello, my dog is cute, I need him in my life&quot;, voice_preset=voice_preset)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; audio_array = model.generate(**inputs, semantic_max_new_tokens=100)</span>
<span class="sd">        &gt;&gt;&gt; audio_array = audio_array.cpu().numpy().squeeze()</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO (joao):workaround until nested generation config is compatible with PreTrained Model</span>
    <span class="c1"># todo: dict</span>
    <span class="n">semantic_generation_config</span> <span class="o">=</span> <span class="n">BarkSemanticGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">semantic_config</span><span class="p">)</span>
    <span class="n">coarse_generation_config</span> <span class="o">=</span> <span class="n">BarkCoarseGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">coarse_acoustics_config</span><span class="p">)</span>
    <span class="n">fine_generation_config</span> <span class="o">=</span> <span class="n">BarkFineGenerationConfig</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">fine_acoustics_config</span><span class="p">)</span>

    <span class="n">kwargs_semantic</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># if &quot;attention_mask&quot; is set, it should not be passed to CoarseModel and FineModel</span>
        <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="s2">&quot;min_eos_p&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;min_eos_p&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="n">kwargs_coarse</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">kwargs_fine</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;semantic_&quot;</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;semantic_&quot;</span><span class="p">)</span> <span class="p">:]</span>
            <span class="n">kwargs_semantic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">elif</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;coarse_&quot;</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;coarse_&quot;</span><span class="p">)</span> <span class="p">:]</span>
            <span class="n">kwargs_coarse</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">elif</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;fine_&quot;</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;fine_&quot;</span><span class="p">)</span> <span class="p">:]</span>
            <span class="n">kwargs_fine</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If the key is already in a specific config, then it&#39;s been set with a</span>
            <span class="c1"># submodules specific value and we don&#39;t override</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs_semantic</span><span class="p">:</span>
                <span class="n">kwargs_semantic</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs_coarse</span><span class="p">:</span>
                <span class="n">kwargs_coarse</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs_fine</span><span class="p">:</span>
                <span class="n">kwargs_fine</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="c1"># 1. Generate from the semantic model</span>
    <span class="n">semantic_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">semantic</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="p">,</span>
        <span class="n">history_prompt</span><span class="o">=</span><span class="n">history_prompt</span><span class="p">,</span>
        <span class="n">semantic_generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs_semantic</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># 2. Generate from the coarse model</span>
    <span class="n">coarse_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coarse_acoustics</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">semantic_output</span><span class="p">,</span>
        <span class="n">history_prompt</span><span class="o">=</span><span class="n">history_prompt</span><span class="p">,</span>
        <span class="n">semantic_generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
        <span class="n">coarse_generation_config</span><span class="o">=</span><span class="n">coarse_generation_config</span><span class="p">,</span>
        <span class="n">codebook_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">codebook_size</span><span class="p">,</span>
        <span class="n">return_output_lengths</span><span class="o">=</span><span class="n">return_output_lengths</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs_coarse</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">output_lengths</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">return_output_lengths</span><span class="p">:</span>
        <span class="n">coarse_output</span><span class="p">,</span> <span class="n">output_lengths</span> <span class="o">=</span> <span class="n">coarse_output</span>
        <span class="c1"># (batch_size, seq_len*coarse_codebooks) -&gt; (batch_size, seq_len)</span>
        <span class="n">output_lengths</span> <span class="o">=</span> <span class="n">output_lengths</span> <span class="o">//</span> <span class="n">coarse_generation_config</span><span class="o">.</span><span class="n">n_coarse_codebooks</span>

    <span class="c1"># 3. &quot;generate&quot; from the fine model</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">coarse_output</span><span class="p">,</span>
        <span class="n">history_prompt</span><span class="o">=</span><span class="n">history_prompt</span><span class="p">,</span>
        <span class="n">semantic_generation_config</span><span class="o">=</span><span class="n">semantic_generation_config</span><span class="p">,</span>
        <span class="n">coarse_generation_config</span><span class="o">=</span><span class="n">coarse_generation_config</span><span class="p">,</span>
        <span class="n">fine_generation_config</span><span class="o">=</span><span class="n">fine_generation_config</span><span class="p">,</span>
        <span class="n">codebook_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">codebook_size</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs_fine</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;fine_acoustics_hook&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Manually offload fine_acoustics to CPU</span>
        <span class="c1"># and load codec_model to GPU</span>
        <span class="c1"># since bark doesn&#39;t use codec_model forward pass</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fine_acoustics_hook</span><span class="o">.</span><span class="n">offload</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">codec_model</span>

    <span class="c1"># 4. Decode the output and generate audio array</span>
    <span class="n">audio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">codec_decode</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">output_lengths</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;codec_model_hook&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Offload codec_model to CPU</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">codec_model_hook</span><span class="o">.</span><span class="n">offload</span><span class="p">()</span>

    <span class="c1"># if return_output_lengths:</span>
    <span class="c1">#     output_lengths = [len(sample) for sample in audio]</span>
    <span class="c1">#     audio = nn.utils.rnn.pad_sequence(audio, batch_first=True, padding_value=0)</span>
    <span class="c1">#     return audio, output_lengths</span>

    <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel</code>


<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.modeling_utils.PreTrainedModel" href="../../modeling_utils/#mindnlp.transformers.modeling_utils.PreTrainedModel">PreTrainedModel</a></code></p>


        <p>An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained
models.</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkPreTrainedModel</span><span class="p">(</span><span class="n">PreTrainedModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained</span>
<span class="sd">    models.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">BarkConfig</span>
    <span class="n">supports_gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cell</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the weights&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
            <span class="c1"># Slightly different from the TF version which uses truncated_normal for initialization</span>
            <span class="c1"># cf https://github.com/pytorch/pytorch/pull/5617</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="n">Normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">),</span>
                                                    <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">):</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cell</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">:</span>
                <span class="n">weight</span><span class="p">[</span><span class="n">cell</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;ones&#39;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
            <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cell</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel</code>


<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkPreTrainedModel">BarkPreTrainedModel</a></code></p>


        <p>The <code>BarkCausalModel</code> class is a subclass of <code>BarkPreTrainedModel</code> and represents a model
for causal language modeling using the Bark framework.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">ATTRIBUTE</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`config`">`config`</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>An instance of the <code>BarkConfig</code> class containing the model configuration.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`input_embeds_layer`">`input_embeds_layer`</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>An embedding layer for the input vocabulary.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`position_embeds_layer`">`position_embeds_layer`</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>An embedding layer for the position indices.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`drop`">`drop`</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>A dropout layer.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`layers`">`layers`</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>A list of <code>BarkBlock</code> layers for the model.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`layernorm_final`">`layernorm_final`</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>A layer normalization module for the final hidden states.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`lm_head`">`lm_head`</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>A dense layer for generating the output vocabulary logits.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`gradient_checkpointing`">`gradient_checkpointing`</span></code></td>
            <td class="doc-attribute-details">
              <div class="doc-md-description">
                <p>A boolean indicating whether gradient checkpointing is enabled.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">METHOD</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`__init__">`__init__</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Initializes the <code>BarkCausalModel</code> instance.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`get_input_embeddings">`get_input_embeddings</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Returns the input embedding layer.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`set_input_embeddings">`set_input_embeddings</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Sets the input embedding layer.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`prepare_inputs_for_generation">`prepare_inputs_for_generation</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Prepares the inputs for generation.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><span title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.`_reorder_cache">`_reorder_cache</span></code></td>
              <td class="doc-function-details">
                <div class="doc-md-description">
                  <p>Reorders the cache for beam search or beam sampling.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>This docstring provides an overview of the class and its methods.
For detailed information on each method, please refer to the corresponding method's docstring.</p>
</details>





              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkCausalModel</span><span class="p">(</span><span class="n">BarkPreTrainedModel</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The `BarkCausalModel` class is a subclass of `BarkPreTrainedModel` and represents a model</span>
<span class="sd">    for causal language modeling using the Bark framework.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        `config`: An instance of the `BarkConfig` class containing the model configuration.</span>
<span class="sd">        `input_embeds_layer`: An embedding layer for the input vocabulary.</span>
<span class="sd">        `position_embeds_layer`: An embedding layer for the position indices.</span>
<span class="sd">        `drop`: A dropout layer.</span>
<span class="sd">        `layers`: A list of `BarkBlock` layers for the model.</span>
<span class="sd">        `layernorm_final`: A layer normalization module for the final hidden states.</span>
<span class="sd">        `lm_head`: A dense layer for generating the output vocabulary logits.</span>
<span class="sd">        `gradient_checkpointing`: A boolean indicating whether gradient checkpointing is enabled.</span>

<span class="sd">    Methods:</span>
<span class="sd">        `__init__(self, config)`: Initializes the `BarkCausalModel` instance.</span>
<span class="sd">        `get_input_embeddings(self)`: Returns the input embedding layer.</span>
<span class="sd">        `set_input_embeddings(self, new_embeddings)`: Sets the input embedding layer.</span>
<span class="sd">        `prepare_inputs_for_generation(self, input_ids, past_key_values=None, **kwargs)`: Prepares the inputs for generation.</span>
<span class="sd">        `forward(self, input_ids, past_key_values=None, attention_mask=None, position_ids=None, head_mask=None, labels=None, input_embeds=None, use_cache=None, output_attentions=None,</span>
<span class="sd">            output_hidden_states=None, return_dict=None)`: forwards the model output based on the provided inputs.</span>
<span class="sd">        `_reorder_cache(past_key_values, beam_idx)`: Reorders the cache for beam search or beam sampling.</span>

<span class="sd">    Note:</span>
<span class="sd">        This docstring provides an overview of the class and its methods.</span>
<span class="sd">        For detailed information on each method, please refer to the corresponding method&#39;s docstring.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">BarkSubModelConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes an instance of the BarkCausalModel class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the class.</span>
<span class="sd">            config (object):</span>
<span class="sd">                An object containing configuration parameters for the model.</span>

<span class="sd">                - input_vocab_size (int): The size of the input vocabulary.</span>
<span class="sd">                - hidden_size (int): The size of the hidden state.</span>
<span class="sd">                - block_size (int): The size of the block.</span>
<span class="sd">                - dropout (float): The dropout probability.</span>
<span class="sd">                - num_layers (int): The number of layers.</span>
<span class="sd">                - bias (bool): Whether to apply bias in BarkLayerNorm.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

        <span class="c1"># initialize as an autoregressive GPT-like model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embeds_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">BarkBlock</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">is_causal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layernorm_final</span> <span class="o">=</span> <span class="n">BarkLayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">output_vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method retrieves the input embeddings from the BarkCausalModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkCausalModel): The instance of the BarkCausalModel class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None: This method returns the input embeddings layer of the BarkCausalModel.</span>

<span class="sd">        Raises:</span>
<span class="sd">            This method does not raise any exceptions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span>

    <span class="k">def</span> <span class="nf">set_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_embeddings</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set input embeddings for the BarkCausalModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkCausalModel): The instance of BarkCausalModel.</span>
<span class="sd">            new_embeddings (any): The new input embeddings to be set for the model. It can be of any type.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span> <span class="o">=</span> <span class="n">new_embeddings</span>

    <span class="k">def</span> <span class="nf">prepare_inputs_for_generation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method prepares inputs for generation in the BarkCausalModel class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (object): The instance of the class.</span>
<span class="sd">            input_ids (tensor): The input tensor containing the tokenized input sequence.</span>
<span class="sd">            past_key_values (tuple, optional): The past key values for fast decoding. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict or None: A dictionary containing the prepared input values for generation,</span>
<span class="sd">            including the input_ids, input_embeds, past_key_values, use_cache, position_ids, and attention_mask.</span>
<span class="sd">            Returns None if input_embeds is not provided and use_cache is False.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the input_ids shape is incompatible with past_key_values.</span>
<span class="sd">            ValueError: If the input_embeds shape is incompatible with use_cache.</span>
<span class="sd">            TypeError: If the attention_mask and position_ids shapes are not compatible.</span>
<span class="sd">            RuntimeError: If there are issues with calculating position_ids based on attention_mask.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_embeds</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_embeds&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;position_ids&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Omit tokens covered by past_key_values</span>
            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">past_length</span> <span class="o">=</span> <span class="n">past_key_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

            <span class="c1"># Some generation methods already pass only the last input ID</span>
            <span class="k">if</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">past_length</span><span class="p">:</span>
                <span class="n">remove_prefix_length</span> <span class="o">=</span> <span class="n">past_length</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Default to old behavior: keep only final ID</span>
                <span class="n">remove_prefix_length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:,</span> <span class="n">remove_prefix_length</span><span class="p">:]</span>

            <span class="c1"># input_embeds have already been used and is not required anymore</span>
            <span class="n">input_embeds</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">):</span>
                <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># ensure that attention_mask and position_ids shapes are aligned with the weird Bark hack of reducing</span>
        <span class="c1"># sequence length on the first forward pass</span>
        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># create position_ids on the fly for batch generation</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">past_key_values</span><span class="p">:</span>
                <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s2">&quot;input_embeds&quot;</span><span class="p">:</span> <span class="n">input_embeds</span><span class="p">,</span>
                <span class="s2">&quot;past_key_values&quot;</span><span class="p">:</span> <span class="n">past_key_values</span><span class="p">,</span>
                <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">),</span>
                <span class="s2">&quot;position_ids&quot;</span><span class="p">:</span> <span class="n">position_ids</span><span class="p">,</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
            <span class="s2">&quot;past_key_values&quot;</span><span class="p">:</span> <span class="n">past_key_values</span><span class="p">,</span>
            <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">),</span>
            <span class="s2">&quot;position_ids&quot;</span><span class="p">:</span> <span class="n">position_ids</span><span class="p">,</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">head_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">CausalLMOutputWithPast</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        forwards the BarkCausalModel.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The object itself.</span>
<span class="sd">            input_ids (Optional[mindspore.Tensor]):</span>
<span class="sd">                The input tensor of shape (batch_size, sequence_length). Defaults to None.</span>
<span class="sd">            past_key_values (Optional[Tuple[mindspore.Tensor]]):</span>
<span class="sd">                The past key values tensor of shape (batch_size, num_heads, sequence_length, embed_size_per_head).</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            attention_mask (Optional[mindspore.Tensor]):</span>
<span class="sd">                The attention mask tensor of shape (batch_size, sequence_length). Defaults to None.</span>
<span class="sd">            position_ids (Optional[mindspore.Tensor]):</span>
<span class="sd">                The position ids tensor of shape (batch_size, sequence_length). Defaults to None.</span>
<span class="sd">            head_mask (Optional[mindspore.Tensor]):</span>
<span class="sd">                The head mask tensor of shape (num_heads, sequence_length, sequence_length). Defaults to None.</span>
<span class="sd">            labels (Optional[mindspore.Tensor]):</span>
<span class="sd">                The labels tensor of shape (batch_size, sequence_length). Defaults to None.</span>
<span class="sd">            input_embeds (Optional[mindspore.Tensor]):</span>
<span class="sd">                The input embeddings tensor of shape (batch_size, sequence_length, embed_size). Defaults to None.</span>
<span class="sd">            use_cache (Optional[bool]): Whether to use cache. Defaults to None.</span>
<span class="sd">            output_attentions (Optional[bool]): Whether to output attentions. Defaults to None.</span>
<span class="sd">            output_hidden_states (Optional[bool]): Whether to output hidden states. Defaults to None.</span>
<span class="sd">            return_dict (Optional[bool]): Whether to return a dictionary. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Union[Tuple[mindspore.Tensor], CausalLMOutputWithPast]:</span>
<span class="sd">                The output of the model. It can be a tuple containing the following elements:</span>

<span class="sd">                - loss (mindspore.Tensor): The loss tensor.</span>
<span class="sd">                - logits (mindspore.Tensor): The logits tensor.</span>
<span class="sd">                - past_key_values (Tuple[mindspore.Tensor]): The past key values tensor.</span>
<span class="sd">                - hidden_states (Tuple[mindspore.Tensor]): The hidden states tensor.</span>
<span class="sd">                - attentions (Tuple[mindspore.Tensor]): The attentions tensor.</span>
<span class="sd">            or an instance of the CausalLMOutputWithPast class.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If both input_ids and input_embeds are specified.</span>
<span class="sd">            ValueError: If batch_size is not defined or &lt;= 0.</span>
<span class="sd">            NotImplementedError: If training is not implemented yet for Bark - ensure you do not pass labels to the model.</span>
<span class="sd">            &#39;&#39;&#39;</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">use_cache</span> <span class="o">=</span> <span class="n">use_cache</span> <span class="k">if</span> <span class="n">use_cache</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="c1"># Verify if input_embeds already exists</span>
        <span class="c1"># then compute embeddings.</span>
        <span class="k">if</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You cannot specify both input_ids and input_embeds at the same time&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># we want to return the input_embeds in priority so that it is in line with a weird hack</span>
            <span class="c1"># of Bark which concatenate two bits of the input_embeds on the first forward pass of the semantic model</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>  <span class="c1"># token embeddings of shape (b, t, n_embd)</span>
        <span class="k">elif</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You have to specify either input_ids or input_embeds&quot;</span><span class="p">)</span>

        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">seq_length</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">past_length</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">past_key_values</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">past_length</span> <span class="o">=</span> <span class="n">past_key_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">past_length</span><span class="p">,</span> <span class="n">seq_length</span> <span class="o">+</span> <span class="n">past_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># shape (1, seq_length)</span>

        <span class="n">position_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeds_layer</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>  <span class="c1"># position embeddings of shape (1, t, n_embd)</span>

        <span class="c1"># Attention mask.</span>
        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;batch_size has to be defined and &gt; 0&quot;</span><span class="p">)</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># [bsz, to_seq_length] -&gt; [bsz, 1, 1, to_seq_length]</span>
            <span class="c1"># from_seq_length is 1 to easily broadcast</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">_prepare_4d_attention_mask</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Prepare head mask if needed</span>
        <span class="c1"># 1.0 in head_mask indicate we keep the head</span>
        <span class="c1"># attention_probs has shape bsz x num_heads x N x N</span>
        <span class="c1"># head_mask has shape num_layers x batch x num_heads x N x N</span>
        <span class="n">head_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_head_mask</span><span class="p">(</span><span class="n">head_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">input_embeds</span> <span class="o">+</span> <span class="n">position_embeds</span><span class="p">)</span>
        <span class="n">output_shape</span> <span class="o">=</span> <span class="n">input_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span>
                    <span class="s2">&quot;`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...&quot;</span>
                <span class="p">)</span>
                <span class="n">use_cache</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">present_key_values</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">use_cache</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">all_self_attentions</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">past_layer_key_values</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="n">past_key_values</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
                <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="n">all_hidden_states</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span>
                <span class="n">hidden_states</span><span class="p">,</span>
                <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_layer_key_values</span><span class="p">,</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">head_mask</span><span class="o">=</span><span class="n">head_mask</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
                <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>
                <span class="n">present_key_values</span> <span class="o">=</span> <span class="n">present_key_values</span> <span class="o">+</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>

            <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
                <span class="n">all_self_attentions</span> <span class="o">=</span> <span class="n">all_self_attentions</span> <span class="o">+</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">2</span> <span class="k">if</span> <span class="n">use_cache</span> <span class="k">else</span> <span class="mi">1</span><span class="p">],)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm_final</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>

        <span class="c1"># Add last hidden state</span>
        <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
            <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="n">all_hidden_states</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;Training is not implemented yet for Bark - ensure you do not pass `labels` to the model.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span>
                <span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">present_key_values</span><span class="p">,</span> <span class="n">all_hidden_states</span><span class="p">,</span> <span class="n">all_self_attentions</span><span class="p">]</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">CausalLMOutputWithPast</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">present_key_values</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">all_hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">all_self_attentions</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_reorder_cache</span><span class="p">(</span>
        <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">beam_idx</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function is used to re-order the `past_key_values` cache if [`~PreTrainedModel.beam_search`] or</span>
<span class="sd">        [`~PreTrainedModel.beam_sample`] is called. This is required to match `past_key_values` with the correct</span>
<span class="sd">        beam_idx at every generation step.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Necessary for beam_search</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">past_state</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">beam_idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">past_state</span> <span class="ow">in</span> <span class="n">layer_past</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">layer_past</span> <span class="ow">in</span> <span class="n">past_key_values</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkCausalModel</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initializes an instance of the BarkCausalModel class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An object containing configuration parameters for the model.</p>
<ul>
<li>input_vocab_size (int): The size of the input vocabulary.</li>
<li>hidden_size (int): The size of the hidden state.</li>
<li>block_size (int): The size of the block.</li>
<li>dropout (float): The dropout probability.</li>
<li>num_layers (int): The number of layers.</li>
<li>bias (bool): Whether to apply bias in BarkLayerNorm.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes an instance of the BarkCausalModel class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The instance of the class.</span>
<span class="sd">        config (object):</span>
<span class="sd">            An object containing configuration parameters for the model.</span>

<span class="sd">            - input_vocab_size (int): The size of the input vocabulary.</span>
<span class="sd">            - hidden_size (int): The size of the hidden state.</span>
<span class="sd">            - block_size (int): The size of the block.</span>
<span class="sd">            - dropout (float): The dropout probability.</span>
<span class="sd">            - num_layers (int): The number of layers.</span>
<span class="sd">            - bias (bool): Whether to apply bias in BarkLayerNorm.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

    <span class="c1"># initialize as an autoregressive GPT-like model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">position_embeds_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">BarkBlock</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">is_causal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)])</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm_final</span> <span class="o">=</span> <span class="n">BarkLayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">output_vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Initialize weights and apply final processing</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkCausalModel</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">head_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>forwards the BarkCausalModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The object itself.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_ids</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The input tensor of shape (batch_size, sequence_length). Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>past_key_values</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The past key values tensor of shape (batch_size, num_heads, sequence_length, embed_size_per_head).
Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="typing.Tuple">Tuple</span>[<span title="mindspore.Tensor">Tensor</span>]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The attention mask tensor of shape (batch_size, sequence_length). Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>position_ids</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The position ids tensor of shape (batch_size, sequence_length). Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>head_mask</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The head mask tensor of shape (num_heads, sequence_length, sequence_length). Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>labels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The labels tensor of shape (batch_size, sequence_length). Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_embeds</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The input embeddings tensor of shape (batch_size, sequence_length, embed_size). Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindspore.Tensor">Tensor</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_cache</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use cache. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[bool]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_attentions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to output attentions. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[bool]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_hidden_states</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to output hidden states. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[bool]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_dict</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to return a dictionary. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[bool]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Union">Union</span>[<span title="typing.Tuple">Tuple</span>[<span title="mindspore.Tensor">Tensor</span>], <span title="mindnlp.transformers.modeling_outputs.CausalLMOutputWithPast">CausalLMOutputWithPast</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Union[Tuple[mindspore.Tensor], CausalLMOutputWithPast]:
The output of the model. It can be a tuple containing the following elements:</p>
<ul>
<li>loss (mindspore.Tensor): The loss tensor.</li>
<li>logits (mindspore.Tensor): The logits tensor.</li>
<li>past_key_values (Tuple[mindspore.Tensor]): The past key values tensor.</li>
<li>hidden_states (Tuple[mindspore.Tensor]): The hidden states tensor.</li>
<li>attentions (Tuple[mindspore.Tensor]): The attentions tensor.</li>
</ul>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Union">Union</span>[<span title="typing.Tuple">Tuple</span>[<span title="mindspore.Tensor">Tensor</span>], <span title="mindnlp.transformers.modeling_outputs.CausalLMOutputWithPast">CausalLMOutputWithPast</span>]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>or an instance of the CausalLMOutputWithPast class.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If both input_ids and input_embeds are specified.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If batch_size is not defined or &lt;= 0.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>NotImplementedError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If training is not implemented yet for Bark - ensure you do not pass labels to the model.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">head_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">CausalLMOutputWithPast</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    forwards the BarkCausalModel.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The object itself.</span>
<span class="sd">        input_ids (Optional[mindspore.Tensor]):</span>
<span class="sd">            The input tensor of shape (batch_size, sequence_length). Defaults to None.</span>
<span class="sd">        past_key_values (Optional[Tuple[mindspore.Tensor]]):</span>
<span class="sd">            The past key values tensor of shape (batch_size, num_heads, sequence_length, embed_size_per_head).</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        attention_mask (Optional[mindspore.Tensor]):</span>
<span class="sd">            The attention mask tensor of shape (batch_size, sequence_length). Defaults to None.</span>
<span class="sd">        position_ids (Optional[mindspore.Tensor]):</span>
<span class="sd">            The position ids tensor of shape (batch_size, sequence_length). Defaults to None.</span>
<span class="sd">        head_mask (Optional[mindspore.Tensor]):</span>
<span class="sd">            The head mask tensor of shape (num_heads, sequence_length, sequence_length). Defaults to None.</span>
<span class="sd">        labels (Optional[mindspore.Tensor]):</span>
<span class="sd">            The labels tensor of shape (batch_size, sequence_length). Defaults to None.</span>
<span class="sd">        input_embeds (Optional[mindspore.Tensor]):</span>
<span class="sd">            The input embeddings tensor of shape (batch_size, sequence_length, embed_size). Defaults to None.</span>
<span class="sd">        use_cache (Optional[bool]): Whether to use cache. Defaults to None.</span>
<span class="sd">        output_attentions (Optional[bool]): Whether to output attentions. Defaults to None.</span>
<span class="sd">        output_hidden_states (Optional[bool]): Whether to output hidden states. Defaults to None.</span>
<span class="sd">        return_dict (Optional[bool]): Whether to return a dictionary. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[Tuple[mindspore.Tensor], CausalLMOutputWithPast]:</span>
<span class="sd">            The output of the model. It can be a tuple containing the following elements:</span>

<span class="sd">            - loss (mindspore.Tensor): The loss tensor.</span>
<span class="sd">            - logits (mindspore.Tensor): The logits tensor.</span>
<span class="sd">            - past_key_values (Tuple[mindspore.Tensor]): The past key values tensor.</span>
<span class="sd">            - hidden_states (Tuple[mindspore.Tensor]): The hidden states tensor.</span>
<span class="sd">            - attentions (Tuple[mindspore.Tensor]): The attentions tensor.</span>
<span class="sd">        or an instance of the CausalLMOutputWithPast class.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If both input_ids and input_embeds are specified.</span>
<span class="sd">        ValueError: If batch_size is not defined or &lt;= 0.</span>
<span class="sd">        NotImplementedError: If training is not implemented yet for Bark - ensure you do not pass labels to the model.</span>
<span class="sd">        &#39;&#39;&#39;</span>
    <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
    <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
    <span class="p">)</span>
    <span class="n">use_cache</span> <span class="o">=</span> <span class="n">use_cache</span> <span class="k">if</span> <span class="n">use_cache</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="c1"># Verify if input_embeds already exists</span>
    <span class="c1"># then compute embeddings.</span>
    <span class="k">if</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You cannot specify both input_ids and input_embeds at the same time&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># we want to return the input_embeds in priority so that it is in line with a weird hack</span>
        <span class="c1"># of Bark which concatenate two bits of the input_embeds on the first forward pass of the semantic model</span>
        <span class="k">pass</span>
    <span class="k">elif</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>  <span class="c1"># token embeddings of shape (b, t, n_embd)</span>
    <span class="k">elif</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You have to specify either input_ids or input_embeds&quot;</span><span class="p">)</span>

    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">seq_length</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">past_length</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">past_key_values</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">past_length</span> <span class="o">=</span> <span class="n">past_key_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">past_length</span><span class="p">,</span> <span class="n">seq_length</span> <span class="o">+</span> <span class="n">past_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># shape (1, seq_length)</span>

    <span class="n">position_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embeds_layer</span><span class="p">(</span><span class="n">position_ids</span><span class="p">)</span>  <span class="c1"># position embeddings of shape (1, t, n_embd)</span>

    <span class="c1"># Attention mask.</span>
    <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;batch_size has to be defined and &gt; 0&quot;</span><span class="p">)</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># [bsz, to_seq_length] -&gt; [bsz, 1, 1, to_seq_length]</span>
        <span class="c1"># from_seq_length is 1 to easily broadcast</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">_prepare_4d_attention_mask</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Prepare head mask if needed</span>
    <span class="c1"># 1.0 in head_mask indicate we keep the head</span>
    <span class="c1"># attention_probs has shape bsz x num_heads x N x N</span>
    <span class="c1"># head_mask has shape num_layers x batch x num_heads x N x N</span>
    <span class="n">head_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_head_mask</span><span class="p">(</span><span class="n">head_mask</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">input_embeds</span> <span class="o">+</span> <span class="n">position_embeds</span><span class="p">)</span>
    <span class="n">output_shape</span> <span class="o">=</span> <span class="n">input_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span>
                <span class="s2">&quot;`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...&quot;</span>
            <span class="p">)</span>
            <span class="n">use_cache</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">present_key_values</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">use_cache</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">all_self_attentions</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="p">()</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">past_layer_key_values</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="n">past_key_values</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
            <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="n">all_hidden_states</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span>
            <span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_layer_key_values</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">head_mask</span><span class="o">=</span><span class="n">head_mask</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>
            <span class="n">present_key_values</span> <span class="o">=</span> <span class="n">present_key_values</span> <span class="o">+</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>

        <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
            <span class="n">all_self_attentions</span> <span class="o">=</span> <span class="n">all_self_attentions</span> <span class="o">+</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">2</span> <span class="k">if</span> <span class="n">use_cache</span> <span class="k">else</span> <span class="mi">1</span><span class="p">],)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm_final</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>

    <span class="c1"># Add last hidden state</span>
    <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
        <span class="n">all_hidden_states</span> <span class="o">=</span> <span class="n">all_hidden_states</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;Training is not implemented yet for Bark - ensure you do not pass `labels` to the model.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">present_key_values</span><span class="p">,</span> <span class="n">all_hidden_states</span><span class="p">,</span> <span class="n">all_self_attentions</span><span class="p">]</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">CausalLMOutputWithPast</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="n">present_key_values</span><span class="p">,</span>
        <span class="n">hidden_states</span><span class="o">=</span><span class="n">all_hidden_states</span><span class="p">,</span>
        <span class="n">attentions</span><span class="o">=</span><span class="n">all_self_attentions</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.get_input_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkCausalModel</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.get_input_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method retrieves the input embeddings from the BarkCausalModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the BarkCausalModel class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel">BarkCausalModel</a></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>None</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>This method returns the input embeddings layer of the BarkCausalModel.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method retrieves the input embeddings from the BarkCausalModel.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkCausalModel): The instance of the BarkCausalModel class.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None: This method returns the input embeddings layer of the BarkCausalModel.</span>

<span class="sd">    Raises:</span>
<span class="sd">        This method does not raise any exceptions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.prepare_inputs_for_generation" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkCausalModel</span><span class="o">.</span><span class="n">prepare_inputs_for_generation</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.prepare_inputs_for_generation" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method prepares inputs for generation in the BarkCausalModel class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_ids</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The input tensor containing the tokenized input sequence.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>tensor</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>past_key_values</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The past key values for fast decoding. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>tuple</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>dict or None: A dictionary containing the prepared input values for generation,</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>including the input_ids, input_embeds, past_key_values, use_cache, position_ids, and attention_mask.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Returns None if input_embeds is not provided and use_cache is False.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the input_ids shape is incompatible with past_key_values.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the input_embeds shape is incompatible with use_cache.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>TypeError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the attention_mask and position_ids shapes are not compatible.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>RuntimeError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If there are issues with calculating position_ids based on attention_mask.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">prepare_inputs_for_generation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method prepares inputs for generation in the BarkCausalModel class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (object): The instance of the class.</span>
<span class="sd">        input_ids (tensor): The input tensor containing the tokenized input sequence.</span>
<span class="sd">        past_key_values (tuple, optional): The past key values for fast decoding. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict or None: A dictionary containing the prepared input values for generation,</span>
<span class="sd">        including the input_ids, input_embeds, past_key_values, use_cache, position_ids, and attention_mask.</span>
<span class="sd">        Returns None if input_embeds is not provided and use_cache is False.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the input_ids shape is incompatible with past_key_values.</span>
<span class="sd">        ValueError: If the input_embeds shape is incompatible with use_cache.</span>
<span class="sd">        TypeError: If the attention_mask and position_ids shapes are not compatible.</span>
<span class="sd">        RuntimeError: If there are issues with calculating position_ids based on attention_mask.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">input_embeds</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;input_embeds&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">position_ids</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;position_ids&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Omit tokens covered by past_key_values</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">past_length</span> <span class="o">=</span> <span class="n">past_key_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

        <span class="c1"># Some generation methods already pass only the last input ID</span>
        <span class="k">if</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">past_length</span><span class="p">:</span>
            <span class="n">remove_prefix_length</span> <span class="o">=</span> <span class="n">past_length</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Default to old behavior: keep only final ID</span>
            <span class="n">remove_prefix_length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:,</span> <span class="n">remove_prefix_length</span><span class="p">:]</span>

        <span class="c1"># input_embeds have already been used and is not required anymore</span>
        <span class="n">input_embeds</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">):</span>
            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># ensure that attention_mask and position_ids shapes are aligned with the weird Bark hack of reducing</span>
    <span class="c1"># sequence length on the first forward pass</span>
    <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">position_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># create position_ids on the fly for batch generation</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">attention_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">past_key_values</span><span class="p">:</span>
            <span class="n">position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">position_ids</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">input_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s2">&quot;input_embeds&quot;</span><span class="p">:</span> <span class="n">input_embeds</span><span class="p">,</span>
            <span class="s2">&quot;past_key_values&quot;</span><span class="p">:</span> <span class="n">past_key_values</span><span class="p">,</span>
            <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">),</span>
            <span class="s2">&quot;position_ids&quot;</span><span class="p">:</span> <span class="n">position_ids</span><span class="p">,</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
        <span class="s2">&quot;past_key_values&quot;</span><span class="p">:</span> <span class="n">past_key_values</span><span class="p">,</span>
        <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">),</span>
        <span class="s2">&quot;position_ids&quot;</span><span class="p">:</span> <span class="n">position_ids</span><span class="p">,</span>
        <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.set_input_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">modeling_bark</span><span class="o">.</span><span class="n">BarkCausalModel</span><span class="o">.</span><span class="n">set_input_embeddings</span><span class="p">(</span><span class="n">new_embeddings</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel.set_input_embeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Set input embeddings for the BarkCausalModel.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of BarkCausalModel.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel" href="#mindnlp.transformers.models.bark.modeling_bark.BarkCausalModel">BarkCausalModel</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>new_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The new input embeddings to be set for the model. It can be of any type.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>any</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\modeling_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_embeddings</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set input embeddings for the BarkCausalModel.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (BarkCausalModel): The instance of BarkCausalModel.</span>
<span class="sd">        new_embeddings (any): The new input embeddings to be set for the model. It can be of any type.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_embeds_layer</span> <span class="o">=</span> <span class="n">new_embeddings</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.bark.processing_bark.BarkProcessor" class="doc doc-heading">
            <code>mindnlp.transformers.models.bark.processing_bark.BarkProcessor</code>


<a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.processing_utils.ProcessorMixin">ProcessorMixin</span></code></p>


        <p>Constructs a Bark processor which wraps a text tokenizer and optional Bark voice presets into a single processor.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An instance of [<code>PreTrainedTokenizer</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`PreTrainedTokenizer`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>speaker_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional nested speaker embeddings dictionary. The first level contains voice preset names (e.g
<code>"en_speaker_4"</code>). The second level contains <code>"semantic_prompt"</code>, <code>"coarse_prompt"</code> and <code>"fine_prompt"</code>
embeddings. The values correspond to the path of the corresponding <code>np.ndarray</code>. See
<a href="https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c">here</a> for
a list of <code>voice_preset_names</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[Dict[str]]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\bark\processing_bark.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BarkProcessor</span><span class="p">(</span><span class="n">ProcessorMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs a Bark processor which wraps a text tokenizer and optional Bark voice presets into a single processor.</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenizer ([`PreTrainedTokenizer`]):</span>
<span class="sd">            An instance of [`PreTrainedTokenizer`].</span>
<span class="sd">        speaker_embeddings (`Dict[Dict[str]]`, *optional*):</span>
<span class="sd">            Optional nested speaker embeddings dictionary. The first level contains voice preset names (e.g</span>
<span class="sd">            `&quot;en_speaker_4&quot;`). The second level contains `&quot;semantic_prompt&quot;`, `&quot;coarse_prompt&quot;` and `&quot;fine_prompt&quot;`</span>
<span class="sd">            embeddings. The values correspond to the path of the corresponding `np.ndarray`. See</span>
<span class="sd">            [here](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c) for</span>
<span class="sd">            a list of `voice_preset_names`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tokenizer_class</span> <span class="o">=</span> <span class="s2">&quot;AutoTokenizer&quot;</span>
    <span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">]</span>

    <span class="n">preset_shape</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;semantic_prompt&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s2">&quot;coarse_prompt&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;fine_prompt&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">speaker_embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the BarkProcessor class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (object): The instance of the class.</span>
<span class="sd">            tokenizer (object): The tokenizer object used for processing text data.</span>
<span class="sd">            speaker_embeddings (object or None, optional): The speaker embeddings associated with the text data. </span>
<span class="sd">                Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="n">speaker_embeddings</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_processor_name_or_path</span><span class="p">,</span> <span class="n">speaker_embeddings_dict_path</span><span class="o">=</span><span class="s2">&quot;speaker_embeddings_path.json&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate a Bark processor associated with a pretrained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            pretrained_model_name_or_path (`str` or `os.PathLike`):</span>
<span class="sd">                This can be either:</span>

<span class="sd">                - a string, the *model id* of a pretrained [`BarkProcessor`] hosted inside a model repo on</span>
<span class="sd">                  hf-mirror.com.</span>
<span class="sd">                - a path to a *directory* containing a processor saved using the [`~BarkProcessor.save_pretrained`]</span>
<span class="sd">                  method, e.g., `./my_model_directory/`.</span>
<span class="sd">            speaker_embeddings_dict_path (`str`, *optional*, defaults to `&quot;speaker_embeddings_path.json&quot;`):</span>
<span class="sd">                The name of the `.json` file containing the speaker_embeddings dictionnary located in</span>
<span class="sd">                `pretrained_model_name_or_path`. If `None`, no speaker_embeddings is loaded.</span>
<span class="sd">            **kwargs:</span>
<span class="sd">                Additional keyword arguments passed along to both</span>
<span class="sd">                [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">speaker_embeddings_dict_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">speaker_embeddings_path</span> <span class="o">=</span> <span class="n">cached_file</span><span class="p">(</span>
                <span class="n">pretrained_processor_name_or_path</span><span class="p">,</span>
                <span class="n">speaker_embeddings_dict_path</span><span class="p">,</span>
                <span class="n">subfolder</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;subfolder&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">cache_dir</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">force_download</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;force_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">proxies</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;proxies&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">resume_download</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;resume_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">local_files_only</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;local_files_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">token</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_auth_token&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">speaker_embeddings_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;`</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_processor_name_or_path</span><span class="p">,</span><span class="n">speaker_embeddings_dict_path</span><span class="p">)</span><span class="si">}</span><span class="s2">` does not exists</span>
<span class="s2">                    , no preloaded speaker embeddings will be used - Make sure to provide a correct path to the json</span>
<span class="s2">                    dictionnary if wanted, otherwise set `speaker_embeddings_dict_path=None`.&quot;&quot;&quot;</span>
                <span class="p">)</span>
                <span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">speaker_embeddings_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">speaker_embeddings_json</span><span class="p">:</span>
                    <span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">speaker_embeddings_json</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_processor_name_or_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">speaker_embeddings</span><span class="o">=</span><span class="n">speaker_embeddings</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_pretrained</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">save_directory</span><span class="p">,</span>
        <span class="n">speaker_embeddings_dict_path</span><span class="o">=</span><span class="s2">&quot;speaker_embeddings_path.json&quot;</span><span class="p">,</span>
        <span class="n">speaker_embeddings_directory</span><span class="o">=</span><span class="s2">&quot;speaker_embeddings&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves the attributes of this processor (tokenizer...) in the specified directory so that it can be reloaded</span>
<span class="sd">        using the [`~BarkProcessor.from_pretrained`] method.</span>

<span class="sd">        Args:</span>
<span class="sd">            save_directory (`str` or `os.PathLike`):</span>
<span class="sd">                Directory where the tokenizer files and the speaker embeddings will be saved (directory will be created</span>
<span class="sd">                if it does not exist).</span>
<span class="sd">            speaker_embeddings_dict_path (`str`, *optional*, defaults to `&quot;speaker_embeddings_path.json&quot;`):</span>
<span class="sd">                The name of the `.json` file that will contains the speaker_embeddings nested path dictionnary, if it</span>
<span class="sd">                exists, and that will be located in `pretrained_model_name_or_path/speaker_embeddings_directory`.</span>
<span class="sd">            speaker_embeddings_directory (`str`, *optional*, defaults to `&quot;speaker_embeddings/&quot;`):</span>
<span class="sd">                The name of the folder in which the speaker_embeddings arrays will be saved.</span>
<span class="sd">            kwargs:</span>
<span class="sd">                Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">speaker_embeddings_directory</span><span class="p">,</span> <span class="s2">&quot;v2&quot;</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">embeddings_dict</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="n">embeddings_dict</span><span class="p">[</span><span class="s2">&quot;repo_or_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">save_directory</span>

            <span class="k">for</span> <span class="n">prompt_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">prompt_key</span> <span class="o">!=</span> <span class="s2">&quot;repo_or_path&quot;</span><span class="p">:</span>
                    <span class="n">voice_preset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_voice_preset</span><span class="p">(</span><span class="n">prompt_key</span><span class="p">)</span>

                    <span class="n">tmp_dict</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span><span class="p">[</span><span class="n">prompt_key</span><span class="p">]:</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                                <span class="n">embeddings_dict</span><span class="p">[</span><span class="s2">&quot;repo_or_path&quot;</span><span class="p">],</span> <span class="n">speaker_embeddings_directory</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt_key</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">),</span>
                            <span class="n">voice_preset</span><span class="p">[</span><span class="n">key</span><span class="p">],</span>
                            <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="n">tmp_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">speaker_embeddings_directory</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt_key</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">)</span>

                    <span class="n">embeddings_dict</span><span class="p">[</span><span class="n">prompt_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_dict</span>

            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">speaker_embeddings_dict_path</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">embeddings_dict</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_load_voice_preset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">voice_preset</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method &#39;_load_voice_preset&#39; is a member of the class &#39;BarkProcessor&#39; and is responsible for loading voice presets.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (object): The instance of the &#39;BarkProcessor&#39; class.</span>
<span class="sd">            voice_preset (str): The name of the voice preset to be loaded. It is an optional parameter and defaults to None.</span>
<span class="sd">                It specifies the voice preset to be loaded from the speaker embeddings.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the loaded voice preset data. The dictionary keys are &#39;semantic_prompt&#39;, &#39;coarse_prompt&#39;,</span>
<span class="sd">            and &#39;fine_prompt&#39;, and the corresponding values are NumPy arrays representing the voice preset data.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: This exception is raised if the voice preset is unrecognized or if any key (&#39;semantic_prompt&#39;, &#39;coarse_prompt&#39;,</span>
<span class="sd">            or &#39;fine_prompt&#39;) is missing in the speaker embeddings for the specified voice preset.</span>
<span class="sd">            ValueError: This exception is raised if the specified voice preset file does not exist, or if the path to the voice preset</span>
<span class="sd">            embeddings is incorrect.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">voice_preset_paths</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span><span class="p">[</span><span class="n">voice_preset</span><span class="p">]</span>

        <span class="n">voice_preset_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;semantic_prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;coarse_prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;fine_prompt&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">voice_preset_paths</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Voice preset unrecognized, missing </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> as a key in self.speaker_embeddings[</span><span class="si">{</span><span class="n">voice_preset</span><span class="si">}</span><span class="s2">].&quot;</span>
                <span class="p">)</span>

            <span class="n">path</span> <span class="o">=</span> <span class="n">cached_file</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;repo_or_path&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">),</span>
                <span class="n">voice_preset_paths</span><span class="p">[</span><span class="n">key</span><span class="p">],</span>
                <span class="n">subfolder</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;subfolder&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">cache_dir</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">force_download</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;force_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">proxies</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;proxies&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">resume_download</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;resume_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">local_files_only</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;local_files_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">token</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_auth_token&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;`</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;repo_or_path&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;/&quot;</span><span class="p">),</span><span class="n">voice_preset_paths</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="si">}</span><span class="s2">` does not exists</span>
<span class="s2">                    , no preloaded voice preset will be used - Make sure to provide correct paths to the </span><span class="si">{</span><span class="n">voice_preset</span><span class="si">}</span>
<span class="s2">                    embeddings.&quot;&quot;&quot;</span>
                <span class="p">)</span>

            <span class="n">voice_preset_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">voice_preset_dict</span>

    <span class="k">def</span> <span class="nf">_validate_voice_preset_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">voice_preset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Validates the voice preset dictionary provided as input.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (BarkProcessor): An instance of the BarkProcessor class.</span>
<span class="sd">            voice_preset (Optional[dict]):</span>
<span class="sd">                A dictionary representing the voice preset. This dictionary should contain the following keys:</span>

<span class="sd">                - &#39;semantic_prompt&#39; (numpy.ndarray): A 2D ndarray representing the semantic prompt.</span>
<span class="sd">                - &#39;coarse_prompt&#39; (numpy.ndarray): A 2D ndarray representing the coarse prompt.</span>
<span class="sd">                - &#39;fine_prompt&#39; (numpy.ndarray): A 2D ndarray representing the fine prompt.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError:</span>
<span class="sd">                If any of the following conditions are not met:</span>

<span class="sd">                - The &#39;semantic_prompt&#39;, &#39;coarse_prompt&#39;, and &#39;fine_prompt&#39; keys are missing in the voice_preset dictionary.</span>
<span class="sd">                - The &#39;semantic_prompt&#39;, &#39;coarse_prompt&#39;, or &#39;fine_prompt&#39; values are not of type numpy.ndarray.</span>
<span class="sd">                - The shape of &#39;semantic_prompt&#39;, &#39;coarse_prompt&#39;, or &#39;fine_prompt&#39; is not equal to the expected preset shape.</span>

<span class="sd">        Note:</span>
<span class="sd">            - The expected preset shape is determined by the preset_shape attribute of the BarkProcessor class.</span>

<span class="sd">        Example:</span>
<span class="sd">            ```python</span>
<span class="sd">            &gt;&gt;&gt; bp = BarkProcessor()</span>
<span class="sd">            &gt;&gt;&gt; voice_preset = {</span>
<span class="sd">            &gt;&gt;&gt;     &#39;semantic_prompt&#39;: np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]),</span>
<span class="sd">            &gt;&gt;&gt;     &#39;coarse_prompt&#39;: np.array([[0.7, 0.8, 0.9], [1.0, 1.1, 1.2]]),</span>
<span class="sd">            &gt;&gt;&gt;     &#39;fine_prompt&#39;: np.array([[1.3, 1.4, 1.5], [1.6, 1.7, 1.8]])</span>
<span class="sd">            &gt;&gt;&gt; }</span>
<span class="sd">            &gt;&gt;&gt; bp._validate_voice_preset_dict(voice_preset)</span>
<span class="sd">            ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;semantic_prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;coarse_prompt&quot;</span><span class="p">,</span> <span class="s2">&quot;fine_prompt&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">voice_preset</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Voice preset unrecognized, missing </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> as a key.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> voice preset must be a </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">preset_shape</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="si">}</span><span class="s2">D ndarray.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preset_shape</span><span class="p">[</span><span class="n">key</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> voice preset must be a </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">preset_shape</span><span class="p">[</span><span class="n">key</span><span class="p">])</span><span class="si">}</span><span class="s2">D ndarray.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">voice_preset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">return_token_type_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Main method to prepare for the model one or several sequences(s). This method forwards the `text` and `kwargs`</span>
<span class="sd">        arguments to the AutoTokenizer&#39;s [`~AutoTokenizer.__call__`] to encode the text. The method also proposes a</span>
<span class="sd">        voice preset which is a dictionary of arrays that conditions `Bark`&#39;s output. `kwargs` arguments are forwarded</span>
<span class="sd">        to the tokenizer and to `cached_file` method if `voice_preset` is a valid filename.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (`str`, `List[str]`, `List[List[str]]`):</span>
<span class="sd">                The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings</span>
<span class="sd">                (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set</span>
<span class="sd">                `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).</span>
<span class="sd">            voice_preset (`str`, `Dict[np.ndarray]`):</span>
<span class="sd">                The voice preset, i.e the speaker embeddings. It can either be a valid voice_preset name, e.g</span>
<span class="sd">                `&quot;en_speaker_1&quot;`, or directly a dictionnary of `np.ndarray` embeddings for each submodel of `Bark`. Or</span>
<span class="sd">                it can be a valid file name of a local `.npz` single voice preset.</span>
<span class="sd">            return_tensors (`str` or [`~utils.TensorType`], *optional*):</span>
<span class="sd">                If set, will return tensors of a particular framework. Acceptable values are:</span>

<span class="sd">                - `&#39;pt&#39;`: Return PyTorch `torch.Tensor` objects.</span>
<span class="sd">                - `&#39;np&#39;`: Return NumPy `np.ndarray` objects.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple([`BatchEncoding`], [`BatchFeature`]): A tuple composed of a [`BatchEncoding`], i.e the output of the</span>
<span class="sd">            `tokenizer` and a [`BatchFeature`], i.e the voice preset with the right tensors type.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">voice_preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">voice_preset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span>
            <span class="p">):</span>
                <span class="n">voice_preset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_voice_preset</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">voice_preset</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.npz&quot;</span><span class="p">):</span>
                    <span class="n">voice_preset</span> <span class="o">=</span> <span class="n">voice_preset</span> <span class="o">+</span> <span class="s2">&quot;.npz&quot;</span>

                <span class="n">voice_preset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">voice_preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_voice_preset_dict</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">voice_preset</span> <span class="o">=</span> <span class="n">BatchFeature</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">voice_preset</span><span class="p">,</span> <span class="n">tensor_type</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">)</span>

        <span class="n">encoded_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">text</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">return_attention_mask</span><span class="o">=</span><span class="n">return_attention_mask</span><span class="p">,</span>
            <span class="n">return_token_type_ids</span><span class="o">=</span><span class="n">return_token_type_ids</span><span class="p">,</span>
            <span class="n">add_special_tokens</span><span class="o">=</span><span class="n">add_special_tokens</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">voice_preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoded_text</span><span class="p">[</span><span class="s2">&quot;history_prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">voice_preset</span>

        <span class="k">return</span> <span class="n">encoded_text</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.processing_bark.BarkProcessor.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">processing_bark</span><span class="o">.</span><span class="n">BarkProcessor</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">voice_preset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;ms&#39;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_token_type_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Main method to prepare for the model one or several sequences(s). This method forwards the <code>text</code> and <code>kwargs</code>
arguments to the AutoTokenizer's [<code>~AutoTokenizer.__call__</code>] to encode the text. The method also proposes a
voice preset which is a dictionary of arrays that conditions <code>Bark</code>'s output. <code>kwargs</code> arguments are forwarded
to the tokenizer and to <code>cached_file</code> method if <code>voice_preset</code> is a valid filename.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>text</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings
(pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set
<code>is_split_into_words=True</code> (to lift the ambiguity with a batch of sequences).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, `List[str]`, `List[List[str]]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>voice_preset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The voice preset, i.e the speaker embeddings. It can either be a valid voice_preset name, e.g
<code>"en_speaker_1"</code>, or directly a dictionnary of <code>np.ndarray</code> embeddings for each submodel of <code>Bark</code>. Or
it can be a valid file name of a local <code>.npz</code> single voice preset.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, `Dict[np.ndarray]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_tensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If set, will return tensors of a particular framework. Acceptable values are:</p>
<ul>
<li><code>'pt'</code>: Return PyTorch <code>torch.Tensor</code> objects.</li>
<li><code>'np'</code>: Return NumPy <code>np.ndarray</code> objects.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~utils.TensorType`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;ms&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>Tuple</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>A tuple composed of a [<code>BatchEncoding</code>], i.e the output of the</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code>[`BatchEncoding`], [`BatchFeature`]</code>
                  </span>
                </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>tokenizer</code> and a [<code>BatchFeature</code>], i.e the voice preset with the right tensors type.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\processing_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">voice_preset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_token_type_ids</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Main method to prepare for the model one or several sequences(s). This method forwards the `text` and `kwargs`</span>
<span class="sd">    arguments to the AutoTokenizer&#39;s [`~AutoTokenizer.__call__`] to encode the text. The method also proposes a</span>
<span class="sd">    voice preset which is a dictionary of arrays that conditions `Bark`&#39;s output. `kwargs` arguments are forwarded</span>
<span class="sd">    to the tokenizer and to `cached_file` method if `voice_preset` is a valid filename.</span>

<span class="sd">    Args:</span>
<span class="sd">        text (`str`, `List[str]`, `List[List[str]]`):</span>
<span class="sd">            The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings</span>
<span class="sd">            (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set</span>
<span class="sd">            `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).</span>
<span class="sd">        voice_preset (`str`, `Dict[np.ndarray]`):</span>
<span class="sd">            The voice preset, i.e the speaker embeddings. It can either be a valid voice_preset name, e.g</span>
<span class="sd">            `&quot;en_speaker_1&quot;`, or directly a dictionnary of `np.ndarray` embeddings for each submodel of `Bark`. Or</span>
<span class="sd">            it can be a valid file name of a local `.npz` single voice preset.</span>
<span class="sd">        return_tensors (`str` or [`~utils.TensorType`], *optional*):</span>
<span class="sd">            If set, will return tensors of a particular framework. Acceptable values are:</span>

<span class="sd">            - `&#39;pt&#39;`: Return PyTorch `torch.Tensor` objects.</span>
<span class="sd">            - `&#39;np&#39;`: Return NumPy `np.ndarray` objects.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple([`BatchEncoding`], [`BatchFeature`]): A tuple composed of a [`BatchEncoding`], i.e the output of the</span>
<span class="sd">        `tokenizer` and a [`BatchFeature`], i.e the voice preset with the right tensors type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">voice_preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="n">voice_preset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span>
        <span class="p">):</span>
            <span class="n">voice_preset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_voice_preset</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">voice_preset</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.npz&quot;</span><span class="p">):</span>
                <span class="n">voice_preset</span> <span class="o">=</span> <span class="n">voice_preset</span> <span class="o">+</span> <span class="s2">&quot;.npz&quot;</span>

            <span class="n">voice_preset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">voice_preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_voice_preset_dict</span><span class="p">(</span><span class="n">voice_preset</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">voice_preset</span> <span class="o">=</span> <span class="n">BatchFeature</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">voice_preset</span><span class="p">,</span> <span class="n">tensor_type</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">)</span>

    <span class="n">encoded_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">text</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
        <span class="n">return_attention_mask</span><span class="o">=</span><span class="n">return_attention_mask</span><span class="p">,</span>
        <span class="n">return_token_type_ids</span><span class="o">=</span><span class="n">return_token_type_ids</span><span class="p">,</span>
        <span class="n">add_special_tokens</span><span class="o">=</span><span class="n">add_special_tokens</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">voice_preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">encoded_text</span><span class="p">[</span><span class="s2">&quot;history_prompt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">voice_preset</span>

    <span class="k">return</span> <span class="n">encoded_text</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.processing_bark.BarkProcessor.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">processing_bark</span><span class="o">.</span><span class="n">BarkProcessor</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">speaker_embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize the BarkProcessor class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The tokenizer object used for processing text data.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>speaker_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The speaker embeddings associated with the text data. 
Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object or None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\processing_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">speaker_embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the BarkProcessor class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (object): The instance of the class.</span>
<span class="sd">        tokenizer (object): The tokenizer object used for processing text data.</span>
<span class="sd">        speaker_embeddings (object or None, optional): The speaker embeddings associated with the text data. </span>
<span class="sd">            Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="n">speaker_embeddings</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.processing_bark.BarkProcessor.from_pretrained" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">processing_bark</span><span class="o">.</span><span class="n">BarkProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_processor_name_or_path</span><span class="p">,</span> <span class="n">speaker_embeddings_dict_path</span><span class="o">=</span><span class="s1">&#39;speaker_embeddings_path.json&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.from_pretrained" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Instantiate a Bark processor associated with a pretrained model.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pretrained_model_name_or_path</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained [<code>BarkProcessor</code>] hosted inside a model repo on
  hf-mirror.com.</li>
<li>a path to a <em>directory</em> containing a processor saved using the [<code>~BarkProcessor.save_pretrained</code>]
  method, e.g., <code>./my_model_directory/</code>.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `os.PathLike`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>speaker_embeddings_dict_path</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The name of the <code>.json</code> file containing the speaker_embeddings dictionnary located in
<code>pretrained_model_name_or_path</code>. If <code>None</code>, no speaker_embeddings is loaded.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;speaker_embeddings_path.json&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;speaker_embeddings_path.json&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional keyword arguments passed along to both
[<code>~tokenization_utils_base.PreTrainedTokenizer.from_pretrained</code>].</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\processing_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_processor_name_or_path</span><span class="p">,</span> <span class="n">speaker_embeddings_dict_path</span><span class="o">=</span><span class="s2">&quot;speaker_embeddings_path.json&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Instantiate a Bark processor associated with a pretrained model.</span>

<span class="sd">    Args:</span>
<span class="sd">        pretrained_model_name_or_path (`str` or `os.PathLike`):</span>
<span class="sd">            This can be either:</span>

<span class="sd">            - a string, the *model id* of a pretrained [`BarkProcessor`] hosted inside a model repo on</span>
<span class="sd">              hf-mirror.com.</span>
<span class="sd">            - a path to a *directory* containing a processor saved using the [`~BarkProcessor.save_pretrained`]</span>
<span class="sd">              method, e.g., `./my_model_directory/`.</span>
<span class="sd">        speaker_embeddings_dict_path (`str`, *optional*, defaults to `&quot;speaker_embeddings_path.json&quot;`):</span>
<span class="sd">            The name of the `.json` file containing the speaker_embeddings dictionnary located in</span>
<span class="sd">            `pretrained_model_name_or_path`. If `None`, no speaker_embeddings is loaded.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Additional keyword arguments passed along to both</span>
<span class="sd">            [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">speaker_embeddings_dict_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">speaker_embeddings_path</span> <span class="o">=</span> <span class="n">cached_file</span><span class="p">(</span>
            <span class="n">pretrained_processor_name_or_path</span><span class="p">,</span>
            <span class="n">speaker_embeddings_dict_path</span><span class="p">,</span>
            <span class="n">subfolder</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;subfolder&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">cache_dir</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">force_download</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;force_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
            <span class="n">proxies</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;proxies&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">resume_download</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;resume_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
            <span class="n">local_files_only</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;local_files_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
            <span class="n">token</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_auth_token&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">speaker_embeddings_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&quot;&quot;`</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrained_processor_name_or_path</span><span class="p">,</span><span class="n">speaker_embeddings_dict_path</span><span class="p">)</span><span class="si">}</span><span class="s2">` does not exists</span>
<span class="s2">                , no preloaded speaker embeddings will be used - Make sure to provide a correct path to the json</span>
<span class="s2">                dictionnary if wanted, otherwise set `speaker_embeddings_dict_path=None`.&quot;&quot;&quot;</span>
            <span class="p">)</span>
            <span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">speaker_embeddings_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">speaker_embeddings_json</span><span class="p">:</span>
                <span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">speaker_embeddings_json</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_processor_name_or_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">speaker_embeddings</span><span class="o">=</span><span class="n">speaker_embeddings</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.bark.processing_bark.BarkProcessor.save_pretrained" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bark</span><span class="o">.</span><span class="n">processing_bark</span><span class="o">.</span><span class="n">BarkProcessor</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">speaker_embeddings_dict_path</span><span class="o">=</span><span class="s1">&#39;speaker_embeddings_path.json&#39;</span><span class="p">,</span> <span class="n">speaker_embeddings_directory</span><span class="o">=</span><span class="s1">&#39;speaker_embeddings&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.bark.processing_bark.BarkProcessor.save_pretrained" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Saves the attributes of this processor (tokenizer...) in the specified directory so that it can be reloaded
using the [<code>~BarkProcessor.from_pretrained</code>] method.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>save_directory</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Directory where the tokenizer files and the speaker embeddings will be saved (directory will be created
if it does not exist).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `os.PathLike`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>speaker_embeddings_dict_path</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The name of the <code>.json</code> file that will contains the speaker_embeddings nested path dictionnary, if it
exists, and that will be located in <code>pretrained_model_name_or_path/speaker_embeddings_directory</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;speaker_embeddings_path.json&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;speaker_embeddings_path.json&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>speaker_embeddings_directory</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The name of the folder in which the speaker_embeddings arrays will be saved.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;speaker_embeddings/&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;speaker_embeddings&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional key word arguments passed along to the [<code>~utils.PushToHubMixin.push_to_hub</code>] method.</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\bark\processing_bark.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_pretrained</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">save_directory</span><span class="p">,</span>
    <span class="n">speaker_embeddings_dict_path</span><span class="o">=</span><span class="s2">&quot;speaker_embeddings_path.json&quot;</span><span class="p">,</span>
    <span class="n">speaker_embeddings_directory</span><span class="o">=</span><span class="s2">&quot;speaker_embeddings&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Saves the attributes of this processor (tokenizer...) in the specified directory so that it can be reloaded</span>
<span class="sd">    using the [`~BarkProcessor.from_pretrained`] method.</span>

<span class="sd">    Args:</span>
<span class="sd">        save_directory (`str` or `os.PathLike`):</span>
<span class="sd">            Directory where the tokenizer files and the speaker embeddings will be saved (directory will be created</span>
<span class="sd">            if it does not exist).</span>
<span class="sd">        speaker_embeddings_dict_path (`str`, *optional*, defaults to `&quot;speaker_embeddings_path.json&quot;`):</span>
<span class="sd">            The name of the `.json` file that will contains the speaker_embeddings nested path dictionnary, if it</span>
<span class="sd">            exists, and that will be located in `pretrained_model_name_or_path/speaker_embeddings_directory`.</span>
<span class="sd">        speaker_embeddings_directory (`str`, *optional*, defaults to `&quot;speaker_embeddings/&quot;`):</span>
<span class="sd">            The name of the folder in which the speaker_embeddings arrays will be saved.</span>
<span class="sd">        kwargs:</span>
<span class="sd">            Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">speaker_embeddings_directory</span><span class="p">,</span> <span class="s2">&quot;v2&quot;</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">embeddings_dict</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">embeddings_dict</span><span class="p">[</span><span class="s2">&quot;repo_or_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">save_directory</span>

        <span class="k">for</span> <span class="n">prompt_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">prompt_key</span> <span class="o">!=</span> <span class="s2">&quot;repo_or_path&quot;</span><span class="p">:</span>
                <span class="n">voice_preset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_voice_preset</span><span class="p">(</span><span class="n">prompt_key</span><span class="p">)</span>

                <span class="n">tmp_dict</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">speaker_embeddings</span><span class="p">[</span><span class="n">prompt_key</span><span class="p">]:</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                            <span class="n">embeddings_dict</span><span class="p">[</span><span class="s2">&quot;repo_or_path&quot;</span><span class="p">],</span> <span class="n">speaker_embeddings_directory</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt_key</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">),</span>
                        <span class="n">voice_preset</span><span class="p">[</span><span class="n">key</span><span class="p">],</span>
                        <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">tmp_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">speaker_embeddings_directory</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prompt_key</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">)</span>

                <span class="n">embeddings_dict</span><span class="p">[</span><span class="n">prompt_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_dict</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">speaker_embeddings_dict_path</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">embeddings_dict</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../baichuan/" class="md-footer__link md-footer__link--prev" aria-label="Previous: baichuan">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                baichuan
              </div>
            </div>
          </a>
        
        
          
          <a href="../bart/" class="md-footer__link md-footer__link--next" aria-label="Next: bart">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                bart
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 - 2024 MindSpore Lab and CQU NLP Team.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:lvyufeng@cqu.edu.cn" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindnlp" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/lu-yu-feng-46-1" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top", "navigation.footer", "navigation.path", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>