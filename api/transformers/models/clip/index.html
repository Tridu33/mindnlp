
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../chatglm3/">
      
      
        <link rel="next" href="../codegen/">
      
      
      <link rel="icon" href="../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.44">
    
    
      
        <title>clip - MindNLP Docs</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="MindNLP Docs" class="md-header__button md-logo" aria-label="MindNLP Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindNLP Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              clip
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../../../zh/api/transformers/models/clip/" hreflang="zh" class="md-select__link">
              中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindnlp
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../tutorials/quick_start/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../supported_models/" class="md-tabs__link">
        
  
    
  
  Supported Models

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../contribute/" class="md-tabs__link">
        
  
    
  
  How-To Contribute

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../accelerate/" class="md-tabs__link">
          
  
    
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../notes/changelog/" class="md-tabs__link">
          
  
    
  
  Notes

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="MindNLP Docs" class="md-nav__button md-logo" aria-label="MindNLP Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    MindNLP Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindnlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/quick_start/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/data_preprocess/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Preprocess
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/use_trainer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Trainer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/use_mirror/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Mirror
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../supported_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supported Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contribute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How-To Contribute
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../accelerate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/load_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    load_dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/BaseMapFunction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BaseMapFunction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/transforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transforms
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Engine
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            Engine
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4_1" >
        
          
          <label class="md-nav__link" for="__nav_5_4_1" id="__nav_5_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    train_args
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4_1">
            <span class="md-nav__icon md-icon"></span>
            train_args
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/train_args/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/train_args/seq2seq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seq2seq
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4_2" >
        
          
          <label class="md-nav__link" for="__nav_5_4_2" id="__nav_5_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    trainer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4_2">
            <span class="md-nav__icon md-icon"></span>
            trainer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/trainer/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/trainer/default_func/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    default_func
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/callbacks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    callbacks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    export
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../modules/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modules
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../parallel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../peft/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            PEFT
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_2" >
        
          
          <label class="md-nav__link" for="__nav_5_7_2" id="__nav_5_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    tuners
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_2">
            <span class="md-nav__icon md-icon"></span>
            tuners
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/adalora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AdaLoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/adaption_prompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adaption_Prompt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/ia3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IA3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/lokr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoKr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/prompt_tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prompt tuning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_3" >
        
          
          <label class="md-nav__link" for="__nav_5_7_3" id="__nav_5_7_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_3">
            <span class="md-nav__icon md-icon"></span>
            utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/utils/merge_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    merge_utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/mapping/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mapping
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/peft_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    peft_model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sentence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_2" >
        
          
          <label class="md-nav__link" for="__nav_5_9_2" id="__nav_5_9_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    generation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_2">
            <span class="md-nav__icon md-icon"></span>
            generation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transforemrs/generation/index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/beam_constraints/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_constraints
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/logits_process/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    logits_process
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/stopping_criteria/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    stopping_criteria
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/streamers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    streamers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    models
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_9_3" id="__nav_5_9_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_9_3">
            <span class="md-nav__icon md-icon"></span>
            models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../albert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    albert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../align/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    align
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../altclip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    altclip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../audio_spectrogram_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    audio_spectrogram_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../auto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    auto
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    autoformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../baichuan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    baichuan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../barthez/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    barthez
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bartpho/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bartpho
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../beit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert_japanese/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert_japanese
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bertweet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bertweet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bge_m3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bge_m3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../big_bird/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    big_bird
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bigbird_pegasus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bigbird_pegasus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../biogpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    biogpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blenderbot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blenderbot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blenderbot_small/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blenderbot_small
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blip_2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bloom
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bridgetower/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bridgetower
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bros/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bros
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../byt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    byt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../camembert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    camembert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../canine/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    canine
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    clip
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    clip
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig.from_text_vision_configs" class="md-nav__link">
    <span class="md-ellipsis">
      from_text_vision_configs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTextConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTextConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig.from_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      from_pretrained
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPVisionConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPVisionConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig.from_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      from_pretrained
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPImageProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPImageProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.preprocess" class="md-nav__link">
    <span class="md-ellipsis">
      preprocess
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.resize" class="md-nav__link">
    <span class="md-ellipsis">
      resize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.get_image_features" class="md-nav__link">
    <span class="md-ellipsis">
      get_image_features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.get_text_features" class="md-nav__link">
    <span class="md-ellipsis">
      get_text_features
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPPreTrainedModel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTextModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTextModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTextModelWithProjection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTextModelWithProjection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPVisionModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPVisionModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPVisionModelWithProjection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPVisionModelWithProjection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPForImageClassification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPForImageClassification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.feature_extractor" class="md-nav__link">
    <span class="md-ellipsis">
      feature_extractor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.feature_extractor_class" class="md-nav__link">
    <span class="md-ellipsis">
      feature_extractor_class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.model_input_names" class="md-nav__link">
    <span class="md-ellipsis">
      model_input_names
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.batch_decode" class="md-nav__link">
    <span class="md-ellipsis">
      batch_decode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.decode" class="md-nav__link">
    <span class="md-ellipsis">
      decode
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTokenizer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.vocab_size" class="md-nav__link">
    <span class="md-ellipsis">
      vocab_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.bpe" class="md-nav__link">
    <span class="md-ellipsis">
      bpe
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.build_inputs_with_special_tokens" class="md-nav__link">
    <span class="md-ellipsis">
      build_inputs_with_special_tokens
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.convert_tokens_to_string" class="md-nav__link">
    <span class="md-ellipsis">
      convert_tokens_to_string
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.create_token_type_ids_from_sequences" class="md-nav__link">
    <span class="md-ellipsis">
      create_token_type_ids_from_sequences
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.get_special_tokens_mask" class="md-nav__link">
    <span class="md-ellipsis">
      get_special_tokens_mask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.get_vocab" class="md-nav__link">
    <span class="md-ellipsis">
      get_vocab
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.save_vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      save_vocabulary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTokenizerFast
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTokenizerFast">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.build_inputs_with_special_tokens" class="md-nav__link">
    <span class="md-ellipsis">
      build_inputs_with_special_tokens
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.create_token_type_ids_from_sequences" class="md-nav__link">
    <span class="md-ellipsis">
      create_token_type_ids_from_sequences
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.save_vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      save_vocabulary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../codegen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    codegen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cogvlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cogvlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cohere/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cohere
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convbert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convbert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convnext/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convnext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpmant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpmant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpmbee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpmbee
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ctrl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctrl
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cvt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cvt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data2vec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data2vec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    deberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deberta_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    deberta_v2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../decision_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decision_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distilbert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    distilbert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../efficientformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    efficientformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../efficientnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    efficientnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../electra/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    electra
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encodec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encodec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ernie/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ernie
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ernie_m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ernie_m
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../esm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    esm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    falcon
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../flava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    flava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../funnel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    funnel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gemma
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../git/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    git
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_bigcode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_bigcode
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neox/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neox
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neox_japanese/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neox_japanese
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_pangu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_pangu
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gptj/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gptj
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../graphormer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    graphormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../groupvit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    groupvit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hubert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hubert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../imagegpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    imagegpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../internlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    internlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jetmoe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jetmoe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../layoutlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    layoutlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../layoutlmv2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    layoutlmv2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../led/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    led
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llava_next/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llava_next
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../longformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    longformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../longt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    longt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../luke/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    luke
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../marian/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    marian
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../maskformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    maskformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mbart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mbart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    megatron_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron_gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    megatron_gpt2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../minicpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    minicpm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../minigpt4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    minigpt4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mistral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mixtral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mixtral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mobilebert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mobilebert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mobilevit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mobilevit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../moss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    moss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mpnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mpnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../musicgen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    musicgen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../musicgen_melody/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    musicgen_melody
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mvp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mvp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nezha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nezha
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nystromformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nystromformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../olmo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    olmo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../openelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    openelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../opt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    opt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../owlvit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    owlvit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pegasus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pegasus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phi
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phi3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../poolformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    poolformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pop2piano/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pop2piano
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../qwen2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    qwen2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../qwen2_moe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    qwen2_moe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rembert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rembert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../resnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    resnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roc_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roc_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rwkv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rwkv
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sam
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seamless_m4t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seamless_m4t
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seamless_m4t_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seamless_m4t_v2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../segformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    segformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seggpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seggpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speech_encoder_decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_encoder_decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speech_to_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_to_text
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../squeezebert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    squeezebert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stablelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    stablelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    starcoder2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../swiftformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    swiftformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../switch_transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    switch_transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    t5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../table_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    table_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../timesformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    timesformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tinybert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tinybert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../van/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    van
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vipllava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vipllava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vision_text_dual_encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vision_text_dual_encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../visual_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    visual_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2_conformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2_conformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2_with_lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2_with_lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wavlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../whisper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    whisper
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x_clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    x_clip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm_roberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm_roberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm_roberta_xl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm_roberta_xl
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlnet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_4" >
        
          
          <label class="md-nav__link" for="__nav_5_9_4" id="__nav_5_9_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_4">
            <span class="md-nav__icon md-icon"></span>
            pipeline
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transforemrs/pipeline/index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/automatic_speech_recognition/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    automatic_speech_recognition
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/document_question_answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    document_question_answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/fill_mask/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fill_mask
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/question_answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    question_answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text2text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text2text_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/zero_shot_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zero_shot_classification
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../configuration_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    configuration_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modeling_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    modeling_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils_base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils_base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils_fast/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils_fast
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../trl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TRL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Notes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/changelog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Change Log
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/code_of_conduct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code of Conduct
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig.from_text_vision_configs" class="md-nav__link">
    <span class="md-ellipsis">
      from_text_vision_configs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTextConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTextConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig.from_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      from_pretrained
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPVisionConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPVisionConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig.from_pretrained" class="md-nav__link">
    <span class="md-ellipsis">
      from_pretrained
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPImageProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPImageProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.preprocess" class="md-nav__link">
    <span class="md-ellipsis">
      preprocess
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.resize" class="md-nav__link">
    <span class="md-ellipsis">
      resize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.get_image_features" class="md-nav__link">
    <span class="md-ellipsis">
      get_image_features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.get_text_features" class="md-nav__link">
    <span class="md-ellipsis">
      get_text_features
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPPreTrainedModel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTextModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTextModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTextModelWithProjection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTextModelWithProjection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPVisionModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPVisionModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPVisionModelWithProjection
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPVisionModelWithProjection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPForImageClassification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPForImageClassification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.feature_extractor" class="md-nav__link">
    <span class="md-ellipsis">
      feature_extractor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.feature_extractor_class" class="md-nav__link">
    <span class="md-ellipsis">
      feature_extractor_class
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.model_input_names" class="md-nav__link">
    <span class="md-ellipsis">
      model_input_names
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.batch_decode" class="md-nav__link">
    <span class="md-ellipsis">
      batch_decode
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.decode" class="md-nav__link">
    <span class="md-ellipsis">
      decode
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTokenizer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTokenizer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.vocab_size" class="md-nav__link">
    <span class="md-ellipsis">
      vocab_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.bpe" class="md-nav__link">
    <span class="md-ellipsis">
      bpe
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.build_inputs_with_special_tokens" class="md-nav__link">
    <span class="md-ellipsis">
      build_inputs_with_special_tokens
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.convert_tokens_to_string" class="md-nav__link">
    <span class="md-ellipsis">
      convert_tokens_to_string
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.create_token_type_ids_from_sequences" class="md-nav__link">
    <span class="md-ellipsis">
      create_token_type_ids_from_sequences
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.get_special_tokens_mask" class="md-nav__link">
    <span class="md-ellipsis">
      get_special_tokens_mask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.get_vocab" class="md-nav__link">
    <span class="md-ellipsis">
      get_vocab
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.save_vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      save_vocabulary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast" class="md-nav__link">
    <span class="md-ellipsis">
      CLIPTokenizerFast
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLIPTokenizerFast">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.build_inputs_with_special_tokens" class="md-nav__link">
    <span class="md-ellipsis">
      build_inputs_with_special_tokens
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.create_token_type_ids_from_sequences" class="md-nav__link">
    <span class="md-ellipsis">
      create_token_type_ids_from_sequences
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.save_vocabulary" class="md-nav__link">
    <span class="md-ellipsis">
      save_vocabulary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/mindspore-lab/mindnlp/edit/master/docs/en/api/transformers/models/clip.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindnlp/raw/master/docs/en/api/transformers/models/clip.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


  <h1>clip</h1>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.configuration_clip.CLIPConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.configuration_clip.CLIPConfig</code>


<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code></p>


        <p>[<code>CLIPConfig</code>] is the configuration class to store the configuration of a [<code>CLIPModel</code>]. It is used to instantiate
a CLIP model according to the specified arguments, defining the text model and vision model configs. Instantiating
a configuration with the defaults will yield a similar configuration to that of the CLIP
<a href="https://hf-mirror.com/openai/clip-vit-base-patch32">openai/clip-vit-base-patch32</a> architecture.</p>
<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the
documentation from [<code>PretrainedConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>text_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary of configuration options used to initialize [<code>CLIPTextConfig</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vision_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary of configuration options used to initialize [<code>CLIPVisionConfig</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>projection_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimentionality of text and vision projection layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 512</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logit_scale_init_value</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The inital value of the <em>logit_scale</em> paramter. Default is used as per the original CLIP implementation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 2.6592</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2.6592</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary of keyword arguments.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>*optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">CLIPConfig</span><span class="p">,</span> <span class="n">CLIPModel</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a CLIPConfig with openai/clip-vit-base-patch32 style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">CLIPConfig</span><span class="p">()</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a CLIPModel (with random weights) from the openai/clip-vit-base-patch32 style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPModel</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Accessing the model configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># We can also initialize a CLIPConfig from a CLIPTextConfig and a CLIPVisionConfig</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">CLIPTextConfig</span><span class="p">,</span> <span class="n">CLIPVisionConfig</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a CLIPText and CLIPVision configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">config_text</span> <span class="o">=</span> <span class="n">CLIPTextConfig</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">config_vision</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span><span class="p">()</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">config</span> <span class="o">=</span> <span class="n">CLIPConfig</span><span class="o">.</span><span class="n">from_text_vision_configs</span><span class="p">(</span><span class="n">config_text</span><span class="p">,</span> <span class="n">config_vision</span><span class="p">)</span>
</code></pre></div>
</details>





              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    [`CLIPConfig`] is the configuration class to store the configuration of a [`CLIPModel`]. It is used to instantiate</span>
<span class="sd">    a CLIP model according to the specified arguments, defining the text model and vision model configs. Instantiating</span>
<span class="sd">    a configuration with the defaults will yield a similar configuration to that of the CLIP</span>
<span class="sd">    [openai/clip-vit-base-patch32](https://hf-mirror.com/openai/clip-vit-base-patch32) architecture.</span>

<span class="sd">    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the</span>
<span class="sd">    documentation from [`PretrainedConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        text_config (`dict`, *optional*):</span>
<span class="sd">            Dictionary of configuration options used to initialize [`CLIPTextConfig`].</span>
<span class="sd">        vision_config (`dict`, *optional*):</span>
<span class="sd">            Dictionary of configuration options used to initialize [`CLIPVisionConfig`].</span>
<span class="sd">        projection_dim (`int`, *optional*, defaults to 512):</span>
<span class="sd">            Dimentionality of text and vision projection layers.</span>
<span class="sd">        logit_scale_init_value (`float`, *optional*, defaults to 2.6592):</span>
<span class="sd">            The inital value of the *logit_scale* paramter. Default is used as per the original CLIP implementation.</span>
<span class="sd">        kwargs (*optional*):</span>
<span class="sd">            Dictionary of keyword arguments.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import CLIPConfig, CLIPModel</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a CLIPConfig with openai/clip-vit-base-patch32 style configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = CLIPConfig()</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a CLIPModel (with random weights) from the openai/clip-vit-base-patch32 style configuration</span>
<span class="sd">        &gt;&gt;&gt; model = CLIPModel(configuration)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Accessing the model configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = model.config</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # We can also initialize a CLIPConfig from a CLIPTextConfig and a CLIPVisionConfig</span>
<span class="sd">        &gt;&gt;&gt; from transformers import CLIPTextConfig, CLIPVisionConfig</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a CLIPText and CLIPVision configuration</span>
<span class="sd">        &gt;&gt;&gt; config_text = CLIPTextConfig()</span>
<span class="sd">        &gt;&gt;&gt; config_vision = CLIPVisionConfig()</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; config = CLIPConfig.from_text_vision_configs(config_text, config_vision)</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;clip&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">text_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vision_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">logit_scale_init_value</span><span class="o">=</span><span class="mf">2.6592</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a new instance of CLIPConfig.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the class.</span>
<span class="sd">            text_config (dict): The configuration for text inputs. If provided, overrides default values. Default is None.</span>
<span class="sd">            vision_config (dict): The configuration for vision inputs. If provided, overrides default values. Default is None.</span>
<span class="sd">            projection_dim (int): The dimension of the projection. Default is 512.</span>
<span class="sd">            logit_scale_init_value (float): The initial value for logit scaling. Default is 2.6592.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If text_config or vision_config are not of type dict.</span>
<span class="sd">            ValueError: If projection_dim or logit_scale_init_value are not of type int or float respectively.</span>
<span class="sd">            KeyError: If &#39;transformers_version&#39; key is present in text_config or vision_config.</span>
<span class="sd">            AttributeError: If &#39;id2label&#39; key is not present in vision_config.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If `_config_dict` exist, we use them for the backward compatibility.</span>
        <span class="c1"># We pop out these 2 attributes before calling `super().__init__` to avoid them being saved (which causes a lot</span>
        <span class="c1"># of confusion!).</span>
        <span class="n">text_config_dict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;text_config_dict&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">vision_config_dict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;vision_config_dict&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Instead of simply assigning `[text|vision]_config_dict` to `[text|vision]_config`, we use the values in</span>
        <span class="c1"># `[text|vision]_config_dict` to update the values in `[text|vision]_config`. The values should be same in most</span>
        <span class="c1"># cases, but we don&#39;t want to break anything regarding `_config_dict` that existed before commit `8827e1b2`.</span>
        <span class="k">if</span> <span class="n">text_config_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">text_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">text_config</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># This is the complete result when using `text_config_dict`.</span>
            <span class="n">_text_config_dict</span> <span class="o">=</span> <span class="n">CLIPTextConfig</span><span class="p">(</span><span class="o">**</span><span class="n">text_config_dict</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

            <span class="c1"># Give a warning if the values exist in both `_text_config_dict` and `text_config` but being different.</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">_text_config_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">text_config</span> <span class="ow">and</span> <span class="n">value</span> <span class="o">!=</span> <span class="n">text_config</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="ow">and</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;transformers_version&quot;</span><span class="p">]:</span>
                    <span class="c1"># If specified in `text_config_dict`</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">text_config_dict</span><span class="p">:</span>
                        <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">` is found in both `text_config_dict` and `text_config` but with different values. &quot;</span>
                            <span class="sa">f</span><span class="s1">&#39;The value `text_config_dict[&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;]` will be used instead.&#39;</span>
                        <span class="p">)</span>
                    <span class="c1"># If inferred from default argument values (just to be super careful)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The &quot;</span>
                            <span class="sa">f</span><span class="s1">&#39;value `text_config[&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;]` will be overriden.&#39;</span>
                        <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

            <span class="c1"># Update all values in `text_config` with the ones in `_text_config_dict`.</span>
            <span class="n">text_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_text_config_dict</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">vision_config_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">vision_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">vision_config</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># This is the complete result when using `vision_config_dict`.</span>
            <span class="n">_vision_config_dict</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span><span class="p">(</span><span class="o">**</span><span class="n">vision_config_dict</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
            <span class="c1"># convert keys to string instead of integer</span>
            <span class="k">if</span> <span class="s2">&quot;id2label&quot;</span> <span class="ow">in</span> <span class="n">_vision_config_dict</span><span class="p">:</span>
                <span class="n">_vision_config_dict</span><span class="p">[</span><span class="s2">&quot;id2label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="nb">str</span><span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">_vision_config_dict</span><span class="p">[</span><span class="s2">&quot;id2label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">}</span>

            <span class="c1"># Give a warning if the values exist in both `_vision_config_dict` and `vision_config` but being different.</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">_vision_config_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">vision_config</span> <span class="ow">and</span> <span class="n">value</span> <span class="o">!=</span> <span class="n">vision_config</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="ow">and</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;transformers_version&quot;</span><span class="p">]:</span>
                    <span class="c1"># If specified in `vision_config_dict`</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">vision_config_dict</span><span class="p">:</span>
                        <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">` is found in both `vision_config_dict` and `vision_config` but with different &quot;</span>
                            <span class="sa">f</span><span class="s1">&#39;values. The value `vision_config_dict[&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;]` will be used instead.&#39;</span>
                        <span class="p">)</span>
                    <span class="c1"># If inferred from default argument values (just to be super careful)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;`vision_config_dict` is provided which will be used to initialize `CLIPVisionConfig`. &quot;</span>
                            <span class="sa">f</span><span class="s1">&#39;The value `vision_config[&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;]` will be overriden.&#39;</span>
                        <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

            <span class="c1"># Update all values in `vision_config` with the ones in `_vision_config_dict`.</span>
            <span class="n">vision_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_vision_config_dict</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">text_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">text_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;`text_config` is `None`. Initializing the `CLIPTextConfig` with default values.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">vision_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">vision_config</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;`vision_config` is `None`. initializing the `CLIPVisionConfig` with default values.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">text_config</span> <span class="o">=</span> <span class="n">CLIPTextConfig</span><span class="p">(</span><span class="o">**</span><span class="n">text_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_config</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span><span class="p">(</span><span class="o">**</span><span class="n">vision_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logit_scale_init_value</span> <span class="o">=</span> <span class="n">logit_scale_init_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_factor</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_text_vision_configs</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">text_config</span><span class="p">:</span> <span class="n">CLIPTextConfig</span><span class="p">,</span> <span class="n">vision_config</span><span class="p">:</span> <span class="n">CLIPVisionConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiate a [`CLIPConfig`] (or a derived class) from clip text model configuration and clip vision model</span>
<span class="sd">        configuration.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`CLIPConfig`]: An instance of a configuration object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">text_config</span><span class="o">=</span><span class="n">text_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">vision_config</span><span class="o">=</span><span class="n">vision_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.configuration_clip.CLIPConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">configuration_clip</span><span class="o">.</span><span class="n">CLIPConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">text_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vision_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">logit_scale_init_value</span><span class="o">=</span><span class="mf">2.6592</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initializes a new instance of CLIPConfig.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The configuration for text inputs. If provided, overrides default values. Default is None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>dict</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vision_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The configuration for vision inputs. If provided, overrides default values. Default is None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>dict</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>projection_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dimension of the projection. Default is 512.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>logit_scale_init_value</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The initial value for logit scaling. Default is 2.6592.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2.6592</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>TypeError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If text_config or vision_config are not of type dict.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If projection_dim or logit_scale_init_value are not of type int or float respectively.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>KeyError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If 'transformers_version' key is present in text_config or vision_config.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>AttributeError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If 'id2label' key is not present in vision_config.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">text_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vision_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">logit_scale_init_value</span><span class="o">=</span><span class="mf">2.6592</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a new instance of CLIPConfig.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The instance of the class.</span>
<span class="sd">        text_config (dict): The configuration for text inputs. If provided, overrides default values. Default is None.</span>
<span class="sd">        vision_config (dict): The configuration for vision inputs. If provided, overrides default values. Default is None.</span>
<span class="sd">        projection_dim (int): The dimension of the projection. Default is 512.</span>
<span class="sd">        logit_scale_init_value (float): The initial value for logit scaling. Default is 2.6592.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If text_config or vision_config are not of type dict.</span>
<span class="sd">        ValueError: If projection_dim or logit_scale_init_value are not of type int or float respectively.</span>
<span class="sd">        KeyError: If &#39;transformers_version&#39; key is present in text_config or vision_config.</span>
<span class="sd">        AttributeError: If &#39;id2label&#39; key is not present in vision_config.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># If `_config_dict` exist, we use them for the backward compatibility.</span>
    <span class="c1"># We pop out these 2 attributes before calling `super().__init__` to avoid them being saved (which causes a lot</span>
    <span class="c1"># of confusion!).</span>
    <span class="n">text_config_dict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;text_config_dict&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">vision_config_dict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;vision_config_dict&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Instead of simply assigning `[text|vision]_config_dict` to `[text|vision]_config`, we use the values in</span>
    <span class="c1"># `[text|vision]_config_dict` to update the values in `[text|vision]_config`. The values should be same in most</span>
    <span class="c1"># cases, but we don&#39;t want to break anything regarding `_config_dict` that existed before commit `8827e1b2`.</span>
    <span class="k">if</span> <span class="n">text_config_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">text_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">text_config</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># This is the complete result when using `text_config_dict`.</span>
        <span class="n">_text_config_dict</span> <span class="o">=</span> <span class="n">CLIPTextConfig</span><span class="p">(</span><span class="o">**</span><span class="n">text_config_dict</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

        <span class="c1"># Give a warning if the values exist in both `_text_config_dict` and `text_config` but being different.</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">_text_config_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">text_config</span> <span class="ow">and</span> <span class="n">value</span> <span class="o">!=</span> <span class="n">text_config</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="ow">and</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;transformers_version&quot;</span><span class="p">]:</span>
                <span class="c1"># If specified in `text_config_dict`</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">text_config_dict</span><span class="p">:</span>
                    <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">` is found in both `text_config_dict` and `text_config` but with different values. &quot;</span>
                        <span class="sa">f</span><span class="s1">&#39;The value `text_config_dict[&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;]` will be used instead.&#39;</span>
                    <span class="p">)</span>
                <span class="c1"># If inferred from default argument values (just to be super careful)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The &quot;</span>
                        <span class="sa">f</span><span class="s1">&#39;value `text_config[&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;]` will be overriden.&#39;</span>
                    <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

        <span class="c1"># Update all values in `text_config` with the ones in `_text_config_dict`.</span>
        <span class="n">text_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_text_config_dict</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">vision_config_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">vision_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">vision_config</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># This is the complete result when using `vision_config_dict`.</span>
        <span class="n">_vision_config_dict</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span><span class="p">(</span><span class="o">**</span><span class="n">vision_config_dict</span><span class="p">)</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="c1"># convert keys to string instead of integer</span>
        <span class="k">if</span> <span class="s2">&quot;id2label&quot;</span> <span class="ow">in</span> <span class="n">_vision_config_dict</span><span class="p">:</span>
            <span class="n">_vision_config_dict</span><span class="p">[</span><span class="s2">&quot;id2label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">key</span><span class="p">):</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">_vision_config_dict</span><span class="p">[</span><span class="s2">&quot;id2label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>

        <span class="c1"># Give a warning if the values exist in both `_vision_config_dict` and `vision_config` but being different.</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">_vision_config_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">vision_config</span> <span class="ow">and</span> <span class="n">value</span> <span class="o">!=</span> <span class="n">vision_config</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="ow">and</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;transformers_version&quot;</span><span class="p">]:</span>
                <span class="c1"># If specified in `vision_config_dict`</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">vision_config_dict</span><span class="p">:</span>
                    <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">` is found in both `vision_config_dict` and `vision_config` but with different &quot;</span>
                        <span class="sa">f</span><span class="s1">&#39;values. The value `vision_config_dict[&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;]` will be used instead.&#39;</span>
                    <span class="p">)</span>
                <span class="c1"># If inferred from default argument values (just to be super careful)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;`vision_config_dict` is provided which will be used to initialize `CLIPVisionConfig`. &quot;</span>
                        <span class="sa">f</span><span class="s1">&#39;The value `vision_config[&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&quot;]` will be overriden.&#39;</span>
                    <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

        <span class="c1"># Update all values in `vision_config` with the ones in `_vision_config_dict`.</span>
        <span class="n">vision_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_vision_config_dict</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">text_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">text_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;`text_config` is `None`. Initializing the `CLIPTextConfig` with default values.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">vision_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">vision_config</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;`vision_config` is `None`. initializing the `CLIPVisionConfig` with default values.&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">text_config</span> <span class="o">=</span> <span class="n">CLIPTextConfig</span><span class="p">(</span><span class="o">**</span><span class="n">text_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vision_config</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span><span class="p">(</span><span class="o">**</span><span class="n">vision_config</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logit_scale_init_value</span> <span class="o">=</span> <span class="n">logit_scale_init_value</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initializer_factor</span> <span class="o">=</span> <span class="mf">1.0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.configuration_clip.CLIPConfig.from_text_vision_configs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">configuration_clip</span><span class="o">.</span><span class="n">CLIPConfig</span><span class="o">.</span><span class="n">from_text_vision_configs</span><span class="p">(</span><span class="n">text_config</span><span class="p">,</span> <span class="n">vision_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPConfig.from_text_vision_configs" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Instantiate a [<code>CLIPConfig</code>] (or a derived class) from clip text model configuration and clip vision model
configuration.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>CLIPConfig</code>]: An instance of a configuration object</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_text_vision_configs</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">text_config</span><span class="p">:</span> <span class="n">CLIPTextConfig</span><span class="p">,</span> <span class="n">vision_config</span><span class="p">:</span> <span class="n">CLIPVisionConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Instantiate a [`CLIPConfig`] (or a derived class) from clip text model configuration and clip vision model</span>
<span class="sd">    configuration.</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`CLIPConfig`]: An instance of a configuration object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">text_config</span><span class="o">=</span><span class="n">text_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">vision_config</span><span class="o">=</span><span class="n">vision_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig</code>


<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code></p>


        <p>This is the configuration class to store the configuration of a [<code>CLIPTextModel</code>]. It is used to instantiate a CLIP
text encoder according to the specified arguments, defining the model architecture. Instantiating a configuration
with the defaults will yield a similar configuration to that of the text encoder of the CLIP
<a href="https://hf-mirror.com/openai/clip-vit-base-patch32">openai/clip-vit-base-patch32</a> architecture.</p>
<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the
documentation from [<code>PretrainedConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>vocab_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Vocabulary size of the CLIP text model. Defines the number of different tokens that can be represented by
the <code>inputs_ids</code> passed when calling [<code>CLIPModel</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 49408</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>49408</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the encoder layers and the pooler layer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 512</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>intermediate_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the "intermediate" (i.e., feed-forward) layer in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 2048</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2048</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>projection_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimentionality of text and vision projection layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 512</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_hidden_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of hidden layers in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 12</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_attention_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of attention heads for each attention layer in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_position_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The maximum sequence length that this model might ever be used with. Typically set this to something large
just in case (e.g., 512 or 1024 or 2048).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 77</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>77</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The non-linear activation function (function or string) in the encoder and pooler. If string, <code>"gelu"</code>,
<code>"relu"</code>, <code>"selu"</code> and <code>"gelu_new"</code> <code>"quick_gelu"</code> are supported.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `function`, *optional*, defaults to `&#34;quick_gelu&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;quick_gelu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon used by the layer normalization layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1e-05</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-05</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dropout ratio for the attention probabilities.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_range</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.02</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.02</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A factor for initializing all weight matrices (should be kept to 1, used internally for initialization
testing).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_token_id</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Padding token id.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bos_token_id</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Beginning of stream token id.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 49406</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>49406</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eos_token_id</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>End of stream token id.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 49407</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>49407</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">CLIPTextConfig</span><span class="p">,</span> <span class="n">CLIPTextModel</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a CLIPTextConfig with openai/clip-vit-base-patch32 style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">CLIPTextConfig</span><span class="p">()</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a CLIPTextModel (with random weights) from the openai/clip-vit-base-patch32 style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPTextModel</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Accessing the model configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
</code></pre></div>
</details>





              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPTextConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the configuration class to store the configuration of a [`CLIPTextModel`]. It is used to instantiate a CLIP</span>
<span class="sd">    text encoder according to the specified arguments, defining the model architecture. Instantiating a configuration</span>
<span class="sd">    with the defaults will yield a similar configuration to that of the text encoder of the CLIP</span>
<span class="sd">    [openai/clip-vit-base-patch32](https://hf-mirror.com/openai/clip-vit-base-patch32) architecture.</span>

<span class="sd">    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the</span>
<span class="sd">    documentation from [`PretrainedConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        vocab_size (`int`, *optional*, defaults to 49408):</span>
<span class="sd">            Vocabulary size of the CLIP text model. Defines the number of different tokens that can be represented by</span>
<span class="sd">            the `inputs_ids` passed when calling [`CLIPModel`].</span>
<span class="sd">        hidden_size (`int`, *optional*, defaults to 512):</span>
<span class="sd">            Dimensionality of the encoder layers and the pooler layer.</span>
<span class="sd">        intermediate_size (`int`, *optional*, defaults to 2048):</span>
<span class="sd">            Dimensionality of the &quot;intermediate&quot; (i.e., feed-forward) layer in the Transformer encoder.</span>
<span class="sd">        projection_dim (`int`, *optional*, defaults to 512):</span>
<span class="sd">            Dimentionality of text and vision projection layers.</span>
<span class="sd">        num_hidden_layers (`int`, *optional*, defaults to 12):</span>
<span class="sd">            Number of hidden layers in the Transformer encoder.</span>
<span class="sd">        num_attention_heads (`int`, *optional*, defaults to 8):</span>
<span class="sd">            Number of attention heads for each attention layer in the Transformer encoder.</span>
<span class="sd">        max_position_embeddings (`int`, *optional*, defaults to 77):</span>
<span class="sd">            The maximum sequence length that this model might ever be used with. Typically set this to something large</span>
<span class="sd">            just in case (e.g., 512 or 1024 or 2048).</span>
<span class="sd">        hidden_act (`str` or `function`, *optional*, defaults to `&quot;quick_gelu&quot;`):</span>
<span class="sd">            The non-linear activation function (function or string) in the encoder and pooler. If string, `&quot;gelu&quot;`,</span>
<span class="sd">            `&quot;relu&quot;`, `&quot;selu&quot;` and `&quot;gelu_new&quot;` `&quot;quick_gelu&quot;` are supported.</span>
<span class="sd">        layer_norm_eps (`float`, *optional*, defaults to 1e-05):</span>
<span class="sd">            The epsilon used by the layer normalization layers.</span>
<span class="sd">        attention_dropout (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            The dropout ratio for the attention probabilities.</span>
<span class="sd">        initializer_range (`float`, *optional*, defaults to 0.02):</span>
<span class="sd">            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</span>
<span class="sd">        initializer_factor (`float`, *optional*, defaults to 1.0):</span>
<span class="sd">            A factor for initializing all weight matrices (should be kept to 1, used internally for initialization</span>
<span class="sd">            testing).</span>
<span class="sd">        pad_token_id (`int`, *optional*, defaults to 1):</span>
<span class="sd">            Padding token id.</span>
<span class="sd">        bos_token_id (`int`, *optional*, defaults to 49406):</span>
<span class="sd">            Beginning of stream token id.</span>
<span class="sd">        eos_token_id (`int`, *optional*, defaults to 49407):</span>
<span class="sd">            End of stream token id.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import CLIPTextConfig, CLIPTextModel</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a CLIPTextConfig with openai/clip-vit-base-patch32 style configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = CLIPTextConfig()</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a CLIPTextModel (with random weights) from the openai/clip-vit-base-patch32 style configuration</span>
<span class="sd">        &gt;&gt;&gt; model = CLIPTextModel(configuration)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Accessing the model configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = model.config</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;clip_text_model&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="mi">49408</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
        <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">77</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;quick_gelu&quot;</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
        <span class="n">initializer_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="c1"># This differs from `CLIPTokenizer`&#39;s default and from openai/clip</span>
        <span class="c1"># See https://github.com/huggingface/transformers/pull/24773#issuecomment-1632287538</span>
        <span class="n">pad_token_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">bos_token_id</span><span class="o">=</span><span class="mi">49406</span><span class="p">,</span>
        <span class="n">eos_token_id</span><span class="o">=</span><span class="mi">49407</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize CLIPTextConfig.</span>

<span class="sd">        Args:</span>
<span class="sd">            vocab_size (int, optional): The size of the vocabulary. Default is 49408.</span>
<span class="sd">            hidden_size (int, optional): The size of the hidden layers. Default is 512.</span>
<span class="sd">            intermediate_size (int, optional): The size of the intermediate layers. Default is 2048.</span>
<span class="sd">            projection_dim (int, optional): The projection dimension. Default is 512.</span>
<span class="sd">            num_hidden_layers (int, optional): The number of hidden layers. Default is 12.</span>
<span class="sd">            num_attention_heads (int, optional): The number of attention heads. Default is 8.</span>
<span class="sd">            max_position_embeddings (int, optional): The maximum position embeddings. Default is 77.</span>
<span class="sd">            hidden_act (str, optional): The type of activation function for the hidden layers. Default is &#39;quick_gelu&#39;.</span>
<span class="sd">            layer_norm_eps (float, optional): Epsilon value for layer normalization. Default is 1e-05.</span>
<span class="sd">            attention_dropout (float, optional): The dropout rate for attention layers. Default is 0.0.</span>
<span class="sd">            initializer_range (float, optional): The range for parameter initializers. Default is 0.02.</span>
<span class="sd">            initializer_factor (float, optional): The factor for parameter initializers. Default is 1.0.</span>
<span class="sd">            pad_token_id (int, optional): The ID of the padding token. Default is 1.</span>
<span class="sd">            bos_token_id (int, optional): The ID of the beginning of sequence token. Default is 49406.</span>
<span class="sd">            eos_token_id (int, optional): The ID of the end of sequence token. Default is 49407.</span>
<span class="sd">            **kwargs: Additional keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="n">bos_token_id</span><span class="o">=</span><span class="n">bos_token_id</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">eos_token_id</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_factor</span> <span class="o">=</span> <span class="n">initializer_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_dropout</span> <span class="o">=</span> <span class="n">attention_dropout</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PretrainedConfig&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a CLIPTextConfig instance from a pretrained model.</span>

<span class="sd">        Args:</span>
<span class="sd">            cls (type): The class object.</span>
<span class="sd">            pretrained_model_name_or_path (Union[str, os.PathLike]): The name or path of the pretrained model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PretrainedConfig: A CLIPTextConfig instance initialized with the configuration specified by the pretrained model.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: If the input parameters are not of the expected types.</span>
<span class="sd">            ValueError: If the configuration dictionary does not contain the required information.</span>
<span class="sd">            Warning: If the model type being used for instantiation does not match the class&#39;s model type, which may lead to errors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config_dict</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_config_dict</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># get the text config dict if we are loading from CLIPConfig</span>
        <span class="k">if</span> <span class="n">config_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;clip&quot;</span><span class="p">:</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;text_config&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;model_type&quot;</span> <span class="ow">in</span> <span class="n">config_dict</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;You are using a model of type </span><span class="si">{</span><span class="n">config_dict</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> to instantiate a model of type &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">. This is not supported for all configurations of models and can yield errors.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">configuration_clip</span><span class="o">.</span><span class="n">CLIPTextConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">49408</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">77</span><span class="p">,</span> <span class="n">hidden_act</span><span class="o">=</span><span class="s1">&#39;quick_gelu&#39;</span><span class="p">,</span> <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">initializer_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bos_token_id</span><span class="o">=</span><span class="mi">49406</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="mi">49407</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize CLIPTextConfig.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>vocab_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the vocabulary. Default is 49408.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>49408</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the hidden layers. Default is 512.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>intermediate_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the intermediate layers. Default is 2048.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2048</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>projection_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The projection dimension. Default is 512.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_hidden_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of hidden layers. Default is 12.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_attention_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of attention heads. Default is 8.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_position_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The maximum position embeddings. Default is 77.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>77</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The type of activation function for the hidden layers. Default is 'quick_gelu'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;quick_gelu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Epsilon value for layer normalization. Default is 1e-05.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-05</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dropout rate for attention layers. Default is 0.0.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_range</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The range for parameter initializers. Default is 0.02.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.02</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The factor for parameter initializers. Default is 1.0.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_token_id</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The ID of the padding token. Default is 1.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bos_token_id</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The ID of the beginning of sequence token. Default is 49406.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>49406</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eos_token_id</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The ID of the end of sequence token. Default is 49407.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>49407</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional keyword arguments.</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">49408</span><span class="p">,</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">max_position_embeddings</span><span class="o">=</span><span class="mi">77</span><span class="p">,</span>
    <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;quick_gelu&quot;</span><span class="p">,</span>
    <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
    <span class="n">initializer_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="c1"># This differs from `CLIPTokenizer`&#39;s default and from openai/clip</span>
    <span class="c1"># See https://github.com/huggingface/transformers/pull/24773#issuecomment-1632287538</span>
    <span class="n">pad_token_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">bos_token_id</span><span class="o">=</span><span class="mi">49406</span><span class="p">,</span>
    <span class="n">eos_token_id</span><span class="o">=</span><span class="mi">49407</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize CLIPTextConfig.</span>

<span class="sd">    Args:</span>
<span class="sd">        vocab_size (int, optional): The size of the vocabulary. Default is 49408.</span>
<span class="sd">        hidden_size (int, optional): The size of the hidden layers. Default is 512.</span>
<span class="sd">        intermediate_size (int, optional): The size of the intermediate layers. Default is 2048.</span>
<span class="sd">        projection_dim (int, optional): The projection dimension. Default is 512.</span>
<span class="sd">        num_hidden_layers (int, optional): The number of hidden layers. Default is 12.</span>
<span class="sd">        num_attention_heads (int, optional): The number of attention heads. Default is 8.</span>
<span class="sd">        max_position_embeddings (int, optional): The maximum position embeddings. Default is 77.</span>
<span class="sd">        hidden_act (str, optional): The type of activation function for the hidden layers. Default is &#39;quick_gelu&#39;.</span>
<span class="sd">        layer_norm_eps (float, optional): Epsilon value for layer normalization. Default is 1e-05.</span>
<span class="sd">        attention_dropout (float, optional): The dropout rate for attention layers. Default is 0.0.</span>
<span class="sd">        initializer_range (float, optional): The range for parameter initializers. Default is 0.02.</span>
<span class="sd">        initializer_factor (float, optional): The factor for parameter initializers. Default is 1.0.</span>
<span class="sd">        pad_token_id (int, optional): The ID of the padding token. Default is 1.</span>
<span class="sd">        bos_token_id (int, optional): The ID of the beginning of sequence token. Default is 49406.</span>
<span class="sd">        eos_token_id (int, optional): The ID of the end of sequence token. Default is 49407.</span>
<span class="sd">        **kwargs: Additional keyword arguments.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="n">bos_token_id</span><span class="o">=</span><span class="n">bos_token_id</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">eos_token_id</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="n">max_position_embeddings</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initializer_factor</span> <span class="o">=</span> <span class="n">initializer_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attention_dropout</span> <span class="o">=</span> <span class="n">attention_dropout</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig.from_pretrained" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">configuration_clip</span><span class="o">.</span><span class="n">CLIPTextConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPTextConfig.from_pretrained" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Creates a CLIPTextConfig instance from a pretrained model.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>cls</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The class object.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>type</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pretrained_model_name_or_path</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The name or path of the pretrained model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[str, <span title="os.PathLike">PathLike</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>PretrainedConfig</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>A CLIPTextConfig instance initialized with the configuration specified by the pretrained model.</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code>
                  </span>
                </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>TypeError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the input parameters are not of the expected types.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the configuration dictionary does not contain the required information.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>Warning</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the model type being used for instantiation does not match the class's model type, which may lead to errors.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PretrainedConfig&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a CLIPTextConfig instance from a pretrained model.</span>

<span class="sd">    Args:</span>
<span class="sd">        cls (type): The class object.</span>
<span class="sd">        pretrained_model_name_or_path (Union[str, os.PathLike]): The name or path of the pretrained model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        PretrainedConfig: A CLIPTextConfig instance initialized with the configuration specified by the pretrained model.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input parameters are not of the expected types.</span>
<span class="sd">        ValueError: If the configuration dictionary does not contain the required information.</span>
<span class="sd">        Warning: If the model type being used for instantiation does not match the class&#39;s model type, which may lead to errors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_dict</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_config_dict</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># get the text config dict if we are loading from CLIPConfig</span>
    <span class="k">if</span> <span class="n">config_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;clip&quot;</span><span class="p">:</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;text_config&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s2">&quot;model_type&quot;</span> <span class="ow">in</span> <span class="n">config_dict</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;You are using a model of type </span><span class="si">{</span><span class="n">config_dict</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> to instantiate a model of type &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">. This is not supported for all configurations of models and can yield errors.&quot;</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig</code>


<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code></p>


        <p>This is the configuration class to store the configuration of a [<code>CLIPVisionModel</code>]. It is used to instantiate a
CLIP vision encoder according to the specified arguments, defining the model architecture. Instantiating a
configuration with the defaults will yield a similar configuration to that of the vision encoder of the CLIP
<a href="https://hf-mirror.com/openai/clip-vit-base-patch32">openai/clip-vit-base-patch32</a> architecture.</p>
<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the
documentation from [<code>PretrainedConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the encoder layers and the pooler layer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 768</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>768</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>intermediate_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the "intermediate" (i.e., feed-forward) layer in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 3072</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3072</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>projection_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimentionality of text and vision projection layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 512</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_hidden_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of hidden layers in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 12</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_attention_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of attention heads for each attention layer in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 12</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_channels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of input channels.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 3</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size (resolution) of each image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 224</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>224</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>patch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size (resolution) of each patch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 32</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>32</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The non-linear activation function (function or string) in the encoder and pooler. If string, <code>"gelu"</code>,
<code>"relu"</code>, <code>"selu"</code> and <code>"gelu_new"</code> <code>`"quick_gelu"</code> are supported.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `function`, *optional*, defaults to `&#34;quick_gelu&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;quick_gelu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon used by the layer normalization layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1e-05</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-05</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dropout ratio for the attention probabilities.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_range</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.02</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.02</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A factor for initializing all weight matrices (should be kept to 1, used internally for initialization
testing).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">CLIPVisionConfig</span><span class="p">,</span> <span class="n">CLIPVisionModel</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a CLIPVisionConfig with openai/clip-vit-base-patch32 style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span><span class="p">()</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a CLIPVisionModel (with random weights) from the openai/clip-vit-base-patch32 style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPVisionModel</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Accessing the model configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
</code></pre></div>
</details>





              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPVisionConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the configuration class to store the configuration of a [`CLIPVisionModel`]. It is used to instantiate a</span>
<span class="sd">    CLIP vision encoder according to the specified arguments, defining the model architecture. Instantiating a</span>
<span class="sd">    configuration with the defaults will yield a similar configuration to that of the vision encoder of the CLIP</span>
<span class="sd">    [openai/clip-vit-base-patch32](https://hf-mirror.com/openai/clip-vit-base-patch32) architecture.</span>

<span class="sd">    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the</span>
<span class="sd">    documentation from [`PretrainedConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        hidden_size (`int`, *optional*, defaults to 768):</span>
<span class="sd">            Dimensionality of the encoder layers and the pooler layer.</span>
<span class="sd">        intermediate_size (`int`, *optional*, defaults to 3072):</span>
<span class="sd">            Dimensionality of the &quot;intermediate&quot; (i.e., feed-forward) layer in the Transformer encoder.</span>
<span class="sd">        projection_dim (`int`, *optional*, defaults to 512):</span>
<span class="sd">            Dimentionality of text and vision projection layers.</span>
<span class="sd">        num_hidden_layers (`int`, *optional*, defaults to 12):</span>
<span class="sd">            Number of hidden layers in the Transformer encoder.</span>
<span class="sd">        num_attention_heads (`int`, *optional*, defaults to 12):</span>
<span class="sd">            Number of attention heads for each attention layer in the Transformer encoder.</span>
<span class="sd">        num_channels (`int`, *optional*, defaults to 3):</span>
<span class="sd">            The number of input channels.</span>
<span class="sd">        image_size (`int`, *optional*, defaults to 224):</span>
<span class="sd">            The size (resolution) of each image.</span>
<span class="sd">        patch_size (`int`, *optional*, defaults to 32):</span>
<span class="sd">            The size (resolution) of each patch.</span>
<span class="sd">        hidden_act (`str` or `function`, *optional*, defaults to `&quot;quick_gelu&quot;`):</span>
<span class="sd">            The non-linear activation function (function or string) in the encoder and pooler. If string, `&quot;gelu&quot;`,</span>
<span class="sd">            `&quot;relu&quot;`, `&quot;selu&quot;` and `&quot;gelu_new&quot;` ``&quot;quick_gelu&quot;` are supported.</span>
<span class="sd">        layer_norm_eps (`float`, *optional*, defaults to 1e-05):</span>
<span class="sd">            The epsilon used by the layer normalization layers.</span>
<span class="sd">        attention_dropout (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            The dropout ratio for the attention probabilities.</span>
<span class="sd">        initializer_range (`float`, *optional*, defaults to 0.02):</span>
<span class="sd">            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</span>
<span class="sd">        initializer_factor (`float`, *optional*, defaults to 1.0):</span>
<span class="sd">            A factor for initializing all weight matrices (should be kept to 1, used internally for initialization</span>
<span class="sd">            testing).</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import CLIPVisionConfig, CLIPVisionModel</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a CLIPVisionConfig with openai/clip-vit-base-patch32 style configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = CLIPVisionConfig()</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a CLIPVisionModel (with random weights) from the openai/clip-vit-base-patch32 style configuration</span>
<span class="sd">        &gt;&gt;&gt; model = CLIPVisionModel(configuration)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Accessing the model configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = model.config</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;clip_vision_model&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
        <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
        <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">num_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
        <span class="n">patch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;quick_gelu&quot;</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
        <span class="n">initializer_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a CLIPVisionConfig object with the provided configuration parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            hidden_size (int): The size of the hidden layers in the network.</span>
<span class="sd">            intermediate_size (int): The size of the intermediate hidden layers in the network.</span>
<span class="sd">            projection_dim (int): The dimension of the projected embeddings.</span>
<span class="sd">            num_hidden_layers (int): The number of hidden layers in the network.</span>
<span class="sd">            num_attention_heads (int): The number of attention heads in the network.</span>
<span class="sd">            num_channels (int): The number of channels in the input image.</span>
<span class="sd">            image_size (int): The size of the input image.</span>
<span class="sd">            patch_size (int): The size of the image patch used in the network.</span>
<span class="sd">            hidden_act (str): The activation function used in the hidden layers.</span>
<span class="sd">            layer_norm_eps (float): The epsilon value for layer normalization.</span>
<span class="sd">            attention_dropout (float): The dropout rate for attention layers.</span>
<span class="sd">            initializer_range (float): The range for parameter initialization.</span>
<span class="sd">            initializer_factor (float): The factor for parameter initialization.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If any of the input parameters are invalid or out of range.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_factor</span> <span class="o">=</span> <span class="n">initializer_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_dropout</span> <span class="o">=</span> <span class="n">attention_dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PretrainedConfig&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load a pretrained configuration from a given model name or path.</span>

<span class="sd">        Args:</span>
<span class="sd">            cls (class): The class object.</span>
<span class="sd">            pretrained_model_name_or_path (Union[str, os.PathLike]): The name or path of the pretrained model.</span>
<span class="sd">                It can be either a string representing the name of the model or a path-like object pointing to the model location.</span>

<span class="sd">        Returns:</span>
<span class="sd">            PretrainedConfig: The loaded pretrained configuration.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>

<span class="sd">        This method is a class method that allows loading a pretrained configuration. It takes in the class object &#39;cls&#39;</span>
<span class="sd">        and the name or path of the pretrained model &#39;pretrained_model_name_or_path&#39; as parameters. The method returns an instance</span>
<span class="sd">        of type &#39;PretrainedConfig&#39;, which represents the loaded pretrained configuration.</span>

<span class="sd">        The &#39;pretrained_model_name_or_path&#39; parameter can be either a string representing the name of the pretrained model</span>
<span class="sd">        or a path-like object pointing to the location of the model. It is used to identify and locate the pretrained model</span>
<span class="sd">        that needs to be loaded.</span>

<span class="sd">        Note: If the loaded configuration belongs to the &#39;clip&#39; model type, the &#39;config_dict&#39; will be updated to use the</span>
<span class="sd">        &#39;vision_config&#39; sub-dictionary. Additionally, if the &#39;model_type&#39; attribute is present in the &#39;cls&#39; class and</span>
<span class="sd">        the loaded configuration&#39;s &#39;model_type&#39; is different from &#39;cls.model_type&#39;, a warning will be logged indicating</span>
<span class="sd">        that instantiating a model of different types may lead to errors.</span>

<span class="sd">        Example:</span>
<span class="sd">            ```python</span>
<span class="sd">            &gt;&gt;&gt; config = CLIPVisionConfig.from_pretrained(&quot;clip_model&quot;)</span>
<span class="sd">            ...</span>
<span class="sd">            ```</span>
<span class="sd">            In the above example, the &#39;from_pretrained&#39; method is called on the &#39;CLIPVisionConfig&#39; class to load the pretrained</span>
<span class="sd">            configuration of the &#39;clip_model&#39;. The resulting configuration is stored in the &#39;config&#39; variable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config_dict</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_config_dict</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># get the vision config dict if we are loading from CLIPConfig</span>
        <span class="k">if</span> <span class="n">config_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;clip&quot;</span><span class="p">:</span>
            <span class="n">config_dict</span> <span class="o">=</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;vision_config&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;model_type&quot;</span> <span class="ow">in</span> <span class="n">config_dict</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;You are using a model of type </span><span class="si">{</span><span class="n">config_dict</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> to instantiate a model of type &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">. This is not supported for all configurations of models and can yield errors.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">configuration_clip</span><span class="o">.</span><span class="n">CLIPVisionConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span> <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">hidden_act</span><span class="o">=</span><span class="s1">&#39;quick_gelu&#39;</span><span class="p">,</span> <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">initializer_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize a CLIPVisionConfig object with the provided configuration parameters.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the hidden layers in the network.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>768</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>intermediate_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the intermediate hidden layers in the network.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3072</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>projection_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dimension of the projected embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_hidden_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of hidden layers in the network.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_attention_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of attention heads in the network.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_channels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of channels in the input image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the input image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>224</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>patch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the image patch used in the network.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>32</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The activation function used in the hidden layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;quick_gelu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon value for layer normalization.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-05</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dropout rate for attention layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_range</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The range for parameter initialization.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.02</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The factor for parameter initialization.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If any of the input parameters are invalid or out of range.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
    <span class="n">intermediate_size</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
    <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">num_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
    <span class="n">patch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;quick_gelu&quot;</span><span class="p">,</span>
    <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
    <span class="n">initializer_factor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize a CLIPVisionConfig object with the provided configuration parameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        hidden_size (int): The size of the hidden layers in the network.</span>
<span class="sd">        intermediate_size (int): The size of the intermediate hidden layers in the network.</span>
<span class="sd">        projection_dim (int): The dimension of the projected embeddings.</span>
<span class="sd">        num_hidden_layers (int): The number of hidden layers in the network.</span>
<span class="sd">        num_attention_heads (int): The number of attention heads in the network.</span>
<span class="sd">        num_channels (int): The number of channels in the input image.</span>
<span class="sd">        image_size (int): The size of the input image.</span>
<span class="sd">        patch_size (int): The size of the image patch used in the network.</span>
<span class="sd">        hidden_act (str): The activation function used in the hidden layers.</span>
<span class="sd">        layer_norm_eps (float): The epsilon value for layer normalization.</span>
<span class="sd">        attention_dropout (float): The dropout rate for attention layers.</span>
<span class="sd">        initializer_range (float): The range for parameter initialization.</span>
<span class="sd">        initializer_factor (float): The factor for parameter initialization.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If any of the input parameters are invalid or out of range.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_size</span> <span class="o">=</span> <span class="n">intermediate_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initializer_factor</span> <span class="o">=</span> <span class="n">initializer_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attention_dropout</span> <span class="o">=</span> <span class="n">attention_dropout</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig.from_pretrained" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">configuration_clip</span><span class="o">.</span><span class="n">CLIPVisionConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

<a href="#mindnlp.transformers.models.clip.configuration_clip.CLIPVisionConfig.from_pretrained" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load a pretrained configuration from a given model name or path.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>cls</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The class object.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>class</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pretrained_model_name_or_path</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The name or path of the pretrained model.
It can be either a string representing the name of the model or a path-like object pointing to the model location.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[str, <span title="os.PathLike">PathLike</span>]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>PretrainedConfig</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>The loaded pretrained configuration.</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code>
                  </span>
                </p>
            </td>
          </tr>
      </tbody>
    </table>
        <p>This method is a class method that allows loading a pretrained configuration. It takes in the class object 'cls'
and the name or path of the pretrained model 'pretrained_model_name_or_path' as parameters. The method returns an instance
of type 'PretrainedConfig', which represents the loaded pretrained configuration.</p>
<p>The 'pretrained_model_name_or_path' parameter can be either a string representing the name of the pretrained model
or a path-like object pointing to the location of the model. It is used to identify and locate the pretrained model
that needs to be loaded.</p>
<p>Note: If the loaded configuration belongs to the 'clip' model type, the 'config_dict' will be updated to use the
'vision_config' sub-dictionary. Additionally, if the 'model_type' attribute is present in the 'cls' class and
the loaded configuration's 'model_type' is different from 'cls.model_type', a warning will be logged indicating
that instantiating a model of different types may lead to errors.</p>


<details class="example" open>
  <summary>Example</summary>
  <p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">config</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;clip_model&quot;</span><span class="p">)</span>
<span class="o">...</span>
</code></pre></div>
In the above example, the 'from_pretrained' method is called on the 'CLIPVisionConfig' class to load the pretrained
configuration of the 'clip_model'. The resulting configuration is stored in the 'config' variable.</p>
</details>
            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\configuration_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;PretrainedConfig&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a pretrained configuration from a given model name or path.</span>

<span class="sd">    Args:</span>
<span class="sd">        cls (class): The class object.</span>
<span class="sd">        pretrained_model_name_or_path (Union[str, os.PathLike]): The name or path of the pretrained model.</span>
<span class="sd">            It can be either a string representing the name of the model or a path-like object pointing to the model location.</span>

<span class="sd">    Returns:</span>
<span class="sd">        PretrainedConfig: The loaded pretrained configuration.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>

<span class="sd">    This method is a class method that allows loading a pretrained configuration. It takes in the class object &#39;cls&#39;</span>
<span class="sd">    and the name or path of the pretrained model &#39;pretrained_model_name_or_path&#39; as parameters. The method returns an instance</span>
<span class="sd">    of type &#39;PretrainedConfig&#39;, which represents the loaded pretrained configuration.</span>

<span class="sd">    The &#39;pretrained_model_name_or_path&#39; parameter can be either a string representing the name of the pretrained model</span>
<span class="sd">    or a path-like object pointing to the location of the model. It is used to identify and locate the pretrained model</span>
<span class="sd">    that needs to be loaded.</span>

<span class="sd">    Note: If the loaded configuration belongs to the &#39;clip&#39; model type, the &#39;config_dict&#39; will be updated to use the</span>
<span class="sd">    &#39;vision_config&#39; sub-dictionary. Additionally, if the &#39;model_type&#39; attribute is present in the &#39;cls&#39; class and</span>
<span class="sd">    the loaded configuration&#39;s &#39;model_type&#39; is different from &#39;cls.model_type&#39;, a warning will be logged indicating</span>
<span class="sd">    that instantiating a model of different types may lead to errors.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; config = CLIPVisionConfig.from_pretrained(&quot;clip_model&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        ```</span>
<span class="sd">        In the above example, the &#39;from_pretrained&#39; method is called on the &#39;CLIPVisionConfig&#39; class to load the pretrained</span>
<span class="sd">        configuration of the &#39;clip_model&#39;. The resulting configuration is stored in the &#39;config&#39; variable.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_dict</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">get_config_dict</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># get the vision config dict if we are loading from CLIPConfig</span>
    <span class="k">if</span> <span class="n">config_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;clip&quot;</span><span class="p">:</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;vision_config&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="s2">&quot;model_type&quot;</span> <span class="ow">in</span> <span class="n">config_dict</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s2">&quot;model_type&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config_dict</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;You are using a model of type </span><span class="si">{</span><span class="n">config_dict</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> to instantiate a model of type &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">. This is not supported for all configurations of models and can yield errors.&quot;</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">config_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor</code>


<a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.image_processing_utils.BaseImageProcessor">BaseImageProcessor</span></code></p>


        <p>Constructs a CLIP image processor.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>do_resize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to resize the image's (height, width) dimensions to the specified <code>size</code>. Can be overridden by
<code>do_resize</code> in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>224}<code>):
Size of the image after resizing. The shortest edge of the image is resized to size["shortest_edge"], with
the longest edge resized to keep the input aspect ratio. Can be overridden by</code>size<code>in the</code>preprocess`
method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]` *optional*, defaults to `{&#34;shortest_edge&#34;</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resample</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Resampling filter to use if resizing the image. Can be overridden by <code>resample</code> in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`PILImageResampling`, *optional*, defaults to `Resampling.BICUBIC`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling.BICUBIC">BICUBIC</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_center_crop</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to center crop the image to the specified <code>crop_size</code>. Can be overridden by <code>do_center_crop</code> in the
<code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>crop_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the output image after applying <code>center_crop</code>. Can be overridden by <code>crop_size</code> in the <code>preprocess</code>
method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]` *optional*, defaults to 224</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_rescale</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to rescale the image by the specified scale <code>rescale_factor</code>. Can be overridden by <code>do_rescale</code> in
the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rescale_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Scale factor to use if rescaling the image. Can be overridden by <code>rescale_factor</code> in the <code>preprocess</code>
method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` or `float`, *optional*, defaults to `1/255`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1 / 255</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_normalize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to normalize the image. Can be overridden by <code>do_normalize</code> in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_mean</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Mean to use if normalizing the image. This is a float or list of floats the length of the number of
channels in the image. Can be overridden by the <code>image_mean</code> parameter in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float` or `List[float]`, *optional*, defaults to `[0.48145466, 0.4578275, 0.40821073]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_std</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Standard deviation to use if normalizing the image. This is a float or list of floats the length of the
number of channels in the image. Can be overridden by the <code>image_std</code> parameter in the <code>preprocess</code> method.
Can be overridden by the <code>image_std</code> parameter in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float` or `List[float]`, *optional*, defaults to `[0.26862954, 0.26130258, 0.27577711]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_convert_rgb</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to convert the image to RGB.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\image_processing_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPImageProcessor</span><span class="p">(</span><span class="n">BaseImageProcessor</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs a CLIP image processor.</span>

<span class="sd">    Args:</span>
<span class="sd">        do_resize (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to resize the image&#39;s (height, width) dimensions to the specified `size`. Can be overridden by</span>
<span class="sd">            `do_resize` in the `preprocess` method.</span>
<span class="sd">        size (`Dict[str, int]` *optional*, defaults to `{&quot;shortest_edge&quot;: 224}`):</span>
<span class="sd">            Size of the image after resizing. The shortest edge of the image is resized to size[&quot;shortest_edge&quot;], with</span>
<span class="sd">            the longest edge resized to keep the input aspect ratio. Can be overridden by `size` in the `preprocess`</span>
<span class="sd">            method.</span>
<span class="sd">        resample (`PILImageResampling`, *optional*, defaults to `Resampling.BICUBIC`):</span>
<span class="sd">            Resampling filter to use if resizing the image. Can be overridden by `resample` in the `preprocess` method.</span>
<span class="sd">        do_center_crop (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to center crop the image to the specified `crop_size`. Can be overridden by `do_center_crop` in the</span>
<span class="sd">            `preprocess` method.</span>
<span class="sd">        crop_size (`Dict[str, int]` *optional*, defaults to 224):</span>
<span class="sd">            Size of the output image after applying `center_crop`. Can be overridden by `crop_size` in the `preprocess`</span>
<span class="sd">            method.</span>
<span class="sd">        do_rescale (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to rescale the image by the specified scale `rescale_factor`. Can be overridden by `do_rescale` in</span>
<span class="sd">            the `preprocess` method.</span>
<span class="sd">        rescale_factor (`int` or `float`, *optional*, defaults to `1/255`):</span>
<span class="sd">            Scale factor to use if rescaling the image. Can be overridden by `rescale_factor` in the `preprocess`</span>
<span class="sd">            method.</span>
<span class="sd">        do_normalize (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to normalize the image. Can be overridden by `do_normalize` in the `preprocess` method.</span>
<span class="sd">        image_mean (`float` or `List[float]`, *optional*, defaults to `[0.48145466, 0.4578275, 0.40821073]`):</span>
<span class="sd">            Mean to use if normalizing the image. This is a float or list of floats the length of the number of</span>
<span class="sd">            channels in the image. Can be overridden by the `image_mean` parameter in the `preprocess` method.</span>
<span class="sd">        image_std (`float` or `List[float]`, *optional*, defaults to `[0.26862954, 0.26130258, 0.27577711]`):</span>
<span class="sd">            Standard deviation to use if normalizing the image. This is a float or list of floats the length of the</span>
<span class="sd">            number of channels in the image. Can be overridden by the `image_std` parameter in the `preprocess` method.</span>
<span class="sd">            Can be overridden by the `image_std` parameter in the `preprocess` method.</span>
<span class="sd">        do_convert_rgb (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to convert the image to RGB.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">do_resize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span>
        <span class="n">do_center_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">crop_size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_rescale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">rescale_factor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">255</span><span class="p">,</span>
        <span class="n">do_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a CLIPImageProcessor object.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The CLIPImageProcessor object itself.</span>
<span class="sd">            do_resize (bool): A flag indicating whether to resize the image. Defaults to True.</span>
<span class="sd">            size (Dict[str, int]): A dictionary containing the size of the image. Defaults to None.</span>
<span class="sd">            resample (PILImageResampling): The resampling method for resizing the image. Defaults to PILImageResampling.BICUBIC.</span>
<span class="sd">            do_center_crop (bool): A flag indicating whether to perform center cropping. Defaults to True.</span>
<span class="sd">            crop_size (Dict[str, int]): A dictionary containing the size for cropping. Defaults to None.</span>
<span class="sd">            do_rescale (bool): A flag indicating whether to rescale the image. Defaults to True.</span>
<span class="sd">            rescale_factor (Union[int, float]): The factor by which to rescale the image. Defaults to 1 / 255.</span>
<span class="sd">            do_normalize (bool): A flag indicating whether to normalize the image. Defaults to True.</span>
<span class="sd">            image_mean (Optional[Union[float, List[float]]]): The mean value for image normalization. Defaults to None.</span>
<span class="sd">            image_std (Optional[Union[float, List[float]]]): The standard deviation for image normalization. Defaults to None.</span>
<span class="sd">            do_convert_rgb (bool): A flag indicating whether to convert the image to RGB format. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">size</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">}</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">crop_size</span> <span class="o">=</span> <span class="n">crop_size</span> <span class="k">if</span> <span class="n">crop_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;height&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">}</span>
        <span class="n">crop_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s2">&quot;crop_size&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">do_resize</span> <span class="o">=</span> <span class="n">do_resize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">resample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_center_crop</span> <span class="o">=</span> <span class="n">do_center_crop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span> <span class="o">=</span> <span class="n">crop_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_rescale</span> <span class="o">=</span> <span class="n">do_rescale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_factor</span> <span class="o">=</span> <span class="n">rescale_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_normalize</span> <span class="o">=</span> <span class="n">do_normalize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_mean</span> <span class="o">=</span> <span class="n">image_mean</span> <span class="k">if</span> <span class="n">image_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">OPENAI_CLIP_MEAN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_std</span> <span class="o">=</span> <span class="n">image_std</span> <span class="k">if</span> <span class="n">image_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">OPENAI_CLIP_STD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_convert_rgb</span> <span class="o">=</span> <span class="n">do_convert_rgb</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_valid_processor_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;images&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_resize&quot;</span><span class="p">,</span>
            <span class="s2">&quot;size&quot;</span><span class="p">,</span>
            <span class="s2">&quot;resample&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_center_crop&quot;</span><span class="p">,</span>
            <span class="s2">&quot;crop_size&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_rescale&quot;</span><span class="p">,</span>
            <span class="s2">&quot;rescale_factor&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_normalize&quot;</span><span class="p">,</span>
            <span class="s2">&quot;image_mean&quot;</span><span class="p">,</span>
            <span class="s2">&quot;image_std&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_convert_rgb&quot;</span><span class="p">,</span>
            <span class="s2">&quot;return_tensors&quot;</span><span class="p">,</span>
            <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input_data_format&quot;</span><span class="p">,</span>
        <span class="p">]</span>

        <span class="c1"># for backwards compatibility of KOSMOS-2</span>
        <span class="k">if</span> <span class="s2">&quot;use_square_size&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;height&quot;</span><span class="p">:</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">],</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">]}</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;use_square_size&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">resize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span>
        <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Resize an image. The shortest edge of the image is resized to size[&quot;shortest_edge&quot;], with the longest edge</span>
<span class="sd">        resized to keep the input aspect ratio.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (`np.ndarray`):</span>
<span class="sd">                Image to resize.</span>
<span class="sd">            size (`Dict[str, int]`):</span>
<span class="sd">                Size of the output image.</span>
<span class="sd">            resample (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BICUBIC`):</span>
<span class="sd">                Resampling filter to use when resiizing the image.</span>
<span class="sd">            data_format (`str` or `ChannelDimension`, *optional*):</span>
<span class="sd">                The channel dimension format of the image. If not provided, it will be the same as the input image.</span>
<span class="sd">            input_data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">                The channel dimension format of the input image. If not provided, it will be inferred.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">default_to_square</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="s2">&quot;shortest_edge&quot;</span> <span class="ow">in</span> <span class="n">size</span><span class="p">:</span>
            <span class="n">size</span> <span class="o">=</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">]</span>
            <span class="n">default_to_square</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="s2">&quot;height&quot;</span> <span class="ow">in</span> <span class="n">size</span> <span class="ow">and</span> <span class="s2">&quot;width&quot;</span> <span class="ow">in</span> <span class="n">size</span><span class="p">:</span>
            <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;width&quot;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Size must contain either &#39;shortest_edge&#39; or &#39;height&#39; and &#39;width&#39;.&quot;</span><span class="p">)</span>

        <span class="n">output_size</span> <span class="o">=</span> <span class="n">get_resize_output_image_size</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
            <span class="n">default_to_square</span><span class="o">=</span><span class="n">default_to_square</span><span class="p">,</span>
            <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">resize</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">output_size</span><span class="p">,</span>
            <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
            <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
            <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="n">ImageInput</span><span class="p">,</span>
        <span class="n">do_resize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_center_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">crop_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_rescale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rescale_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ChannelDimension</span><span class="p">]</span> <span class="o">=</span> <span class="n">ChannelDimension</span><span class="o">.</span><span class="n">FIRST</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Preprocess an image or batch of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            images (`ImageInput`):</span>
<span class="sd">                Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If</span>
<span class="sd">                passing in images with pixel values between 0 and 1, set `do_rescale=False`.</span>
<span class="sd">            do_resize (`bool`, *optional*, defaults to `self.do_resize`):</span>
<span class="sd">                Whether to resize the image.</span>
<span class="sd">            size (`Dict[str, int]`, *optional*, defaults to `self.size`):</span>
<span class="sd">                Size of the image after resizing. Shortest edge of the image is resized to size[&quot;shortest_edge&quot;], with</span>
<span class="sd">                the longest edge resized to keep the input aspect ratio.</span>
<span class="sd">            resample (`int`, *optional*, defaults to `self.resample`):</span>
<span class="sd">                Resampling filter to use if resizing the image. This can be one of the enum `PILImageResampling`. Only</span>
<span class="sd">                has an effect if `do_resize` is set to `True`.</span>
<span class="sd">            do_center_crop (`bool`, *optional*, defaults to `self.do_center_crop`):</span>
<span class="sd">                Whether to center crop the image.</span>
<span class="sd">            crop_size (`Dict[str, int]`, *optional*, defaults to `self.crop_size`):</span>
<span class="sd">                Size of the center crop. Only has an effect if `do_center_crop` is set to `True`.</span>
<span class="sd">            do_rescale (`bool`, *optional*, defaults to `self.do_rescale`):</span>
<span class="sd">                Whether to rescale the image.</span>
<span class="sd">            rescale_factor (`float`, *optional*, defaults to `self.rescale_factor`):</span>
<span class="sd">                Rescale factor to rescale the image by if `do_rescale` is set to `True`.</span>
<span class="sd">            do_normalize (`bool`, *optional*, defaults to `self.do_normalize`):</span>
<span class="sd">                Whether to normalize the image.</span>
<span class="sd">            image_mean (`float` or `List[float]`, *optional*, defaults to `self.image_mean`):</span>
<span class="sd">                Image mean to use for normalization. Only has an effect if `do_normalize` is set to `True`.</span>
<span class="sd">            image_std (`float` or `List[float]`, *optional*, defaults to `self.image_std`):</span>
<span class="sd">                Image standard deviation to use for normalization. Only has an effect if `do_normalize` is set to</span>
<span class="sd">                `True`.</span>
<span class="sd">            do_convert_rgb (`bool`, *optional*, defaults to `self.do_convert_rgb`):</span>
<span class="sd">                Whether to convert the image to RGB.</span>
<span class="sd">            return_tensors (`str` or `TensorType`, *optional*):</span>
<span class="sd">                The type of tensors to return. Can be one of:</span>

<span class="sd">                - Unset: Return a list of `np.ndarray`.</span>
<span class="sd">                - `TensorType.TENSORFLOW` or `&#39;tf&#39;`: Return a batch of type `tf.Tensor`.</span>
<span class="sd">                - `TensorType.PYTORCH` or `&#39;pt&#39;`: Return a batch of type `torch.Tensor`.</span>
<span class="sd">                - `TensorType.NUMPY` or `&#39;np&#39;`: Return a batch of type `np.ndarray`.</span>
<span class="sd">                - `TensorType.JAX` or `&#39;jax&#39;`: Return a batch of type `jax.numpy.ndarray`.</span>
<span class="sd">            data_format (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`):</span>
<span class="sd">                The channel dimension format for the output image. Can be one of:</span>

<span class="sd">                - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">                - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">                - Unset: Use the channel dimension format of the input image.</span>
<span class="sd">            input_data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">                The channel dimension format for the input image. If unset, the channel dimension format is inferred</span>
<span class="sd">                from the input image. Can be one of:</span>
<span class="sd">                - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">                - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">                - `&quot;none&quot;` or `ChannelDimension.NONE`: image in (height, width) format.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">do_resize</span> <span class="o">=</span> <span class="n">do_resize</span> <span class="k">if</span> <span class="n">do_resize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_resize</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">size</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">resample</span> <span class="o">=</span> <span class="n">resample</span> <span class="k">if</span> <span class="n">resample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample</span>
        <span class="n">do_center_crop</span> <span class="o">=</span> <span class="n">do_center_crop</span> <span class="k">if</span> <span class="n">do_center_crop</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_center_crop</span>
        <span class="n">crop_size</span> <span class="o">=</span> <span class="n">crop_size</span> <span class="k">if</span> <span class="n">crop_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span>
        <span class="n">crop_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s2">&quot;crop_size&quot;</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">do_rescale</span> <span class="o">=</span> <span class="n">do_rescale</span> <span class="k">if</span> <span class="n">do_rescale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_rescale</span>
        <span class="n">rescale_factor</span> <span class="o">=</span> <span class="n">rescale_factor</span> <span class="k">if</span> <span class="n">rescale_factor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_factor</span>
        <span class="n">do_normalize</span> <span class="o">=</span> <span class="n">do_normalize</span> <span class="k">if</span> <span class="n">do_normalize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_normalize</span>
        <span class="n">image_mean</span> <span class="o">=</span> <span class="n">image_mean</span> <span class="k">if</span> <span class="n">image_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_mean</span>
        <span class="n">image_std</span> <span class="o">=</span> <span class="n">image_std</span> <span class="k">if</span> <span class="n">image_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_std</span>
        <span class="n">do_convert_rgb</span> <span class="o">=</span> <span class="n">do_convert_rgb</span> <span class="k">if</span> <span class="n">do_convert_rgb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_convert_rgb</span>
        <span class="n">validate_kwargs</span><span class="p">(</span><span class="n">captured_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">valid_processor_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_valid_processor_keys</span><span class="p">)</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">make_list_of_images</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_images</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid image type. Must be of type PIL.Image.Image, numpy.ndarray, &quot;</span>
                <span class="s2">&quot;torch.Tensor, tf.Tensor or jax.ndarray.&quot;</span>
            <span class="p">)</span>
        <span class="n">validate_preprocess_arguments</span><span class="p">(</span>
            <span class="n">do_rescale</span><span class="o">=</span><span class="n">do_rescale</span><span class="p">,</span>
            <span class="n">rescale_factor</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span>
            <span class="n">do_normalize</span><span class="o">=</span><span class="n">do_normalize</span><span class="p">,</span>
            <span class="n">image_mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span>
            <span class="n">image_std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span>
            <span class="n">do_center_crop</span><span class="o">=</span><span class="n">do_center_crop</span><span class="p">,</span>
            <span class="n">crop_size</span><span class="o">=</span><span class="n">crop_size</span><span class="p">,</span>
            <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
            <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">do_convert_rgb</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">convert_to_rgb</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">]</span>

        <span class="c1"># All transformations expect numpy arrays.</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_numpy_array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">is_scaled_image</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">and</span> <span class="n">do_rescale</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span>
                <span class="s2">&quot;It looks like you are trying to rescale already rescaled images. If the input&quot;</span>
                <span class="s2">&quot; images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">input_data_format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># We assume that all images have the same channel dimension format.</span>
            <span class="n">input_data_format</span> <span class="o">=</span> <span class="n">infer_channel_dimension_format</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">do_resize</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
            <span class="p">]</span>

        <span class="k">if</span> <span class="n">do_center_crop</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
            <span class="p">]</span>

        <span class="k">if</span> <span class="n">do_rescale</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
            <span class="p">]</span>

        <span class="k">if</span> <span class="n">do_normalize</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
            <span class="p">]</span>

        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">to_channel_dimension_format</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">input_channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
        <span class="p">]</span>

        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">:</span> <span class="n">images</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">BatchFeature</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">tensor_type</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">image_processing_clip</span><span class="o">.</span><span class="n">CLIPImageProcessor</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">do_resize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span> <span class="n">do_center_crop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">crop_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_rescale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rescale_factor</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">255</span><span class="p">,</span> <span class="n">do_normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">image_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_convert_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initializes a CLIPImageProcessor object.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The CLIPImageProcessor object itself.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_resize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A flag indicating whether to resize the image. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A dictionary containing the size of the image. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Dict">Dict</span>[str, int]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resample</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The resampling method for resizing the image. Defaults to PILImageResampling.BICUBIC.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling">PILImageResampling</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling.BICUBIC">BICUBIC</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_center_crop</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A flag indicating whether to perform center cropping. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>crop_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A dictionary containing the size for cropping. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Dict">Dict</span>[str, int]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_rescale</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A flag indicating whether to rescale the image. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rescale_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The factor by which to rescale the image. Defaults to 1 / 255.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[int, float]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1 / 255</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_normalize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A flag indicating whether to normalize the image. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_mean</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The mean value for image normalization. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[float, <span title="typing.List">List</span>[float]]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_std</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The standard deviation for image normalization. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[float, <span title="typing.List">List</span>[float]]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_convert_rgb</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A flag indicating whether to convert the image to RGB format. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code>None</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\image_processing_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">do_resize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span>
    <span class="n">do_center_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">crop_size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_rescale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">rescale_factor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">255</span><span class="p">,</span>
    <span class="n">do_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a CLIPImageProcessor object.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The CLIPImageProcessor object itself.</span>
<span class="sd">        do_resize (bool): A flag indicating whether to resize the image. Defaults to True.</span>
<span class="sd">        size (Dict[str, int]): A dictionary containing the size of the image. Defaults to None.</span>
<span class="sd">        resample (PILImageResampling): The resampling method for resizing the image. Defaults to PILImageResampling.BICUBIC.</span>
<span class="sd">        do_center_crop (bool): A flag indicating whether to perform center cropping. Defaults to True.</span>
<span class="sd">        crop_size (Dict[str, int]): A dictionary containing the size for cropping. Defaults to None.</span>
<span class="sd">        do_rescale (bool): A flag indicating whether to rescale the image. Defaults to True.</span>
<span class="sd">        rescale_factor (Union[int, float]): The factor by which to rescale the image. Defaults to 1 / 255.</span>
<span class="sd">        do_normalize (bool): A flag indicating whether to normalize the image. Defaults to True.</span>
<span class="sd">        image_mean (Optional[Union[float, List[float]]]): The mean value for image normalization. Defaults to None.</span>
<span class="sd">        image_std (Optional[Union[float, List[float]]]): The standard deviation for image normalization. Defaults to None.</span>
<span class="sd">        do_convert_rgb (bool): A flag indicating whether to convert the image to RGB format. Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None specified.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">size</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">}</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">crop_size</span> <span class="o">=</span> <span class="n">crop_size</span> <span class="k">if</span> <span class="n">crop_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;height&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">224</span><span class="p">}</span>
    <span class="n">crop_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s2">&quot;crop_size&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">do_resize</span> <span class="o">=</span> <span class="n">do_resize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">resample</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_center_crop</span> <span class="o">=</span> <span class="n">do_center_crop</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span> <span class="o">=</span> <span class="n">crop_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_rescale</span> <span class="o">=</span> <span class="n">do_rescale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rescale_factor</span> <span class="o">=</span> <span class="n">rescale_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_normalize</span> <span class="o">=</span> <span class="n">do_normalize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_mean</span> <span class="o">=</span> <span class="n">image_mean</span> <span class="k">if</span> <span class="n">image_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">OPENAI_CLIP_MEAN</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_std</span> <span class="o">=</span> <span class="n">image_std</span> <span class="k">if</span> <span class="n">image_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">OPENAI_CLIP_STD</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_convert_rgb</span> <span class="o">=</span> <span class="n">do_convert_rgb</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_valid_processor_keys</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;images&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_resize&quot;</span><span class="p">,</span>
        <span class="s2">&quot;size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;resample&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_center_crop&quot;</span><span class="p">,</span>
        <span class="s2">&quot;crop_size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_rescale&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rescale_factor&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_normalize&quot;</span><span class="p">,</span>
        <span class="s2">&quot;image_mean&quot;</span><span class="p">,</span>
        <span class="s2">&quot;image_std&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_convert_rgb&quot;</span><span class="p">,</span>
        <span class="s2">&quot;return_tensors&quot;</span><span class="p">,</span>
        <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
        <span class="s2">&quot;input_data_format&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="c1"># for backwards compatibility of KOSMOS-2</span>
    <span class="k">if</span> <span class="s2">&quot;use_square_size&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;height&quot;</span><span class="p">:</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">],</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">]}</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;use_square_size&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.preprocess" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">image_processing_clip</span><span class="o">.</span><span class="n">CLIPImageProcessor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">do_resize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_center_crop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">crop_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_rescale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rescale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_convert_rgb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">ChannelDimension</span><span class="o">.</span><span class="n">FIRST</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.preprocess" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Preprocess an image or batch of images.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>images</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If
passing in images with pixel values between 0 and 1, set <code>do_rescale=False</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ImageInput`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_resize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to resize the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_resize`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the image after resizing. Shortest edge of the image is resized to size["shortest_edge"], with
the longest edge resized to keep the input aspect ratio.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`, *optional*, defaults to `self.size`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resample</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Resampling filter to use if resizing the image. This can be one of the enum <code>PILImageResampling</code>. Only
has an effect if <code>do_resize</code> is set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to `self.resample`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_center_crop</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to center crop the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_center_crop`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>crop_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the center crop. Only has an effect if <code>do_center_crop</code> is set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`, *optional*, defaults to `self.crop_size`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_rescale</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to rescale the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_rescale`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rescale_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Rescale factor to rescale the image by if <code>do_rescale</code> is set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to `self.rescale_factor`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_normalize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to normalize the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_normalize`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_mean</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image mean to use for normalization. Only has an effect if <code>do_normalize</code> is set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float` or `List[float]`, *optional*, defaults to `self.image_mean`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_std</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image standard deviation to use for normalization. Only has an effect if <code>do_normalize</code> is set to
<code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float` or `List[float]`, *optional*, defaults to `self.image_std`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_convert_rgb</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to convert the image to RGB.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_convert_rgb`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_tensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The type of tensors to return. Can be one of:</p>
<ul>
<li>Unset: Return a list of <code>np.ndarray</code>.</li>
<li><code>TensorType.TENSORFLOW</code> or <code>'tf'</code>: Return a batch of type <code>tf.Tensor</code>.</li>
<li><code>TensorType.PYTORCH</code> or <code>'pt'</code>: Return a batch of type <code>torch.Tensor</code>.</li>
<li><code>TensorType.NUMPY</code> or <code>'np'</code>: Return a batch of type <code>np.ndarray</code>.</li>
<li><code>TensorType.JAX</code> or <code>'jax'</code>: Return a batch of type <code>jax.numpy.ndarray</code>.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `TensorType`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format for the output image. Can be one of:</p>
<ul>
<li><code>"channels_first"</code> or <code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.</li>
<li><code>"channels_last"</code> or <code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.</li>
<li>Unset: Use the channel dimension format of the input image.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.transformers.image_utils.ChannelDimension.FIRST">FIRST</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format for the input image. If unset, the channel dimension format is inferred
from the input image. Can be one of:
- <code>"channels_first"</code> or <code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.
- <code>"channels_last"</code> or <code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.
- <code>"none"</code> or <code>ChannelDimension.NONE</code>: image in (height, width) format.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ChannelDimension` or `str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\image_processing_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">images</span><span class="p">:</span> <span class="n">ImageInput</span><span class="p">,</span>
    <span class="n">do_resize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_center_crop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">crop_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_rescale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">rescale_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ChannelDimension</span><span class="p">]</span> <span class="o">=</span> <span class="n">ChannelDimension</span><span class="o">.</span><span class="n">FIRST</span><span class="p">,</span>
    <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess an image or batch of images.</span>

<span class="sd">    Args:</span>
<span class="sd">        images (`ImageInput`):</span>
<span class="sd">            Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If</span>
<span class="sd">            passing in images with pixel values between 0 and 1, set `do_rescale=False`.</span>
<span class="sd">        do_resize (`bool`, *optional*, defaults to `self.do_resize`):</span>
<span class="sd">            Whether to resize the image.</span>
<span class="sd">        size (`Dict[str, int]`, *optional*, defaults to `self.size`):</span>
<span class="sd">            Size of the image after resizing. Shortest edge of the image is resized to size[&quot;shortest_edge&quot;], with</span>
<span class="sd">            the longest edge resized to keep the input aspect ratio.</span>
<span class="sd">        resample (`int`, *optional*, defaults to `self.resample`):</span>
<span class="sd">            Resampling filter to use if resizing the image. This can be one of the enum `PILImageResampling`. Only</span>
<span class="sd">            has an effect if `do_resize` is set to `True`.</span>
<span class="sd">        do_center_crop (`bool`, *optional*, defaults to `self.do_center_crop`):</span>
<span class="sd">            Whether to center crop the image.</span>
<span class="sd">        crop_size (`Dict[str, int]`, *optional*, defaults to `self.crop_size`):</span>
<span class="sd">            Size of the center crop. Only has an effect if `do_center_crop` is set to `True`.</span>
<span class="sd">        do_rescale (`bool`, *optional*, defaults to `self.do_rescale`):</span>
<span class="sd">            Whether to rescale the image.</span>
<span class="sd">        rescale_factor (`float`, *optional*, defaults to `self.rescale_factor`):</span>
<span class="sd">            Rescale factor to rescale the image by if `do_rescale` is set to `True`.</span>
<span class="sd">        do_normalize (`bool`, *optional*, defaults to `self.do_normalize`):</span>
<span class="sd">            Whether to normalize the image.</span>
<span class="sd">        image_mean (`float` or `List[float]`, *optional*, defaults to `self.image_mean`):</span>
<span class="sd">            Image mean to use for normalization. Only has an effect if `do_normalize` is set to `True`.</span>
<span class="sd">        image_std (`float` or `List[float]`, *optional*, defaults to `self.image_std`):</span>
<span class="sd">            Image standard deviation to use for normalization. Only has an effect if `do_normalize` is set to</span>
<span class="sd">            `True`.</span>
<span class="sd">        do_convert_rgb (`bool`, *optional*, defaults to `self.do_convert_rgb`):</span>
<span class="sd">            Whether to convert the image to RGB.</span>
<span class="sd">        return_tensors (`str` or `TensorType`, *optional*):</span>
<span class="sd">            The type of tensors to return. Can be one of:</span>

<span class="sd">            - Unset: Return a list of `np.ndarray`.</span>
<span class="sd">            - `TensorType.TENSORFLOW` or `&#39;tf&#39;`: Return a batch of type `tf.Tensor`.</span>
<span class="sd">            - `TensorType.PYTORCH` or `&#39;pt&#39;`: Return a batch of type `torch.Tensor`.</span>
<span class="sd">            - `TensorType.NUMPY` or `&#39;np&#39;`: Return a batch of type `np.ndarray`.</span>
<span class="sd">            - `TensorType.JAX` or `&#39;jax&#39;`: Return a batch of type `jax.numpy.ndarray`.</span>
<span class="sd">        data_format (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`):</span>
<span class="sd">            The channel dimension format for the output image. Can be one of:</span>

<span class="sd">            - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">            - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">            - Unset: Use the channel dimension format of the input image.</span>
<span class="sd">        input_data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">            The channel dimension format for the input image. If unset, the channel dimension format is inferred</span>
<span class="sd">            from the input image. Can be one of:</span>
<span class="sd">            - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">            - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">            - `&quot;none&quot;` or `ChannelDimension.NONE`: image in (height, width) format.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">do_resize</span> <span class="o">=</span> <span class="n">do_resize</span> <span class="k">if</span> <span class="n">do_resize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_resize</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">size</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">resample</span> <span class="o">=</span> <span class="n">resample</span> <span class="k">if</span> <span class="n">resample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample</span>
    <span class="n">do_center_crop</span> <span class="o">=</span> <span class="n">do_center_crop</span> <span class="k">if</span> <span class="n">do_center_crop</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_center_crop</span>
    <span class="n">crop_size</span> <span class="o">=</span> <span class="n">crop_size</span> <span class="k">if</span> <span class="n">crop_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span>
    <span class="n">crop_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s2">&quot;crop_size&quot;</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">do_rescale</span> <span class="o">=</span> <span class="n">do_rescale</span> <span class="k">if</span> <span class="n">do_rescale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_rescale</span>
    <span class="n">rescale_factor</span> <span class="o">=</span> <span class="n">rescale_factor</span> <span class="k">if</span> <span class="n">rescale_factor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_factor</span>
    <span class="n">do_normalize</span> <span class="o">=</span> <span class="n">do_normalize</span> <span class="k">if</span> <span class="n">do_normalize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_normalize</span>
    <span class="n">image_mean</span> <span class="o">=</span> <span class="n">image_mean</span> <span class="k">if</span> <span class="n">image_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_mean</span>
    <span class="n">image_std</span> <span class="o">=</span> <span class="n">image_std</span> <span class="k">if</span> <span class="n">image_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_std</span>
    <span class="n">do_convert_rgb</span> <span class="o">=</span> <span class="n">do_convert_rgb</span> <span class="k">if</span> <span class="n">do_convert_rgb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_convert_rgb</span>
    <span class="n">validate_kwargs</span><span class="p">(</span><span class="n">captured_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">valid_processor_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_valid_processor_keys</span><span class="p">)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">make_list_of_images</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_images</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Invalid image type. Must be of type PIL.Image.Image, numpy.ndarray, &quot;</span>
            <span class="s2">&quot;torch.Tensor, tf.Tensor or jax.ndarray.&quot;</span>
        <span class="p">)</span>
    <span class="n">validate_preprocess_arguments</span><span class="p">(</span>
        <span class="n">do_rescale</span><span class="o">=</span><span class="n">do_rescale</span><span class="p">,</span>
        <span class="n">rescale_factor</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span>
        <span class="n">do_normalize</span><span class="o">=</span><span class="n">do_normalize</span><span class="p">,</span>
        <span class="n">image_mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span>
        <span class="n">image_std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span>
        <span class="n">do_center_crop</span><span class="o">=</span><span class="n">do_center_crop</span><span class="p">,</span>
        <span class="n">crop_size</span><span class="o">=</span><span class="n">crop_size</span><span class="p">,</span>
        <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
        <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">do_convert_rgb</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">convert_to_rgb</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">]</span>

    <span class="c1"># All transformations expect numpy arrays.</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_numpy_array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">is_scaled_image</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">and</span> <span class="n">do_rescale</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span>
            <span class="s2">&quot;It looks like you are trying to rescale already rescaled images. If the input&quot;</span>
            <span class="s2">&quot; images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">input_data_format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We assume that all images have the same channel dimension format.</span>
        <span class="n">input_data_format</span> <span class="o">=</span> <span class="n">infer_channel_dimension_format</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">do_resize</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
        <span class="p">]</span>

    <span class="k">if</span> <span class="n">do_center_crop</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
        <span class="p">]</span>

    <span class="k">if</span> <span class="n">do_rescale</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
        <span class="p">]</span>

    <span class="k">if</span> <span class="n">do_normalize</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
        <span class="p">]</span>

    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">to_channel_dimension_format</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">input_channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
    <span class="p">]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">:</span> <span class="n">images</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">BatchFeature</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">tensor_type</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.resize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">image_processing_clip</span><span class="o">.</span><span class="n">CLIPImageProcessor</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.image_processing_clip.CLIPImageProcessor.resize" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Resize an image. The shortest edge of the image is resized to size["shortest_edge"], with the longest edge
resized to keep the input aspect ratio.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image to resize.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.ndarray`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the output image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resample</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Resampling filter to use when resiizing the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`PILImageResampling`, *optional*, defaults to `PILImageResampling.BICUBIC`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling.BICUBIC">BICUBIC</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format of the image. If not provided, it will be the same as the input image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `ChannelDimension`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format of the input image. If not provided, it will be inferred.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ChannelDimension` or `str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\image_processing_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">resize</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span>
    <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resize an image. The shortest edge of the image is resized to size[&quot;shortest_edge&quot;], with the longest edge</span>
<span class="sd">    resized to keep the input aspect ratio.</span>

<span class="sd">    Args:</span>
<span class="sd">        image (`np.ndarray`):</span>
<span class="sd">            Image to resize.</span>
<span class="sd">        size (`Dict[str, int]`):</span>
<span class="sd">            Size of the output image.</span>
<span class="sd">        resample (`PILImageResampling`, *optional*, defaults to `PILImageResampling.BICUBIC`):</span>
<span class="sd">            Resampling filter to use when resiizing the image.</span>
<span class="sd">        data_format (`str` or `ChannelDimension`, *optional*):</span>
<span class="sd">            The channel dimension format of the image. If not provided, it will be the same as the input image.</span>
<span class="sd">        input_data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">            The channel dimension format of the input image. If not provided, it will be inferred.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">default_to_square</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="s2">&quot;shortest_edge&quot;</span> <span class="ow">in</span> <span class="n">size</span><span class="p">:</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">]</span>
        <span class="n">default_to_square</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="s2">&quot;height&quot;</span> <span class="ow">in</span> <span class="n">size</span> <span class="ow">and</span> <span class="s2">&quot;width&quot;</span> <span class="ow">in</span> <span class="n">size</span><span class="p">:</span>
        <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;width&quot;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Size must contain either &#39;shortest_edge&#39; or &#39;height&#39; and &#39;width&#39;.&quot;</span><span class="p">)</span>

    <span class="n">output_size</span> <span class="o">=</span> <span class="n">get_resize_output_image_size</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
        <span class="n">default_to_square</span><span class="o">=</span><span class="n">default_to_square</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">resize</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="n">output_size</span><span class="p">,</span>
        <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.modeling_clip.CLIPModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.modeling_clip.CLIPModel</code>


<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel">CLIPPreTrainedModel</a></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPModel</span><span class="p">(</span><span class="n">CLIPPreTrainedModel</span><span class="p">):</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">CLIPConfig</span>
    <span class="n">_no_split_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;CLIPTextEmbeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;CLIPEncoderLayer&quot;</span><span class="p">,</span> <span class="s2">&quot;CLIPVisionEmbeddings&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CLIPConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">text_config</span><span class="p">,</span> <span class="n">CLIPTextConfig</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;config.text_config is expected to be of type CLIPTextConfig but is of type&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">text_config</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vision_config</span><span class="p">,</span> <span class="n">CLIPVisionConfig</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;config.vision_config is expected to be of type CLIPVisionConfig but is of type&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vision_config</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="n">text_config</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">text_config</span>
        <span class="n">vision_config</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">vision_config</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">projection_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_embed_dim</span> <span class="o">=</span> <span class="n">text_config</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_embed_dim</span> <span class="o">=</span> <span class="n">vision_config</span><span class="o">.</span><span class="n">hidden_size</span>

        <span class="n">text_model</span> <span class="o">=</span> <span class="n">CLIPTextModel</span><span class="o">.</span><span class="n">_from_config</span><span class="p">(</span><span class="n">text_config</span><span class="p">,</span> <span class="n">attn_implementation</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span> <span class="o">=</span> <span class="n">text_model</span><span class="o">.</span><span class="n">text_model</span>

        <span class="n">vision_model</span> <span class="o">=</span> <span class="n">CLIPVisionModel</span><span class="o">.</span><span class="n">_from_config</span><span class="p">(</span><span class="n">vision_config</span><span class="p">,</span> <span class="n">attn_implementation</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span> <span class="o">=</span> <span class="n">vision_model</span><span class="o">.</span><span class="n">vision_model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">visual_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vision_embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logit_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">logit_scale_init_value</span><span class="p">))</span>

        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_text_features</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns:</span>
<span class="sd">            text_features (`mindspore.Tensor` of shape `(batch_size, output_dim`): The text embeddings obtained by</span>
<span class="sd">            applying the projection layer to the pooled output of [`CLIPTextModel`].</span>

<span class="sd">        Examples:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer, CLIPModel</span>

<span class="sd">        &gt;&gt;&gt; model = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">        &gt;&gt;&gt; inputs = tokenizer([&quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;], padding=True, return_tensors=&quot;ms&quot;)</span>
<span class="sd">        &gt;&gt;&gt; text_features = model.get_text_features(**inputs)</span>
<span class="sd">        ```&quot;&quot;&quot;</span>
        <span class="c1"># Use CLIP model&#39;s config for some fields (if specified) instead of those of vision &amp; text components.</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="n">text_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">text_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">text_features</span>

    <span class="k">def</span> <span class="nf">get_image_features</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns:</span>
<span class="sd">            image_features (`mindspore.Tensor` of shape `(batch_size, output_dim`): The image embeddings obtained by</span>
<span class="sd">            applying the projection layer to the pooled output of [`CLIPVisionModel`].</span>

<span class="sd">        Examples:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">        &gt;&gt;&gt; import requests</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoProcessor, CLIPModel</span>

<span class="sd">        &gt;&gt;&gt; model = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">        &gt;&gt;&gt; url = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="sd">        &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)</span>

<span class="sd">        &gt;&gt;&gt; inputs = processor(images=image, return_tensors=&quot;ms&quot;)</span>

<span class="sd">        &gt;&gt;&gt; image_features = model.get_image_features(**inputs)</span>
<span class="sd">        ```&quot;&quot;&quot;</span>
        <span class="c1"># Use CLIP model&#39;s config for some fields (if specified) instead of those of vision &amp; text components.</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
            <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pooled_output</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visual_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">image_features</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">CLIPOutput</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns:</span>

<span class="sd">        Examples:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">        &gt;&gt;&gt; import requests</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoProcessor, CLIPModel</span>

<span class="sd">        &gt;&gt;&gt; model = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">        &gt;&gt;&gt; url = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="sd">        &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)</span>

<span class="sd">        &gt;&gt;&gt; inputs = processor(</span>
<span class="sd">        ...     text=[&quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;], images=image, return_tensors=&quot;ms&quot;, padding=True</span>
<span class="sd">        ... )</span>

<span class="sd">        &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">        &gt;&gt;&gt; logits_per_image = outputs.logits_per_image  # this is the image-text similarity score</span>
<span class="sd">        &gt;&gt;&gt; probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities</span>
<span class="sd">        ```&quot;&quot;&quot;</span>
        <span class="c1"># Use CLIP model&#39;s config for some fields (if specified) instead of those of vision &amp; text components.</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
            <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">text_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">image_embeds</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">image_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visual_projection</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">)</span>

        <span class="n">text_embeds</span> <span class="o">=</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">)</span>

        <span class="c1"># normalized features</span>
        <span class="n">image_embeds</span> <span class="o">=</span> <span class="n">image_embeds</span> <span class="o">/</span> <span class="n">ops</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">text_embeds</span> <span class="o">=</span> <span class="n">text_embeds</span> <span class="o">/</span> <span class="n">ops</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># cosine similarity as logits</span>
        <span class="n">logit_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_scale</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
        <span class="n">logits_per_text</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">,</span> <span class="n">image_embeds</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="o">*</span> <span class="n">logit_scale</span>
        <span class="n">logits_per_image</span> <span class="o">=</span> <span class="n">logits_per_text</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">return_loss</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">clip_loss</span><span class="p">(</span><span class="n">logits_per_text</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits_per_image</span><span class="p">,</span> <span class="n">logits_per_text</span><span class="p">,</span> <span class="n">text_embeds</span><span class="p">,</span> <span class="n">image_embeds</span><span class="p">,</span> <span class="n">text_outputs</span><span class="p">,</span> <span class="n">vision_outputs</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">((</span><span class="n">loss</span><span class="p">,)</span> <span class="o">+</span> <span class="n">output</span><span class="p">)</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span>

        <span class="k">return</span> <span class="n">CLIPOutput</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">logits_per_image</span><span class="o">=</span><span class="n">logits_per_image</span><span class="p">,</span>
            <span class="n">logits_per_text</span><span class="o">=</span><span class="n">logits_per_text</span><span class="p">,</span>
            <span class="n">text_embeds</span><span class="o">=</span><span class="n">text_embeds</span><span class="p">,</span>
            <span class="n">image_embeds</span><span class="o">=</span><span class="n">image_embeds</span><span class="p">,</span>
            <span class="n">text_model_output</span><span class="o">=</span><span class="n">text_outputs</span><span class="p">,</span>
            <span class="n">vision_model_output</span><span class="o">=</span><span class="n">vision_outputs</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.modeling_clip.CLIPModel.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">modeling_clip</span><span class="o">.</span><span class="n">CLIPModel</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pixel_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Examples:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">requests</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">CLIPModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">text</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a photo of a cat&quot;</span><span class="p">,</span> <span class="s2">&quot;a photo of a dog&quot;</span><span class="p">],</span> <span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span>
<span class="o">...</span> <span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">logits_per_image</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits_per_image</span>  <span class="c1"># this is the image-text similarity score</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">logits_per_image</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># we can take the softmax to get the label probabilities</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">CLIPOutput</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>

<span class="sd">    Examples:</span>

<span class="sd">    ```python</span>
<span class="sd">    &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">    &gt;&gt;&gt; import requests</span>
<span class="sd">    &gt;&gt;&gt; from transformers import AutoProcessor, CLIPModel</span>

<span class="sd">    &gt;&gt;&gt; model = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">    &gt;&gt;&gt; url = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="sd">    &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)</span>

<span class="sd">    &gt;&gt;&gt; inputs = processor(</span>
<span class="sd">    ...     text=[&quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;], images=image, return_tensors=&quot;ms&quot;, padding=True</span>
<span class="sd">    ... )</span>

<span class="sd">    &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">    &gt;&gt;&gt; logits_per_image = outputs.logits_per_image  # this is the image-text similarity score</span>
<span class="sd">    &gt;&gt;&gt; probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities</span>
<span class="sd">    ```&quot;&quot;&quot;</span>
    <span class="c1"># Use CLIP model&#39;s config for some fields (if specified) instead of those of vision &amp; text components.</span>
    <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
    <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
    <span class="p">)</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
        <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">text_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">image_embeds</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">image_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visual_projection</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">)</span>

    <span class="n">text_embeds</span> <span class="o">=</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">)</span>

    <span class="c1"># normalized features</span>
    <span class="n">image_embeds</span> <span class="o">=</span> <span class="n">image_embeds</span> <span class="o">/</span> <span class="n">ops</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">text_embeds</span> <span class="o">=</span> <span class="n">text_embeds</span> <span class="o">/</span> <span class="n">ops</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># cosine similarity as logits</span>
    <span class="n">logit_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_scale</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="n">logits_per_text</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">,</span> <span class="n">image_embeds</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="o">*</span> <span class="n">logit_scale</span>
    <span class="n">logits_per_image</span> <span class="o">=</span> <span class="n">logits_per_text</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">return_loss</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">clip_loss</span><span class="p">(</span><span class="n">logits_per_text</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits_per_image</span><span class="p">,</span> <span class="n">logits_per_text</span><span class="p">,</span> <span class="n">text_embeds</span><span class="p">,</span> <span class="n">image_embeds</span><span class="p">,</span> <span class="n">text_outputs</span><span class="p">,</span> <span class="n">vision_outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">loss</span><span class="p">,)</span> <span class="o">+</span> <span class="n">output</span><span class="p">)</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span>

    <span class="k">return</span> <span class="n">CLIPOutput</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">logits_per_image</span><span class="o">=</span><span class="n">logits_per_image</span><span class="p">,</span>
        <span class="n">logits_per_text</span><span class="o">=</span><span class="n">logits_per_text</span><span class="p">,</span>
        <span class="n">text_embeds</span><span class="o">=</span><span class="n">text_embeds</span><span class="p">,</span>
        <span class="n">image_embeds</span><span class="o">=</span><span class="n">image_embeds</span><span class="p">,</span>
        <span class="n">text_model_output</span><span class="o">=</span><span class="n">text_outputs</span><span class="p">,</span>
        <span class="n">vision_model_output</span><span class="o">=</span><span class="n">vision_outputs</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.modeling_clip.CLIPModel.get_image_features" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">modeling_clip</span><span class="o">.</span><span class="n">CLIPModel</span><span class="o">.</span><span class="n">get_image_features</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.get_image_features" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">



<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image_features</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>The image embeddings obtained by</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, output_dim`</code>
                  </span>
                </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindspore.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>applying the projection layer to the pooled output of [<code>CLIPVisionModel</code>].</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">requests</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">CLIPModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">image_features</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_image_features</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_image_features</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>
<span class="sd">        image_features (`mindspore.Tensor` of shape `(batch_size, output_dim`): The image embeddings obtained by</span>
<span class="sd">        applying the projection layer to the pooled output of [`CLIPVisionModel`].</span>

<span class="sd">    Examples:</span>

<span class="sd">    ```python</span>
<span class="sd">    &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">    &gt;&gt;&gt; import requests</span>
<span class="sd">    &gt;&gt;&gt; from transformers import AutoProcessor, CLIPModel</span>

<span class="sd">    &gt;&gt;&gt; model = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">    &gt;&gt;&gt; url = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="sd">    &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)</span>

<span class="sd">    &gt;&gt;&gt; inputs = processor(images=image, return_tensors=&quot;ms&quot;)</span>

<span class="sd">    &gt;&gt;&gt; image_features = model.get_image_features(**inputs)</span>
<span class="sd">    ```&quot;&quot;&quot;</span>
    <span class="c1"># Use CLIP model&#39;s config for some fields (if specified) instead of those of vision &amp; text components.</span>
    <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
    <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
    <span class="p">)</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
        <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pooled_output</span>
    <span class="n">image_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visual_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">image_features</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.modeling_clip.CLIPModel.get_text_features" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">modeling_clip</span><span class="o">.</span><span class="n">CLIPModel</span><span class="o">.</span><span class="n">get_text_features</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPModel.get_text_features" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">



<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>text_features</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>The text embeddings obtained by</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, output_dim`</code>
                  </span>
                </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindspore.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>applying the projection layer to the pooled output of [<code>CLIPTextModel</code>].</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">CLIPModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="s2">&quot;a photo of a cat&quot;</span><span class="p">,</span> <span class="s2">&quot;a photo of a dog&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text_features</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_text_features</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_text_features</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>
<span class="sd">        text_features (`mindspore.Tensor` of shape `(batch_size, output_dim`): The text embeddings obtained by</span>
<span class="sd">        applying the projection layer to the pooled output of [`CLIPTextModel`].</span>

<span class="sd">    Examples:</span>

<span class="sd">    ```python</span>
<span class="sd">    &gt;&gt;&gt; from transformers import AutoTokenizer, CLIPModel</span>

<span class="sd">    &gt;&gt;&gt; model = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">    &gt;&gt;&gt; inputs = tokenizer([&quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;], padding=True, return_tensors=&quot;ms&quot;)</span>
<span class="sd">    &gt;&gt;&gt; text_features = model.get_text_features(**inputs)</span>
<span class="sd">    ```&quot;&quot;&quot;</span>
    <span class="c1"># Use CLIP model&#39;s config for some fields (if specified) instead of those of vision &amp; text components.</span>
    <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
    <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
    <span class="p">)</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="n">text_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">text_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">text_features</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel</code>


<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.modeling_utils.PreTrainedModel" href="../../modeling_utils/#mindnlp.transformers.modeling_utils.PreTrainedModel">PreTrainedModel</a></code></p>


        <p>An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained
models.</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPPreTrainedModel</span><span class="p">(</span><span class="n">PreTrainedModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained</span>
<span class="sd">    models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">config_class</span> <span class="o">=</span> <span class="n">CLIPConfig</span>
    <span class="n">base_model_prefix</span> <span class="o">=</span> <span class="s2">&quot;clip&quot;</span>
    <span class="n">supports_gradient_checkpointing</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">_supports_sdpa</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">_supports_flash_attn_2</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the weights&quot;&quot;&quot;</span>
        <span class="n">factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">CLIPTextEmbeddings</span><span class="p">):</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">token_embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">factor</span> <span class="o">*</span> <span class="mf">0.02</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">position_embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">factor</span> <span class="o">*</span> <span class="mf">0.02</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">CLIPVisionEmbeddings</span><span class="p">):</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">class_embedding</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">module</span><span class="o">.</span><span class="n">embed_dim</span><span class="o">**-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">factor</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">patch_embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">module</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">*</span> <span class="n">factor</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">position_embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">module</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">*</span> <span class="n">factor</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">CLIPAttention</span><span class="p">):</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span>
            <span class="n">in_proj_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">embed_dim</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">module</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
            <span class="n">out_proj_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">embed_dim</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">q_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">in_proj_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">k_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">in_proj_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">v_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">in_proj_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">out_proj_std</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">CLIPMLP</span><span class="p">):</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span>
            <span class="n">in_proj_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">module</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">factor</span>
            <span class="n">fc_std</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">module</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">factor</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">fc_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">in_proj_std</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">CLIPModel</span><span class="p">):</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span>
                <span class="n">module</span><span class="o">.</span><span class="n">text_projection</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
                <span class="n">std</span><span class="o">=</span><span class="n">module</span><span class="o">.</span><span class="n">text_embed_dim</span><span class="o">**-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span>
                <span class="n">module</span><span class="o">.</span><span class="n">visual_projection</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
                <span class="n">std</span><span class="o">=</span><span class="n">module</span><span class="o">.</span><span class="n">vision_embed_dim</span><span class="o">**-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">CLIPVisionModelWithProjection</span><span class="p">):</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span>
                <span class="n">module</span><span class="o">.</span><span class="n">visual_projection</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
                <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">**-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">CLIPTextModelWithProjection</span><span class="p">):</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span>
                <span class="n">module</span><span class="o">.</span><span class="n">text_projection</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
                <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">**-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">CLIPForImageClassification</span><span class="p">):</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span>
                <span class="n">module</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
                <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vision_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="o">**-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initializer_factor</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">ones_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel</code>


<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel">CLIPPreTrainedModel</a></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPTextModel</span><span class="p">(</span><span class="n">CLIPPreTrainedModel</span><span class="p">):</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">CLIPTextConfig</span>

    <span class="n">_no_split_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;CLIPTextEmbeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;CLIPEncoderLayer&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CLIPTextConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span> <span class="o">=</span> <span class="n">CLIPTextTransformer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">token_embedding</span>

    <span class="k">def</span> <span class="nf">set_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">BaseModelOutputWithPooling</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns:</span>

<span class="sd">        Examples:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer, CLIPTextModel</span>

<span class="sd">        &gt;&gt;&gt; model = CLIPTextModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">        &gt;&gt;&gt; inputs = tokenizer([&quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;], padding=True, return_tensors=&quot;ms&quot;)</span>

<span class="sd">        &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">        &gt;&gt;&gt; last_hidden_state = outputs.last_hidden_state</span>
<span class="sd">        &gt;&gt;&gt; pooled_output = outputs.pooler_output  # pooled (EOS token) states</span>
<span class="sd">        ```&quot;&quot;&quot;</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">modeling_clip</span><span class="o">.</span><span class="n">CLIPTextModel</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModel.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Examples:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">CLIPTextModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPTextModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="s2">&quot;a photo of a cat&quot;</span><span class="p">,</span> <span class="s2">&quot;a photo of a dog&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">pooler_output</span>  <span class="c1"># pooled (EOS token) states</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">BaseModelOutputWithPooling</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>

<span class="sd">    Examples:</span>

<span class="sd">    ```python</span>
<span class="sd">    &gt;&gt;&gt; from transformers import AutoTokenizer, CLIPTextModel</span>

<span class="sd">    &gt;&gt;&gt; model = CLIPTextModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">    &gt;&gt;&gt; inputs = tokenizer([&quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;], padding=True, return_tensors=&quot;ms&quot;)</span>

<span class="sd">    &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">    &gt;&gt;&gt; last_hidden_state = outputs.last_hidden_state</span>
<span class="sd">    &gt;&gt;&gt; pooled_output = outputs.pooler_output  # pooled (EOS token) states</span>
<span class="sd">    ```&quot;&quot;&quot;</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection</code>


<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel">CLIPPreTrainedModel</a></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPTextModelWithProjection</span><span class="p">(</span><span class="n">CLIPPreTrainedModel</span><span class="p">):</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">CLIPTextConfig</span>

    <span class="n">_no_split_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;CLIPTextEmbeddings&quot;</span><span class="p">,</span> <span class="s2">&quot;CLIPEncoderLayer&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CLIPTextConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="n">text_model</span> <span class="o">=</span> <span class="n">CLIPTextModel</span><span class="o">.</span><span class="n">_from_config</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">attn_implementation</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span> <span class="o">=</span> <span class="n">text_model</span><span class="o">.</span><span class="n">text_model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">token_embedding</span>

    <span class="k">def</span> <span class="nf">set_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">CLIPTextModelOutput</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns:</span>

<span class="sd">        Examples:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoTokenizer, CLIPTextModelWithProjection</span>

<span class="sd">        &gt;&gt;&gt; model = CLIPTextModelWithProjection.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">        &gt;&gt;&gt; inputs = tokenizer([&quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;], padding=True, return_tensors=&quot;ms&quot;)</span>

<span class="sd">        &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">        &gt;&gt;&gt; text_embeds = outputs.text_embeds</span>
<span class="sd">        ```&quot;&quot;&quot;</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="n">text_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">text_embeds</span><span class="p">,</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">CLIPTextModelOutput</span><span class="p">(</span>
            <span class="n">text_embeds</span><span class="o">=</span><span class="n">text_embeds</span><span class="p">,</span>
            <span class="n">last_hidden_state</span><span class="o">=</span><span class="n">text_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">text_outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">text_outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">modeling_clip</span><span class="o">.</span><span class="n">CLIPTextModelWithProjection</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPTextModelWithProjection.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Examples:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">CLIPTextModelWithProjection</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPTextModelWithProjection</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="s2">&quot;a photo of a cat&quot;</span><span class="p">,</span> <span class="s2">&quot;a photo of a dog&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">text_embeds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">text_embeds</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">CLIPTextModelOutput</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>

<span class="sd">    Examples:</span>

<span class="sd">    ```python</span>
<span class="sd">    &gt;&gt;&gt; from transformers import AutoTokenizer, CLIPTextModelWithProjection</span>

<span class="sd">    &gt;&gt;&gt; model = CLIPTextModelWithProjection.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">    &gt;&gt;&gt; inputs = tokenizer([&quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;], padding=True, return_tensors=&quot;ms&quot;)</span>

<span class="sd">    &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">    &gt;&gt;&gt; text_embeds = outputs.text_embeds</span>
<span class="sd">    ```&quot;&quot;&quot;</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="n">text_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_model</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">text_embeds</span><span class="p">,</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">text_outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">CLIPTextModelOutput</span><span class="p">(</span>
        <span class="n">text_embeds</span><span class="o">=</span><span class="n">text_embeds</span><span class="p">,</span>
        <span class="n">last_hidden_state</span><span class="o">=</span><span class="n">text_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span>
        <span class="n">hidden_states</span><span class="o">=</span><span class="n">text_outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
        <span class="n">attentions</span><span class="o">=</span><span class="n">text_outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel</code>


<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel">CLIPPreTrainedModel</a></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPVisionModel</span><span class="p">(</span><span class="n">CLIPPreTrainedModel</span><span class="p">):</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span>
    <span class="n">main_input_name</span> <span class="o">=</span> <span class="s2">&quot;pixel_values&quot;</span>
    <span class="n">_no_split_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;CLIPEncoderLayer&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CLIPVisionConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span> <span class="o">=</span> <span class="n">CLIPVisionTransformer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">patch_embedding</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">BaseModelOutputWithPooling</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns:</span>

<span class="sd">        Examples:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">        &gt;&gt;&gt; import requests</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoProcessor, CLIPVisionModel</span>

<span class="sd">        &gt;&gt;&gt; model = CLIPVisionModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">        &gt;&gt;&gt; url = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="sd">        &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)</span>

<span class="sd">        &gt;&gt;&gt; inputs = processor(images=image, return_tensors=&quot;ms&quot;)</span>

<span class="sd">        &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">        &gt;&gt;&gt; last_hidden_state = outputs.last_hidden_state</span>
<span class="sd">        &gt;&gt;&gt; pooled_output = outputs.pooler_output  # pooled CLS states</span>
<span class="sd">        ```&quot;&quot;&quot;</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
            <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">modeling_clip</span><span class="o">.</span><span class="n">CLIPVisionModel</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModel.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Examples:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">requests</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">CLIPVisionModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPVisionModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">pooler_output</span>  <span class="c1"># pooled CLS states</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">BaseModelOutputWithPooling</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>

<span class="sd">    Examples:</span>

<span class="sd">    ```python</span>
<span class="sd">    &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">    &gt;&gt;&gt; import requests</span>
<span class="sd">    &gt;&gt;&gt; from transformers import AutoProcessor, CLIPVisionModel</span>

<span class="sd">    &gt;&gt;&gt; model = CLIPVisionModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">    &gt;&gt;&gt; url = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="sd">    &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)</span>

<span class="sd">    &gt;&gt;&gt; inputs = processor(images=image, return_tensors=&quot;ms&quot;)</span>

<span class="sd">    &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">    &gt;&gt;&gt; last_hidden_state = outputs.last_hidden_state</span>
<span class="sd">    &gt;&gt;&gt; pooled_output = outputs.pooler_output  # pooled CLS states</span>
<span class="sd">    ```&quot;&quot;&quot;</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
        <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection</code>


<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel">CLIPPreTrainedModel</a></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPVisionModelWithProjection</span><span class="p">(</span><span class="n">CLIPPreTrainedModel</span><span class="p">):</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">CLIPVisionConfig</span>
    <span class="n">main_input_name</span> <span class="o">=</span> <span class="s2">&quot;pixel_values&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CLIPVisionConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="n">vision_model</span> <span class="o">=</span> <span class="n">CLIPVisionModel</span><span class="o">.</span><span class="n">_from_config</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">attn_implementation</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span> <span class="o">=</span> <span class="n">vision_model</span><span class="o">.</span><span class="n">vision_model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">visual_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">patch_embedding</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">CLIPVisionModelOutput</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns:</span>

<span class="sd">        Examples:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">        &gt;&gt;&gt; import requests</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoProcessor, CLIPVisionModelWithProjection</span>

<span class="sd">        &gt;&gt;&gt; model = CLIPVisionModelWithProjection.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">        &gt;&gt;&gt; url = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="sd">        &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)</span>

<span class="sd">        &gt;&gt;&gt; inputs = processor(images=image, return_tensors=&quot;ms&quot;)</span>

<span class="sd">        &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">        &gt;&gt;&gt; image_embeds = outputs.image_embeds</span>
<span class="sd">        ```&quot;&quot;&quot;</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
            <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pooled_output</span>

        <span class="n">image_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visual_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">CLIPVisionModelOutput</span><span class="p">(</span>
            <span class="n">image_embeds</span><span class="o">=</span><span class="n">image_embeds</span><span class="p">,</span>
            <span class="n">last_hidden_state</span><span class="o">=</span><span class="n">vision_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">vision_outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">vision_outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">modeling_clip</span><span class="o">.</span><span class="n">CLIPVisionModelWithProjection</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPVisionModelWithProjection.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Examples:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">requests</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoProcessor</span><span class="p">,</span> <span class="n">CLIPVisionModelWithProjection</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">CLIPVisionModelWithProjection</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-base-patch32&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">image_embeds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">image_embeds</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">CLIPVisionModelOutput</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>

<span class="sd">    Examples:</span>

<span class="sd">    ```python</span>
<span class="sd">    &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">    &gt;&gt;&gt; import requests</span>
<span class="sd">    &gt;&gt;&gt; from transformers import AutoProcessor, CLIPVisionModelWithProjection</span>

<span class="sd">    &gt;&gt;&gt; model = CLIPVisionModelWithProjection.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)</span>

<span class="sd">    &gt;&gt;&gt; url = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="sd">    &gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)</span>

<span class="sd">    &gt;&gt;&gt; inputs = processor(images=image, return_tensors=&quot;ms&quot;)</span>

<span class="sd">    &gt;&gt;&gt; outputs = model(**inputs)</span>
<span class="sd">    &gt;&gt;&gt; image_embeds = outputs.image_embeds</span>
<span class="sd">    ```&quot;&quot;&quot;</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
        <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">pooled_output</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># pooled_output</span>

    <span class="n">image_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">visual_projection</span><span class="p">(</span><span class="n">pooled_output</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_embeds</span><span class="p">,</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span> <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">CLIPVisionModelOutput</span><span class="p">(</span>
        <span class="n">image_embeds</span><span class="o">=</span><span class="n">image_embeds</span><span class="p">,</span>
        <span class="n">last_hidden_state</span><span class="o">=</span><span class="n">vision_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span>
        <span class="n">hidden_states</span><span class="o">=</span><span class="n">vision_outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
        <span class="n">attentions</span><span class="o">=</span><span class="n">vision_outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification</code>


<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel" href="#mindnlp.transformers.models.clip.modeling_clip.CLIPPreTrainedModel">CLIPPreTrainedModel</a></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPForImageClassification</span><span class="p">(</span><span class="n">CLIPPreTrainedModel</span><span class="p">):</span>
    <span class="n">main_input_name</span> <span class="o">=</span> <span class="s2">&quot;pixel_values&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CLIPConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
        <span class="n">vision_model</span> <span class="o">=</span> <span class="n">CLIPVisionModel</span><span class="o">.</span><span class="n">_from_config</span><span class="p">(</span>
            <span class="n">config</span><span class="o">.</span><span class="n">vision_config</span><span class="p">,</span> <span class="n">attn_implementation</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">_attn_implementation</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span> <span class="o">=</span> <span class="n">vision_model</span><span class="o">.</span><span class="n">vision_model</span>

        <span class="c1"># Classifier head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vision_config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">ImageClassifierOutput</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        labels (`mindspore.Tensor` of shape `(batch_size,)`, *optional*):</span>
<span class="sd">            Labels for computing the image classification/regression loss. Indices should be in `[0, ...,</span>
<span class="sd">            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If</span>
<span class="sd">            `config.num_labels &gt; 1` a classification loss is computed (Cross-Entropy).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
            <span class="n">pixel_values</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># average pool the patch tokens</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># apply classifier</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;regression&quot;</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;single_label_classification&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;single_label_classification&quot;</span><span class="p">:</span>
                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;multi_label_classification&quot;</span><span class="p">:</span>
                <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span><span class="p">,)</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
            <span class="k">return</span> <span class="p">((</span><span class="n">loss</span><span class="p">,)</span> <span class="o">+</span> <span class="n">output</span><span class="p">)</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span>

        <span class="k">return</span> <span class="n">ImageClassifierOutput</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">modeling_clip</span><span class="o">.</span><span class="n">CLIPForImageClassification</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.modeling_clip.CLIPForImageClassification.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>labels (<code>mindspore.Tensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>):
    Labels for computing the image classification/regression loss. Indices should be in <code>[0, ...,
    config.num_labels - 1]</code>. If <code>config.num_labels == 1</code> a regression loss is computed (Mean-Square loss), If
    <code>config.num_labels &gt; 1</code> a classification loss is computed (Cross-Entropy).</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\modeling_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">ImageClassifierOutput</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    labels (`mindspore.Tensor` of shape `(batch_size,)`, *optional*):</span>
<span class="sd">        Labels for computing the image classification/regression loss. Indices should be in `[0, ...,</span>
<span class="sd">        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If</span>
<span class="sd">        `config.num_labels &gt; 1` a classification loss is computed (Cross-Entropy).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
    <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
    <span class="p">)</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_model</span><span class="p">(</span>
        <span class="n">pixel_values</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># average pool the patch tokens</span>
    <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># apply classifier</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;regression&quot;</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;single_label_classification&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;regression&quot;</span><span class="p">:</span>
            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;single_label_classification&quot;</span><span class="p">:</span>
            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">==</span> <span class="s2">&quot;multi_label_classification&quot;</span><span class="p">:</span>
            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span><span class="p">,)</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">loss</span><span class="p">,)</span> <span class="o">+</span> <span class="n">output</span><span class="p">)</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span>

    <span class="k">return</span> <span class="n">ImageClassifierOutput</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
        <span class="n">hidden_states</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
        <span class="n">attentions</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.processing_clip.CLIPProcessor" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.processing_clip.CLIPProcessor</code>


<a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.processing_utils.ProcessorMixin">ProcessorMixin</span></code></p>


        <p>Constructs a CLIP processor which wraps a CLIP image processor and a CLIP tokenizer into a single processor.</p>
<p>[<code>CLIPProcessor</code>] offers all the functionalities of [<code>CLIPImageProcessor</code>] and [<code>CLIPTokenizerFast</code>]. See the
[<code>~CLIPProcessor.__call__</code>] and [<code>~CLIPProcessor.decode</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image_processor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The image processor is a required input.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`CLIPImageProcessor`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The tokenizer is a required input.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`CLIPTokenizerFast`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\processing_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPProcessor</span><span class="p">(</span><span class="n">ProcessorMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs a CLIP processor which wraps a CLIP image processor and a CLIP tokenizer into a single processor.</span>

<span class="sd">    [`CLIPProcessor`] offers all the functionalities of [`CLIPImageProcessor`] and [`CLIPTokenizerFast`]. See the</span>
<span class="sd">    [`~CLIPProcessor.__call__`] and [`~CLIPProcessor.decode`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        image_processor ([`CLIPImageProcessor`], *optional*):</span>
<span class="sd">            The image processor is a required input.</span>
<span class="sd">        tokenizer ([`CLIPTokenizerFast`], *optional*):</span>
<span class="sd">            The tokenizer is a required input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;image_processor&quot;</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">]</span>
    <span class="n">image_processor_class</span> <span class="o">=</span> <span class="s2">&quot;CLIPImageProcessor&quot;</span>
    <span class="n">tokenizer_class</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;CLIPTokenizer&quot;</span><span class="p">,</span> <span class="s2">&quot;CLIPTokenizerFast&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a CLIPProcessor object.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (object): The instance of the class.</span>
<span class="sd">            image_processor (object, optional): An image processor object used for processing images. </span>
<span class="sd">                If not provided, it can be passed as part of the kwargs parameter.</span>
<span class="sd">            tokenizer (object): A tokenizer object used for tokenizing text inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If either `image_processor` or `tokenizer` is not specified.</span>
<span class="sd">            FutureWarning: If the deprecated argument `feature_extractor` is used,</span>
<span class="sd">                a warning is issued recommending to use `image_processor` instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">feature_extractor</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="s2">&quot;feature_extractor&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`&quot;</span>
                <span class="s2">&quot; instead.&quot;</span><span class="p">,</span>
                <span class="ne">FutureWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;feature_extractor&quot;</span><span class="p">)</span>

        <span class="n">image_processor</span> <span class="o">=</span> <span class="n">image_processor</span> <span class="k">if</span> <span class="n">image_processor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feature_extractor</span>
        <span class="k">if</span> <span class="n">image_processor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You need to specify an `image_processor`.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You need to specify a `tokenizer`.&quot;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">image_processor</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Main method to prepare for the model one or several sequences(s) and image(s). This method forwards the `text`</span>
<span class="sd">        and `kwargs` arguments to CLIPTokenizerFast&#39;s [`~CLIPTokenizerFast.__call__`] if `text` is not `None` to encode</span>
<span class="sd">        the text. To prepare the image(s), this method forwards the `images` and `kwrags` arguments to</span>
<span class="sd">        CLIPImageProcessor&#39;s [`~CLIPImageProcessor.__call__`] if `images` is not `None`. Please refer to the doctsring</span>
<span class="sd">        of the above two methods for more information.</span>

<span class="sd">        Args:</span>
<span class="sd">            text (`str`, `List[str]`, `List[List[str]]`):</span>
<span class="sd">                The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings</span>
<span class="sd">                (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set</span>
<span class="sd">                `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).</span>
<span class="sd">            images (`PIL.Image.Image`, `np.ndarray`, `torch.Tensor`, `List[PIL.Image.Image]`, `List[np.ndarray]`, `List[torch.Tensor]`):</span>
<span class="sd">                The image or batch of images to be prepared. Each image can be a PIL image, NumPy array or PyTorch</span>
<span class="sd">                tensor. In case of a NumPy array/PyTorch tensor, each image should be of shape (C, H, W), where C is a</span>
<span class="sd">                number of channels, H and W are image height and width.</span>

<span class="sd">            return_tensors (`str` or [`~utils.TensorType`], *optional*):</span>
<span class="sd">                If set, will return tensors of a particular framework. Acceptable values are:</span>

<span class="sd">                - `&#39;tf&#39;`: Return TensorFlow `tf.constant` objects.</span>
<span class="sd">                - `&#39;pt&#39;`: Return PyTorch `torch.Tensor` objects.</span>
<span class="sd">                - `&#39;np&#39;`: Return NumPy `np.ndarray` objects.</span>
<span class="sd">                - `&#39;jax&#39;`: Return JAX `jnp.ndarray` objects.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`BatchEncoding`]: A [`BatchEncoding`] with the following fields:</span>

<span class="sd">                - **input_ids** -- List of token ids to be fed to a model. Returned when `text` is not `None`.</span>
<span class="sd">                - **attention_mask** -- List of indices specifying which tokens should be attended to by the model (when</span>
<span class="sd">                `return_attention_mask=True` or if *&quot;attention_mask&quot;* is in `self.model_input_names` and if `text` is not</span>
<span class="sd">                `None`).</span>
<span class="sd">                - **pixel_values** -- Pixel values to be fed to a model. Returned when `images` is not `None`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">images</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You have to specify either text or images. Both cannot be none.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">image_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoding</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">pixel_values</span>
            <span class="k">return</span> <span class="n">encoding</span>
        <span class="k">elif</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">encoding</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">BatchEncoding</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">image_features</span><span class="p">},</span> <span class="n">tensor_type</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">batch_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method forwards all its arguments to CLIPTokenizerFast&#39;s [`~PreTrainedTokenizer.batch_decode`]. Please</span>
<span class="sd">        refer to the docstring of this method for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method forwards all its arguments to CLIPTokenizerFast&#39;s [`~PreTrainedTokenizer.decode`]. Please refer to</span>
<span class="sd">        the docstring of this method for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_input_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method, &#39;model_input_names&#39;, is a property of the &#39;CLIPProcessor&#39; class.</span>
<span class="sd">        It returns a list of unique model input names derived from the tokenizer and image processor model input names.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: An instance of the &#39;CLIPProcessor&#39; class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The method returns a list of unique model input names derived from the tokenizer and image processor model input names.</span>

<span class="sd">        Raises:</span>
<span class="sd">            No exceptions are explicitly raised by this method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tokenizer_input_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_input_names</span>
        <span class="n">image_processor_input_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">model_input_names</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">tokenizer_input_names</span> <span class="o">+</span> <span class="n">image_processor_input_names</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">feature_extractor_class</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method returns the image processor class used for extracting features in the CLIPProcessor class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: An instance of the CLIPProcessor class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Raises:</span>
<span class="sd">            FutureWarning: If the method is called, a FutureWarning will be raised to inform the user that</span>
<span class="sd">                `feature_extractor_class` is deprecated. It is recommended to use</span>
<span class="sd">                `image_processor_class` instead.</span>

<span class="sd">        Note:</span>
<span class="sd">            The returned image processor class is responsible for extracting features from images in the CLIPProcessor.</span>

<span class="sd">        Example:</span>
<span class="sd">            ```python</span>
<span class="sd">            &gt;&gt;&gt; clip_processor = CLIPProcessor()</span>
<span class="sd">            &gt;&gt;&gt; clip_processor.feature_extractor_class</span>
<span class="sd">            &lt;class &#39;image_processor.ImageProcessor&#39;&gt;</span>
<span class="sd">            ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;`feature_extractor_class` is deprecated. Use `image_processor_class` instead.&quot;</span><span class="p">,</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor_class</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">feature_extractor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method is deprecated. Use `image_processor` instead.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: An instance of the CLIPProcessor class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            FutureWarning: This method raises a FutureWarning to alert users that it is deprecated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;`feature_extractor` is deprecated. Use `image_processor` instead.&quot;</span><span class="p">,</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.feature_extractor" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">processing_clip</span><span class="o">.</span><span class="n">CLIPProcessor</span><span class="o">.</span><span class="n">feature_extractor</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.feature_extractor" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method is deprecated. Use <code>image_processor</code> instead.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An instance of the CLIPProcessor class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>FutureWarning</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>This method raises a FutureWarning to alert users that it is deprecated.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.feature_extractor_class" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">processing_clip</span><span class="o">.</span><span class="n">CLIPProcessor</span><span class="o">.</span><span class="n">feature_extractor_class</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.feature_extractor_class" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method returns the image processor class used for extracting features in the CLIPProcessor class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An instance of the CLIPProcessor class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>FutureWarning</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the method is called, a FutureWarning will be raised to inform the user that
<code>feature_extractor_class</code> is deprecated. It is recommended to use
<code>image_processor_class</code> instead.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Note</summary>
  <p>The returned image processor class is responsible for extracting features from images in the CLIPProcessor.</p>
</details>

<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">clip_processor</span> <span class="o">=</span> <span class="n">CLIPProcessor</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">clip_processor</span><span class="o">.</span><span class="n">feature_extractor_class</span>
<span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">image_processor</span><span class="o">.</span><span class="n">ImageProcessor</span><span class="s1">&#39;&gt;</span>
</code></pre></div>
</details>    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.model_input_names" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">processing_clip</span><span class="o">.</span><span class="n">CLIPProcessor</span><span class="o">.</span><span class="n">model_input_names</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.model_input_names" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method, 'model_input_names', is a property of the 'CLIPProcessor' class.
It returns a list of unique model input names derived from the tokenizer and image processor model input names.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An instance of the 'CLIPProcessor' class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>The method returns a list of unique model input names derived from the tokenizer and image processor model input names.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">processing_clip</span><span class="o">.</span><span class="n">CLIPProcessor</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Main method to prepare for the model one or several sequences(s) and image(s). This method forwards the <code>text</code>
and <code>kwargs</code> arguments to CLIPTokenizerFast's [<code>~CLIPTokenizerFast.__call__</code>] if <code>text</code> is not <code>None</code> to encode
the text. To prepare the image(s), this method forwards the <code>images</code> and <code>kwrags</code> arguments to
CLIPImageProcessor's [<code>~CLIPImageProcessor.__call__</code>] if <code>images</code> is not <code>None</code>. Please refer to the doctsring
of the above two methods for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>text</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings
(pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set
<code>is_split_into_words=True</code> (to lift the ambiguity with a batch of sequences).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, `List[str]`, `List[List[str]]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>images</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The image or batch of images to be prepared. Each image can be a PIL image, NumPy array or PyTorch
tensor. In case of a NumPy array/PyTorch tensor, each image should be of shape (C, H, W), where C is a
number of channels, H and W are image height and width.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`PIL.Image.Image`, `np.ndarray`, `torch.Tensor`, `List[PIL.Image.Image]`, `List[np.ndarray]`, `List[torch.Tensor]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_tensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If set, will return tensors of a particular framework. Acceptable values are:</p>
<ul>
<li><code>'tf'</code>: Return TensorFlow <code>tf.constant</code> objects.</li>
<li><code>'pt'</code>: Return PyTorch <code>torch.Tensor</code> objects.</li>
<li><code>'np'</code>: Return NumPy <code>np.ndarray</code> objects.</li>
<li><code>'jax'</code>: Return JAX <code>jnp.ndarray</code> objects.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or [`~utils.TensorType`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>BatchEncoding</code>]: A [<code>BatchEncoding</code>] with the following fields:</p>
<ul>
<li><strong>input_ids</strong> -- List of token ids to be fed to a model. Returned when <code>text</code> is not <code>None</code>.</li>
<li><strong>attention_mask</strong> -- List of indices specifying which tokens should be attended to by the model (when
<code>return_attention_mask=True</code> or if <em>"attention_mask"</em> is in <code>self.model_input_names</code> and if <code>text</code> is not
<code>None</code>).</li>
<li><strong>pixel_values</strong> -- Pixel values to be fed to a model. Returned when <code>images</code> is not <code>None</code>.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\processing_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Main method to prepare for the model one or several sequences(s) and image(s). This method forwards the `text`</span>
<span class="sd">    and `kwargs` arguments to CLIPTokenizerFast&#39;s [`~CLIPTokenizerFast.__call__`] if `text` is not `None` to encode</span>
<span class="sd">    the text. To prepare the image(s), this method forwards the `images` and `kwrags` arguments to</span>
<span class="sd">    CLIPImageProcessor&#39;s [`~CLIPImageProcessor.__call__`] if `images` is not `None`. Please refer to the doctsring</span>
<span class="sd">    of the above two methods for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        text (`str`, `List[str]`, `List[List[str]]`):</span>
<span class="sd">            The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings</span>
<span class="sd">            (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set</span>
<span class="sd">            `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).</span>
<span class="sd">        images (`PIL.Image.Image`, `np.ndarray`, `torch.Tensor`, `List[PIL.Image.Image]`, `List[np.ndarray]`, `List[torch.Tensor]`):</span>
<span class="sd">            The image or batch of images to be prepared. Each image can be a PIL image, NumPy array or PyTorch</span>
<span class="sd">            tensor. In case of a NumPy array/PyTorch tensor, each image should be of shape (C, H, W), where C is a</span>
<span class="sd">            number of channels, H and W are image height and width.</span>

<span class="sd">        return_tensors (`str` or [`~utils.TensorType`], *optional*):</span>
<span class="sd">            If set, will return tensors of a particular framework. Acceptable values are:</span>

<span class="sd">            - `&#39;tf&#39;`: Return TensorFlow `tf.constant` objects.</span>
<span class="sd">            - `&#39;pt&#39;`: Return PyTorch `torch.Tensor` objects.</span>
<span class="sd">            - `&#39;np&#39;`: Return NumPy `np.ndarray` objects.</span>
<span class="sd">            - `&#39;jax&#39;`: Return JAX `jnp.ndarray` objects.</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`BatchEncoding`]: A [`BatchEncoding`] with the following fields:</span>

<span class="sd">            - **input_ids** -- List of token ids to be fed to a model. Returned when `text` is not `None`.</span>
<span class="sd">            - **attention_mask** -- List of indices specifying which tokens should be attended to by the model (when</span>
<span class="sd">            `return_attention_mask=True` or if *&quot;attention_mask&quot;* is in `self.model_input_names` and if `text` is not</span>
<span class="sd">            `None`).</span>
<span class="sd">            - **pixel_values** -- Pixel values to be fed to a model. Returned when `images` is not `None`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">images</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You have to specify either text or images. Both cannot be none.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">image_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">encoding</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_features</span><span class="o">.</span><span class="n">pixel_values</span>
        <span class="k">return</span> <span class="n">encoding</span>
    <span class="k">elif</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">encoding</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">BatchEncoding</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">image_features</span><span class="p">},</span> <span class="n">tensor_type</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">processing_clip</span><span class="o">.</span><span class="n">CLIPProcessor</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">image_processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize a CLIPProcessor object.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_processor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An image processor object used for processing images. 
If not provided, it can be passed as part of the kwargs parameter.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A tokenizer object used for tokenizing text inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If either <code>image_processor</code> or <code>tokenizer</code> is not specified.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>FutureWarning</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the deprecated argument <code>feature_extractor</code> is used,
a warning is issued recommending to use <code>image_processor</code> instead.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\processing_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize a CLIPProcessor object.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (object): The instance of the class.</span>
<span class="sd">        image_processor (object, optional): An image processor object used for processing images. </span>
<span class="sd">            If not provided, it can be passed as part of the kwargs parameter.</span>
<span class="sd">        tokenizer (object): A tokenizer object used for tokenizing text inputs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If either `image_processor` or `tokenizer` is not specified.</span>
<span class="sd">        FutureWarning: If the deprecated argument `feature_extractor` is used,</span>
<span class="sd">            a warning is issued recommending to use `image_processor` instead.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">feature_extractor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="s2">&quot;feature_extractor&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;The `feature_extractor` argument is deprecated and will be removed in v5, use `image_processor`&quot;</span>
            <span class="s2">&quot; instead.&quot;</span><span class="p">,</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;feature_extractor&quot;</span><span class="p">)</span>

    <span class="n">image_processor</span> <span class="o">=</span> <span class="n">image_processor</span> <span class="k">if</span> <span class="n">image_processor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feature_extractor</span>
    <span class="k">if</span> <span class="n">image_processor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You need to specify an `image_processor`.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You need to specify a `tokenizer`.&quot;</span><span class="p">)</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">image_processor</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.batch_decode" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">processing_clip</span><span class="o">.</span><span class="n">CLIPProcessor</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.batch_decode" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method forwards all its arguments to CLIPTokenizerFast's [<code>~PreTrainedTokenizer.batch_decode</code>]. Please
refer to the docstring of this method for more information.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\processing_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">batch_decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method forwards all its arguments to CLIPTokenizerFast&#39;s [`~PreTrainedTokenizer.batch_decode`]. Please</span>
<span class="sd">    refer to the docstring of this method for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.decode" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">processing_clip</span><span class="o">.</span><span class="n">CLIPProcessor</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.processing_clip.CLIPProcessor.decode" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method forwards all its arguments to CLIPTokenizerFast's [<code>~PreTrainedTokenizer.decode</code>]. Please refer to
the docstring of this method for more information.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\processing_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method forwards all its arguments to CLIPTokenizerFast&#39;s [`~PreTrainedTokenizer.decode`]. Please refer to</span>
<span class="sd">    the docstring of this method for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer</code>


<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.tokenization_utils.PreTrainedTokenizer" href="../../tokenization_utils/#mindnlp.transformers.tokenization_utils.PreTrainedTokenizer">PreTrainedTokenizer</a></code></p>


        <p>Construct a CLIP tokenizer. Based on byte-level Byte-Pair-Encoding.</p>
<p>This tokenizer inherits from [<code>PreTrainedTokenizer</code>] which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>vocab_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Path to the vocabulary file.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>merges_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Path to the merges file.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>errors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Paradigm to follow when decoding bytes to UTF-8. See
<a href="https://docs.python.org/3/library/stdtypes.html#bytes.decode">bytes.decode</a> for more information.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;replace&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;replace&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>unk_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this
token instead.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&lt;|endoftext|&gt;&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bos_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The beginning of sequence token.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&lt;|startoftext|&gt;&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|startoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eos_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The end of sequence token.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&lt;|endoftext|&gt;&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The token used for padding, for example when batching sequences of different lengths.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&lt;|endoftext|&gt;&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPTokenizer</span><span class="p">(</span><span class="n">PreTrainedTokenizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct a CLIP tokenizer. Based on byte-level Byte-Pair-Encoding.</span>

<span class="sd">    This tokenizer inherits from [`PreTrainedTokenizer`] which contains most of the main methods. Users should refer to</span>
<span class="sd">    this superclass for more information regarding those methods.</span>

<span class="sd">    Args:</span>
<span class="sd">        vocab_file (`str`):</span>
<span class="sd">            Path to the vocabulary file.</span>
<span class="sd">        merges_file (`str`):</span>
<span class="sd">            Path to the merges file.</span>
<span class="sd">        errors (`str`, *optional*, defaults to `&quot;replace&quot;`):</span>
<span class="sd">            Paradigm to follow when decoding bytes to UTF-8. See</span>
<span class="sd">            [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode) for more information.</span>
<span class="sd">        unk_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
<span class="sd">            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this</span>
<span class="sd">            token instead.</span>
<span class="sd">        bos_token (`str`, *optional*, defaults to `&quot;&lt;|startoftext|&gt;&quot;`):</span>
<span class="sd">            The beginning of sequence token.</span>
<span class="sd">        eos_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
<span class="sd">            The end of sequence token.</span>
<span class="sd">        pad_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
<span class="sd">            The token used for padding, for example when batching sequences of different lengths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vocab_files_names</span> <span class="o">=</span> <span class="n">VOCAB_FILES_NAMES</span>
    <span class="n">pretrained_vocab_files_map</span> <span class="o">=</span> <span class="n">PRETRAINED_VOCAB_FILES_MAP</span>
    <span class="n">max_model_input_sizes</span> <span class="o">=</span> <span class="n">PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES</span>
    <span class="n">model_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vocab_file</span><span class="p">,</span>
        <span class="n">merges_file</span><span class="p">,</span>
        <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;replace&quot;</span><span class="p">,</span>
        <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
        <span class="n">bos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">,</span>
        <span class="n">eos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>  <span class="c1"># hack to enable padding</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a CLIPTokenizer object.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (object): The instance of the CLIPTokenizer class.</span>
<span class="sd">            vocab_file (str): The path to the vocabulary file containing token encodings.</span>
<span class="sd">            merges_file (str): The path to the file containing BPE merges for tokenization.</span>
<span class="sd">            errors (str, optional): The error handling strategy for text decoding. Defaults to &#39;replace&#39;.</span>
<span class="sd">            unk_token (str, optional): The token to represent unknown words. Defaults to an empty string.</span>
<span class="sd">            bos_token (str, optional): The beginning of sequence token. Defaults to &#39;&lt;|startoftext|&gt;&#39;.</span>
<span class="sd">            eos_token (str, optional): The end of sequence token. Defaults to an empty string.</span>
<span class="sd">            pad_token (str, optional): The padding token. Defaults to an empty string.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ImportError: If the &#39;ftfy&#39; package is not installed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">bos_token</span>
        <span class="n">eos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">eos_token</span>
        <span class="n">unk_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">unk_token</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">ftfy</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">fix_text</span> <span class="o">=</span> <span class="n">ftfy</span><span class="o">.</span><span class="n">fix_text</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;ftfy or spacy is not installed using custom BasicTokenizer instead of ftfy.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nlp</span> <span class="o">=</span> <span class="n">BasicTokenizer</span><span class="p">(</span><span class="n">strip_accents</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">do_split_on_punc</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fix_text</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">vocab_handle</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">vocab_handle</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">errors</span> <span class="o">=</span> <span class="n">errors</span>  <span class="c1"># how to handle errors in decoding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">merges_handle</span><span class="p">:</span>
            <span class="n">bpe_merges</span> <span class="o">=</span> <span class="n">merges_handle</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)[</span><span class="mi">1</span> <span class="p">:</span> <span class="mi">49152</span> <span class="o">-</span> <span class="mi">256</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">bpe_merges</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">merge</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">merge</span> <span class="ow">in</span> <span class="n">bpe_merges</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">))))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
<span class="w">            </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;&lt;\|startoftext\|&gt;|&lt;\|endoftext\|&gt;|&#39;s|&#39;t|&#39;re|&#39;ve|&#39;m|&#39;ll|&#39;d|[\p{L}]+|[\p{N}]|[^\s\p{L}\p{N}]+&quot;&quot;&quot;</span><span class="p">,</span>
            <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">errors</span><span class="o">=</span><span class="n">errors</span><span class="p">,</span>
            <span class="n">unk_token</span><span class="o">=</span><span class="n">unk_token</span><span class="p">,</span>
            <span class="n">bos_token</span><span class="o">=</span><span class="n">bos_token</span><span class="p">,</span>
            <span class="n">eos_token</span><span class="o">=</span><span class="n">eos_token</span><span class="p">,</span>
            <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">vocab_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to return the vocabulary size of the CLIPTokenizer instance.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (CLIPTokenizer): The instance of the CLIPTokenizer class.</span>
<span class="sd">                This parameter refers to the current instance of the CLIPTokenizer for which the vocabulary size is to</span>
<span class="sd">                be calculated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: The number of unique tokens in the vocabulary.</span>
<span class="sd">                The method returns an integer value representing the size of the vocabulary as the count of unique</span>
<span class="sd">                tokens stored in the encoder.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to retrieve the vocabulary of the CLIPTokenizer instance.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (CLIPTokenizer): The instance of the CLIPTokenizer class.</span>
<span class="sd">                Represents the current instance of the CLIPTokenizer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the combined vocabulary of the encoder and added_tokens_encoder.</span>
<span class="sd">                The vocabulary includes both the original encoder tokens and any additional tokens added to the tokenizer.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">added_tokens_encoder</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_inputs_with_special_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and</span>
<span class="sd">        adding special tokens. A CLIP sequence has the following format:</span>

<span class="sd">        - single sequence: `&lt;|startoftext|&gt; X &lt;|endoftext|&gt;`</span>

<span class="sd">        Pairs of sequences are not the expected use case, but they will be handled without a separator.</span>

<span class="sd">        Args:</span>
<span class="sd">            token_ids_0 (`List[int]`):</span>
<span class="sd">                List of IDs to which the special tokens will be added.</span>
<span class="sd">            token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">                Optional second list of IDs for sequence pairs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `List[int]`: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]</span>
        <span class="n">eos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span>
        <span class="k">return</span> <span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">eos_token</span>

    <span class="k">def</span> <span class="nf">get_special_tokens_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">already_has_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding</span>
<span class="sd">        special tokens using the tokenizer `prepare_for_model` method.</span>

<span class="sd">        Args:</span>
<span class="sd">            token_ids_0 (`List[int]`):</span>
<span class="sd">                List of IDs.</span>
<span class="sd">            token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">                Optional second list of IDs for sequence pairs.</span>
<span class="sd">            already_has_special_tokens (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether or not the token list is already formatted with special tokens for the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">already_has_special_tokens</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_special_tokens_mask</span><span class="p">(</span>
                <span class="n">token_ids_0</span><span class="o">=</span><span class="n">token_ids_0</span><span class="p">,</span> <span class="n">token_ids_1</span><span class="o">=</span><span class="n">token_ids_1</span><span class="p">,</span> <span class="n">already_has_special_tokens</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_1</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">create_token_type_ids_from_sequences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a mask from the two sequences passed. CLIP does not make use of token type ids, therefore a list of</span>
<span class="sd">        zeros is returned.</span>

<span class="sd">        Args:</span>
<span class="sd">            token_ids_0 (`List[int]`):</span>
<span class="sd">                List of IDs.</span>
<span class="sd">            token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">                Optional second list of IDs for sequence pairs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `List[int]`: List of zeros.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]</span>
        <span class="n">eos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">eos_token</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method &#39;bpe&#39; is defined in the class &#39;CLIPTokenizer&#39;. It processes a given token using Byte Pair Encoding (BPE).</span>

<span class="sd">        Args:</span>
<span class="sd">            self: This parameter represents the instance of the class &#39;CLIPTokenizer&#39;.</span>
<span class="sd">                It is used to access the attributes and methods of the class.</span>
<span class="sd">            token (str): The input token to be processed using Byte Pair Encoding (BPE).</span>
<span class="sd">                It should be a string representing a single token.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: The processed token after applying Byte Pair Encoding (BPE) algorithm.</span>
<span class="sd">                The token is modified based on the algorithm rules.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
        <span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="n">token</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;&lt;/w&gt;&quot;</span><span class="p">,)</span>
        <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">pairs</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">token</span> <span class="o">+</span> <span class="s2">&quot;&lt;/w&gt;&quot;</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)))</span>
            <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">bigram</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">j</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
                    <span class="k">break</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>

                <span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span> <span class="o">+</span> <span class="n">second</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">new_word</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">word</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
        <span class="k">return</span> <span class="n">word</span>

    <span class="k">def</span> <span class="nf">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenize a string.&quot;&quot;&quot;</span>
        <span class="n">bpe_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fix_text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nlp</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">whitespace_clean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fix_text</span><span class="p">(</span><span class="n">text</span><span class="p">))</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pat</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
            <span class="n">token</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">token</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
            <span class="p">)</span>  <span class="c1"># Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)</span>
            <span class="n">bpe_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bpe_token</span> <span class="k">for</span> <span class="n">bpe_token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe</span><span class="p">(</span><span class="n">token</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">bpe_tokens</span>

    <span class="k">def</span> <span class="nf">_convert_token_to_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a token (str) in an id using the vocab.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unk_token</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_convert_id_to_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts an index (integer) in a token (str) using the vocab.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">convert_tokens_to_string</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a sequence of tokens (string) in a single string.&quot;&quot;&quot;</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="n">byte_array</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">byte_array</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;/w&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">text</span>

    <span class="k">def</span> <span class="nf">save_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the vocabulary to the specified directory with an optional filename prefix.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (CLIPTokenizer): The instance of the CLIPTokenizer class.</span>
<span class="sd">            save_directory (str): The directory where the vocabulary files will be saved.</span>
<span class="sd">            filename_prefix (Optional[str], optional): An optional prefix to be added to the filename. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[str]: A tuple containing the paths to the saved vocabulary file and merge file.</span>

<span class="sd">        Raises:</span>
<span class="sd">            OSError: If the specified save_directory is not a valid directory.</span>
<span class="sd">            IOError: If there is an issue with writing the vocabulary or merge files.</span>
<span class="sd">            Exception: If any other unexpected error occurs during the saving process.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Vocabulary path (</span><span class="si">{}</span><span class="s2">) should be a directory&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">save_directory</span><span class="p">))</span>
            <span class="k">return</span>
        <span class="n">vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;vocab_file&quot;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">merge_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;merges_file&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merge_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;#version: 0.2</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">bpe_tokens</span><span class="p">,</span> <span class="n">token_index</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">kv</span><span class="p">:</span> <span class="n">kv</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">index</span> <span class="o">!=</span> <span class="n">token_index</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;Saving vocabulary to </span><span class="si">{}</span><span class="s2">: BPE merge indices are not consecutive.&quot;</span>
                        <span class="s2">&quot; Please check that the tokenizer is not corrupted!&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">merge_file</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">index</span> <span class="o">=</span> <span class="n">token_index</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bpe_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">merge_file</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.vocab_size" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">vocab_size</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.vocab_size" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Method to return the vocabulary size of the CLIPTokenizer instance.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the CLIPTokenizer class.
This parameter refers to the current instance of the CLIPTokenizer for which the vocabulary size is to
be calculated.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer" href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer">CLIPTokenizer</a></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>int</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>The number of unique tokens in the vocabulary.
The method returns an integer value representing the size of the vocabulary as the count of unique
tokens stored in the encoder.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">merges_file</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;replace&#39;</span><span class="p">,</span> <span class="n">unk_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">,</span> <span class="n">bos_token</span><span class="o">=</span><span class="s1">&#39;&lt;|startoftext|&gt;&#39;</span><span class="p">,</span> <span class="n">eos_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initializes a CLIPTokenizer object.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the CLIPTokenizer class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vocab_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The path to the vocabulary file containing token encodings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>merges_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The path to the file containing BPE merges for tokenization.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>errors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The error handling strategy for text decoding. Defaults to 'replace'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;replace&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>unk_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The token to represent unknown words. Defaults to an empty string.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bos_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The beginning of sequence token. Defaults to '&lt;|startoftext|&gt;'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|startoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eos_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The end of sequence token. Defaults to an empty string.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The padding token. Defaults to an empty string.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ImportError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the 'ftfy' package is not installed.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">vocab_file</span><span class="p">,</span>
    <span class="n">merges_file</span><span class="p">,</span>
    <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;replace&quot;</span><span class="p">,</span>
    <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
    <span class="n">bos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">,</span>
    <span class="n">eos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
    <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>  <span class="c1"># hack to enable padding</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a CLIPTokenizer object.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (object): The instance of the CLIPTokenizer class.</span>
<span class="sd">        vocab_file (str): The path to the vocabulary file containing token encodings.</span>
<span class="sd">        merges_file (str): The path to the file containing BPE merges for tokenization.</span>
<span class="sd">        errors (str, optional): The error handling strategy for text decoding. Defaults to &#39;replace&#39;.</span>
<span class="sd">        unk_token (str, optional): The token to represent unknown words. Defaults to an empty string.</span>
<span class="sd">        bos_token (str, optional): The beginning of sequence token. Defaults to &#39;&lt;|startoftext|&gt;&#39;.</span>
<span class="sd">        eos_token (str, optional): The end of sequence token. Defaults to an empty string.</span>
<span class="sd">        pad_token (str, optional): The padding token. Defaults to an empty string.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ImportError: If the &#39;ftfy&#39; package is not installed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">bos_token</span>
    <span class="n">eos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">eos_token</span>
    <span class="n">unk_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">unk_token</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">ftfy</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fix_text</span> <span class="o">=</span> <span class="n">ftfy</span><span class="o">.</span><span class="n">fix_text</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;ftfy or spacy is not installed using custom BasicTokenizer instead of ftfy.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nlp</span> <span class="o">=</span> <span class="n">BasicTokenizer</span><span class="p">(</span><span class="n">strip_accents</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">do_split_on_punc</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fix_text</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">vocab_handle</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">vocab_handle</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">errors</span> <span class="o">=</span> <span class="n">errors</span>  <span class="c1"># how to handle errors in decoding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">merges_handle</span><span class="p">:</span>
        <span class="n">bpe_merges</span> <span class="o">=</span> <span class="n">merges_handle</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)[</span><span class="mi">1</span> <span class="p">:</span> <span class="mi">49152</span> <span class="o">-</span> <span class="mi">256</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">bpe_merges</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">merge</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">merge</span> <span class="ow">in</span> <span class="n">bpe_merges</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">))))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">}</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;&lt;\|startoftext\|&gt;|&lt;\|endoftext\|&gt;|&#39;s|&#39;t|&#39;re|&#39;ve|&#39;m|&#39;ll|&#39;d|[\p{L}]+|[\p{N}]|[^\s\p{L}\p{N}]+&quot;&quot;&quot;</span><span class="p">,</span>
        <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">errors</span><span class="o">=</span><span class="n">errors</span><span class="p">,</span>
        <span class="n">unk_token</span><span class="o">=</span><span class="n">unk_token</span><span class="p">,</span>
        <span class="n">bos_token</span><span class="o">=</span><span class="n">bos_token</span><span class="p">,</span>
        <span class="n">eos_token</span><span class="o">=</span><span class="n">eos_token</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.bpe" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">bpe</span><span class="p">(</span><span class="n">token</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.bpe" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>This method 'bpe' is defined in the class 'CLIPTokenizer'. It processes a given token using Byte Pair Encoding (BPE).</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>This parameter represents the instance of the class 'CLIPTokenizer'.
It is used to access the attributes and methods of the class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The input token to be processed using Byte Pair Encoding (BPE).
It should be a string representing a single token.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>str</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>The processed token after applying Byte Pair Encoding (BPE) algorithm.
The token is modified based on the algorithm rules.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method &#39;bpe&#39; is defined in the class &#39;CLIPTokenizer&#39;. It processes a given token using Byte Pair Encoding (BPE).</span>

<span class="sd">    Args:</span>
<span class="sd">        self: This parameter represents the instance of the class &#39;CLIPTokenizer&#39;.</span>
<span class="sd">            It is used to access the attributes and methods of the class.</span>
<span class="sd">        token (str): The input token to be processed using Byte Pair Encoding (BPE).</span>
<span class="sd">            It should be a string representing a single token.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: The processed token after applying Byte Pair Encoding (BPE) algorithm.</span>
<span class="sd">            The token is modified based on the algorithm rules.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
    <span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="n">token</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;&lt;/w&gt;&quot;</span><span class="p">,)</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">pairs</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">token</span> <span class="o">+</span> <span class="s2">&quot;&lt;/w&gt;&quot;</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">bigram</span>
        <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">j</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">])</span>
                <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>

            <span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
                <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span> <span class="o">+</span> <span class="n">second</span><span class="p">)</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">new_word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">new_word</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="n">word</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
    <span class="k">return</span> <span class="n">word</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.build_inputs_with_special_tokens" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">build_inputs_with_special_tokens</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">,</span> <span class="n">token_ids_1</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.build_inputs_with_special_tokens" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A CLIP sequence has the following format:</p>
<ul>
<li>single sequence: <code>&lt;|startoftext|&gt; X &lt;|endoftext|&gt;</code></li>
</ul>
<p>Pairs of sequences are not the expected use case, but they will be handled without a separator.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_0</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of IDs to which the special tokens will be added.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_1</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional second list of IDs for sequence pairs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.List">List</span>[int]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>List[int]</code>: List of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">build_inputs_with_special_tokens</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and</span>
<span class="sd">    adding special tokens. A CLIP sequence has the following format:</span>

<span class="sd">    - single sequence: `&lt;|startoftext|&gt; X &lt;|endoftext|&gt;`</span>

<span class="sd">    Pairs of sequences are not the expected use case, but they will be handled without a separator.</span>

<span class="sd">    Args:</span>
<span class="sd">        token_ids_0 (`List[int]`):</span>
<span class="sd">            List of IDs to which the special tokens will be added.</span>
<span class="sd">        token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">            Optional second list of IDs for sequence pairs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `List[int]`: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]</span>
    <span class="n">eos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span>
    <span class="k">return</span> <span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">eos_token</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.convert_tokens_to_string" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_string</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.convert_tokens_to_string" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Converts a sequence of tokens (string) in a single string.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">convert_tokens_to_string</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts a sequence of tokens (string) in a single string.&quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">byte_array</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">byte_array</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;/w&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.create_token_type_ids_from_sequences" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">create_token_type_ids_from_sequences</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">,</span> <span class="n">token_ids_1</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.create_token_type_ids_from_sequences" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Create a mask from the two sequences passed. CLIP does not make use of token type ids, therefore a list of
zeros is returned.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_0</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of IDs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_1</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional second list of IDs for sequence pairs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.List">List</span>[int]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>List[int]</code>: List of zeros.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_token_type_ids_from_sequences</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a mask from the two sequences passed. CLIP does not make use of token type ids, therefore a list of</span>
<span class="sd">    zeros is returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        token_ids_0 (`List[int]`):</span>
<span class="sd">            List of IDs.</span>
<span class="sd">        token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">            Optional second list of IDs for sequence pairs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `List[int]`: List of zeros.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]</span>
    <span class="n">eos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">eos_token</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.get_special_tokens_mask" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">get_special_tokens_mask</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">,</span> <span class="n">token_ids_1</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">already_has_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.get_special_tokens_mask" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer <code>prepare_for_model</code> method.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_0</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of IDs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_1</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional second list of IDs for sequence pairs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>already_has_special_tokens</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not the token list is already formatted with special tokens for the model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.List">List</span>[int]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>List[int]</code>: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_special_tokens_mask</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">already_has_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding</span>
<span class="sd">    special tokens using the tokenizer `prepare_for_model` method.</span>

<span class="sd">    Args:</span>
<span class="sd">        token_ids_0 (`List[int]`):</span>
<span class="sd">            List of IDs.</span>
<span class="sd">        token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">            Optional second list of IDs for sequence pairs.</span>
<span class="sd">        already_has_special_tokens (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not the token list is already formatted with special tokens for the model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `List[int]`: A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">already_has_special_tokens</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_special_tokens_mask</span><span class="p">(</span>
            <span class="n">token_ids_0</span><span class="o">=</span><span class="n">token_ids_0</span><span class="p">,</span> <span class="n">token_ids_1</span><span class="o">=</span><span class="n">token_ids_1</span><span class="p">,</span> <span class="n">already_has_special_tokens</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_1</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.get_vocab" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.get_vocab" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Method to retrieve the vocabulary of the CLIPTokenizer instance.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the CLIPTokenizer class.
Represents the current instance of the CLIPTokenizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer" href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer">CLIPTokenizer</a></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dict</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>A dictionary containing the combined vocabulary of the encoder and added_tokens_encoder.
The vocabulary includes both the original encoder tokens and any additional tokens added to the tokenizer.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Method to retrieve the vocabulary of the CLIPTokenizer instance.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (CLIPTokenizer): The instance of the CLIPTokenizer class.</span>
<span class="sd">            Represents the current instance of the CLIPTokenizer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary containing the combined vocabulary of the encoder and added_tokens_encoder.</span>
<span class="sd">            The vocabulary includes both the original encoder tokens and any additional tokens added to the tokenizer.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">added_tokens_encoder</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.save_vocabulary" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip</span><span class="o">.</span><span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">save_vocabulary</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer.save_vocabulary" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the vocabulary to the specified directory with an optional filename prefix.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the CLIPTokenizer class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer" href="#mindnlp.transformers.models.clip.tokenization_clip.CLIPTokenizer">CLIPTokenizer</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_directory</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The directory where the vocabulary files will be saved.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>filename_prefix</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An optional prefix to be added to the filename. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[str]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Tuple">Tuple</span>[str]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Tuple[str]: A tuple containing the paths to the saved vocabulary file and merge file.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>OSError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the specified save_directory is not a valid directory.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>IOError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If there is an issue with writing the vocabulary or merge files.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>Exception</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If any other unexpected error occurs during the saving process.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save the vocabulary to the specified directory with an optional filename prefix.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (CLIPTokenizer): The instance of the CLIPTokenizer class.</span>
<span class="sd">        save_directory (str): The directory where the vocabulary files will be saved.</span>
<span class="sd">        filename_prefix (Optional[str], optional): An optional prefix to be added to the filename. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[str]: A tuple containing the paths to the saved vocabulary file and merge file.</span>

<span class="sd">    Raises:</span>
<span class="sd">        OSError: If the specified save_directory is not a valid directory.</span>
<span class="sd">        IOError: If there is an issue with writing the vocabulary or merge files.</span>
<span class="sd">        Exception: If any other unexpected error occurs during the saving process.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Vocabulary path (</span><span class="si">{}</span><span class="s2">) should be a directory&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">save_directory</span><span class="p">))</span>
        <span class="k">return</span>
    <span class="n">vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;vocab_file&quot;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">merge_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;merges_file&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merge_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;#version: 0.2</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">bpe_tokens</span><span class="p">,</span> <span class="n">token_index</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">kv</span><span class="p">:</span> <span class="n">kv</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">index</span> <span class="o">!=</span> <span class="n">token_index</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Saving vocabulary to </span><span class="si">{}</span><span class="s2">: BPE merge indices are not consecutive.&quot;</span>
                    <span class="s2">&quot; Please check that the tokenizer is not corrupted!&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">merge_file</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">index</span> <span class="o">=</span> <span class="n">token_index</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bpe_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">merge_file</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast" class="doc doc-heading">
            <code>mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast</code>


<a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.tokenization_utils_fast.PreTrainedTokenizerFast" href="../../tokenization_utils_fast/#mindnlp.transformers.tokenization_utils_fast.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a></code></p>


        <p>Construct a "fast" CLIP tokenizer (backed by HuggingFace's <em>tokenizers</em> library). Based on byte-level
Byte-Pair-Encoding.</p>
<p>This tokenizer inherits from [<code>PreTrainedTokenizerFast</code>] which contains most of the main methods. Users should
refer to this superclass for more information regarding those methods.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>vocab_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Path to the vocabulary file.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>merges_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Path to the merges file.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The path to a tokenizer file to use instead of the vocab file.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>unk_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this
token instead.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&lt;|endoftext|&gt;&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bos_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The beginning of sequence token.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&lt;|startoftext|&gt;&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|startoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eos_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The end of sequence token.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&lt;|endoftext|&gt;&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The token used for padding, for example when batching sequences of different lengths.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&lt;|endoftext|&gt;&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip_fast.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">CLIPTokenizerFast</span><span class="p">(</span><span class="n">PreTrainedTokenizerFast</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct a &quot;fast&quot; CLIP tokenizer (backed by HuggingFace&#39;s *tokenizers* library). Based on byte-level</span>
<span class="sd">    Byte-Pair-Encoding.</span>

<span class="sd">    This tokenizer inherits from [`PreTrainedTokenizerFast`] which contains most of the main methods. Users should</span>
<span class="sd">    refer to this superclass for more information regarding those methods.</span>

<span class="sd">    Args:</span>
<span class="sd">        vocab_file (`str`, *optional*):</span>
<span class="sd">            Path to the vocabulary file.</span>
<span class="sd">        merges_file (`str`, *optional*):</span>
<span class="sd">            Path to the merges file.</span>
<span class="sd">        tokenizer_file (`str`, *optional*):</span>
<span class="sd">            The path to a tokenizer file to use instead of the vocab file.</span>
<span class="sd">        unk_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
<span class="sd">            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this</span>
<span class="sd">            token instead.</span>
<span class="sd">        bos_token (`str`, *optional*, defaults to `&quot;&lt;|startoftext|&gt;&quot;`):</span>
<span class="sd">            The beginning of sequence token.</span>
<span class="sd">        eos_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
<span class="sd">            The end of sequence token.</span>
<span class="sd">        pad_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
<span class="sd">            The token used for padding, for example when batching sequences of different lengths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vocab_files_names</span> <span class="o">=</span> <span class="n">VOCAB_FILES_NAMES</span>
    <span class="n">pretrained_vocab_files_map</span> <span class="o">=</span> <span class="n">PRETRAINED_VOCAB_FILES_MAP</span>
    <span class="n">max_model_input_sizes</span> <span class="o">=</span> <span class="n">PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES</span>
    <span class="n">model_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
    <span class="n">slow_tokenizer_class</span> <span class="o">=</span> <span class="n">CLIPTokenizer</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vocab_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">merges_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
        <span class="n">bos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">,</span>
        <span class="n">eos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>  <span class="c1"># hack to enable padding</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the CLIPTokenizerFast class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (object): The instance of the CLIPTokenizerFast class.</span>
<span class="sd">            vocab_file (str, optional): Path to the vocabulary file. Default is None.</span>
<span class="sd">            merges_file (str, optional): Path to the merges file. Default is None.</span>
<span class="sd">            tokenizer_file (str, optional): Path to the tokenizer file. Default is None.</span>
<span class="sd">            unk_token (str, optional): The unknown token. Default is &#39;endoftext&#39;.</span>
<span class="sd">            bos_token (str, optional): The beginning of sequence token. Default is &#39;&lt;|startoftext|&gt;&#39;.</span>
<span class="sd">            eos_token (str, optional): The end of sequence token. Default is &#39;endoftext&#39;.</span>
<span class="sd">            pad_token (str, optional): The padding token. Default is &#39;endoftext&#39;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: Raised if the backend tokenizer pre_tokenizer does not match the expected format.</span>
<span class="sd">                The CLIP tokenizer in this version has been heavily modified from transformers version 4.17.0. To</span>
<span class="sd">                resolve this issue, convert the existing tokenizer to be compatible with this version using</span>
<span class="sd">                `CLIPTokenizerFast.from_pretrained(&quot;path_to_local_folder_or_hub_repo&quot;, from_slow=True)`.</span>
<span class="sd">                If using an older tokenizer version, revert to a version prior to 4.17.0 of transformers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">vocab_file</span><span class="p">,</span>
            <span class="n">merges_file</span><span class="p">,</span>
            <span class="n">tokenizer_file</span><span class="o">=</span><span class="n">tokenizer_file</span><span class="p">,</span>
            <span class="n">unk_token</span><span class="o">=</span><span class="n">unk_token</span><span class="p">,</span>
            <span class="n">bos_token</span><span class="o">=</span><span class="n">bos_token</span><span class="p">,</span>
            <span class="n">eos_token</span><span class="o">=</span><span class="n">eos_token</span><span class="p">,</span>
            <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">backend_tokenizer</span><span class="o">.</span><span class="n">pre_tokenizer</span><span class="p">,</span> <span class="n">pre_tokenizers</span><span class="o">.</span><span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The `backend_tokenizer` provided does not match the expected format. The CLIP tokenizer has been&quot;</span>
                <span class="s2">&quot; heavily modified from transformers version 4.17.0. You need to convert the tokenizer you are using&quot;</span>
                <span class="s2">&quot; to be compatible with this version.The easiest way to do so is&quot;</span>
                <span class="s1">&#39; `CLIPTokenizerFast.from_pretrained(&quot;path_to_local_folder_or_hub_repo, from_slow=True)`. If you want&#39;</span>
                <span class="s2">&quot; to use your existing tokenizer, you will have to revert to a version prior to 4.17.0 of&quot;</span>
                <span class="s2">&quot; transformers.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_wrap_decode_method_backend_tokenizer</span><span class="p">()</span>

    <span class="c1"># Very ugly hack to enable padding to have a correct decoding see https://github.com/huggingface/tokenizers/issues/872</span>
    <span class="k">def</span> <span class="nf">_wrap_decode_method_backend_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method &#39;_wrap_decode_method_backend_tokenizer&#39; is a private method within the &#39;CLIPTokenizerFast&#39; class.</span>
<span class="sd">        It wraps the &#39;decode&#39; method of the backend tokenizer by modifying its behavior.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (CLIPTokenizerFast): The instance of the CLIPTokenizerFast class itself.</span>
<span class="sd">                It is used to access the backend_tokenizer attribute and modify the decode method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None: This method does not return any value explicitly,</span>
<span class="sd">                but it modifies the behavior of the &#39;decode&#39; method of the backend tokenizer.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None: However, potential exceptions that could be raised during the execution of the modified &#39;decode&#39;</span>
<span class="sd">                method of the backend tokenizer should be handled within that method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">orig_decode_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend_tokenizer</span><span class="o">.</span><span class="n">decode</span>

        <span class="k">def</span> <span class="nf">new_decode_method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">orig_decode_method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">backend_tokenizer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">end_of_word_suffix</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">text</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">backend_tokenizer</span><span class="o">.</span><span class="n">decode</span> <span class="o">=</span> <span class="n">new_decode_method</span>

    <span class="k">def</span> <span class="nf">build_inputs_with_special_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and</span>
<span class="sd">        adding special tokens. A CLIP sequence has the following format:</span>

<span class="sd">        - single sequence: `&lt;|startoftext|&gt; X &lt;|endoftext|&gt;`</span>

<span class="sd">        Pairs of sequences are not the expected use case, but they will be handled without a separator.</span>

<span class="sd">        Args:</span>
<span class="sd">            token_ids_0 (`List[int]`):</span>
<span class="sd">                List of IDs to which the special tokens will be added.</span>
<span class="sd">            token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">                Optional second list of IDs for sequence pairs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `List[int]`: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]</span>
        <span class="n">eos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span>
        <span class="k">return</span> <span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">eos_token</span>

    <span class="k">def</span> <span class="nf">create_token_type_ids_from_sequences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a mask from the two sequences passed. CLIP does not make use of token type ids, therefore a list of</span>
<span class="sd">        zeros is returned.</span>

<span class="sd">        Args:</span>
<span class="sd">            token_ids_0 (`List[int]`):</span>
<span class="sd">                List of IDs.</span>
<span class="sd">            token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">                Optional second list of IDs for sequence pairs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `List[int]`: List of zeros.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]</span>
        <span class="n">eos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">eos_token</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">save_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the vocabulary generated by the CLIPTokenizerFast model to the specified directory.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (CLIPTokenizerFast): The instance of the CLIPTokenizerFast class.</span>
<span class="sd">            save_directory (str): The directory where the vocabulary files will be saved.</span>
<span class="sd">            filename_prefix (Optional[str], optional): An optional prefix to be included in the saved filenames.</span>
<span class="sd">                Default is None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[str]: A tuple containing the filenames of the saved vocabulary files.</span>

<span class="sd">        Raises:</span>
<span class="sd">            This method does not raise any exceptions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">filename_prefix</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip_fast</span><span class="o">.</span><span class="n">CLIPTokenizerFast</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">merges_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unk_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">,</span> <span class="n">bos_token</span><span class="o">=</span><span class="s1">&#39;&lt;|startoftext|&gt;&#39;</span><span class="p">,</span> <span class="n">eos_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize the CLIPTokenizerFast class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the CLIPTokenizerFast class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>object</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vocab_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Path to the vocabulary file. Default is None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>merges_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Path to the merges file. Default is None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer_file</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Path to the tokenizer file. Default is None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>unk_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The unknown token. Default is 'endoftext'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bos_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The beginning of sequence token. Default is '&lt;|startoftext|&gt;'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|startoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eos_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The end of sequence token. Default is 'endoftext'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_token</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The padding token. Default is 'endoftext'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;&lt;|endoftext|&gt;&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>Raised if the backend tokenizer pre_tokenizer does not match the expected format.
The CLIP tokenizer in this version has been heavily modified from transformers version 4.17.0. To
resolve this issue, convert the existing tokenizer to be compatible with this version using
<code>CLIPTokenizerFast.from_pretrained("path_to_local_folder_or_hub_repo", from_slow=True)</code>.
If using an older tokenizer version, revert to a version prior to 4.17.0 of transformers.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip_fast.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">vocab_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">merges_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">tokenizer_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
    <span class="n">bos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">,</span>
    <span class="n">eos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
    <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>  <span class="c1"># hack to enable padding</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize the CLIPTokenizerFast class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (object): The instance of the CLIPTokenizerFast class.</span>
<span class="sd">        vocab_file (str, optional): Path to the vocabulary file. Default is None.</span>
<span class="sd">        merges_file (str, optional): Path to the merges file. Default is None.</span>
<span class="sd">        tokenizer_file (str, optional): Path to the tokenizer file. Default is None.</span>
<span class="sd">        unk_token (str, optional): The unknown token. Default is &#39;endoftext&#39;.</span>
<span class="sd">        bos_token (str, optional): The beginning of sequence token. Default is &#39;&lt;|startoftext|&gt;&#39;.</span>
<span class="sd">        eos_token (str, optional): The end of sequence token. Default is &#39;endoftext&#39;.</span>
<span class="sd">        pad_token (str, optional): The padding token. Default is &#39;endoftext&#39;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: Raised if the backend tokenizer pre_tokenizer does not match the expected format.</span>
<span class="sd">            The CLIP tokenizer in this version has been heavily modified from transformers version 4.17.0. To</span>
<span class="sd">            resolve this issue, convert the existing tokenizer to be compatible with this version using</span>
<span class="sd">            `CLIPTokenizerFast.from_pretrained(&quot;path_to_local_folder_or_hub_repo&quot;, from_slow=True)`.</span>
<span class="sd">            If using an older tokenizer version, revert to a version prior to 4.17.0 of transformers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">vocab_file</span><span class="p">,</span>
        <span class="n">merges_file</span><span class="p">,</span>
        <span class="n">tokenizer_file</span><span class="o">=</span><span class="n">tokenizer_file</span><span class="p">,</span>
        <span class="n">unk_token</span><span class="o">=</span><span class="n">unk_token</span><span class="p">,</span>
        <span class="n">bos_token</span><span class="o">=</span><span class="n">bos_token</span><span class="p">,</span>
        <span class="n">eos_token</span><span class="o">=</span><span class="n">eos_token</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">backend_tokenizer</span><span class="o">.</span><span class="n">pre_tokenizer</span><span class="p">,</span> <span class="n">pre_tokenizers</span><span class="o">.</span><span class="n">Sequence</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The `backend_tokenizer` provided does not match the expected format. The CLIP tokenizer has been&quot;</span>
            <span class="s2">&quot; heavily modified from transformers version 4.17.0. You need to convert the tokenizer you are using&quot;</span>
            <span class="s2">&quot; to be compatible with this version.The easiest way to do so is&quot;</span>
            <span class="s1">&#39; `CLIPTokenizerFast.from_pretrained(&quot;path_to_local_folder_or_hub_repo, from_slow=True)`. If you want&#39;</span>
            <span class="s2">&quot; to use your existing tokenizer, you will have to revert to a version prior to 4.17.0 of&quot;</span>
            <span class="s2">&quot; transformers.&quot;</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_wrap_decode_method_backend_tokenizer</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.build_inputs_with_special_tokens" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip_fast</span><span class="o">.</span><span class="n">CLIPTokenizerFast</span><span class="o">.</span><span class="n">build_inputs_with_special_tokens</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">,</span> <span class="n">token_ids_1</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.build_inputs_with_special_tokens" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A CLIP sequence has the following format:</p>
<ul>
<li>single sequence: <code>&lt;|startoftext|&gt; X &lt;|endoftext|&gt;</code></li>
</ul>
<p>Pairs of sequences are not the expected use case, but they will be handled without a separator.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_0</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of IDs to which the special tokens will be added.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_1</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional second list of IDs for sequence pairs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.List">List</span>[int]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>List[int]</code>: List of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip_fast.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">build_inputs_with_special_tokens</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and</span>
<span class="sd">    adding special tokens. A CLIP sequence has the following format:</span>

<span class="sd">    - single sequence: `&lt;|startoftext|&gt; X &lt;|endoftext|&gt;`</span>

<span class="sd">    Pairs of sequences are not the expected use case, but they will be handled without a separator.</span>

<span class="sd">    Args:</span>
<span class="sd">        token_ids_0 (`List[int]`):</span>
<span class="sd">            List of IDs to which the special tokens will be added.</span>
<span class="sd">        token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">            Optional second list of IDs for sequence pairs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `List[int]`: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]</span>
    <span class="n">eos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span>
    <span class="k">return</span> <span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">eos_token</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.create_token_type_ids_from_sequences" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip_fast</span><span class="o">.</span><span class="n">CLIPTokenizerFast</span><span class="o">.</span><span class="n">create_token_type_ids_from_sequences</span><span class="p">(</span><span class="n">token_ids_0</span><span class="p">,</span> <span class="n">token_ids_1</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.create_token_type_ids_from_sequences" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Create a mask from the two sequences passed. CLIP does not make use of token type ids, therefore a list of
zeros is returned.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_0</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of IDs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_ids_1</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional second list of IDs for sequence pairs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.List">List</span>[int]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>List[int]</code>: List of zeros.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip_fast.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">create_token_type_ids_from_sequences</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">token_ids_0</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">token_ids_1</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a mask from the two sequences passed. CLIP does not make use of token type ids, therefore a list of</span>
<span class="sd">    zeros is returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        token_ids_0 (`List[int]`):</span>
<span class="sd">            List of IDs.</span>
<span class="sd">        token_ids_1 (`List[int]`, *optional*):</span>
<span class="sd">            Optional second list of IDs for sequence pairs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `List[int]`: List of zeros.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]</span>
    <span class="n">eos_token</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">token_ids_1</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">bos_token</span> <span class="o">+</span> <span class="n">token_ids_0</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">eos_token</span> <span class="o">+</span> <span class="n">token_ids_1</span> <span class="o">+</span> <span class="n">eos_token</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.save_vocabulary" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clip</span><span class="o">.</span><span class="n">tokenization_clip_fast</span><span class="o">.</span><span class="n">CLIPTokenizerFast</span><span class="o">.</span><span class="n">save_vocabulary</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast.save_vocabulary" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save the vocabulary generated by the CLIPTokenizerFast model to the specified directory.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the CLIPTokenizerFast class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast" href="#mindnlp.transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast">CLIPTokenizerFast</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>save_directory</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The directory where the vocabulary files will be saved.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>filename_prefix</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An optional prefix to be included in the saved filenames.
Default is None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[str]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="typing.Tuple">Tuple</span>[str]</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Tuple[str]: A tuple containing the filenames of the saved vocabulary files.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\clip\tokenization_clip_fast.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save the vocabulary generated by the CLIPTokenizerFast model to the specified directory.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (CLIPTokenizerFast): The instance of the CLIPTokenizerFast class.</span>
<span class="sd">        save_directory (str): The directory where the vocabulary files will be saved.</span>
<span class="sd">        filename_prefix (Optional[str], optional): An optional prefix to be included in the saved filenames.</span>
<span class="sd">            Default is None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[str]: A tuple containing the filenames of the saved vocabulary files.</span>

<span class="sd">    Raises:</span>
<span class="sd">        This method does not raise any exceptions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">files</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">filename_prefix</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../chatglm3/" class="md-footer__link md-footer__link--prev" aria-label="Previous: chatglm3">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                chatglm3
              </div>
            </div>
          </a>
        
        
          
          <a href="../codegen/" class="md-footer__link md-footer__link--next" aria-label="Next: codegen">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                codegen
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 - 2024 MindSpore Lab and CQU NLP Team.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:lvyufeng@cqu.edu.cn" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindnlp" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/lu-yu-feng-46-1" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top", "navigation.footer", "navigation.path", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>