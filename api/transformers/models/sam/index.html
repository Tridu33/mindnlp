
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../rwkv/">
      
      
        <link rel="next" href="../seamless_m4t/">
      
      
      <link rel="icon" href="../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.44">
    
    
      
        <title>sam - MindNLP Docs</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#mindnlp.transformers.models.sam.configuration_sam" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="MindNLP Docs" class="md-header__button md-logo" aria-label="MindNLP Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindNLP Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              sam
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../../../zh/api/transformers/models/sam/" hreflang="zh" class="md-select__link">
              中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindnlp
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../tutorials/quick_start/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../supported_models/" class="md-tabs__link">
        
  
    
  
  Supported Models

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../contribute/" class="md-tabs__link">
        
  
    
  
  How-To Contribute

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../accelerate/" class="md-tabs__link">
          
  
    
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../notes/changelog/" class="md-tabs__link">
          
  
    
  
  Notes

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="MindNLP Docs" class="md-nav__button md-logo" aria-label="MindNLP Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    MindNLP Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindnlp" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindnlp
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/quick_start/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/data_preprocess/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Preprocess
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/use_trainer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Trainer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tutorials/use_mirror/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Mirror
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../supported_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supported Models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../contribute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How-To Contribute
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../accelerate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/load_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    load_dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/BaseMapFunction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BaseMapFunction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/transforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transforms
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Engine
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            Engine
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4_1" >
        
          
          <label class="md-nav__link" for="__nav_5_4_1" id="__nav_5_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    train_args
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4_1">
            <span class="md-nav__icon md-icon"></span>
            train_args
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/train_args/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/train_args/seq2seq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seq2seq
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4_2" >
        
          
          <label class="md-nav__link" for="__nav_5_4_2" id="__nav_5_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    trainer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4_2">
            <span class="md-nav__icon md-icon"></span>
            trainer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/trainer/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/trainer/default_func/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    default_func
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/callbacks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    callbacks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/export/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    export
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../engine/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../modules/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modules
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../parallel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parallel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../peft/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            PEFT
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_2" >
        
          
          <label class="md-nav__link" for="__nav_5_7_2" id="__nav_5_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    tuners
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_2">
            <span class="md-nav__icon md-icon"></span>
            tuners
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/adalora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AdaLoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/adaption_prompt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adaption_Prompt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/ia3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IA3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/lokr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoKr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/tuners/prompt_tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prompt tuning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_3" >
        
          
          <label class="md-nav__link" for="__nav_5_7_3" id="__nav_5_7_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_3">
            <span class="md-nav__icon md-icon"></span>
            utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/utils/merge_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    merge_utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/mapping/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mapping
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../peft/peft_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    peft_model
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sentence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentence
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_2" >
        
          
          <label class="md-nav__link" for="__nav_5_9_2" id="__nav_5_9_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    generation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_2">
            <span class="md-nav__icon md-icon"></span>
            generation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transforemrs/generation/index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/beam_constraints/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_constraints
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/logits_process/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    logits_process
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/stopping_criteria/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    stopping_criteria
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/streamers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    streamers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../generation/utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    models
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_9_3" id="__nav_5_9_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_9_3">
            <span class="md-nav__icon md-icon"></span>
            models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../albert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    albert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../align/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    align
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../altclip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    altclip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../audio_spectrogram_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    audio_spectrogram_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../auto/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    auto
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    autoformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../baichuan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    baichuan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../barthez/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    barthez
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bartpho/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bartpho
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../beit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bert_japanese/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bert_japanese
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bertweet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bertweet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bge_m3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bge_m3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../big_bird/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    big_bird
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bigbird_pegasus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bigbird_pegasus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../biogpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    biogpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blenderbot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blenderbot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blenderbot_small/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blenderbot_small
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    blip_2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bloom
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bridgetower/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bridgetower
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bros/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bros
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../byt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    byt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../camembert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    camembert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../canine/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    canine
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chatglm3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chatglm3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    clip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../codegen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    codegen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cogvlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cogvlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cohere/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cohere
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convbert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convbert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convnext/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    convnext
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpmant/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpmant
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpmbee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cpmbee
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ctrl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctrl
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cvt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cvt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data2vec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data2vec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    deberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deberta_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    deberta_v2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../decision_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decision_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../distilbert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    distilbert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../efficientformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    efficientformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../efficientnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    efficientnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../electra/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    electra
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encodec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encodec
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ernie/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ernie
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ernie_m/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ernie_m
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../esm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    esm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    falcon
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../flava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    flava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../funnel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    funnel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gemma
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../git/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    git
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_bigcode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_bigcode
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neox/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neox
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_neox_japanese/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_neox_japanese
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gpt_pangu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gpt_pangu
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gptj/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    gptj
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../graphormer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    graphormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../groupvit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    groupvit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hubert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hubert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../imagegpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    imagegpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../internlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    internlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jetmoe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    jetmoe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../layoutlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    layoutlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../layoutlmv2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    layoutlmv2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../led/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    led
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llama
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llava_next/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    llava_next
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../longformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    longformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../longt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    longt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../luke/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    luke
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../marian/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    marian
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../maskformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    maskformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mbart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mbart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    megatron_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron_gpt2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    megatron_gpt2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../minicpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    minicpm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../minigpt4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    minigpt4
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mistral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mixtral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mixtral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mobilebert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mobilebert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mobilevit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mobilevit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../moss/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    moss
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mpnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mpnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mt5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mt5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../musicgen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    musicgen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../musicgen_melody/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    musicgen_melody
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mvp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mvp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nezha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nezha
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nystromformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nystromformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../olmo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    olmo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../openelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    openelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../opt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    opt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../owlvit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    owlvit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pegasus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pegasus
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phi
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phi3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../poolformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    poolformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pop2piano/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pop2piano
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../qwen2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    qwen2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../qwen2_moe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    qwen2_moe
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    reformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rembert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rembert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../resnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    resnet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roc_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    roc_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rwkv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    rwkv
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    sam
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    sam
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam" class="md-nav__link">
    <span class="md-ellipsis">
      configuration_sam
    </span>
  </a>
  
    <nav class="md-nav" aria-label="configuration_sam">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamConfig" class="md-nav__link">
    <span class="md-ellipsis">
      SamConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig" class="md-nav__link">
    <span class="md-ellipsis">
      SamMaskDecoderConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamMaskDecoderConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig" class="md-nav__link">
    <span class="md-ellipsis">
      SamPromptEncoderConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamPromptEncoderConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig" class="md-nav__link">
    <span class="md-ellipsis">
      SamVisionConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamVisionConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam" class="md-nav__link">
    <span class="md-ellipsis">
      image_processing_sam
    </span>
  </a>
  
    <nav class="md-nav" aria-label="image_processing_sam">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      SamImageProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamImageProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.filter_masks" class="md-nav__link">
    <span class="md-ellipsis">
      filter_masks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.generate_crop_boxes" class="md-nav__link">
    <span class="md-ellipsis">
      generate_crop_boxes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.pad_image" class="md-nav__link">
    <span class="md-ellipsis">
      pad_image
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.post_process_for_mask_generation" class="md-nav__link">
    <span class="md-ellipsis">
      post_process_for_mask_generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.post_process_masks" class="md-nav__link">
    <span class="md-ellipsis">
      post_process_masks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.preprocess" class="md-nav__link">
    <span class="md-ellipsis">
      preprocess
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.resize" class="md-nav__link">
    <span class="md-ellipsis">
      resize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.batched_nms" class="md-nav__link">
    <span class="md-ellipsis">
      batched_nms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.nms" class="md-nav__link">
    <span class="md-ellipsis">
      nms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam" class="md-nav__link">
    <span class="md-ellipsis">
      modeling_sam
    </span>
  </a>
  
    <nav class="md-nav" aria-label="modeling_sam">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SamAttention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamImageSegmentationOutput" class="md-nav__link">
    <span class="md-ellipsis">
      SamImageSegmentationOutput
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamLayerNorm" class="md-nav__link">
    <span class="md-ellipsis">
      SamLayerNorm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder" class="md-nav__link">
    <span class="md-ellipsis">
      SamMaskDecoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamMaskDecoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel" class="md-nav__link">
    <span class="md-ellipsis">
      SamModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.get_image_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_image_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.get_prompt_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_prompt_embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPatchEmbeddings" class="md-nav__link">
    <span class="md-ellipsis">
      SamPatchEmbeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding" class="md-nav__link">
    <span class="md-ellipsis">
      SamPositionalEmbedding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamPositionalEmbedding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      SamPromptEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamPromptEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock" class="md-nav__link">
    <span class="md-ellipsis">
      SamTwoWayAttentionBlock
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamTwoWayAttentionBlock">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SamVisionAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamVisionAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention.add_decomposed_rel_pos" class="md-nav__link">
    <span class="md-ellipsis">
      add_decomposed_rel_pos
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention.get_rel_pos" class="md-nav__link">
    <span class="md-ellipsis">
      get_rel_pos
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionEncoderOutput" class="md-nav__link">
    <span class="md-ellipsis">
      SamVisionEncoderOutput
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer" class="md-nav__link">
    <span class="md-ellipsis">
      SamVisionLayer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamVisionLayer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer.window_partition" class="md-nav__link">
    <span class="md-ellipsis">
      window_partition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer.window_unpartition" class="md-nav__link">
    <span class="md-ellipsis">
      window_unpartition
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam" class="md-nav__link">
    <span class="md-ellipsis">
      processing_sam
    </span>
  </a>
  
    <nav class="md-nav" aria-label="processing_sam">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      SamProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.model_input_names" class="md-nav__link">
    <span class="md-ellipsis">
      model_input_names
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.post_process_masks" class="md-nav__link">
    <span class="md-ellipsis">
      post_process_masks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seamless_m4t/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seamless_m4t
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seamless_m4t_v2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seamless_m4t_v2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../segformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    segformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seggpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    seggpt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speech_encoder_decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_encoder_decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speech_to_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_to_text
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../squeezebert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    squeezebert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stablelm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    stablelm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    starcoder2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../swiftformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    swiftformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../switch_transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    switch_transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    t5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../table_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    table_transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../timesformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    timesformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tinybert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tinybert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../van/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    van
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vipllava/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vipllava
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vision_text_dual_encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vision_text_dual_encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../visual_bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    visual_bert
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2_conformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2_conformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2_with_lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wav2vec2_with_lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wavlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../whisper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    whisper
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../x_clip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    x_clip
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm_roberta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm_roberta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlm_roberta_xl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlm_roberta_xl
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xlnet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9_4" >
        
          
          <label class="md-nav__link" for="__nav_5_9_4" id="__nav_5_9_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_9_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9_4">
            <span class="md-nav__icon md-icon"></span>
            pipeline
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../transforemrs/pipeline/index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/automatic_speech_recognition/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    automatic_speech_recognition
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/document_question_answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    document_question_answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/fill_mask/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fill_mask
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pipeline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/question_answering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    question_answering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text2text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text2text_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/text_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipeline/zero_shot_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    zero_shot_classification
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../configuration_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    configuration_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modeling_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    modeling_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils_base/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils_base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization_utils_fast/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tokenization_utils_fast
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../trl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TRL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Notes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/changelog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Change Log
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/code_of_conduct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code of Conduct
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notes/faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam" class="md-nav__link">
    <span class="md-ellipsis">
      configuration_sam
    </span>
  </a>
  
    <nav class="md-nav" aria-label="configuration_sam">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamConfig" class="md-nav__link">
    <span class="md-ellipsis">
      SamConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig" class="md-nav__link">
    <span class="md-ellipsis">
      SamMaskDecoderConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamMaskDecoderConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig" class="md-nav__link">
    <span class="md-ellipsis">
      SamPromptEncoderConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamPromptEncoderConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig" class="md-nav__link">
    <span class="md-ellipsis">
      SamVisionConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamVisionConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam" class="md-nav__link">
    <span class="md-ellipsis">
      image_processing_sam
    </span>
  </a>
  
    <nav class="md-nav" aria-label="image_processing_sam">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      SamImageProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamImageProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.filter_masks" class="md-nav__link">
    <span class="md-ellipsis">
      filter_masks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.generate_crop_boxes" class="md-nav__link">
    <span class="md-ellipsis">
      generate_crop_boxes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.pad_image" class="md-nav__link">
    <span class="md-ellipsis">
      pad_image
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.post_process_for_mask_generation" class="md-nav__link">
    <span class="md-ellipsis">
      post_process_for_mask_generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.post_process_masks" class="md-nav__link">
    <span class="md-ellipsis">
      post_process_masks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.preprocess" class="md-nav__link">
    <span class="md-ellipsis">
      preprocess
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.resize" class="md-nav__link">
    <span class="md-ellipsis">
      resize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.batched_nms" class="md-nav__link">
    <span class="md-ellipsis">
      batched_nms
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.image_processing_sam.nms" class="md-nav__link">
    <span class="md-ellipsis">
      nms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam" class="md-nav__link">
    <span class="md-ellipsis">
      modeling_sam
    </span>
  </a>
  
    <nav class="md-nav" aria-label="modeling_sam">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SamAttention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamImageSegmentationOutput" class="md-nav__link">
    <span class="md-ellipsis">
      SamImageSegmentationOutput
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamLayerNorm" class="md-nav__link">
    <span class="md-ellipsis">
      SamLayerNorm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder" class="md-nav__link">
    <span class="md-ellipsis">
      SamMaskDecoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamMaskDecoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel" class="md-nav__link">
    <span class="md-ellipsis">
      SamModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.get_image_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_image_embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.get_prompt_embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      get_prompt_embeddings
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPatchEmbeddings" class="md-nav__link">
    <span class="md-ellipsis">
      SamPatchEmbeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding" class="md-nav__link">
    <span class="md-ellipsis">
      SamPositionalEmbedding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamPositionalEmbedding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      SamPromptEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamPromptEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock" class="md-nav__link">
    <span class="md-ellipsis">
      SamTwoWayAttentionBlock
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamTwoWayAttentionBlock">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SamVisionAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamVisionAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention.add_decomposed_rel_pos" class="md-nav__link">
    <span class="md-ellipsis">
      add_decomposed_rel_pos
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention.get_rel_pos" class="md-nav__link">
    <span class="md-ellipsis">
      get_rel_pos
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionEncoderOutput" class="md-nav__link">
    <span class="md-ellipsis">
      SamVisionEncoderOutput
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer" class="md-nav__link">
    <span class="md-ellipsis">
      SamVisionLayer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamVisionLayer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer.window_partition" class="md-nav__link">
    <span class="md-ellipsis">
      window_partition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer.window_unpartition" class="md-nav__link">
    <span class="md-ellipsis">
      window_unpartition
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam" class="md-nav__link">
    <span class="md-ellipsis">
      processing_sam
    </span>
  </a>
  
    <nav class="md-nav" aria-label="processing_sam">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor" class="md-nav__link">
    <span class="md-ellipsis">
      SamProcessor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SamProcessor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.model_input_names" class="md-nav__link">
    <span class="md-ellipsis">
      model_input_names
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.post_process_masks" class="md-nav__link">
    <span class="md-ellipsis">
      post_process_masks
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/mindspore-lab/mindnlp/edit/master/docs/en/api/transformers/models/sam.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindnlp/raw/master/docs/en/api/transformers/models/sam.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


  <h1>sam</h1>

<div class="doc doc-object doc-module">



<h2 id="mindnlp.transformers.models.sam.configuration_sam" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.configuration_sam</code>


<a href="#mindnlp.transformers.models.sam.configuration_sam" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>SAM model configuration</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.configuration_sam.SamConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.configuration_sam.SamConfig</code>


<a href="#mindnlp.transformers.models.sam.configuration_sam.SamConfig" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code></p>


        <p>[<code>SamConfig</code>] is the configuration class to store the configuration of a [<code>SamModel</code>]. It is used to instantiate a
SAM model according to the specified arguments, defining the vision model, prompt-encoder model and mask decoder
configs. Instantiating a configuration with the defaults will yield a similar configuration to that of the
SAM-ViT-H <a href="https://huggingface.co/facebook/sam-vit-huge">facebook/sam-vit-huge</a> architecture.</p>
<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the
documentation from [<code>PretrainedConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>vision_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary of configuration options used to initialize [<code>SamVisionConfig</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>Union[`dict`, `SamVisionConfig`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt_encoder_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary of configuration options used to initialize [<code>SamPromptEncoderConfig</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>Union[`dict`, `SamPromptEncoderConfig`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_decoder_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary of configuration options used to initialize [<code>SamMaskDecoderConfig</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>Union[`dict`, `SamMaskDecoderConfig`], *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary of keyword arguments.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>*optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<details class="example" open>
  <summary>Example</summary>
  <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
<span class="o">...</span>     <span class="n">SamVisionConfig</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">SamPromptEncoderConfig</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">SamMaskDecoderConfig</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">SamModel</span><span class="p">,</span>
<span class="o">...</span> <span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a SamConfig with `&quot;facebook/sam-vit-huge&quot;` style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">SamConfig</span><span class="p">()</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing a SamModel (with random weights) from the `&quot;facebook/sam-vit-huge&quot;` style configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">SamModel</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Accessing the model configuration</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">configuration</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># We can also initialize a SamConfig from a SamVisionConfig, SamPromptEncoderConfig, and SamMaskDecoderConfig</span>
<span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Initializing SAM vision, SAM Q-Former and language model configurations</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">vision_config</span> <span class="o">=</span> <span class="n">SamVisionConfig</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">prompt_encoder_config</span> <span class="o">=</span> <span class="n">SamPromptEncoderConfig</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mask_decoder_config</span> <span class="o">=</span> <span class="n">SamMaskDecoderConfig</span><span class="p">()</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">config</span> <span class="o">=</span> <span class="n">SamConfig</span><span class="p">(</span><span class="n">vision_config</span><span class="p">,</span> <span class="n">prompt_encoder_config</span><span class="p">,</span> <span class="n">mask_decoder_config</span><span class="p">)</span>
</code></pre></div>
</details>





              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\configuration_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    [`SamConfig`] is the configuration class to store the configuration of a [`SamModel`]. It is used to instantiate a</span>
<span class="sd">    SAM model according to the specified arguments, defining the vision model, prompt-encoder model and mask decoder</span>
<span class="sd">    configs. Instantiating a configuration with the defaults will yield a similar configuration to that of the</span>
<span class="sd">    SAM-ViT-H [facebook/sam-vit-huge](https://huggingface.co/facebook/sam-vit-huge) architecture.</span>

<span class="sd">    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the</span>
<span class="sd">    documentation from [`PretrainedConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        vision_config (Union[`dict`, `SamVisionConfig`], *optional*):</span>
<span class="sd">            Dictionary of configuration options used to initialize [`SamVisionConfig`].</span>
<span class="sd">        prompt_encoder_config (Union[`dict`, `SamPromptEncoderConfig`], *optional*):</span>
<span class="sd">            Dictionary of configuration options used to initialize [`SamPromptEncoderConfig`].</span>
<span class="sd">        mask_decoder_config (Union[`dict`, `SamMaskDecoderConfig`], *optional*):</span>
<span class="sd">            Dictionary of configuration options used to initialize [`SamMaskDecoderConfig`].</span>

<span class="sd">        kwargs (*optional*):</span>
<span class="sd">            Dictionary of keyword arguments.</span>

<span class="sd">    Example:</span>
<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from transformers import (</span>
<span class="sd">        ...     SamVisionConfig,</span>
<span class="sd">        ...     SamPromptEncoderConfig,</span>
<span class="sd">        ...     SamMaskDecoderConfig,</span>
<span class="sd">        ...     SamModel,</span>
<span class="sd">        ... )</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a SamConfig with `&quot;facebook/sam-vit-huge&quot;` style configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = SamConfig()</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing a SamModel (with random weights) from the `&quot;facebook/sam-vit-huge&quot;` style configuration</span>
<span class="sd">        &gt;&gt;&gt; model = SamModel(configuration)</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Accessing the model configuration</span>
<span class="sd">        &gt;&gt;&gt; configuration = model.config</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # We can also initialize a SamConfig from a SamVisionConfig, SamPromptEncoderConfig, and SamMaskDecoderConfig</span>
<span class="sd">        ...</span>
<span class="sd">        &gt;&gt;&gt; # Initializing SAM vision, SAM Q-Former and language model configurations</span>
<span class="sd">        &gt;&gt;&gt; vision_config = SamVisionConfig()</span>
<span class="sd">        &gt;&gt;&gt; prompt_encoder_config = SamPromptEncoderConfig()</span>
<span class="sd">        &gt;&gt;&gt; mask_decoder_config = SamMaskDecoderConfig()</span>

<span class="sd">        &gt;&gt;&gt; config = SamConfig(vision_config, prompt_encoder_config, mask_decoder_config)</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;sam&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vision_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_encoder_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mask_decoder_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a new instance of the SamConfig class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The current instance of the SamConfig class.</span>
<span class="sd">            vision_config (SamVisionConfig or None): The configuration for vision. If provided,</span>
<span class="sd">                it should be an instance of SamVisionConfig. Defaults to None.</span>
<span class="sd">            prompt_encoder_config (SamPromptEncoderConfig or None): The configuration for prompt encoder.</span>
<span class="sd">                If provided, it should be an instance of SamPromptEncoderConfig. Defaults to None.</span>
<span class="sd">            mask_decoder_config (SamMaskDecoderConfig or None): The configuration for mask decoder.</span>
<span class="sd">                If provided, it should be an instance of SamMaskDecoderConfig. Defaults to None.</span>
<span class="sd">            initializer_range (float): The range for weight initialization. Defaults to 0.02.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">vision_config</span> <span class="o">=</span> <span class="n">vision_config</span> <span class="k">if</span> <span class="n">vision_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">prompt_encoder_config</span> <span class="o">=</span> <span class="n">prompt_encoder_config</span> <span class="k">if</span> <span class="n">prompt_encoder_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">mask_decoder_config</span> <span class="o">=</span> <span class="n">mask_decoder_config</span> <span class="k">if</span> <span class="n">mask_decoder_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vision_config</span><span class="p">,</span> <span class="n">SamVisionConfig</span><span class="p">):</span>
            <span class="n">vision_config</span> <span class="o">=</span> <span class="n">vision_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt_encoder_config</span><span class="p">,</span> <span class="n">SamPromptEncoderConfig</span><span class="p">):</span>
            <span class="n">prompt_encoder_config</span> <span class="o">=</span> <span class="n">prompt_encoder_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask_decoder_config</span><span class="p">,</span> <span class="n">SamMaskDecoderConfig</span><span class="p">):</span>
            <span class="n">mask_decoder_config</span> <span class="o">=</span> <span class="n">mask_decoder_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vision_config</span> <span class="o">=</span> <span class="n">SamVisionConfig</span><span class="p">(</span><span class="o">**</span><span class="n">vision_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_encoder_config</span> <span class="o">=</span> <span class="n">SamPromptEncoderConfig</span><span class="p">(</span><span class="o">**</span><span class="n">prompt_encoder_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_decoder_config</span> <span class="o">=</span> <span class="n">SamMaskDecoderConfig</span><span class="p">(</span><span class="o">**</span><span class="n">mask_decoder_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.configuration_sam.SamConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">configuration_sam</span><span class="o">.</span><span class="n">SamConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">vision_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_encoder_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask_decoder_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.configuration_sam.SamConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Initializes a new instance of the SamConfig class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The current instance of the SamConfig class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vision_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The configuration for vision. If provided,
it should be an instance of SamVisionConfig. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig" href="#mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig">SamVisionConfig</a> or None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt_encoder_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The configuration for prompt encoder.
If provided, it should be an instance of SamPromptEncoderConfig. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig" href="#mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig">SamPromptEncoderConfig</a> or None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_decoder_config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The configuration for mask decoder.
If provided, it should be an instance of SamMaskDecoderConfig. Defaults to None.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig" href="#mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig">SamMaskDecoderConfig</a> or None</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_range</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The range for weight initialization. Defaults to 0.02.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.02</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\configuration_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">vision_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">prompt_encoder_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mask_decoder_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initializer_range</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a new instance of the SamConfig class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The current instance of the SamConfig class.</span>
<span class="sd">        vision_config (SamVisionConfig or None): The configuration for vision. If provided,</span>
<span class="sd">            it should be an instance of SamVisionConfig. Defaults to None.</span>
<span class="sd">        prompt_encoder_config (SamPromptEncoderConfig or None): The configuration for prompt encoder.</span>
<span class="sd">            If provided, it should be an instance of SamPromptEncoderConfig. Defaults to None.</span>
<span class="sd">        mask_decoder_config (SamMaskDecoderConfig or None): The configuration for mask decoder.</span>
<span class="sd">            If provided, it should be an instance of SamMaskDecoderConfig. Defaults to None.</span>
<span class="sd">        initializer_range (float): The range for weight initialization. Defaults to 0.02.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">vision_config</span> <span class="o">=</span> <span class="n">vision_config</span> <span class="k">if</span> <span class="n">vision_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">prompt_encoder_config</span> <span class="o">=</span> <span class="n">prompt_encoder_config</span> <span class="k">if</span> <span class="n">prompt_encoder_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
    <span class="n">mask_decoder_config</span> <span class="o">=</span> <span class="n">mask_decoder_config</span> <span class="k">if</span> <span class="n">mask_decoder_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vision_config</span><span class="p">,</span> <span class="n">SamVisionConfig</span><span class="p">):</span>
        <span class="n">vision_config</span> <span class="o">=</span> <span class="n">vision_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt_encoder_config</span><span class="p">,</span> <span class="n">SamPromptEncoderConfig</span><span class="p">):</span>
        <span class="n">prompt_encoder_config</span> <span class="o">=</span> <span class="n">prompt_encoder_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask_decoder_config</span><span class="p">,</span> <span class="n">SamMaskDecoderConfig</span><span class="p">):</span>
        <span class="n">mask_decoder_config</span> <span class="o">=</span> <span class="n">mask_decoder_config</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">vision_config</span> <span class="o">=</span> <span class="n">SamVisionConfig</span><span class="p">(</span><span class="o">**</span><span class="n">vision_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prompt_encoder_config</span> <span class="o">=</span> <span class="n">SamPromptEncoderConfig</span><span class="p">(</span><span class="o">**</span><span class="n">prompt_encoder_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask_decoder_config</span> <span class="o">=</span> <span class="n">SamMaskDecoderConfig</span><span class="p">(</span><span class="o">**</span><span class="n">mask_decoder_config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig</code>


<a href="#mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code></p>


        <p>This is the configuration class to store the configuration of a [<code>SamMaskDecoder</code>]. It is used to instantiate a SAM
mask decoder to the specified arguments, defining the model architecture. Instantiating a configuration defaults
will yield a similar configuration to that of the SAM-vit-h
<a href="https://huggingface.co/facebook/sam-vit-huge">facebook/sam-vit-huge</a> architecture.</p>
<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the
documentation from [<code>PretrainedConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the hidden states.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 256</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>256</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The non-linear activation function used inside the <code>SamMaskDecoder</code> module.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;relu&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;relu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mlp_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the "intermediate" (i.e., feed-forward) layer in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 2048</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2048</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_hidden_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of hidden layers in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 2</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_attention_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of attention heads for each attention layer in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 8</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_downsample_rate</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The downsampling rate of the attention layer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 2</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_multimask_outputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of outputs from the <code>SamMaskDecoder</code> module. In the Segment Anything paper, this is set to 3.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 3</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iou_head_depth</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of layers in the IoU head module.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 3</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iou_head_hidden_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dimensionality of the hidden states in the IoU head module.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 256</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>256</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon used by the layer normalization layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1e-06</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-06</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\configuration_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamMaskDecoderConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the configuration class to store the configuration of a [`SamMaskDecoder`]. It is used to instantiate a SAM</span>
<span class="sd">    mask decoder to the specified arguments, defining the model architecture. Instantiating a configuration defaults</span>
<span class="sd">    will yield a similar configuration to that of the SAM-vit-h</span>
<span class="sd">    [facebook/sam-vit-huge](https://huggingface.co/facebook/sam-vit-huge) architecture.</span>

<span class="sd">    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the</span>
<span class="sd">    documentation from [`PretrainedConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        hidden_size (`int`, *optional*, defaults to 256):</span>
<span class="sd">            Dimensionality of the hidden states.</span>
<span class="sd">        hidden_act (`str`, *optional*, defaults to `&quot;relu&quot;`):</span>
<span class="sd">            The non-linear activation function used inside the `SamMaskDecoder` module.</span>
<span class="sd">        mlp_dim (`int`, *optional*, defaults to 2048):</span>
<span class="sd">            Dimensionality of the &quot;intermediate&quot; (i.e., feed-forward) layer in the Transformer encoder.</span>
<span class="sd">        num_hidden_layers (`int`, *optional*, defaults to 2):</span>
<span class="sd">            Number of hidden layers in the Transformer encoder.</span>
<span class="sd">        num_attention_heads (`int`, *optional*, defaults to 8):</span>
<span class="sd">            Number of attention heads for each attention layer in the Transformer encoder.</span>
<span class="sd">        attention_downsample_rate (`int`, *optional*, defaults to 2):</span>
<span class="sd">            The downsampling rate of the attention layer.</span>
<span class="sd">        num_multimask_outputs (`int`, *optional*, defaults to 3):</span>
<span class="sd">            The number of outputs from the `SamMaskDecoder` module. In the Segment Anything paper, this is set to 3.</span>
<span class="sd">        iou_head_depth (`int`, *optional*, defaults to 3):</span>
<span class="sd">            The number of layers in the IoU head module.</span>
<span class="sd">        iou_head_hidden_dim (`int`, *optional*, defaults to 256):</span>
<span class="sd">            The dimensionality of the hidden states in the IoU head module.</span>
<span class="sd">        layer_norm_eps (`float`, *optional*, defaults to 1e-06):</span>
<span class="sd">            The epsilon used by the layer normalization layers.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
        <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">attention_downsample_rate</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">num_multimask_outputs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">iou_head_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">iou_head_hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a new instance of the SamMaskDecoderConfig class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The object itself.</span>
<span class="sd">            hidden_size (int, optional): The size of the hidden layer. Default is 256.</span>
<span class="sd">            hidden_act (str, optional): The activation function to be used in the hidden layer. Default is &#39;relu&#39;.</span>
<span class="sd">            mlp_dim (int, optional): The dimension of the Multi-Layer Perceptron (MLP). Default is 2048.</span>
<span class="sd">            num_hidden_layers (int, optional): The number of hidden layers. Default is 2.</span>
<span class="sd">            num_attention_heads (int, optional): The number of attention heads. Default is 8.</span>
<span class="sd">            attention_downsample_rate (int, optional): The downsample rate for attention. Default is 2.</span>
<span class="sd">            num_multimask_outputs (int, optional): The number of outputs for multimask. Default is 3.</span>
<span class="sd">            iou_head_depth (int, optional): The depth of the Intersection over Union (IoU) head. Default is 3.</span>
<span class="sd">            iou_head_hidden_dim (int, optional): The hidden dimension of the IoU head. Default is 256.</span>
<span class="sd">            layer_norm_eps (float, optional): The epsilon value for layer normalization. Default is 1e-06.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Raises:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dim</span> <span class="o">=</span> <span class="n">mlp_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_downsample_rate</span> <span class="o">=</span> <span class="n">attention_downsample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_multimask_outputs</span> <span class="o">=</span> <span class="n">num_multimask_outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iou_head_depth</span> <span class="o">=</span> <span class="n">iou_head_depth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iou_head_hidden_dim</span> <span class="o">=</span> <span class="n">iou_head_hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">configuration_sam</span><span class="o">.</span><span class="n">SamMaskDecoderConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">hidden_act</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">attention_downsample_rate</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_multimask_outputs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">iou_head_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">iou_head_hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.configuration_sam.SamMaskDecoderConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Initializes a new instance of the SamMaskDecoderConfig class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The object itself.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the hidden layer. Default is 256.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>256</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The activation function to be used in the hidden layer. Default is 'relu'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;relu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mlp_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dimension of the Multi-Layer Perceptron (MLP). Default is 2048.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2048</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_hidden_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of hidden layers. Default is 2.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_attention_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of attention heads. Default is 8.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_downsample_rate</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The downsample rate for attention. Default is 2.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_multimask_outputs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of outputs for multimask. Default is 3.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iou_head_depth</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The depth of the Intersection over Union (IoU) head. Default is 3.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iou_head_hidden_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The hidden dimension of the IoU head. Default is 256.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>256</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon value for layer normalization. Default is 1e-06.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-06</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\configuration_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
    <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">attention_downsample_rate</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">num_multimask_outputs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">iou_head_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">iou_head_hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a new instance of the SamMaskDecoderConfig class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The object itself.</span>
<span class="sd">        hidden_size (int, optional): The size of the hidden layer. Default is 256.</span>
<span class="sd">        hidden_act (str, optional): The activation function to be used in the hidden layer. Default is &#39;relu&#39;.</span>
<span class="sd">        mlp_dim (int, optional): The dimension of the Multi-Layer Perceptron (MLP). Default is 2048.</span>
<span class="sd">        num_hidden_layers (int, optional): The number of hidden layers. Default is 2.</span>
<span class="sd">        num_attention_heads (int, optional): The number of attention heads. Default is 8.</span>
<span class="sd">        attention_downsample_rate (int, optional): The downsample rate for attention. Default is 2.</span>
<span class="sd">        num_multimask_outputs (int, optional): The number of outputs for multimask. Default is 3.</span>
<span class="sd">        iou_head_depth (int, optional): The depth of the Intersection over Union (IoU) head. Default is 3.</span>
<span class="sd">        iou_head_hidden_dim (int, optional): The hidden dimension of the IoU head. Default is 256.</span>
<span class="sd">        layer_norm_eps (float, optional): The epsilon value for layer normalization. Default is 1e-06.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Raises:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dim</span> <span class="o">=</span> <span class="n">mlp_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attention_downsample_rate</span> <span class="o">=</span> <span class="n">attention_downsample_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_multimask_outputs</span> <span class="o">=</span> <span class="n">num_multimask_outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">iou_head_depth</span> <span class="o">=</span> <span class="n">iou_head_depth</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">iou_head_hidden_dim</span> <span class="o">=</span> <span class="n">iou_head_hidden_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig</code>


<a href="#mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code></p>


        <p>This is the configuration class to store the configuration of a [<code>SamPromptEncoder</code>]. The [<code>SamPromptEncoder</code>]
module is used to encode the input 2D points and bounding boxes. Instantiating a configuration defaults will yield
a similar configuration to that of the SAM-vit-h
<a href="https://huggingface.co/facebook/sam-vit-huge">facebook/sam-vit-huge</a> architecture.</p>
<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the
documentation from [<code>PretrainedConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the hidden states.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 256</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>256</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The expected output resolution of the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1024</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>patch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size (resolution) of each patch.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 16</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>16</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_input_channels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of channels to be fed to the <code>MaskDecoder</code> module.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 16</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>16</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_point_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of point embeddings to be used.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 4</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>4</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The non-linear activation function in the encoder and pooler.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;gelu&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;gelu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\configuration_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamPromptEncoderConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the configuration class to store the configuration of a [`SamPromptEncoder`]. The [`SamPromptEncoder`]</span>
<span class="sd">    module is used to encode the input 2D points and bounding boxes. Instantiating a configuration defaults will yield</span>
<span class="sd">    a similar configuration to that of the SAM-vit-h</span>
<span class="sd">    [facebook/sam-vit-huge](https://huggingface.co/facebook/sam-vit-huge) architecture.</span>

<span class="sd">    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the</span>
<span class="sd">    documentation from [`PretrainedConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        hidden_size (`int`, *optional*, defaults to 256):</span>
<span class="sd">            Dimensionality of the hidden states.</span>
<span class="sd">        image_size (`int`, *optional*, defaults to 1024):</span>
<span class="sd">            The expected output resolution of the image.</span>
<span class="sd">        patch_size (`int`, *optional*, defaults to 16):</span>
<span class="sd">            The size (resolution) of each patch.</span>
<span class="sd">        mask_input_channels (`int`, *optional*, defaults to 16):</span>
<span class="sd">            The number of channels to be fed to the `MaskDecoder` module.</span>
<span class="sd">        num_point_embeddings (`int`, *optional*, defaults to 4):</span>
<span class="sd">            The number of point embeddings to be used.</span>
<span class="sd">        hidden_act (`str`, *optional*, defaults to `&quot;gelu&quot;`):</span>
<span class="sd">            The non-linear activation function in the encoder and pooler.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">image_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
        <span class="n">mask_input_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
        <span class="n">num_point_embeddings</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes an instance of the SamPromptEncoderConfig class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (SamPromptEncoderConfig): The instance of the class itself.</span>
<span class="sd">            hidden_size (int, optional): The size of the hidden state. Defaults to 256.</span>
<span class="sd">            image_size (int, optional): The size of the input image. Defaults to 1024.</span>
<span class="sd">            patch_size (int, optional): The size of each image patch. Defaults to 16.</span>
<span class="sd">            mask_input_channels (int, optional): The number of input channels for masking. Defaults to 16.</span>
<span class="sd">            num_point_embeddings (int, optional): The number of point embeddings. Defaults to 4.</span>
<span class="sd">            hidden_act (str, optional): The activation function for the hidden layers. Defaults to &#39;gelu&#39;.</span>
<span class="sd">            layer_norm_eps (float, optional): The epsilon value for layer normalization. Defaults to 1e-06.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        Raises:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_size</span> <span class="o">=</span> <span class="n">image_size</span> <span class="o">//</span> <span class="n">patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_input_channels</span> <span class="o">=</span> <span class="n">mask_input_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_point_embeddings</span> <span class="o">=</span> <span class="n">num_point_embeddings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">configuration_sam</span><span class="o">.</span><span class="n">SamPromptEncoderConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">mask_input_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_point_embeddings</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hidden_act</span><span class="o">=</span><span class="s1">&#39;gelu&#39;</span><span class="p">,</span> <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Initializes an instance of the SamPromptEncoderConfig class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the class itself.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig" href="#mindnlp.transformers.models.sam.configuration_sam.SamPromptEncoderConfig">SamPromptEncoderConfig</a></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the hidden state. Defaults to 256.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>256</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the input image. Defaults to 1024.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>patch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of each image patch. Defaults to 16.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>16</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_input_channels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of input channels for masking. Defaults to 16.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>16</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_point_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of point embeddings. Defaults to 4.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>4</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The activation function for the hidden layers. Defaults to 'gelu'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;gelu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon value for layer normalization. Defaults to 1e-06.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-06</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\configuration_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">mask_input_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_point_embeddings</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
    <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes an instance of the SamPromptEncoderConfig class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self (SamPromptEncoderConfig): The instance of the class itself.</span>
<span class="sd">        hidden_size (int, optional): The size of the hidden state. Defaults to 256.</span>
<span class="sd">        image_size (int, optional): The size of the input image. Defaults to 1024.</span>
<span class="sd">        patch_size (int, optional): The size of each image patch. Defaults to 16.</span>
<span class="sd">        mask_input_channels (int, optional): The number of input channels for masking. Defaults to 16.</span>
<span class="sd">        num_point_embeddings (int, optional): The number of point embeddings. Defaults to 4.</span>
<span class="sd">        hidden_act (str, optional): The activation function for the hidden layers. Defaults to &#39;gelu&#39;.</span>
<span class="sd">        layer_norm_eps (float, optional): The epsilon value for layer normalization. Defaults to 1e-06.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    Raises:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_size</span> <span class="o">=</span> <span class="n">image_size</span> <span class="o">//</span> <span class="n">patch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask_input_channels</span> <span class="o">=</span> <span class="n">mask_input_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_point_embeddings</span> <span class="o">=</span> <span class="n">num_point_embeddings</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig</code>


<a href="#mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.configuration_utils.PretrainedConfig" href="../../configuration_utils/#mindnlp.transformers.configuration_utils.PretrainedConfig">PretrainedConfig</a></code></p>


        <p>This is the configuration class to store the configuration of a [<code>SamVisionModel</code>]. It is used to instantiate a SAM
vision encoder according to the specified arguments, defining the model architecture. Instantiating a configuration
defaults will yield a similar configuration to that of the SAM ViT-h
<a href="https://huggingface.co/facebook/sam-vit-huge">facebook/sam-vit-huge</a> architecture.</p>
<p>Configuration objects inherit from [<code>PretrainedConfig</code>] and can be used to control the model outputs. Read the
documentation from [<code>PretrainedConfig</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the encoder layers and the pooler layer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 768</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>768</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_channels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimensionality of the output channels in the Patch Encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 256</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>256</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_hidden_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of hidden layers in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 12</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_attention_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of attention heads for each attention layer in the Transformer encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 12</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_channels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of channels in the input image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 3</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Expected resolution. Target size of the resized input image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1024</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>patch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the patches to be extracted from the input image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 16</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>16</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The non-linear activation function (function or string)</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;gelu&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;gelu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon used by the layer normalization layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1e-06</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-06</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dropout ratio for the attention probabilities.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_range</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1e-10</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-10</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>qkv_bias</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to add a bias to query, key, value projections.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mlp_ratio</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Ratio of mlp hidden dim to embedding dim.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 4.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>4.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_abs_pos</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use absolute position embedding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_rel_pos</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use relative position embedding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>window_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Window size for relative position.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 14</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>14</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>global_attn_indexes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The indexes of the global attention layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*, defaults to `[2, 5, 8, 11]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>[2, 5, 8, 11]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_pos_feats</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dimensionality of the position embedding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 128</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>128</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mlp_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dimensionality of the MLP layer in the Transformer encoder. If <code>None</code>, defaults to <code>mlp_ratio *
hidden_size</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\configuration_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamVisionConfig</span><span class="p">(</span><span class="n">PretrainedConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the configuration class to store the configuration of a [`SamVisionModel`]. It is used to instantiate a SAM</span>
<span class="sd">    vision encoder according to the specified arguments, defining the model architecture. Instantiating a configuration</span>
<span class="sd">    defaults will yield a similar configuration to that of the SAM ViT-h</span>
<span class="sd">    [facebook/sam-vit-huge](https://huggingface.co/facebook/sam-vit-huge) architecture.</span>

<span class="sd">    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the</span>
<span class="sd">    documentation from [`PretrainedConfig`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        hidden_size (`int`, *optional*, defaults to 768):</span>
<span class="sd">            Dimensionality of the encoder layers and the pooler layer.</span>
<span class="sd">        output_channels (`int`, *optional*, defaults to 256):</span>
<span class="sd">            Dimensionality of the output channels in the Patch Encoder.</span>
<span class="sd">        num_hidden_layers (`int`, *optional*, defaults to 12):</span>
<span class="sd">            Number of hidden layers in the Transformer encoder.</span>
<span class="sd">        num_attention_heads (`int`, *optional*, defaults to 12):</span>
<span class="sd">            Number of attention heads for each attention layer in the Transformer encoder.</span>
<span class="sd">        num_channels (`int`, *optional*, defaults to 3):</span>
<span class="sd">            Number of channels in the input image.</span>
<span class="sd">        image_size (`int`, *optional*, defaults to 1024):</span>
<span class="sd">            Expected resolution. Target size of the resized input image.</span>
<span class="sd">        patch_size (`int`, *optional*, defaults to 16):</span>
<span class="sd">            Size of the patches to be extracted from the input image.</span>
<span class="sd">        hidden_act (`str`, *optional*, defaults to `&quot;gelu&quot;`):</span>
<span class="sd">            The non-linear activation function (function or string)</span>
<span class="sd">        layer_norm_eps (`float`, *optional*, defaults to 1e-06):</span>
<span class="sd">            The epsilon used by the layer normalization layers.</span>
<span class="sd">        attention_dropout (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            The dropout ratio for the attention probabilities.</span>
<span class="sd">        initializer_range (`float`, *optional*, defaults to 1e-10):</span>
<span class="sd">            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.</span>
<span class="sd">        qkv_bias (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to add a bias to query, key, value projections.</span>
<span class="sd">        mlp_ratio (`float`, *optional*, defaults to 4.0):</span>
<span class="sd">            Ratio of mlp hidden dim to embedding dim.</span>
<span class="sd">        use_abs_pos (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to use absolute position embedding.</span>
<span class="sd">        use_rel_pos (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to use relative position embedding.</span>
<span class="sd">        window_size (`int`, *optional*, defaults to 14):</span>
<span class="sd">            Window size for relative position.</span>
<span class="sd">        global_attn_indexes (`List[int]`, *optional*, defaults to `[2, 5, 8, 11]`):</span>
<span class="sd">            The indexes of the global attention layers.</span>
<span class="sd">        num_pos_feats (`int`, *optional*, defaults to 128):</span>
<span class="sd">            The dimensionality of the position embedding.</span>
<span class="sd">        mlp_dim (`int`, *optional*):</span>
<span class="sd">            The dimensionality of the MLP layer in the Transformer encoder. If `None`, defaults to `mlp_ratio *</span>
<span class="sd">            hidden_size`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
        <span class="n">output_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">num_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">image_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
        <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
        <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
        <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">initializer_range</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
        <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">mlp_ratio</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span>
        <span class="n">use_abs_pos</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">use_rel_pos</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">window_size</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
        <span class="n">global_attn_indexes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">mlp_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes an instance of the SamVisionConfig class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The object instance.</span>
<span class="sd">            hidden_size (int, optional): The size of the hidden state. Defaults to 768.</span>
<span class="sd">            output_channels (int, optional): The number of output channels. Defaults to 256.</span>
<span class="sd">            num_hidden_layers (int, optional): The number of hidden layers. Defaults to 12.</span>
<span class="sd">            num_attention_heads (int, optional): The number of attention heads. Defaults to 12.</span>
<span class="sd">            num_channels (int, optional): The number of input channels. Defaults to 3.</span>
<span class="sd">            image_size (int, optional): The size of the input image. Defaults to 1024.</span>
<span class="sd">            patch_size (int, optional): The size of each patch in the image. Defaults to 16.</span>
<span class="sd">            hidden_act (str, optional): The activation function for the hidden layers. Defaults to &#39;gelu&#39;.</span>
<span class="sd">            layer_norm_eps (float, optional): The epsilon value for layer normalization. Defaults to 1e-06.</span>
<span class="sd">            attention_dropout (float, optional): The dropout rate for the attention mechanism. Defaults to 0.0.</span>
<span class="sd">            initializer_range (float, optional): The range for parameter initialization. Defaults to 1e-10.</span>
<span class="sd">            qkv_bias (bool, optional): Whether to include bias in the query, key, and value projections. Defaults to True.</span>
<span class="sd">            mlp_ratio (float, optional): The ratio of the hidden size to the feed-forward network size. Defaults to 4.0.</span>
<span class="sd">            use_abs_pos (bool, optional): Whether to use absolute position embeddings. Defaults to True.</span>
<span class="sd">            use_rel_pos (bool, optional): Whether to use relative position embeddings. Defaults to True.</span>
<span class="sd">            window_size (int, optional): The size of the attention window. Defaults to 14.</span>
<span class="sd">            global_attn_indexes (list[int], optional): The list of indexes for global attention. Defaults to [2, 5, 8, 11].</span>
<span class="sd">            num_pos_feats (int, optional): The number of positional features. Defaults to 128.</span>
<span class="sd">            mlp_dim (int, optional): The size of the hidden layer in the feed-forward network. If not provided,</span>
<span class="sd">                it is calculated as int(hidden_size * mlp_ratio).</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span> <span class="o">=</span> <span class="n">output_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_dropout</span> <span class="o">=</span> <span class="n">attention_dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qkv_bias</span> <span class="o">=</span> <span class="n">qkv_bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_ratio</span> <span class="o">=</span> <span class="n">mlp_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_abs_pos</span> <span class="o">=</span> <span class="n">use_abs_pos</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span> <span class="o">=</span> <span class="n">use_rel_pos</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_attn_indexes</span> <span class="o">=</span> <span class="n">global_attn_indexes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span> <span class="o">=</span> <span class="n">num_pos_feats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">)</span> <span class="k">if</span> <span class="n">mlp_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">mlp_dim</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">configuration_sam</span><span class="o">.</span><span class="n">SamVisionConfig</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">output_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">hidden_act</span><span class="o">=</span><span class="s1">&#39;gelu&#39;</span><span class="p">,</span> <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">initializer_range</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mlp_ratio</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">use_abs_pos</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_rel_pos</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">global_attn_indexes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.configuration_sam.SamVisionConfig.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Initializes an instance of the SamVisionConfig class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The object instance.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the hidden state. Defaults to 768.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>768</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_channels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of output channels. Defaults to 256.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>256</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_hidden_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of hidden layers. Defaults to 12.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_attention_heads</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of attention heads. Defaults to 12.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_channels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of input channels. Defaults to 3.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>3</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the input image. Defaults to 1024.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>patch_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of each patch in the image. Defaults to 16.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>16</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_act</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The activation function for the hidden layers. Defaults to 'gelu'.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;gelu&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>layer_norm_eps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The epsilon value for layer normalization. Defaults to 1e-06.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-06</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_dropout</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The dropout rate for the attention mechanism. Defaults to 0.0.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initializer_range</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The range for parameter initialization. Defaults to 1e-10.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1e-10</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>qkv_bias</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to include bias in the query, key, and value projections. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mlp_ratio</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The ratio of the hidden size to the feed-forward network size. Defaults to 4.0.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>4.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_abs_pos</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use absolute position embeddings. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_rel_pos</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use relative position embeddings. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>window_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the attention window. Defaults to 14.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>14</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>global_attn_indexes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of indexes for global attention. Defaults to [2, 5, 8, 11].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>list[int]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>[2, 5, 8, 11]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_pos_feats</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of positional features. Defaults to 128.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>128</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mlp_dim</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of the hidden layer in the feed-forward network. If not provided,
it is calculated as int(hidden_size * mlp_ratio).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\configuration_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">hidden_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
    <span class="n">output_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">num_hidden_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">num_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
    <span class="n">layer_norm_eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
    <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">initializer_range</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
    <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">mlp_ratio</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span>
    <span class="n">use_abs_pos</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">use_rel_pos</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">window_size</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
    <span class="n">global_attn_indexes</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
    <span class="n">num_pos_feats</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">mlp_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes an instance of the SamVisionConfig class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The object instance.</span>
<span class="sd">        hidden_size (int, optional): The size of the hidden state. Defaults to 768.</span>
<span class="sd">        output_channels (int, optional): The number of output channels. Defaults to 256.</span>
<span class="sd">        num_hidden_layers (int, optional): The number of hidden layers. Defaults to 12.</span>
<span class="sd">        num_attention_heads (int, optional): The number of attention heads. Defaults to 12.</span>
<span class="sd">        num_channels (int, optional): The number of input channels. Defaults to 3.</span>
<span class="sd">        image_size (int, optional): The size of the input image. Defaults to 1024.</span>
<span class="sd">        patch_size (int, optional): The size of each patch in the image. Defaults to 16.</span>
<span class="sd">        hidden_act (str, optional): The activation function for the hidden layers. Defaults to &#39;gelu&#39;.</span>
<span class="sd">        layer_norm_eps (float, optional): The epsilon value for layer normalization. Defaults to 1e-06.</span>
<span class="sd">        attention_dropout (float, optional): The dropout rate for the attention mechanism. Defaults to 0.0.</span>
<span class="sd">        initializer_range (float, optional): The range for parameter initialization. Defaults to 1e-10.</span>
<span class="sd">        qkv_bias (bool, optional): Whether to include bias in the query, key, and value projections. Defaults to True.</span>
<span class="sd">        mlp_ratio (float, optional): The ratio of the hidden size to the feed-forward network size. Defaults to 4.0.</span>
<span class="sd">        use_abs_pos (bool, optional): Whether to use absolute position embeddings. Defaults to True.</span>
<span class="sd">        use_rel_pos (bool, optional): Whether to use relative position embeddings. Defaults to True.</span>
<span class="sd">        window_size (int, optional): The size of the attention window. Defaults to 14.</span>
<span class="sd">        global_attn_indexes (list[int], optional): The list of indexes for global attention. Defaults to [2, 5, 8, 11].</span>
<span class="sd">        num_pos_feats (int, optional): The number of positional features. Defaults to 128.</span>
<span class="sd">        mlp_dim (int, optional): The size of the hidden layer in the feed-forward network. If not provided,</span>
<span class="sd">            it is calculated as int(hidden_size * mlp_ratio).</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span> <span class="o">=</span> <span class="n">output_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden_layers</span> <span class="o">=</span> <span class="n">num_hidden_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">num_attention_heads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_act</span> <span class="o">=</span> <span class="n">hidden_act</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">layer_norm_eps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attention_dropout</span> <span class="o">=</span> <span class="n">attention_dropout</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initializer_range</span> <span class="o">=</span> <span class="n">initializer_range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">qkv_bias</span> <span class="o">=</span> <span class="n">qkv_bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_ratio</span> <span class="o">=</span> <span class="n">mlp_ratio</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_abs_pos</span> <span class="o">=</span> <span class="n">use_abs_pos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span> <span class="o">=</span> <span class="n">use_rel_pos</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">global_attn_indexes</span> <span class="o">=</span> <span class="n">global_attn_indexes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_pos_feats</span> <span class="o">=</span> <span class="n">num_pos_feats</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">)</span> <span class="k">if</span> <span class="n">mlp_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">mlp_dim</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="mindnlp.transformers.models.sam.image_processing_sam" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.image_processing_sam</code>


<a href="#mindnlp.transformers.models.sam.image_processing_sam" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Image processor class for SAM.</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor</code>


<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.image_processing_utils.BaseImageProcessor">BaseImageProcessor</span></code></p>


        <p>Constructs a SAM image processor.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>do_resize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to resize the image's (height, width) dimensions to the specified <code>size</code>. Can be overridden by the
<code>do_resize</code> parameter in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the output image after resizing. Resizes the longest edge of the image to match
<code>size["longest_edge"]</code> while maintaining the aspect ratio. Can be overridden by the <code>size</code> parameter in the
<code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*, defaults to `{&#34;longest_edge&#34; -- 1024}`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the output segmentation map after resizing. Resizes the longest edge of the image to match
<code>size["longest_edge"]</code> while maintaining the aspect ratio. Can be overridden by the <code>mask_size</code> parameter
in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*, defaults to `{&#34;longest_edge&#34; -- 256}`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resample</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Resampling filter to use if resizing the image. Can be overridden by the <code>resample</code> parameter in the
<code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling.BILINEAR">BILINEAR</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_rescale</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Wwhether to rescale the image by the specified scale <code>rescale_factor</code>. Can be overridden by the
<code>do_rescale</code> parameter in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rescale_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Scale factor to use if rescaling the image. Only has an effect if <code>do_rescale</code> is set to <code>True</code>. Can be
overridden by the <code>rescale_factor</code> parameter in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` or `float`, *optional*, defaults to `1/255`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1 / 255</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_normalize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to normalize the image. Can be overridden by the <code>do_normalize</code> parameter in the <code>preprocess</code>
method. Can be overridden by the <code>do_normalize</code> parameter in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_mean</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Mean to use if normalizing the image. This is a float or list of floats the length of the number of
channels in the image. Can be overridden by the <code>image_mean</code> parameter in the <code>preprocess</code> method. Can be
overridden by the <code>image_mean</code> parameter in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_MEAN`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_std</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Standard deviation to use if normalizing the image. This is a float or list of floats the length of the
number of channels in the image. Can be overridden by the <code>image_std</code> parameter in the <code>preprocess</code> method.
Can be overridden by the <code>image_std</code> parameter in the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_STD`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_pad</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to pad the image to the specified <code>pad_size</code>. Can be overridden by the <code>do_pad</code> parameter in the
<code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the output image after padding. Can be overridden by the <code>pad_size</code> parameter in the <code>preprocess</code>
method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*, defaults to `{&#34;height&#34; -- 1024, &#34;width&#34; -- 1024}`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_pad_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the output segmentation map after padding. Can be overridden by the <code>mask_pad_size</code> parameter in
the <code>preprocess</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*, defaults to `{&#34;height&#34; -- 256, &#34;width&#34; -- 256}`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_convert_rgb</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to convert the image to RGB.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamImageProcessor</span><span class="p">(</span><span class="n">BaseImageProcessor</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs a SAM image processor.</span>

<span class="sd">    Args:</span>
<span class="sd">        do_resize (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to resize the image&#39;s (height, width) dimensions to the specified `size`. Can be overridden by the</span>
<span class="sd">            `do_resize` parameter in the `preprocess` method.</span>
<span class="sd">        size (`dict`, *optional*, defaults to `{&quot;longest_edge&quot; -- 1024}`):</span>
<span class="sd">            Size of the output image after resizing. Resizes the longest edge of the image to match</span>
<span class="sd">            `size[&quot;longest_edge&quot;]` while maintaining the aspect ratio. Can be overridden by the `size` parameter in the</span>
<span class="sd">            `preprocess` method.</span>
<span class="sd">        mask_size (`dict`, *optional*, defaults to `{&quot;longest_edge&quot; -- 256}`):</span>
<span class="sd">            Size of the output segmentation map after resizing. Resizes the longest edge of the image to match</span>
<span class="sd">            `size[&quot;longest_edge&quot;]` while maintaining the aspect ratio. Can be overridden by the `mask_size` parameter</span>
<span class="sd">            in the `preprocess` method.</span>
<span class="sd">        resample (`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`):</span>
<span class="sd">            Resampling filter to use if resizing the image. Can be overridden by the `resample` parameter in the</span>
<span class="sd">            `preprocess` method.</span>
<span class="sd">        do_rescale (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Wwhether to rescale the image by the specified scale `rescale_factor`. Can be overridden by the</span>
<span class="sd">            `do_rescale` parameter in the `preprocess` method.</span>
<span class="sd">        rescale_factor (`int` or `float`, *optional*, defaults to `1/255`):</span>
<span class="sd">            Scale factor to use if rescaling the image. Only has an effect if `do_rescale` is set to `True`. Can be</span>
<span class="sd">            overridden by the `rescale_factor` parameter in the `preprocess` method.</span>
<span class="sd">        do_normalize (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to normalize the image. Can be overridden by the `do_normalize` parameter in the `preprocess`</span>
<span class="sd">            method. Can be overridden by the `do_normalize` parameter in the `preprocess` method.</span>
<span class="sd">        image_mean (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_MEAN`):</span>
<span class="sd">            Mean to use if normalizing the image. This is a float or list of floats the length of the number of</span>
<span class="sd">            channels in the image. Can be overridden by the `image_mean` parameter in the `preprocess` method. Can be</span>
<span class="sd">            overridden by the `image_mean` parameter in the `preprocess` method.</span>
<span class="sd">        image_std (`float` or `List[float]`, *optional*, defaults to `IMAGENET_DEFAULT_STD`):</span>
<span class="sd">            Standard deviation to use if normalizing the image. This is a float or list of floats the length of the</span>
<span class="sd">            number of channels in the image. Can be overridden by the `image_std` parameter in the `preprocess` method.</span>
<span class="sd">            Can be overridden by the `image_std` parameter in the `preprocess` method.</span>
<span class="sd">        do_pad (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to pad the image to the specified `pad_size`. Can be overridden by the `do_pad` parameter in the</span>
<span class="sd">            `preprocess` method.</span>
<span class="sd">        pad_size (`dict`, *optional*, defaults to `{&quot;height&quot; -- 1024, &quot;width&quot; -- 1024}`):</span>
<span class="sd">            Size of the output image after padding. Can be overridden by the `pad_size` parameter in the `preprocess`</span>
<span class="sd">            method.</span>
<span class="sd">        mask_pad_size (`dict`, *optional*, defaults to `{&quot;height&quot; -- 256, &quot;width&quot; -- 256}`):</span>
<span class="sd">            Size of the output segmentation map after padding. Can be overridden by the `mask_pad_size` parameter in</span>
<span class="sd">            the `preprocess` method.</span>
<span class="sd">        do_convert_rgb (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to convert the image to RGB.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">do_resize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mask_size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">,</span>
        <span class="n">do_rescale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">rescale_factor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">255</span><span class="p">,</span>
        <span class="n">do_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_pad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">pad_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mask_pad_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes an instance of the SamImageProcessor class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the class.</span>
<span class="sd">            do_resize (bool): Determines whether resizing of images should be performed. Defaults to True.</span>
<span class="sd">            size (Dict[str, int]): The desired size of the images. Defaults to {&#39;longest_edge&#39;: 1024}.</span>
<span class="sd">                The size can be specified as a dictionary with keys &#39;longest_edge&#39; or &#39;height&#39; and &#39;width&#39;.</span>
<span class="sd">                If not provided as a dictionary, it is converted to a dictionary with the &#39;longest_edge&#39; key.</span>
<span class="sd">            mask_size (Dict[str, int]): The desired size of the segmentation masks. Defaults to {&#39;longest_edge&#39;: 256}.</span>
<span class="sd">                The size can be specified as a dictionary with keys &#39;longest_edge&#39; or &#39;height&#39; and &#39;width&#39;.</span>
<span class="sd">                If not provided as a dictionary, it is converted to a dictionary with the &#39;longest_edge&#39; key.</span>
<span class="sd">            resample (PILImageResampling): The resampling method to use during image resizing.</span>
<span class="sd">                Defaults to PILImageResampling.BILINEAR.</span>
<span class="sd">            do_rescale (bool): Determines whether rescaling of pixel values should be performed. Defaults to True.</span>
<span class="sd">            rescale_factor (Union[int, float]): The factor to divide pixel values by during rescaling.</span>
<span class="sd">                Defaults to 1 / 255.</span>
<span class="sd">            do_normalize (bool): Determines whether normalization of pixel values should be performed.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            image_mean (Optional[Union[float, List[float]]]): The mean values to subtract from pixel values</span>
<span class="sd">                during normalization. Defaults to None, which uses the IMAGENET_DEFAULT_MEAN.</span>
<span class="sd">            image_std (Optional[Union[float, List[float]]]): The standard deviation values to divide pixel values</span>
<span class="sd">                by during normalization. Defaults to None, which uses the IMAGENET_DEFAULT_STD.</span>
<span class="sd">            do_pad (bool): Determines whether padding of images should be performed. Defaults to True.</span>
<span class="sd">            pad_size (int): The desired size of the padded images. Defaults to None,</span>
<span class="sd">                which uses {&#39;height&#39;: 1024, &#39;width&#39;: 1024}. The size can be specified as a single integer, representing</span>
<span class="sd">                both height and width.</span>
<span class="sd">            mask_pad_size (int): The desired size of the padded segmentation masks. Defaults to None,</span>
<span class="sd">                which uses {&#39;height&#39;: 256, &#39;width&#39;: 256}. The size can be specified as a single integer,</span>
<span class="sd">                representing both height and width.</span>
<span class="sd">            do_convert_rgb (bool): Determines whether conversion to RGB color space should be performed. Defaults to True.</span>
<span class="sd">            **kwargs: Additional keyword arguments to be passed to the parent class forwardor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">size</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;longest_edge&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">}</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">size</span>

        <span class="n">pad_size</span> <span class="o">=</span> <span class="n">pad_size</span> <span class="k">if</span> <span class="n">pad_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;height&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">}</span>
        <span class="n">pad_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">pad_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">mask_size</span> <span class="o">=</span> <span class="n">mask_size</span> <span class="k">if</span> <span class="n">mask_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;longest_edge&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">}</span>
        <span class="n">mask_size</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">get_size_dict</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">mask_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask_size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">mask_size</span>
        <span class="p">)</span>

        <span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">mask_pad_size</span> <span class="k">if</span> <span class="n">mask_pad_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;height&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">}</span>
        <span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">mask_pad_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">do_resize</span> <span class="o">=</span> <span class="n">do_resize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_size</span> <span class="o">=</span> <span class="n">mask_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">resample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_rescale</span> <span class="o">=</span> <span class="n">do_rescale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_factor</span> <span class="o">=</span> <span class="n">rescale_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_normalize</span> <span class="o">=</span> <span class="n">do_normalize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_mean</span> <span class="o">=</span> <span class="n">image_mean</span> <span class="k">if</span> <span class="n">image_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">IMAGENET_DEFAULT_MEAN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_std</span> <span class="o">=</span> <span class="n">image_std</span> <span class="k">if</span> <span class="n">image_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">IMAGENET_DEFAULT_STD</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_pad</span> <span class="o">=</span> <span class="n">do_pad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_size</span> <span class="o">=</span> <span class="n">pad_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">mask_pad_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_convert_rgb</span> <span class="o">=</span> <span class="n">do_convert_rgb</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_valid_processor_keys</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;images&quot;</span><span class="p">,</span>
            <span class="s2">&quot;segmentation_maps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_resize&quot;</span><span class="p">,</span>
            <span class="s2">&quot;size&quot;</span><span class="p">,</span>
            <span class="s2">&quot;mask_size&quot;</span><span class="p">,</span>
            <span class="s2">&quot;resample&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_rescale&quot;</span><span class="p">,</span>
            <span class="s2">&quot;rescale_factor&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_normalize&quot;</span><span class="p">,</span>
            <span class="s2">&quot;image_mean&quot;</span><span class="p">,</span>
            <span class="s2">&quot;image_std&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_pad&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pad_size&quot;</span><span class="p">,</span>
            <span class="s2">&quot;mask_pad_size&quot;</span><span class="p">,</span>
            <span class="s2">&quot;do_convert_rgb&quot;</span><span class="p">,</span>
            <span class="s2">&quot;return_tensors&quot;</span><span class="p">,</span>
            <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
            <span class="s2">&quot;input_data_format&quot;</span><span class="p">,</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">pad_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">pad_size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pad an image to `(pad_size[&quot;height&quot;], pad_size[&quot;width&quot;])` with zeros to the right and bottom.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (`np.ndarray`):</span>
<span class="sd">                Image to pad.</span>
<span class="sd">            pad_size (`Dict[str, int]`):</span>
<span class="sd">                Size of the output image after padding.</span>
<span class="sd">            data_format (`str` or `ChannelDimension`, *optional*):</span>
<span class="sd">                The data format of the image. Can be either &quot;channels_first&quot; or &quot;channels_last&quot;. If `None`, the</span>
<span class="sd">                `data_format` of the `image` will be used.</span>
<span class="sd">            input_data_format (`str` or `ChannelDimension`, *optional*):</span>
<span class="sd">                The channel dimension format of the input image. If not provided, it will be inferred.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_height</span><span class="p">,</span> <span class="n">output_width</span> <span class="o">=</span> <span class="n">pad_size</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">pad_size</span><span class="p">[</span><span class="s2">&quot;width&quot;</span><span class="p">]</span>
        <span class="n">input_height</span><span class="p">,</span> <span class="n">input_width</span> <span class="o">=</span> <span class="n">get_image_size</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

        <span class="n">pad_width</span> <span class="o">=</span> <span class="n">output_width</span> <span class="o">-</span> <span class="n">input_width</span>
        <span class="n">pad_height</span> <span class="o">=</span> <span class="n">output_height</span> <span class="o">-</span> <span class="n">input_height</span>

        <span class="n">padded_image</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_height</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">)),</span>
            <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
            <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">padded_image</span>

    <span class="k">def</span> <span class="nf">_get_preprocess_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">old_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">longest_edge</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the output size given input size and target long side length.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">oldh</span><span class="p">,</span> <span class="n">oldw</span> <span class="o">=</span> <span class="n">old_shape</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">longest_edge</span> <span class="o">*</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">oldh</span><span class="p">,</span> <span class="n">oldw</span><span class="p">)</span>
        <span class="n">newh</span><span class="p">,</span> <span class="n">neww</span> <span class="o">=</span> <span class="n">oldh</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="n">oldw</span> <span class="o">*</span> <span class="n">scale</span>
        <span class="n">newh</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">newh</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">neww</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">neww</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">newh</span><span class="p">,</span> <span class="n">neww</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">resize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span>
        <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Resize an image to `(size[&quot;height&quot;], size[&quot;width&quot;])`.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (`np.ndarray`):</span>
<span class="sd">                Image to resize.</span>
<span class="sd">            size (`Dict[str, int]`):</span>
<span class="sd">                Dictionary in the format `{&quot;longest_edge&quot;: int}` specifying the size of the output image. The longest</span>
<span class="sd">                edge of the image will be resized to the specified size, while the other edge will be resized to</span>
<span class="sd">                maintain the aspect ratio.</span>
<span class="sd">            resample:</span>
<span class="sd">                `PILImageResampling` filter to use when resizing the image e.g. `PILImageResampling.BILINEAR`.</span>
<span class="sd">            data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">                The channel dimension format for the output image. If unset, the channel dimension format of the input</span>
<span class="sd">                image is used. Can be one of:</span>

<span class="sd">                - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">                - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">            input_data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">                The channel dimension format for the input image. If unset, the channel dimension format is inferred</span>
<span class="sd">                from the input image. Can be one of:</span>

<span class="sd">                - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">                - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `np.ndarray`: The resized image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;longest_edge&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The `size` dictionary must contain the key `longest_edge`. Got </span><span class="si">{</span><span class="n">size</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">input_size</span> <span class="o">=</span> <span class="n">get_image_size</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
        <span class="n">output_height</span><span class="p">,</span> <span class="n">output_width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_preprocess_shape</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;longest_edge&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">resize</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">output_height</span><span class="p">,</span> <span class="n">output_width</span><span class="p">),</span>
            <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
            <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
            <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_preprocess</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">ImageInput</span><span class="p">,</span>
        <span class="n">do_resize</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">do_rescale</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">do_normalize</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rescale_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_pad</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pad_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        This method preprocesses the input image according to the specified operations such as resizing, rescaling,</span>
<span class="sd">        normalization, and padding.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the SamImageProcessor class.</span>
<span class="sd">            image (ImageInput): The input image to be preprocessed.</span>
<span class="sd">            do_resize (bool): A flag indicating whether to perform resizing on the input image.</span>
<span class="sd">            do_rescale (bool): A flag indicating whether to perform rescaling on the input image.</span>
<span class="sd">            do_normalize (bool): A flag indicating whether to perform normalization on the input image.</span>
<span class="sd">            size (Optional[Dict[str, int]]): The target size for resizing the image in the format</span>
<span class="sd">                {&#39;width&#39;: int, &#39;height&#39;: int}. Default is None.</span>
<span class="sd">            resample (PILImageResampling): The resampling filter to be used during image resizing. Default is None.</span>
<span class="sd">            rescale_factor (Optional[float]): The factor by which the image should be rescaled. Default is None.</span>
<span class="sd">            image_mean (Optional[Union[float, List[float]]]): The mean value to be used for image normalization.</span>
<span class="sd">                It can be a single float value or a list of float values, depending on the input_data_format.</span>
<span class="sd">                Default is None.</span>
<span class="sd">            image_std (Optional[Union[float, List[float]]]):</span>
<span class="sd">                The standard deviation value to be used for image normalization.</span>
<span class="sd">                It can be a single float value or a list of float values, depending on the input_data_format.</span>
<span class="sd">                Default is None.</span>
<span class="sd">            do_pad (Optional[bool]): A flag indicating whether to perform padding on the input image. Default is None.</span>
<span class="sd">            pad_size (Optional[Dict[str, int]]): The size of the padding to be applied in the format</span>
<span class="sd">                {&#39;top&#39;: int, &#39;bottom&#39;: int, &#39;left&#39;: int, &#39;right&#39;: int}. Default is None.</span>
<span class="sd">            input_data_format (Optional[Union[str, ChannelDimension]]): The data format of the input image,</span>
<span class="sd">                e.g., &#39;channels_first&#39; or &#39;channels_last&#39;. Default is None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[ImageInput, Tuple[int, int, int]]: The preprocessed image and the reshaped input size in the format</span>
<span class="sd">                (image, (height, width, channels)).</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the input_data_format is invalid or not supported.</span>
<span class="sd">            TypeError: If the input_data_format is not a string or ChannelDimension.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">do_resize</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
        <span class="n">reshaped_input_size</span> <span class="o">=</span> <span class="n">get_image_size</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">do_rescale</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">do_normalize</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">do_pad</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_image</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">pad_size</span><span class="o">=</span><span class="n">pad_size</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">reshaped_input_size</span>

    <span class="k">def</span> <span class="nf">_preprocess_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">ImageInput</span><span class="p">,</span>
        <span class="n">do_resize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_rescale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rescale_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_normalize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_pad</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pad_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method preprocesses the input image with various transformations and returns the processed image,</span>
<span class="sd">        original size, and reshaped input size.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the SamImageProcessor class.</span>
<span class="sd">            image (ImageInput): The input image to be preprocessed.</span>
<span class="sd">            do_resize (Optional[bool]): A flag indicating whether to resize the image. Defaults to None.</span>
<span class="sd">            size (Optional[Dict[str, int]]): A dictionary containing the target width and height for resizing the image.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            resample (PILImageResampling): The resampling filter to be used during image resizing.</span>
<span class="sd">            do_rescale (Optional[bool]): A flag indicating whether to rescale the image. Defaults to None.</span>
<span class="sd">            rescale_factor (Optional[float]): The factor by which to rescale the image. Defaults to None.</span>
<span class="sd">            do_normalize (Optional[bool]): A flag indicating whether to normalize the image. Defaults to None.</span>
<span class="sd">            image_mean (Optional[Union[float, List[float]]]): The mean values to be used for image normalization.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            image_std (Optional[Union[float, List[float]]]): The standard deviation values to be used for</span>
<span class="sd">                image normalization. Defaults to None.</span>
<span class="sd">            do_pad (Optional[bool]): A flag indicating whether to pad the image. Defaults to None.</span>
<span class="sd">            pad_size (Optional[Dict[str, int]]): A dictionary containing the padding width and height.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            do_convert_rgb (Optional[bool]): A flag indicating whether to convert the image to RGB format.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            data_format (Optional[Union[str, ChannelDimension]]): The desired data format for the processed image.</span>
<span class="sd">            input_data_format (Optional[Union[str, ChannelDimension]]): The input data format of the image.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[np.ndarray, Tuple[int, int], Tuple[int, int]]: A tuple containing the processed image as a numpy array,</span>
<span class="sd">                the original size of the input image, and the reshaped input size after preprocessing.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">to_numpy_array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># PIL RGBA images are converted to RGB</span>
        <span class="k">if</span> <span class="n">do_convert_rgb</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">convert_to_rgb</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># All transformations expect numpy arrays.</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">to_numpy_array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_scaled_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="ow">and</span> <span class="n">do_rescale</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span>
                <span class="s2">&quot;It looks like you are trying to rescale already rescaled images. If the input&quot;</span>
                <span class="s2">&quot; images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">input_data_format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_data_format</span> <span class="o">=</span> <span class="n">infer_channel_dimension_format</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="n">original_size</span> <span class="o">=</span> <span class="n">get_image_size</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

        <span class="n">image</span><span class="p">,</span> <span class="n">reshaped_input_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span>
            <span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span>
            <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
            <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
            <span class="n">do_rescale</span><span class="o">=</span><span class="n">do_rescale</span><span class="p">,</span>
            <span class="n">rescale_factor</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span>
            <span class="n">do_normalize</span><span class="o">=</span><span class="n">do_normalize</span><span class="p">,</span>
            <span class="n">image_mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span>
            <span class="n">image_std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span>
            <span class="n">do_pad</span><span class="o">=</span><span class="n">do_pad</span><span class="p">,</span>
            <span class="n">pad_size</span><span class="o">=</span><span class="n">pad_size</span><span class="p">,</span>
            <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">data_format</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">to_channel_dimension_format</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">input_channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">original_size</span><span class="p">,</span> <span class="n">reshaped_input_size</span>

    <span class="k">def</span> <span class="nf">_preprocess_mask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">segmentation_map</span><span class="p">:</span> <span class="n">ImageInput</span><span class="p">,</span>
        <span class="n">do_resize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mask_size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_pad</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mask_pad_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to preprocess a segmentation mask.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the SamImageProcessor class.</span>
<span class="sd">            segmentation_map (ImageInput): The input segmentation map to be preprocessed.</span>
<span class="sd">            do_resize (Optional[bool]): Flag indicating whether resizing should be performed. Default is None.</span>
<span class="sd">            mask_size (Dict[str, int]): Dictionary containing the target size for the mask after resizing.</span>
<span class="sd">            do_pad (Optional[bool]): Flag indicating whether padding should be applied. Default is None.</span>
<span class="sd">            mask_pad_size (Optional[Dict[str, int]]): Dictionary containing the padding size for the mask.</span>
<span class="sd">            input_data_format (Optional[Union[str, ChannelDimension]]): Format of the input data. Default is None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: The preprocessed segmentation map as a NumPy array.</span>
<span class="sd">            original_size: The size of the original segmentation map.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">segmentation_map</span> <span class="o">=</span> <span class="n">to_numpy_array</span><span class="p">(</span><span class="n">segmentation_map</span><span class="p">)</span>

        <span class="c1"># Add channel dimension if missing - needed for certain transformations</span>
        <span class="k">if</span> <span class="n">segmentation_map</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">added_channel_dim</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">segmentation_map</span> <span class="o">=</span> <span class="n">segmentation_map</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="n">input_data_format</span> <span class="o">=</span> <span class="n">ChannelDimension</span><span class="o">.</span><span class="n">FIRST</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">added_channel_dim</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">input_data_format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">input_data_format</span> <span class="o">=</span> <span class="n">infer_channel_dimension_format</span><span class="p">(</span><span class="n">segmentation_map</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">original_size</span> <span class="o">=</span> <span class="n">get_image_size</span><span class="p">(</span><span class="n">segmentation_map</span><span class="p">,</span> <span class="n">channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

        <span class="n">segmentation_map</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span>
            <span class="n">image</span><span class="o">=</span><span class="n">segmentation_map</span><span class="p">,</span>
            <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">mask_size</span><span class="p">,</span>
            <span class="n">resample</span><span class="o">=</span><span class="n">PILImageResampling</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">,</span>
            <span class="n">do_rescale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">do_normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">do_pad</span><span class="o">=</span><span class="n">do_pad</span><span class="p">,</span>
            <span class="n">pad_size</span><span class="o">=</span><span class="n">mask_pad_size</span><span class="p">,</span>
            <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Remove extra channel dimension if added for processing</span>
        <span class="k">if</span> <span class="n">added_channel_dim</span><span class="p">:</span>
            <span class="n">segmentation_map</span> <span class="o">=</span> <span class="n">segmentation_map</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">segmentation_map</span> <span class="o">=</span> <span class="n">segmentation_map</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">segmentation_map</span><span class="p">,</span> <span class="n">original_size</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">images</span><span class="p">:</span> <span class="n">ImageInput</span><span class="p">,</span>
        <span class="n">segmentation_maps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ImageInput</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_resize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mask_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">resample</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;PILImageResampling&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_rescale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rescale_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_normalize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_pad</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pad_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mask_pad_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">data_format</span><span class="p">:</span> <span class="n">ChannelDimension</span> <span class="o">=</span> <span class="n">ChannelDimension</span><span class="o">.</span><span class="n">FIRST</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Preprocess an image or batch of images.</span>

<span class="sd">        Args:</span>
<span class="sd">            images (`ImageInput`):</span>
<span class="sd">                Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If</span>
<span class="sd">                passing in images with pixel values between 0 and 1, set `do_rescale=False`.</span>
<span class="sd">            segmentation_maps (`ImageInput`, *optional*):</span>
<span class="sd">                Segmentation map to preprocess.</span>
<span class="sd">            do_resize (`bool`, *optional*, defaults to `self.do_resize`):</span>
<span class="sd">                Whether to resize the image.</span>
<span class="sd">            size (`Dict[str, int]`, *optional*, defaults to `self.size`):</span>
<span class="sd">                Controls the size of the image after `resize`. The longest edge of the image is resized to</span>
<span class="sd">                `size[&quot;longest_edge&quot;]` whilst preserving the aspect ratio.</span>
<span class="sd">            mask_size (`Dict[str, int]`, *optional*, defaults to `self.mask_size`):</span>
<span class="sd">                Controls the size of the segmentation map after `resize`. The longest edge of the image is resized to</span>
<span class="sd">                `size[&quot;longest_edge&quot;]` whilst preserving the aspect ratio.</span>
<span class="sd">            resample (`PILImageResampling`, *optional*, defaults to `self.resample`):</span>
<span class="sd">                `PILImageResampling` filter to use when resizing the image e.g. `PILImageResampling.BILINEAR`.</span>
<span class="sd">            do_rescale (`bool`, *optional*, defaults to `self.do_rescale`):</span>
<span class="sd">                Whether to rescale the image pixel values by rescaling factor.</span>
<span class="sd">            rescale_factor (`int` or `float`, *optional*, defaults to `self.rescale_factor`):</span>
<span class="sd">                Rescale factor to apply to the image pixel values.</span>
<span class="sd">            do_normalize (`bool`, *optional*, defaults to `self.do_normalize`):</span>
<span class="sd">                Whether to normalize the image.</span>
<span class="sd">            image_mean (`float` or `List[float]`, *optional*, defaults to `self.image_mean`):</span>
<span class="sd">                Image mean to normalize the image by if `do_normalize` is set to `True`.</span>
<span class="sd">            image_std (`float` or `List[float]`, *optional*, defaults to `self.image_std`):</span>
<span class="sd">                Image standard deviation to normalize the image by if `do_normalize` is set to `True`.</span>
<span class="sd">            do_pad (`bool`, *optional*, defaults to `self.do_pad`):</span>
<span class="sd">                Whether to pad the image.</span>
<span class="sd">            pad_size (`Dict[str, int]`, *optional*, defaults to `self.pad_size`):</span>
<span class="sd">                Controls the size of the padding applied to the image. The image is padded to `pad_size[&quot;height&quot;]` and</span>
<span class="sd">                `pad_size[&quot;width&quot;]` if `do_pad` is set to `True`.</span>
<span class="sd">            mask_pad_size (`Dict[str, int]`, *optional*, defaults to `self.mask_pad_size`):</span>
<span class="sd">                Controls the size of the padding applied to the segmentation map. The image is padded to</span>
<span class="sd">                `mask_pad_size[&quot;height&quot;]` and `mask_pad_size[&quot;width&quot;]` if `do_pad` is set to `True`.</span>
<span class="sd">            do_convert_rgb (`bool`, *optional*, defaults to `self.do_convert_rgb`):</span>
<span class="sd">                Whether to convert the image to RGB.</span>
<span class="sd">            return_tensors (`str` or `TensorType`, *optional*):</span>
<span class="sd">                The type of tensors to return. Can be one of:</span>

<span class="sd">                - Unset: Return a list of `np.ndarray`.</span>
<span class="sd">                - `TensorType.TENSORFLOW` or `&#39;tf&#39;`: Return a batch of type `tf.Tensor`.</span>
<span class="sd">                - `TensorType.PYTORCH` or `&#39;pt&#39;`: Return a batch of type `mindspore.Tensor`.</span>
<span class="sd">                - `TensorType.NUMPY` or `&#39;np&#39;`: Return a batch of type `np.ndarray`.</span>
<span class="sd">                - `TensorType.JAX` or `&#39;jax&#39;`: Return a batch of type `jax.numpy.ndarray`.</span>
<span class="sd">            data_format (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`):</span>
<span class="sd">                The channel dimension format for the output image. Can be one of:</span>

<span class="sd">                - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">                - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">                - Unset: Use the channel dimension format of the input image.</span>
<span class="sd">            input_data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">                The channel dimension format for the input image. If unset, the channel dimension format is inferred</span>
<span class="sd">                from the input image. Can be one of:</span>

<span class="sd">                - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">                - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">                - `&quot;none&quot;` or `ChannelDimension.NONE`: image in (height, width) format.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">do_resize</span> <span class="o">=</span> <span class="n">do_resize</span> <span class="k">if</span> <span class="n">do_resize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_resize</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">size</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">size</span>
        <span class="n">mask_size</span> <span class="o">=</span> <span class="n">mask_size</span> <span class="k">if</span> <span class="n">mask_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_size</span>
        <span class="n">mask_size</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">get_size_dict</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">mask_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask_size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">mask_size</span>
        <span class="p">)</span>
        <span class="n">resample</span> <span class="o">=</span> <span class="n">resample</span> <span class="k">if</span> <span class="n">resample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample</span>
        <span class="n">do_rescale</span> <span class="o">=</span> <span class="n">do_rescale</span> <span class="k">if</span> <span class="n">do_rescale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_rescale</span>
        <span class="n">rescale_factor</span> <span class="o">=</span> <span class="n">rescale_factor</span> <span class="k">if</span> <span class="n">rescale_factor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_factor</span>
        <span class="n">do_normalize</span> <span class="o">=</span> <span class="n">do_normalize</span> <span class="k">if</span> <span class="n">do_normalize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_normalize</span>
        <span class="n">image_mean</span> <span class="o">=</span> <span class="n">image_mean</span> <span class="k">if</span> <span class="n">image_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_mean</span>
        <span class="n">image_std</span> <span class="o">=</span> <span class="n">image_std</span> <span class="k">if</span> <span class="n">image_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_std</span>
        <span class="n">do_pad</span> <span class="o">=</span> <span class="n">do_pad</span> <span class="k">if</span> <span class="n">do_pad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_pad</span>
        <span class="n">pad_size</span> <span class="o">=</span> <span class="n">pad_size</span> <span class="k">if</span> <span class="n">pad_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_size</span>
        <span class="n">pad_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">pad_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">mask_pad_size</span> <span class="k">if</span> <span class="n">mask_pad_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_pad_size</span>
        <span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">mask_pad_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">do_convert_rgb</span> <span class="o">=</span> <span class="n">do_convert_rgb</span> <span class="k">if</span> <span class="n">do_convert_rgb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_convert_rgb</span>

        <span class="n">images</span> <span class="o">=</span> <span class="n">make_list_of_images</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="n">validate_kwargs</span><span class="p">(</span><span class="n">captured_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">valid_processor_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_valid_processor_keys</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_images</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid image type. Must be of type PIL.Image.Image, numpy.ndarray, &quot;</span>
                <span class="s2">&quot;mindspore.Tensor, tf.Tensor or jax.ndarray.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">segmentation_maps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">segmentation_maps</span> <span class="o">=</span> <span class="n">make_list_of_images</span><span class="p">(</span><span class="n">segmentation_maps</span><span class="p">,</span> <span class="n">expected_ndims</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_images</span><span class="p">(</span><span class="n">segmentation_maps</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Invalid segmentation map type. Must be of type PIL.Image.Image, numpy.ndarray, &quot;</span>
                    <span class="s2">&quot;mindspore.Tensor, tf.Tensor or jax.ndarray.&quot;</span>
                <span class="p">)</span>
        <span class="n">validate_preprocess_arguments</span><span class="p">(</span>
            <span class="n">do_rescale</span><span class="o">=</span><span class="n">do_rescale</span><span class="p">,</span>
            <span class="n">rescale_factor</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span>
            <span class="n">do_normalize</span><span class="o">=</span><span class="n">do_normalize</span><span class="p">,</span>
            <span class="n">image_mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span>
            <span class="n">image_std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span>
            <span class="n">do_pad</span><span class="o">=</span><span class="n">do_pad</span><span class="p">,</span>
            <span class="n">size_divisibility</span><span class="o">=</span><span class="n">pad_size</span><span class="p">,</span>  <span class="c1"># Here _preprocess needs do_pad and pad_size.</span>
            <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
            <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">images</span><span class="p">,</span> <span class="n">original_sizes</span><span class="p">,</span> <span class="n">reshaped_input_sizes</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="o">*</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_image</span><span class="p">(</span>
                    <span class="n">image</span><span class="o">=</span><span class="n">img</span><span class="p">,</span>
                    <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
                    <span class="n">do_rescale</span><span class="o">=</span><span class="n">do_rescale</span><span class="p">,</span>
                    <span class="n">rescale_factor</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span>
                    <span class="n">do_normalize</span><span class="o">=</span><span class="n">do_normalize</span><span class="p">,</span>
                    <span class="n">image_mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span>
                    <span class="n">image_std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span>
                    <span class="n">do_pad</span><span class="o">=</span><span class="n">do_pad</span><span class="p">,</span>
                    <span class="n">pad_size</span><span class="o">=</span><span class="n">pad_size</span><span class="p">,</span>
                    <span class="n">do_convert_rgb</span><span class="o">=</span><span class="n">do_convert_rgb</span><span class="p">,</span>
                    <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
                    <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;pixel_values&quot;</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span>
            <span class="s2">&quot;original_sizes&quot;</span><span class="p">:</span> <span class="n">original_sizes</span><span class="p">,</span>
            <span class="s2">&quot;reshaped_input_sizes&quot;</span><span class="p">:</span> <span class="n">reshaped_input_sizes</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">segmentation_maps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">segmentation_maps</span><span class="p">,</span> <span class="n">original_mask_sizes</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="o">*</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_mask</span><span class="p">(</span>
                        <span class="n">segmentation_map</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
                        <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
                        <span class="n">mask_size</span><span class="o">=</span><span class="n">mask_size</span><span class="p">,</span>
                        <span class="n">do_pad</span><span class="o">=</span><span class="n">do_pad</span><span class="p">,</span>
                        <span class="n">mask_pad_size</span><span class="o">=</span><span class="n">mask_pad_size</span><span class="p">,</span>
                        <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">segmentation_maps</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># masks should start out the same size as input images</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
                <span class="n">original_im_size</span> <span class="o">==</span> <span class="n">original_mask_size</span>
                <span class="k">for</span> <span class="n">original_im_size</span><span class="p">,</span> <span class="n">original_mask_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">original_sizes</span><span class="p">,</span> <span class="n">original_mask_sizes</span><span class="p">)</span>
            <span class="p">),</span> <span class="s2">&quot;Segmentation maps should be the same size as input images.&quot;</span>

            <span class="n">data</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">segmentation_maps</span>

        <span class="k">return</span> <span class="n">BatchFeature</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">tensor_type</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">post_process_masks</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">masks</span><span class="p">,</span>
        <span class="n">original_sizes</span><span class="p">,</span>
        <span class="n">reshaped_input_sizes</span><span class="p">,</span>
        <span class="n">mask_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">binarize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">pad_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Remove padding and upscale masks to the original image size.</span>

<span class="sd">        Args:</span>
<span class="sd">            masks (`Union[List[mindspore.Tensor], List[np.ndarray], List[tf.Tensor]]`):</span>
<span class="sd">                Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.</span>
<span class="sd">            original_sizes (`Union[mindspore.Tensor, tf.Tensor, List[Tuple[int,int]]]`):</span>
<span class="sd">                The original sizes of each image before it was resized to the model&#39;s expected input shape, in (height,</span>
<span class="sd">                width) format.</span>
<span class="sd">            reshaped_input_sizes (`Union[mindspore.Tensor, tf.Tensor, List[Tuple[int,int]]]`):</span>
<span class="sd">                The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.</span>
<span class="sd">            mask_threshold (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">                The threshold to use for binarizing the masks.</span>
<span class="sd">            binarize (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                Whether to binarize the masks.</span>
<span class="sd">            pad_size (`int`, *optional*, defaults to `self.pad_size`):</span>
<span class="sd">                The target size the images were padded to before being passed to the model. If None, the target size is</span>
<span class="sd">                assumed to be the processor&#39;s `pad_size`.</span>
<span class="sd">            return_tensors (`str`, *optional*, defaults to `&quot;ms&quot;`):</span>
<span class="sd">                If `&quot;ms&quot;`, return PyTorch tensors. If `&quot;tf&quot;`, return TensorFlow tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (`Union[mindspore.Tensor, tf.Tensor]`): Batched masks in batch_size, num_channels, height, width) format, where</span>
<span class="sd">            (height, width) is given by original_size.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_process_masks_ms</span><span class="p">(</span>
                <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
                <span class="n">original_sizes</span><span class="o">=</span><span class="n">original_sizes</span><span class="p">,</span>
                <span class="n">reshaped_input_sizes</span><span class="o">=</span><span class="n">reshaped_input_sizes</span><span class="p">,</span>
                <span class="n">mask_threshold</span><span class="o">=</span><span class="n">mask_threshold</span><span class="p">,</span>
                <span class="n">binarize</span><span class="o">=</span><span class="n">binarize</span><span class="p">,</span>
                <span class="n">pad_size</span><span class="o">=</span><span class="n">pad_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;return_tensors must be &#39;ms&#39;.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_post_process_masks_ms</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">original_sizes</span><span class="p">,</span> <span class="n">reshaped_input_sizes</span><span class="p">,</span> <span class="n">mask_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">binarize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_size</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Remove padding and upscale masks to the original image size.</span>

<span class="sd">        Args:</span>
<span class="sd">            masks (`Union[List[mindspore.Tensor], List[np.ndarray]]`):</span>
<span class="sd">                Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.</span>
<span class="sd">            original_sizes (`Union[mindspore.Tensor, List[Tuple[int,int]]]`):</span>
<span class="sd">                The original sizes of each image before it was resized to the model&#39;s expected input shape, in (height,</span>
<span class="sd">                width) format.</span>
<span class="sd">            reshaped_input_sizes (`Union[mindspore.Tensor, List[Tuple[int,int]]]`):</span>
<span class="sd">                The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.</span>
<span class="sd">            mask_threshold (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">                The threshold to use for binarizing the masks.</span>
<span class="sd">            binarize (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                Whether to binarize the masks.</span>
<span class="sd">            pad_size (`int`, *optional*, defaults to `self.pad_size`):</span>
<span class="sd">                The target size the images were padded to before being passed to the model. If None, the target size is</span>
<span class="sd">                assumed to be the processor&#39;s `pad_size`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (`mindspore.Tensor`): Batched masks in batch_size, num_channels, height, width) format, where (height, width)</span>
<span class="sd">            is given by original_size.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">requires_backends</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;mindspore&quot;</span><span class="p">])</span>
        <span class="n">pad_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_size</span> <span class="k">if</span> <span class="n">pad_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">pad_size</span>
        <span class="n">target_image_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">pad_size</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">pad_size</span><span class="p">[</span><span class="s2">&quot;width&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">original_sizes</span><span class="p">,</span> <span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
            <span class="n">original_sizes</span> <span class="o">=</span> <span class="n">original_sizes</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reshaped_input_sizes</span><span class="p">,</span> <span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
            <span class="n">reshaped_input_sizes</span> <span class="o">=</span> <span class="n">reshaped_input_sizes</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">output_masks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">original_size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">original_sizes</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">masks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">masks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">masks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">masks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input masks should be a list of `mindspore.tensors` or a list of `np.ndarray`&quot;</span><span class="p">)</span>
            <span class="n">interpolated_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">masks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">target_image_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">interpolated_mask</span> <span class="o">=</span> <span class="n">interpolated_mask</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span> <span class="n">reshaped_input_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span> <span class="n">reshaped_input_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">interpolated_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">interpolated_mask</span><span class="p">,</span> <span class="n">original_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">binarize</span><span class="p">:</span>
                <span class="n">interpolated_mask</span> <span class="o">=</span> <span class="n">interpolated_mask</span> <span class="o">&gt;</span> <span class="n">mask_threshold</span>
            <span class="n">output_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">interpolated_mask</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output_masks</span>

    <span class="k">def</span> <span class="nf">post_process_for_mask_generation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">all_masks</span><span class="p">,</span> <span class="n">all_scores</span><span class="p">,</span> <span class="n">all_boxes</span><span class="p">,</span> <span class="n">crops_nms_thresh</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Post processes mask that are generated by calling the Non Maximum Suppression algorithm on the predicted masks.</span>

<span class="sd">        Args:</span>
<span class="sd">            all_masks (`Union[List[mindspore.Tensor], List[tf.Tensor]]`):</span>
<span class="sd">                List of all predicted segmentation masks</span>
<span class="sd">            all_scores (`Union[List[mindspore.Tensor], List[tf.Tensor]]`):</span>
<span class="sd">                List of all predicted iou scores</span>
<span class="sd">            all_boxes (`Union[List[mindspore.Tensor], List[tf.Tensor]]`):</span>
<span class="sd">                List of all bounding boxes of the predicted masks</span>
<span class="sd">            crops_nms_thresh (`float`):</span>
<span class="sd">                Threshold for NMS (Non Maximum Suppression) algorithm.</span>
<span class="sd">            return_tensors (`str`, *optional*, defaults to `pt`):</span>
<span class="sd">                If `pt`, returns `mindspore.Tensor`. If `tf`, returns `tf.Tensor`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_postprocess_for_mg</span><span class="p">(</span><span class="n">all_masks</span><span class="p">,</span> <span class="n">all_scores</span><span class="p">,</span> <span class="n">all_boxes</span><span class="p">,</span> <span class="n">crops_nms_thresh</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">generate_crop_boxes</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="n">target_size</span><span class="p">,</span>
        <span class="n">crop_n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">overlap_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">512</span> <span class="o">/</span> <span class="mi">1500</span><span class="p">,</span>
        <span class="n">points_per_crop</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">crop_n_points_downscale_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ms&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates a list of crop boxes of different sizes. Each layer has (2**i)**2 boxes for the ith layer.</span>

<span class="sd">        Args:</span>
<span class="sd">            image (`np.array`):</span>
<span class="sd">                Input original image</span>
<span class="sd">            target_size (`int`):</span>
<span class="sd">                Target size of the resized image</span>
<span class="sd">            crop_n_layers (`int`, *optional*, defaults to 0):</span>
<span class="sd">                If &gt;0, mask prediction will be run again on crops of the image. Sets the number of layers to run, where</span>
<span class="sd">                each layer has 2**i_layer number of image crops.</span>
<span class="sd">            overlap_ratio (`float`, *optional*, defaults to 512/1500):</span>
<span class="sd">                Sets the degree to which crops overlap. In the first crop layer, crops will overlap by this fraction of</span>
<span class="sd">                the image length. Later layers with more crops scale down this overlap.</span>
<span class="sd">            points_per_crop (`int`, *optional*, defaults to 32):</span>
<span class="sd">                Number of points to sample from each crop.</span>
<span class="sd">            crop_n_points_downscale_factor (`List[int]`, *optional*, defaults to 1):</span>
<span class="sd">                The number of points-per-side sampled in layer n is scaled down by crop_n_points_downscale_factor**n.</span>
<span class="sd">            input_data_format (`str` or `ChannelDimension`, *optional*):</span>
<span class="sd">                The channel dimension format of the input image. If not provided, it will be inferred.</span>
<span class="sd">            return_tensors (`str`, *optional*, defaults to `pt`):</span>
<span class="sd">                If `pt`, returns `mindspore.Tensor`. If `tf`, returns `tf.Tensor`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">crop_boxes</span><span class="p">,</span> <span class="n">points_per_crop</span><span class="p">,</span> <span class="n">cropped_images</span><span class="p">,</span> <span class="n">input_labels</span> <span class="o">=</span> <span class="n">_generate_crop_boxes</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span>
            <span class="n">target_size</span><span class="p">,</span>
            <span class="n">crop_n_layers</span><span class="p">,</span>
            <span class="n">overlap_ratio</span><span class="p">,</span>
            <span class="n">points_per_crop</span><span class="p">,</span>
            <span class="n">crop_n_points_downscale_factor</span><span class="p">,</span>
            <span class="n">input_data_format</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
            <span class="n">crop_boxes</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">crop_boxes</span><span class="p">)</span>
            <span class="n">points_per_crop</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">points_per_crop</span><span class="p">)</span>
            <span class="c1"># cropped_images stays as np</span>
            <span class="n">input_labels</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;return_tensors must be &#39;ms&#39;.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">crop_boxes</span><span class="p">,</span> <span class="n">points_per_crop</span><span class="p">,</span> <span class="n">cropped_images</span><span class="p">,</span> <span class="n">input_labels</span>

    <span class="k">def</span> <span class="nf">filter_masks</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">masks</span><span class="p">,</span>
        <span class="n">iou_scores</span><span class="p">,</span>
        <span class="n">original_size</span><span class="p">,</span>
        <span class="n">cropped_box_image</span><span class="p">,</span>
        <span class="n">pred_iou_thresh</span><span class="o">=</span><span class="mf">0.88</span><span class="p">,</span>
        <span class="n">stability_score_thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
        <span class="n">mask_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">stability_score_offset</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Filters the predicted masks by selecting only the ones that meets several criteria. The first criterion being</span>
<span class="sd">        that the iou scores needs to be greater than `pred_iou_thresh`. The second criterion is that the stability</span>
<span class="sd">        score needs to be greater than `stability_score_thresh`. The method also converts the predicted masks to</span>
<span class="sd">        bounding boxes and pad the predicted masks if necessary.</span>

<span class="sd">        Args:</span>
<span class="sd">            masks (`Union[mindspore.Tensor, tf.Tensor]`):</span>
<span class="sd">                Input masks.</span>
<span class="sd">            iou_scores (`Union[mindspore.Tensor, tf.Tensor]`):</span>
<span class="sd">                List of IoU scores.</span>
<span class="sd">            original_size (`Tuple[int,int]`):</span>
<span class="sd">                Size of the orginal image.</span>
<span class="sd">            cropped_box_image (`np.array`):</span>
<span class="sd">                The cropped image.</span>
<span class="sd">            pred_iou_thresh (`float`, *optional*, defaults to 0.88):</span>
<span class="sd">                The threshold for the iou scores.</span>
<span class="sd">            stability_score_thresh (`float`, *optional*, defaults to 0.95):</span>
<span class="sd">                The threshold for the stability score.</span>
<span class="sd">            mask_threshold (`float`, *optional*, defaults to 0):</span>
<span class="sd">                The threshold for the predicted masks.</span>
<span class="sd">            stability_score_offset (`float`, *optional*, defaults to 1):</span>
<span class="sd">                The offset for the stability score used in the `_compute_stability_score` method.</span>
<span class="sd">            return_tensors (`str`, *optional*, defaults to `pt`):</span>
<span class="sd">                If `pt`, returns `mindspore.Tensor`. If `tf`, returns `tf.Tensor`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_filter_masks</span><span class="p">(</span>
                <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
                <span class="n">iou_scores</span><span class="o">=</span><span class="n">iou_scores</span><span class="p">,</span>
                <span class="n">original_size</span><span class="o">=</span><span class="n">original_size</span><span class="p">,</span>
                <span class="n">cropped_box_image</span><span class="o">=</span><span class="n">cropped_box_image</span><span class="p">,</span>
                <span class="n">pred_iou_thresh</span><span class="o">=</span><span class="n">pred_iou_thresh</span><span class="p">,</span>
                <span class="n">stability_score_thresh</span><span class="o">=</span><span class="n">stability_score_thresh</span><span class="p">,</span>
                <span class="n">mask_threshold</span><span class="o">=</span><span class="n">mask_threshold</span><span class="p">,</span>
                <span class="n">stability_score_offset</span><span class="o">=</span><span class="n">stability_score_offset</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_filter_masks_tf</span><span class="p">(</span>
                <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
                <span class="n">iou_scores</span><span class="o">=</span><span class="n">iou_scores</span><span class="p">,</span>
                <span class="n">original_size</span><span class="o">=</span><span class="n">original_size</span><span class="p">,</span>
                <span class="n">cropped_box_image</span><span class="o">=</span><span class="n">cropped_box_image</span><span class="p">,</span>
                <span class="n">pred_iou_thresh</span><span class="o">=</span><span class="n">pred_iou_thresh</span><span class="p">,</span>
                <span class="n">stability_score_thresh</span><span class="o">=</span><span class="n">stability_score_thresh</span><span class="p">,</span>
                <span class="n">mask_threshold</span><span class="o">=</span><span class="n">mask_threshold</span><span class="p">,</span>
                <span class="n">stability_score_offset</span><span class="o">=</span><span class="n">stability_score_offset</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_filter_masks</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">masks</span><span class="p">,</span>
        <span class="n">iou_scores</span><span class="p">,</span>
        <span class="n">original_size</span><span class="p">,</span>
        <span class="n">cropped_box_image</span><span class="p">,</span>
        <span class="n">pred_iou_thresh</span><span class="o">=</span><span class="mf">0.88</span><span class="p">,</span>
        <span class="n">stability_score_thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
        <span class="n">mask_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">stability_score_offset</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Filters the predicted masks by selecting only the ones that meets several criteria. The first criterion being</span>
<span class="sd">        that the iou scores needs to be greater than `pred_iou_thresh`. The second criterion is that the stability</span>
<span class="sd">        score needs to be greater than `stability_score_thresh`. The method also converts the predicted masks to</span>
<span class="sd">        bounding boxes and pad the predicted masks if necessary.</span>

<span class="sd">        Args:</span>
<span class="sd">            masks (`mindspore.Tensor`):</span>
<span class="sd">                Input masks.</span>
<span class="sd">            iou_scores (`mindspore.Tensor`):</span>
<span class="sd">                List of IoU scores.</span>
<span class="sd">            original_size (`Tuple[int,int]`):</span>
<span class="sd">                Size of the orginal image.</span>
<span class="sd">            cropped_box_image (`np.array`):</span>
<span class="sd">                The cropped image.</span>
<span class="sd">            pred_iou_thresh (`float`, *optional*, defaults to 0.88):</span>
<span class="sd">                The threshold for the iou scores.</span>
<span class="sd">            stability_score_thresh (`float`, *optional*, defaults to 0.95):</span>
<span class="sd">                The threshold for the stability score.</span>
<span class="sd">            mask_threshold (`float`, *optional*, defaults to 0):</span>
<span class="sd">                The threshold for the predicted masks.</span>
<span class="sd">            stability_score_offset (`float`, *optional*, defaults to 1):</span>
<span class="sd">                The offset for the stability score used in the `_compute_stability_score` method.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">requires_backends</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;torch&quot;</span><span class="p">])</span>
        <span class="n">original_height</span><span class="p">,</span> <span class="n">original_width</span> <span class="o">=</span> <span class="n">original_size</span>
        <span class="n">iou_scores</span> <span class="o">=</span> <span class="n">iou_scores</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">iou_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;masks and iou_scores must have the same batch size.&quot;</span><span class="p">)</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">keep_mask</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">bool_</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pred_iou_thresh</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">keep_mask</span> <span class="o">=</span> <span class="n">keep_mask</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">iou_scores</span> <span class="o">&gt;</span> <span class="n">pred_iou_thresh</span><span class="p">)</span>

        <span class="c1"># compute stability score</span>
        <span class="k">if</span> <span class="n">stability_score_thresh</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">stability_scores</span> <span class="o">=</span> <span class="n">_compute_stability_score</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">mask_threshold</span><span class="p">,</span> <span class="n">stability_score_offset</span><span class="p">)</span>
            <span class="n">keep_mask</span> <span class="o">=</span> <span class="n">keep_mask</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">stability_scores</span> <span class="o">&gt;</span> <span class="n">stability_score_thresh</span><span class="p">)</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="n">iou_scores</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>

        <span class="c1"># binarize masks</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span> <span class="o">&gt;</span> <span class="n">mask_threshold</span>
        <span class="n">converted_boxes</span> <span class="o">=</span> <span class="n">_batched_mask_to_box</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>

        <span class="n">keep_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">_is_box_near_crop_edge</span><span class="p">(</span>
            <span class="n">converted_boxes</span><span class="p">,</span> <span class="n">cropped_box_image</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">original_width</span><span class="p">,</span> <span class="n">original_height</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>
        <span class="n">converted_boxes</span> <span class="o">=</span> <span class="n">converted_boxes</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>

        <span class="n">masks</span> <span class="o">=</span> <span class="n">_pad_masks</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">cropped_box_image</span><span class="p">,</span> <span class="n">original_height</span><span class="p">,</span> <span class="n">original_width</span><span class="p">)</span>
        <span class="c1"># conversion to rle is necessary to run non-maximum suppresion</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">_mask_to_rle</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">masks</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">converted_boxes</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">SamImageProcessor</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">do_resize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">,</span> <span class="n">do_rescale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rescale_factor</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">255</span><span class="p">,</span> <span class="n">do_normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">image_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask_pad_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_convert_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Initializes an instance of the SamImageProcessor class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_resize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Determines whether resizing of images should be performed. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The desired size of the images. Defaults to {'longest_edge': 1024}.
The size can be specified as a dictionary with keys 'longest_edge' or 'height' and 'width'.
If not provided as a dictionary, it is converted to a dictionary with the 'longest_edge' key.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Dict">Dict</span>[str, int]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The desired size of the segmentation masks. Defaults to {'longest_edge': 256}.
The size can be specified as a dictionary with keys 'longest_edge' or 'height' and 'width'.
If not provided as a dictionary, it is converted to a dictionary with the 'longest_edge' key.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Dict">Dict</span>[str, int]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resample</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The resampling method to use during image resizing.
Defaults to PILImageResampling.BILINEAR.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling">PILImageResampling</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling.BILINEAR">BILINEAR</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_rescale</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Determines whether rescaling of pixel values should be performed. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rescale_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The factor to divide pixel values by during rescaling.
Defaults to 1 / 255.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[int, float]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1 / 255</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_normalize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Determines whether normalization of pixel values should be performed.
Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_mean</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The mean values to subtract from pixel values
during normalization. Defaults to None, which uses the IMAGENET_DEFAULT_MEAN.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[float, <span title="typing.List">List</span>[float]]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_std</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The standard deviation values to divide pixel values
by during normalization. Defaults to None, which uses the IMAGENET_DEFAULT_STD.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[float, <span title="typing.List">List</span>[float]]]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_pad</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Determines whether padding of images should be performed. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The desired size of the padded images. Defaults to None,
which uses {'height': 1024, 'width': 1024}. The size can be specified as a single integer, representing
both height and width.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_pad_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The desired size of the padded segmentation masks. Defaults to None,
which uses {'height': 256, 'width': 256}. The size can be specified as a single integer,
representing both height and width.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_convert_rgb</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Determines whether conversion to RGB color space should be performed. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Additional keyword arguments to be passed to the parent class forwardor.</p>
              </div>
              <p>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>{}</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code>None</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">do_resize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mask_size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">,</span>
    <span class="n">do_rescale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">rescale_factor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">255</span><span class="p">,</span>
    <span class="n">do_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_pad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">pad_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mask_pad_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes an instance of the SamImageProcessor class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The instance of the class.</span>
<span class="sd">        do_resize (bool): Determines whether resizing of images should be performed. Defaults to True.</span>
<span class="sd">        size (Dict[str, int]): The desired size of the images. Defaults to {&#39;longest_edge&#39;: 1024}.</span>
<span class="sd">            The size can be specified as a dictionary with keys &#39;longest_edge&#39; or &#39;height&#39; and &#39;width&#39;.</span>
<span class="sd">            If not provided as a dictionary, it is converted to a dictionary with the &#39;longest_edge&#39; key.</span>
<span class="sd">        mask_size (Dict[str, int]): The desired size of the segmentation masks. Defaults to {&#39;longest_edge&#39;: 256}.</span>
<span class="sd">            The size can be specified as a dictionary with keys &#39;longest_edge&#39; or &#39;height&#39; and &#39;width&#39;.</span>
<span class="sd">            If not provided as a dictionary, it is converted to a dictionary with the &#39;longest_edge&#39; key.</span>
<span class="sd">        resample (PILImageResampling): The resampling method to use during image resizing.</span>
<span class="sd">            Defaults to PILImageResampling.BILINEAR.</span>
<span class="sd">        do_rescale (bool): Determines whether rescaling of pixel values should be performed. Defaults to True.</span>
<span class="sd">        rescale_factor (Union[int, float]): The factor to divide pixel values by during rescaling.</span>
<span class="sd">            Defaults to 1 / 255.</span>
<span class="sd">        do_normalize (bool): Determines whether normalization of pixel values should be performed.</span>
<span class="sd">            Defaults to True.</span>
<span class="sd">        image_mean (Optional[Union[float, List[float]]]): The mean values to subtract from pixel values</span>
<span class="sd">            during normalization. Defaults to None, which uses the IMAGENET_DEFAULT_MEAN.</span>
<span class="sd">        image_std (Optional[Union[float, List[float]]]): The standard deviation values to divide pixel values</span>
<span class="sd">            by during normalization. Defaults to None, which uses the IMAGENET_DEFAULT_STD.</span>
<span class="sd">        do_pad (bool): Determines whether padding of images should be performed. Defaults to True.</span>
<span class="sd">        pad_size (int): The desired size of the padded images. Defaults to None,</span>
<span class="sd">            which uses {&#39;height&#39;: 1024, &#39;width&#39;: 1024}. The size can be specified as a single integer, representing</span>
<span class="sd">            both height and width.</span>
<span class="sd">        mask_pad_size (int): The desired size of the padded segmentation masks. Defaults to None,</span>
<span class="sd">            which uses {&#39;height&#39;: 256, &#39;width&#39;: 256}. The size can be specified as a single integer,</span>
<span class="sd">            representing both height and width.</span>
<span class="sd">        do_convert_rgb (bool): Determines whether conversion to RGB color space should be performed. Defaults to True.</span>
<span class="sd">        **kwargs: Additional keyword arguments to be passed to the parent class forwardor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">size</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;longest_edge&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">}</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">size</span>

    <span class="n">pad_size</span> <span class="o">=</span> <span class="n">pad_size</span> <span class="k">if</span> <span class="n">pad_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;height&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">}</span>
    <span class="n">pad_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">pad_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">mask_size</span> <span class="o">=</span> <span class="n">mask_size</span> <span class="k">if</span> <span class="n">mask_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;longest_edge&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">}</span>
    <span class="n">mask_size</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">get_size_dict</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">mask_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask_size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="k">else</span> <span class="n">mask_size</span>
    <span class="p">)</span>

    <span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">mask_pad_size</span> <span class="k">if</span> <span class="n">mask_pad_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{</span><span class="s2">&quot;height&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">}</span>
    <span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">mask_pad_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">do_resize</span> <span class="o">=</span> <span class="n">do_resize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask_size</span> <span class="o">=</span> <span class="n">mask_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">resample</span> <span class="o">=</span> <span class="n">resample</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_rescale</span> <span class="o">=</span> <span class="n">do_rescale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rescale_factor</span> <span class="o">=</span> <span class="n">rescale_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_normalize</span> <span class="o">=</span> <span class="n">do_normalize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_mean</span> <span class="o">=</span> <span class="n">image_mean</span> <span class="k">if</span> <span class="n">image_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">IMAGENET_DEFAULT_MEAN</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">image_std</span> <span class="o">=</span> <span class="n">image_std</span> <span class="k">if</span> <span class="n">image_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">IMAGENET_DEFAULT_STD</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_pad</span> <span class="o">=</span> <span class="n">do_pad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pad_size</span> <span class="o">=</span> <span class="n">pad_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">mask_pad_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">do_convert_rgb</span> <span class="o">=</span> <span class="n">do_convert_rgb</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_valid_processor_keys</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;images&quot;</span><span class="p">,</span>
        <span class="s2">&quot;segmentation_maps&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_resize&quot;</span><span class="p">,</span>
        <span class="s2">&quot;size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;mask_size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;resample&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_rescale&quot;</span><span class="p">,</span>
        <span class="s2">&quot;rescale_factor&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_normalize&quot;</span><span class="p">,</span>
        <span class="s2">&quot;image_mean&quot;</span><span class="p">,</span>
        <span class="s2">&quot;image_std&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_pad&quot;</span><span class="p">,</span>
        <span class="s2">&quot;pad_size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;mask_pad_size&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_convert_rgb&quot;</span><span class="p">,</span>
        <span class="s2">&quot;return_tensors&quot;</span><span class="p">,</span>
        <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
        <span class="s2">&quot;input_data_format&quot;</span><span class="p">,</span>
    <span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.filter_masks" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">SamImageProcessor</span><span class="o">.</span><span class="n">filter_masks</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">iou_scores</span><span class="p">,</span> <span class="n">original_size</span><span class="p">,</span> <span class="n">cropped_box_image</span><span class="p">,</span> <span class="n">pred_iou_thresh</span><span class="o">=</span><span class="mf">0.88</span><span class="p">,</span> <span class="n">stability_score_thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">mask_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stability_score_offset</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;ms&#39;</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.filter_masks" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Filters the predicted masks by selecting only the ones that meets several criteria. The first criterion being
that the iou scores needs to be greater than <code>pred_iou_thresh</code>. The second criterion is that the stability
score needs to be greater than <code>stability_score_thresh</code>. The method also converts the predicted masks to
bounding boxes and pad the predicted masks if necessary.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>masks</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input masks.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[mindspore.Tensor, tf.Tensor]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iou_scores</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of IoU scores.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[mindspore.Tensor, tf.Tensor]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>original_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the orginal image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Tuple[int,int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cropped_box_image</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The cropped image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.array`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pred_iou_thresh</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The threshold for the iou scores.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.88</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.88</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stability_score_thresh</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The threshold for the stability score.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.95</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.95</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_threshold</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The threshold for the predicted masks.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stability_score_offset</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The offset for the stability score used in the <code>_compute_stability_score</code> method.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_tensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If <code>pt</code>, returns <code>mindspore.Tensor</code>. If <code>tf</code>, returns <code>tf.Tensor</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `pt`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;ms&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">filter_masks</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">masks</span><span class="p">,</span>
    <span class="n">iou_scores</span><span class="p">,</span>
    <span class="n">original_size</span><span class="p">,</span>
    <span class="n">cropped_box_image</span><span class="p">,</span>
    <span class="n">pred_iou_thresh</span><span class="o">=</span><span class="mf">0.88</span><span class="p">,</span>
    <span class="n">stability_score_thresh</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
    <span class="n">mask_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">stability_score_offset</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Filters the predicted masks by selecting only the ones that meets several criteria. The first criterion being</span>
<span class="sd">    that the iou scores needs to be greater than `pred_iou_thresh`. The second criterion is that the stability</span>
<span class="sd">    score needs to be greater than `stability_score_thresh`. The method also converts the predicted masks to</span>
<span class="sd">    bounding boxes and pad the predicted masks if necessary.</span>

<span class="sd">    Args:</span>
<span class="sd">        masks (`Union[mindspore.Tensor, tf.Tensor]`):</span>
<span class="sd">            Input masks.</span>
<span class="sd">        iou_scores (`Union[mindspore.Tensor, tf.Tensor]`):</span>
<span class="sd">            List of IoU scores.</span>
<span class="sd">        original_size (`Tuple[int,int]`):</span>
<span class="sd">            Size of the orginal image.</span>
<span class="sd">        cropped_box_image (`np.array`):</span>
<span class="sd">            The cropped image.</span>
<span class="sd">        pred_iou_thresh (`float`, *optional*, defaults to 0.88):</span>
<span class="sd">            The threshold for the iou scores.</span>
<span class="sd">        stability_score_thresh (`float`, *optional*, defaults to 0.95):</span>
<span class="sd">            The threshold for the stability score.</span>
<span class="sd">        mask_threshold (`float`, *optional*, defaults to 0):</span>
<span class="sd">            The threshold for the predicted masks.</span>
<span class="sd">        stability_score_offset (`float`, *optional*, defaults to 1):</span>
<span class="sd">            The offset for the stability score used in the `_compute_stability_score` method.</span>
<span class="sd">        return_tensors (`str`, *optional*, defaults to `pt`):</span>
<span class="sd">            If `pt`, returns `mindspore.Tensor`. If `tf`, returns `tf.Tensor`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_filter_masks</span><span class="p">(</span>
            <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
            <span class="n">iou_scores</span><span class="o">=</span><span class="n">iou_scores</span><span class="p">,</span>
            <span class="n">original_size</span><span class="o">=</span><span class="n">original_size</span><span class="p">,</span>
            <span class="n">cropped_box_image</span><span class="o">=</span><span class="n">cropped_box_image</span><span class="p">,</span>
            <span class="n">pred_iou_thresh</span><span class="o">=</span><span class="n">pred_iou_thresh</span><span class="p">,</span>
            <span class="n">stability_score_thresh</span><span class="o">=</span><span class="n">stability_score_thresh</span><span class="p">,</span>
            <span class="n">mask_threshold</span><span class="o">=</span><span class="n">mask_threshold</span><span class="p">,</span>
            <span class="n">stability_score_offset</span><span class="o">=</span><span class="n">stability_score_offset</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;tf&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_filter_masks_tf</span><span class="p">(</span>
            <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
            <span class="n">iou_scores</span><span class="o">=</span><span class="n">iou_scores</span><span class="p">,</span>
            <span class="n">original_size</span><span class="o">=</span><span class="n">original_size</span><span class="p">,</span>
            <span class="n">cropped_box_image</span><span class="o">=</span><span class="n">cropped_box_image</span><span class="p">,</span>
            <span class="n">pred_iou_thresh</span><span class="o">=</span><span class="n">pred_iou_thresh</span><span class="p">,</span>
            <span class="n">stability_score_thresh</span><span class="o">=</span><span class="n">stability_score_thresh</span><span class="p">,</span>
            <span class="n">mask_threshold</span><span class="o">=</span><span class="n">mask_threshold</span><span class="p">,</span>
            <span class="n">stability_score_offset</span><span class="o">=</span><span class="n">stability_score_offset</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.generate_crop_boxes" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">SamImageProcessor</span><span class="o">.</span><span class="n">generate_crop_boxes</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">target_size</span><span class="p">,</span> <span class="n">crop_n_layers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">overlap_ratio</span><span class="o">=</span><span class="mi">512</span> <span class="o">/</span> <span class="mi">1500</span><span class="p">,</span> <span class="n">points_per_crop</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">crop_n_points_downscale_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;ms&#39;</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.generate_crop_boxes" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Generates a list of crop boxes of different sizes. Each layer has (2**i)**2 boxes for the ith layer.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input original image</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.array`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>target_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Target size of the resized image</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>crop_n_layers</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If &gt;0, mask prediction will be run again on crops of the image. Sets the number of layers to run, where
each layer has 2**i_layer number of image crops.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>overlap_ratio</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Sets the degree to which crops overlap. In the first crop layer, crops will overlap by this fraction of
the image length. Later layers with more crops scale down this overlap.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 512/1500</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512 / 1500</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>points_per_crop</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of points to sample from each crop.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 32</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>32</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>crop_n_points_downscale_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of points-per-side sampled in layer n is scaled down by crop_n_points_downscale_factor**n.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format of the input image. If not provided, it will be inferred.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `ChannelDimension`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_tensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If <code>pt</code>, returns <code>mindspore.Tensor</code>. If <code>tf</code>, returns <code>tf.Tensor</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `pt`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;ms&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">generate_crop_boxes</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">image</span><span class="p">,</span>
    <span class="n">target_size</span><span class="p">,</span>
    <span class="n">crop_n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">overlap_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">512</span> <span class="o">/</span> <span class="mi">1500</span><span class="p">,</span>
    <span class="n">points_per_crop</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
    <span class="n">crop_n_points_downscale_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ms&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates a list of crop boxes of different sizes. Each layer has (2**i)**2 boxes for the ith layer.</span>

<span class="sd">    Args:</span>
<span class="sd">        image (`np.array`):</span>
<span class="sd">            Input original image</span>
<span class="sd">        target_size (`int`):</span>
<span class="sd">            Target size of the resized image</span>
<span class="sd">        crop_n_layers (`int`, *optional*, defaults to 0):</span>
<span class="sd">            If &gt;0, mask prediction will be run again on crops of the image. Sets the number of layers to run, where</span>
<span class="sd">            each layer has 2**i_layer number of image crops.</span>
<span class="sd">        overlap_ratio (`float`, *optional*, defaults to 512/1500):</span>
<span class="sd">            Sets the degree to which crops overlap. In the first crop layer, crops will overlap by this fraction of</span>
<span class="sd">            the image length. Later layers with more crops scale down this overlap.</span>
<span class="sd">        points_per_crop (`int`, *optional*, defaults to 32):</span>
<span class="sd">            Number of points to sample from each crop.</span>
<span class="sd">        crop_n_points_downscale_factor (`List[int]`, *optional*, defaults to 1):</span>
<span class="sd">            The number of points-per-side sampled in layer n is scaled down by crop_n_points_downscale_factor**n.</span>
<span class="sd">        input_data_format (`str` or `ChannelDimension`, *optional*):</span>
<span class="sd">            The channel dimension format of the input image. If not provided, it will be inferred.</span>
<span class="sd">        return_tensors (`str`, *optional*, defaults to `pt`):</span>
<span class="sd">            If `pt`, returns `mindspore.Tensor`. If `tf`, returns `tf.Tensor`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">crop_boxes</span><span class="p">,</span> <span class="n">points_per_crop</span><span class="p">,</span> <span class="n">cropped_images</span><span class="p">,</span> <span class="n">input_labels</span> <span class="o">=</span> <span class="n">_generate_crop_boxes</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="n">target_size</span><span class="p">,</span>
        <span class="n">crop_n_layers</span><span class="p">,</span>
        <span class="n">overlap_ratio</span><span class="p">,</span>
        <span class="n">points_per_crop</span><span class="p">,</span>
        <span class="n">crop_n_points_downscale_factor</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
        <span class="n">crop_boxes</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">crop_boxes</span><span class="p">)</span>
        <span class="n">points_per_crop</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">points_per_crop</span><span class="p">)</span>
        <span class="c1"># cropped_images stays as np</span>
        <span class="n">input_labels</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;return_tensors must be &#39;ms&#39;.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">crop_boxes</span><span class="p">,</span> <span class="n">points_per_crop</span><span class="p">,</span> <span class="n">cropped_images</span><span class="p">,</span> <span class="n">input_labels</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.pad_image" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">SamImageProcessor</span><span class="o">.</span><span class="n">pad_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.pad_image" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Pad an image to <code>(pad_size["height"], pad_size["width"])</code> with zeros to the right and bottom.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image to pad.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.ndarray`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Size of the output image after padding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The data format of the image. Can be either "channels_first" or "channels_last". If <code>None</code>, the
<code>data_format</code> of the <code>image</code> will be used.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `ChannelDimension`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format of the input image. If not provided, it will be inferred.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `ChannelDimension`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pad_image</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">pad_size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pad an image to `(pad_size[&quot;height&quot;], pad_size[&quot;width&quot;])` with zeros to the right and bottom.</span>

<span class="sd">    Args:</span>
<span class="sd">        image (`np.ndarray`):</span>
<span class="sd">            Image to pad.</span>
<span class="sd">        pad_size (`Dict[str, int]`):</span>
<span class="sd">            Size of the output image after padding.</span>
<span class="sd">        data_format (`str` or `ChannelDimension`, *optional*):</span>
<span class="sd">            The data format of the image. Can be either &quot;channels_first&quot; or &quot;channels_last&quot;. If `None`, the</span>
<span class="sd">            `data_format` of the `image` will be used.</span>
<span class="sd">        input_data_format (`str` or `ChannelDimension`, *optional*):</span>
<span class="sd">            The channel dimension format of the input image. If not provided, it will be inferred.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output_height</span><span class="p">,</span> <span class="n">output_width</span> <span class="o">=</span> <span class="n">pad_size</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">pad_size</span><span class="p">[</span><span class="s2">&quot;width&quot;</span><span class="p">]</span>
    <span class="n">input_height</span><span class="p">,</span> <span class="n">input_width</span> <span class="o">=</span> <span class="n">get_image_size</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>

    <span class="n">pad_width</span> <span class="o">=</span> <span class="n">output_width</span> <span class="o">-</span> <span class="n">input_width</span>
    <span class="n">pad_height</span> <span class="o">=</span> <span class="n">output_height</span> <span class="o">-</span> <span class="n">input_height</span>

    <span class="n">padded_image</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_height</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">)),</span>
        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">padded_image</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.post_process_for_mask_generation" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">SamImageProcessor</span><span class="o">.</span><span class="n">post_process_for_mask_generation</span><span class="p">(</span><span class="n">all_masks</span><span class="p">,</span> <span class="n">all_scores</span><span class="p">,</span> <span class="n">all_boxes</span><span class="p">,</span> <span class="n">crops_nms_thresh</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;ms&#39;</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.post_process_for_mask_generation" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Post processes mask that are generated by calling the Non Maximum Suppression algorithm on the predicted masks.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>all_masks</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of all predicted segmentation masks</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[List[mindspore.Tensor], List[tf.Tensor]]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>all_scores</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of all predicted iou scores</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[List[mindspore.Tensor], List[tf.Tensor]]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>all_boxes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>List of all bounding boxes of the predicted masks</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[List[mindspore.Tensor], List[tf.Tensor]]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>crops_nms_thresh</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Threshold for NMS (Non Maximum Suppression) algorithm.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_tensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If <code>pt</code>, returns <code>mindspore.Tensor</code>. If <code>tf</code>, returns <code>tf.Tensor</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `pt`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;ms&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">post_process_for_mask_generation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">all_masks</span><span class="p">,</span> <span class="n">all_scores</span><span class="p">,</span> <span class="n">all_boxes</span><span class="p">,</span> <span class="n">crops_nms_thresh</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Post processes mask that are generated by calling the Non Maximum Suppression algorithm on the predicted masks.</span>

<span class="sd">    Args:</span>
<span class="sd">        all_masks (`Union[List[mindspore.Tensor], List[tf.Tensor]]`):</span>
<span class="sd">            List of all predicted segmentation masks</span>
<span class="sd">        all_scores (`Union[List[mindspore.Tensor], List[tf.Tensor]]`):</span>
<span class="sd">            List of all predicted iou scores</span>
<span class="sd">        all_boxes (`Union[List[mindspore.Tensor], List[tf.Tensor]]`):</span>
<span class="sd">            List of all bounding boxes of the predicted masks</span>
<span class="sd">        crops_nms_thresh (`float`):</span>
<span class="sd">            Threshold for NMS (Non Maximum Suppression) algorithm.</span>
<span class="sd">        return_tensors (`str`, *optional*, defaults to `pt`):</span>
<span class="sd">            If `pt`, returns `mindspore.Tensor`. If `tf`, returns `tf.Tensor`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_postprocess_for_mg</span><span class="p">(</span><span class="n">all_masks</span><span class="p">,</span> <span class="n">all_scores</span><span class="p">,</span> <span class="n">all_boxes</span><span class="p">,</span> <span class="n">crops_nms_thresh</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.post_process_masks" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">SamImageProcessor</span><span class="o">.</span><span class="n">post_process_masks</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">original_sizes</span><span class="p">,</span> <span class="n">reshaped_input_sizes</span><span class="p">,</span> <span class="n">mask_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">binarize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;ms&#39;</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.post_process_masks" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Remove padding and upscale masks to the original image size.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>masks</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[List[mindspore.Tensor], List[np.ndarray], List[tf.Tensor]]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>original_sizes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The original sizes of each image before it was resized to the model's expected input shape, in (height,
width) format.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[mindspore.Tensor, tf.Tensor, List[Tuple[int,int]]]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>reshaped_input_sizes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[mindspore.Tensor, tf.Tensor, List[Tuple[int,int]]]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_threshold</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The threshold to use for binarizing the masks.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>binarize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to binarize the masks.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The target size the images were padded to before being passed to the model. If None, the target size is
assumed to be the processor's <code>pad_size</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to `self.pad_size`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_tensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If <code>"ms"</code>, return PyTorch tensors. If <code>"tf"</code>, return TensorFlow tensors.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;ms&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;ms&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code>`Union[mindspore.Tensor, tf.Tensor]`</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Batched masks in batch_size, num_channels, height, width) format, where</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>(height, width) is given by original_size.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">post_process_masks</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">masks</span><span class="p">,</span>
    <span class="n">original_sizes</span><span class="p">,</span>
    <span class="n">reshaped_input_sizes</span><span class="p">,</span>
    <span class="n">mask_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">binarize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">pad_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Remove padding and upscale masks to the original image size.</span>

<span class="sd">    Args:</span>
<span class="sd">        masks (`Union[List[mindspore.Tensor], List[np.ndarray], List[tf.Tensor]]`):</span>
<span class="sd">            Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.</span>
<span class="sd">        original_sizes (`Union[mindspore.Tensor, tf.Tensor, List[Tuple[int,int]]]`):</span>
<span class="sd">            The original sizes of each image before it was resized to the model&#39;s expected input shape, in (height,</span>
<span class="sd">            width) format.</span>
<span class="sd">        reshaped_input_sizes (`Union[mindspore.Tensor, tf.Tensor, List[Tuple[int,int]]]`):</span>
<span class="sd">            The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.</span>
<span class="sd">        mask_threshold (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            The threshold to use for binarizing the masks.</span>
<span class="sd">        binarize (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to binarize the masks.</span>
<span class="sd">        pad_size (`int`, *optional*, defaults to `self.pad_size`):</span>
<span class="sd">            The target size the images were padded to before being passed to the model. If None, the target size is</span>
<span class="sd">            assumed to be the processor&#39;s `pad_size`.</span>
<span class="sd">        return_tensors (`str`, *optional*, defaults to `&quot;ms&quot;`):</span>
<span class="sd">            If `&quot;ms&quot;`, return PyTorch tensors. If `&quot;tf&quot;`, return TensorFlow tensors.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (`Union[mindspore.Tensor, tf.Tensor]`): Batched masks in batch_size, num_channels, height, width) format, where</span>
<span class="sd">        (height, width) is given by original_size.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_process_masks_ms</span><span class="p">(</span>
            <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
            <span class="n">original_sizes</span><span class="o">=</span><span class="n">original_sizes</span><span class="p">,</span>
            <span class="n">reshaped_input_sizes</span><span class="o">=</span><span class="n">reshaped_input_sizes</span><span class="p">,</span>
            <span class="n">mask_threshold</span><span class="o">=</span><span class="n">mask_threshold</span><span class="p">,</span>
            <span class="n">binarize</span><span class="o">=</span><span class="n">binarize</span><span class="p">,</span>
            <span class="n">pad_size</span><span class="o">=</span><span class="n">pad_size</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;return_tensors must be &#39;ms&#39;.&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.preprocess" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">SamImageProcessor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">segmentation_maps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_resize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_rescale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rescale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_std</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_pad</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask_pad_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_convert_rgb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">ChannelDimension</span><span class="o">.</span><span class="n">FIRST</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.preprocess" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Preprocess an image or batch of images.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>images</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If
passing in images with pixel values between 0 and 1, set <code>do_rescale=False</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ImageInput`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>segmentation_maps</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Segmentation map to preprocess.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ImageInput`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_resize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to resize the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_resize`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Controls the size of the image after <code>resize</code>. The longest edge of the image is resized to
<code>size["longest_edge"]</code> whilst preserving the aspect ratio.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`, *optional*, defaults to `self.size`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Controls the size of the segmentation map after <code>resize</code>. The longest edge of the image is resized to
<code>size["longest_edge"]</code> whilst preserving the aspect ratio.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`, *optional*, defaults to `self.mask_size`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resample</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p><code>PILImageResampling</code> filter to use when resizing the image e.g. <code>PILImageResampling.BILINEAR</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`PILImageResampling`, *optional*, defaults to `self.resample`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_rescale</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to rescale the image pixel values by rescaling factor.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_rescale`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rescale_factor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Rescale factor to apply to the image pixel values.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int` or `float`, *optional*, defaults to `self.rescale_factor`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_normalize</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to normalize the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_normalize`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_mean</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image mean to normalize the image by if <code>do_normalize</code> is set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float` or `List[float]`, *optional*, defaults to `self.image_mean`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_std</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image standard deviation to normalize the image by if <code>do_normalize</code> is set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float` or `List[float]`, *optional*, defaults to `self.image_std`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_pad</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to pad the image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_pad`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pad_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Controls the size of the padding applied to the image. The image is padded to <code>pad_size["height"]</code> and
<code>pad_size["width"]</code> if <code>do_pad</code> is set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`, *optional*, defaults to `self.pad_size`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_pad_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Controls the size of the padding applied to the segmentation map. The image is padded to
<code>mask_pad_size["height"]</code> and <code>mask_pad_size["width"]</code> if <code>do_pad</code> is set to <code>True</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`, *optional*, defaults to `self.mask_pad_size`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_convert_rgb</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to convert the image to RGB.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `self.do_convert_rgb`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_tensors</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The type of tensors to return. Can be one of:</p>
<ul>
<li>Unset: Return a list of <code>np.ndarray</code>.</li>
<li><code>TensorType.TENSORFLOW</code> or <code>'tf'</code>: Return a batch of type <code>tf.Tensor</code>.</li>
<li><code>TensorType.PYTORCH</code> or <code>'pt'</code>: Return a batch of type <code>mindspore.Tensor</code>.</li>
<li><code>TensorType.NUMPY</code> or <code>'np'</code>: Return a batch of type <code>np.ndarray</code>.</li>
<li><code>TensorType.JAX</code> or <code>'jax'</code>: Return a batch of type <code>jax.numpy.ndarray</code>.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `TensorType`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format for the output image. Can be one of:</p>
<ul>
<li><code>"channels_first"</code> or <code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.</li>
<li><code>"channels_last"</code> or <code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.</li>
<li>Unset: Use the channel dimension format of the input image.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.transformers.image_utils.ChannelDimension.FIRST">FIRST</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format for the input image. If unset, the channel dimension format is inferred
from the input image. Can be one of:</p>
<ul>
<li><code>"channels_first"</code> or <code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.</li>
<li><code>"channels_last"</code> or <code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.</li>
<li><code>"none"</code> or <code>ChannelDimension.NONE</code>: image in (height, width) format.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ChannelDimension` or `str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">images</span><span class="p">:</span> <span class="n">ImageInput</span><span class="p">,</span>
    <span class="n">segmentation_maps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ImageInput</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_resize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mask_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">resample</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;PILImageResampling&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_rescale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">rescale_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_normalize</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_mean</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_std</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_pad</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pad_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mask_pad_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">do_convert_rgb</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">data_format</span><span class="p">:</span> <span class="n">ChannelDimension</span> <span class="o">=</span> <span class="n">ChannelDimension</span><span class="o">.</span><span class="n">FIRST</span><span class="p">,</span>
    <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess an image or batch of images.</span>

<span class="sd">    Args:</span>
<span class="sd">        images (`ImageInput`):</span>
<span class="sd">            Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If</span>
<span class="sd">            passing in images with pixel values between 0 and 1, set `do_rescale=False`.</span>
<span class="sd">        segmentation_maps (`ImageInput`, *optional*):</span>
<span class="sd">            Segmentation map to preprocess.</span>
<span class="sd">        do_resize (`bool`, *optional*, defaults to `self.do_resize`):</span>
<span class="sd">            Whether to resize the image.</span>
<span class="sd">        size (`Dict[str, int]`, *optional*, defaults to `self.size`):</span>
<span class="sd">            Controls the size of the image after `resize`. The longest edge of the image is resized to</span>
<span class="sd">            `size[&quot;longest_edge&quot;]` whilst preserving the aspect ratio.</span>
<span class="sd">        mask_size (`Dict[str, int]`, *optional*, defaults to `self.mask_size`):</span>
<span class="sd">            Controls the size of the segmentation map after `resize`. The longest edge of the image is resized to</span>
<span class="sd">            `size[&quot;longest_edge&quot;]` whilst preserving the aspect ratio.</span>
<span class="sd">        resample (`PILImageResampling`, *optional*, defaults to `self.resample`):</span>
<span class="sd">            `PILImageResampling` filter to use when resizing the image e.g. `PILImageResampling.BILINEAR`.</span>
<span class="sd">        do_rescale (`bool`, *optional*, defaults to `self.do_rescale`):</span>
<span class="sd">            Whether to rescale the image pixel values by rescaling factor.</span>
<span class="sd">        rescale_factor (`int` or `float`, *optional*, defaults to `self.rescale_factor`):</span>
<span class="sd">            Rescale factor to apply to the image pixel values.</span>
<span class="sd">        do_normalize (`bool`, *optional*, defaults to `self.do_normalize`):</span>
<span class="sd">            Whether to normalize the image.</span>
<span class="sd">        image_mean (`float` or `List[float]`, *optional*, defaults to `self.image_mean`):</span>
<span class="sd">            Image mean to normalize the image by if `do_normalize` is set to `True`.</span>
<span class="sd">        image_std (`float` or `List[float]`, *optional*, defaults to `self.image_std`):</span>
<span class="sd">            Image standard deviation to normalize the image by if `do_normalize` is set to `True`.</span>
<span class="sd">        do_pad (`bool`, *optional*, defaults to `self.do_pad`):</span>
<span class="sd">            Whether to pad the image.</span>
<span class="sd">        pad_size (`Dict[str, int]`, *optional*, defaults to `self.pad_size`):</span>
<span class="sd">            Controls the size of the padding applied to the image. The image is padded to `pad_size[&quot;height&quot;]` and</span>
<span class="sd">            `pad_size[&quot;width&quot;]` if `do_pad` is set to `True`.</span>
<span class="sd">        mask_pad_size (`Dict[str, int]`, *optional*, defaults to `self.mask_pad_size`):</span>
<span class="sd">            Controls the size of the padding applied to the segmentation map. The image is padded to</span>
<span class="sd">            `mask_pad_size[&quot;height&quot;]` and `mask_pad_size[&quot;width&quot;]` if `do_pad` is set to `True`.</span>
<span class="sd">        do_convert_rgb (`bool`, *optional*, defaults to `self.do_convert_rgb`):</span>
<span class="sd">            Whether to convert the image to RGB.</span>
<span class="sd">        return_tensors (`str` or `TensorType`, *optional*):</span>
<span class="sd">            The type of tensors to return. Can be one of:</span>

<span class="sd">            - Unset: Return a list of `np.ndarray`.</span>
<span class="sd">            - `TensorType.TENSORFLOW` or `&#39;tf&#39;`: Return a batch of type `tf.Tensor`.</span>
<span class="sd">            - `TensorType.PYTORCH` or `&#39;pt&#39;`: Return a batch of type `mindspore.Tensor`.</span>
<span class="sd">            - `TensorType.NUMPY` or `&#39;np&#39;`: Return a batch of type `np.ndarray`.</span>
<span class="sd">            - `TensorType.JAX` or `&#39;jax&#39;`: Return a batch of type `jax.numpy.ndarray`.</span>
<span class="sd">        data_format (`ChannelDimension` or `str`, *optional*, defaults to `ChannelDimension.FIRST`):</span>
<span class="sd">            The channel dimension format for the output image. Can be one of:</span>

<span class="sd">            - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">            - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">            - Unset: Use the channel dimension format of the input image.</span>
<span class="sd">        input_data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">            The channel dimension format for the input image. If unset, the channel dimension format is inferred</span>
<span class="sd">            from the input image. Can be one of:</span>

<span class="sd">            - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">            - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">            - `&quot;none&quot;` or `ChannelDimension.NONE`: image in (height, width) format.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">do_resize</span> <span class="o">=</span> <span class="n">do_resize</span> <span class="k">if</span> <span class="n">do_resize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_resize</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">size</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">size</span>
    <span class="n">mask_size</span> <span class="o">=</span> <span class="n">mask_size</span> <span class="k">if</span> <span class="n">mask_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_size</span>
    <span class="n">mask_size</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">get_size_dict</span><span class="p">(</span><span class="n">max_size</span><span class="o">=</span><span class="n">mask_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask_size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="k">else</span> <span class="n">mask_size</span>
    <span class="p">)</span>
    <span class="n">resample</span> <span class="o">=</span> <span class="n">resample</span> <span class="k">if</span> <span class="n">resample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">resample</span>
    <span class="n">do_rescale</span> <span class="o">=</span> <span class="n">do_rescale</span> <span class="k">if</span> <span class="n">do_rescale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_rescale</span>
    <span class="n">rescale_factor</span> <span class="o">=</span> <span class="n">rescale_factor</span> <span class="k">if</span> <span class="n">rescale_factor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_factor</span>
    <span class="n">do_normalize</span> <span class="o">=</span> <span class="n">do_normalize</span> <span class="k">if</span> <span class="n">do_normalize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_normalize</span>
    <span class="n">image_mean</span> <span class="o">=</span> <span class="n">image_mean</span> <span class="k">if</span> <span class="n">image_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_mean</span>
    <span class="n">image_std</span> <span class="o">=</span> <span class="n">image_std</span> <span class="k">if</span> <span class="n">image_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_std</span>
    <span class="n">do_pad</span> <span class="o">=</span> <span class="n">do_pad</span> <span class="k">if</span> <span class="n">do_pad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_pad</span>
    <span class="n">pad_size</span> <span class="o">=</span> <span class="n">pad_size</span> <span class="k">if</span> <span class="n">pad_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_size</span>
    <span class="n">pad_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">pad_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">mask_pad_size</span> <span class="k">if</span> <span class="n">mask_pad_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_pad_size</span>
    <span class="n">mask_pad_size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">mask_pad_size</span><span class="p">,</span> <span class="n">default_to_square</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">do_convert_rgb</span> <span class="o">=</span> <span class="n">do_convert_rgb</span> <span class="k">if</span> <span class="n">do_convert_rgb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_convert_rgb</span>

    <span class="n">images</span> <span class="o">=</span> <span class="n">make_list_of_images</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

    <span class="n">validate_kwargs</span><span class="p">(</span><span class="n">captured_kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">valid_processor_keys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_valid_processor_keys</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_images</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Invalid image type. Must be of type PIL.Image.Image, numpy.ndarray, &quot;</span>
            <span class="s2">&quot;mindspore.Tensor, tf.Tensor or jax.ndarray.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">segmentation_maps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">segmentation_maps</span> <span class="o">=</span> <span class="n">make_list_of_images</span><span class="p">(</span><span class="n">segmentation_maps</span><span class="p">,</span> <span class="n">expected_ndims</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_images</span><span class="p">(</span><span class="n">segmentation_maps</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Invalid segmentation map type. Must be of type PIL.Image.Image, numpy.ndarray, &quot;</span>
                <span class="s2">&quot;mindspore.Tensor, tf.Tensor or jax.ndarray.&quot;</span>
            <span class="p">)</span>
    <span class="n">validate_preprocess_arguments</span><span class="p">(</span>
        <span class="n">do_rescale</span><span class="o">=</span><span class="n">do_rescale</span><span class="p">,</span>
        <span class="n">rescale_factor</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span>
        <span class="n">do_normalize</span><span class="o">=</span><span class="n">do_normalize</span><span class="p">,</span>
        <span class="n">image_mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span>
        <span class="n">image_std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span>
        <span class="n">do_pad</span><span class="o">=</span><span class="n">do_pad</span><span class="p">,</span>
        <span class="n">size_divisibility</span><span class="o">=</span><span class="n">pad_size</span><span class="p">,</span>  <span class="c1"># Here _preprocess needs do_pad and pad_size.</span>
        <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
        <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">images</span><span class="p">,</span> <span class="n">original_sizes</span><span class="p">,</span> <span class="n">reshaped_input_sizes</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="o">*</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_image</span><span class="p">(</span>
                <span class="n">image</span><span class="o">=</span><span class="n">img</span><span class="p">,</span>
                <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
                <span class="n">do_rescale</span><span class="o">=</span><span class="n">do_rescale</span><span class="p">,</span>
                <span class="n">rescale_factor</span><span class="o">=</span><span class="n">rescale_factor</span><span class="p">,</span>
                <span class="n">do_normalize</span><span class="o">=</span><span class="n">do_normalize</span><span class="p">,</span>
                <span class="n">image_mean</span><span class="o">=</span><span class="n">image_mean</span><span class="p">,</span>
                <span class="n">image_std</span><span class="o">=</span><span class="n">image_std</span><span class="p">,</span>
                <span class="n">do_pad</span><span class="o">=</span><span class="n">do_pad</span><span class="p">,</span>
                <span class="n">pad_size</span><span class="o">=</span><span class="n">pad_size</span><span class="p">,</span>
                <span class="n">do_convert_rgb</span><span class="o">=</span><span class="n">do_convert_rgb</span><span class="p">,</span>
                <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
                <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;pixel_values&quot;</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span>
        <span class="s2">&quot;original_sizes&quot;</span><span class="p">:</span> <span class="n">original_sizes</span><span class="p">,</span>
        <span class="s2">&quot;reshaped_input_sizes&quot;</span><span class="p">:</span> <span class="n">reshaped_input_sizes</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">segmentation_maps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">segmentation_maps</span><span class="p">,</span> <span class="n">original_mask_sizes</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="o">*</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_mask</span><span class="p">(</span>
                    <span class="n">segmentation_map</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
                    <span class="n">do_resize</span><span class="o">=</span><span class="n">do_resize</span><span class="p">,</span>
                    <span class="n">mask_size</span><span class="o">=</span><span class="n">mask_size</span><span class="p">,</span>
                    <span class="n">do_pad</span><span class="o">=</span><span class="n">do_pad</span><span class="p">,</span>
                    <span class="n">mask_pad_size</span><span class="o">=</span><span class="n">mask_pad_size</span><span class="p">,</span>
                    <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">segmentation_maps</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># masks should start out the same size as input images</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">original_im_size</span> <span class="o">==</span> <span class="n">original_mask_size</span>
            <span class="k">for</span> <span class="n">original_im_size</span><span class="p">,</span> <span class="n">original_mask_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">original_sizes</span><span class="p">,</span> <span class="n">original_mask_sizes</span><span class="p">)</span>
        <span class="p">),</span> <span class="s2">&quot;Segmentation maps should be the same size as input images.&quot;</span>

        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">segmentation_maps</span>

    <span class="k">return</span> <span class="n">BatchFeature</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">tensor_type</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.resize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">SamImageProcessor</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_data_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.SamImageProcessor.resize" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Resize an image to <code>(size["height"], size["width"])</code>.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image to resize.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.ndarray`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dictionary in the format <code>{"longest_edge": int}</code> specifying the size of the output image. The longest
edge of the image will be resized to the specified size, while the other edge will be resized to
maintain the aspect ratio.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, int]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>resample</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p><code>PILImageResampling</code> filter to use when resizing the image e.g. <code>PILImageResampling.BILINEAR</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling">PILImageResampling</span></code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindnlp.transformers.image_utils.PILImageResampling.BICUBIC">BICUBIC</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format for the output image. If unset, the channel dimension format of the input
image is used. Can be one of:</p>
<ul>
<li><code>"channels_first"</code> or <code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.</li>
<li><code>"channels_last"</code> or <code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ChannelDimension` or `str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_data_format</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The channel dimension format for the input image. If unset, the channel dimension format is inferred
from the input image. Can be one of:</p>
<ul>
<li><code>"channels_first"</code> or <code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.</li>
<li><code>"channels_last"</code> or <code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.</li>
</ul>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ChannelDimension` or `str`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="numpy.ndarray">ndarray</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>np.ndarray</code>: The resized image.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">resize</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">resample</span><span class="p">:</span> <span class="n">PILImageResampling</span> <span class="o">=</span> <span class="n">PILImageResampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">,</span>
    <span class="n">data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_data_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ChannelDimension</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resize an image to `(size[&quot;height&quot;], size[&quot;width&quot;])`.</span>

<span class="sd">    Args:</span>
<span class="sd">        image (`np.ndarray`):</span>
<span class="sd">            Image to resize.</span>
<span class="sd">        size (`Dict[str, int]`):</span>
<span class="sd">            Dictionary in the format `{&quot;longest_edge&quot;: int}` specifying the size of the output image. The longest</span>
<span class="sd">            edge of the image will be resized to the specified size, while the other edge will be resized to</span>
<span class="sd">            maintain the aspect ratio.</span>
<span class="sd">        resample:</span>
<span class="sd">            `PILImageResampling` filter to use when resizing the image e.g. `PILImageResampling.BILINEAR`.</span>
<span class="sd">        data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">            The channel dimension format for the output image. If unset, the channel dimension format of the input</span>
<span class="sd">            image is used. Can be one of:</span>

<span class="sd">            - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">            - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>
<span class="sd">        input_data_format (`ChannelDimension` or `str`, *optional*):</span>
<span class="sd">            The channel dimension format for the input image. If unset, the channel dimension format is inferred</span>
<span class="sd">            from the input image. Can be one of:</span>

<span class="sd">            - `&quot;channels_first&quot;` or `ChannelDimension.FIRST`: image in (num_channels, height, width) format.</span>
<span class="sd">            - `&quot;channels_last&quot;` or `ChannelDimension.LAST`: image in (height, width, num_channels) format.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `np.ndarray`: The resized image.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">get_size_dict</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;longest_edge&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">size</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The `size` dictionary must contain the key `longest_edge`. Got </span><span class="si">{</span><span class="n">size</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">input_size</span> <span class="o">=</span> <span class="n">get_image_size</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">channel_dim</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">)</span>
    <span class="n">output_height</span><span class="p">,</span> <span class="n">output_width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_preprocess_shape</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">size</span><span class="p">[</span><span class="s2">&quot;longest_edge&quot;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">resize</span><span class="p">(</span>
        <span class="n">image</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">output_height</span><span class="p">,</span> <span class="n">output_width</span><span class="p">),</span>
        <span class="n">resample</span><span class="o">=</span><span class="n">resample</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span>
        <span class="n">input_data_format</span><span class="o">=</span><span class="n">input_data_format</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.sam.image_processing_sam.batched_nms" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">batched_nms</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">idxs</span><span class="p">,</span> <span class="n">iou_threshold</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.batched_nms" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Performs non-maximum suppression in a batched fashion.</p>
<p>Each index value correspond to a category, and NMS
will not be applied between elements of different categories.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>boxes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>boxes where NMS will be performed. They
are expected to be in <code>(x1, y1, x2, y2)</code> format with <code>0 &lt;= x1 &lt; x2</code> and <code>0 &lt;= y1 &lt; y2</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>Tensor[N, 4]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>scores</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>scores for each one of the boxes</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>Tensor[N]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>idxs</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>indices of the categories for each one of the boxes.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>Tensor[N]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iou_threshold</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>discards all overlapping boxes with IoU &gt; iou_threshold</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>Tensor</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>int64 tensor with the indices of the elements that have been kept by NMS, sorted
in decreasing order of scores</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.Tensor">Tensor</span></code>
                  </span>
                </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">batched_nms</span><span class="p">(</span>
    <span class="n">boxes</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">scores</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">idxs</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">iou_threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs non-maximum suppression in a batched fashion.</span>

<span class="sd">    Each index value correspond to a category, and NMS</span>
<span class="sd">    will not be applied between elements of different categories.</span>

<span class="sd">    Args:</span>
<span class="sd">        boxes (Tensor[N, 4]): boxes where NMS will be performed. They</span>
<span class="sd">            are expected to be in ``(x1, y1, x2, y2)`` format with ``0 &lt;= x1 &lt; x2`` and ``0 &lt;= y1 &lt; y2``.</span>
<span class="sd">        scores (Tensor[N]): scores for each one of the boxes</span>
<span class="sd">        idxs (Tensor[N]): indices of the categories for each one of the boxes.</span>
<span class="sd">        iou_threshold (float): discards all overlapping boxes with IoU &gt; iou_threshold</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: int64 tensor with the indices of the elements that have been kept by NMS, sorted</span>
<span class="sd">            in decreasing order of scores</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Benchmarks that drove the following thresholds are at</span>
    <span class="c1"># https://github.com/pytorch/vision/issues/1311#issuecomment-781329339</span>
    <span class="k">if</span> <span class="n">boxes</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="p">(</span><span class="mi">4000</span> <span class="k">if</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s1">&#39;device_target&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;CPU&quot;</span> <span class="k">else</span> <span class="mi">20000</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_batched_nms_vanilla</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">idxs</span><span class="p">,</span> <span class="n">iou_threshold</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_batched_nms_coordinate_trick</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">idxs</span><span class="p">,</span> <span class="n">iou_threshold</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindnlp.transformers.models.sam.image_processing_sam.nms" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">image_processing_sam</span><span class="o">.</span><span class="n">nms</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">iou_threshold</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.image_processing_sam.nms" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Performs non-maximum suppression (NMS) on a set of bounding boxes.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>boxes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A tensor of shape (N, 4) representing the coordinates of the N bounding boxes. 
Each bounding box is defined by four values: (x_min, y_min, x_max, y_max).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>scores</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A tensor of shape (N,) representing the scores associated with each bounding box.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.Tensor">Tensor</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iou_threshold</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The Intersection over Union (IoU) threshold used for NMS. 
Bounding boxes with IoU greater than or equal to this threshold will be suppressed.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>mindspore.Tensor: A tensor containing the indices of the selected bounding boxes after NMS. 
The shape of the returned tensor is (M,), where M is the number of selected bounding boxes.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RAISES</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>TypeError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If any of the input arguments are not of the expected type.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
              <span class="doc-raises-annotation">
                  <code>ValueError</code>
              </span>
            </td>
            <td class="doc-raises-details">
              <div class="doc-md-description">
                <p>If the shape of 'boxes' and 'scores' tensors are incompatible or if 'iou_threshold'
is not within the valid range.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\image_processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">nms</span><span class="p">(</span><span class="n">boxes</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">scores</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">iou_threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs non-maximum suppression (NMS) on a set of bounding boxes.</span>

<span class="sd">    Args:</span>
<span class="sd">        boxes (mindspore.Tensor): A tensor of shape (N, 4) representing the coordinates of the N bounding boxes. </span>
<span class="sd">            Each bounding box is defined by four values: (x_min, y_min, x_max, y_max).</span>
<span class="sd">        scores (mindspore.Tensor): A tensor of shape (N,) representing the scores associated with each bounding box.</span>
<span class="sd">        iou_threshold (float): The Intersection over Union (IoU) threshold used for NMS. </span>
<span class="sd">            Bounding boxes with IoU greater than or equal to this threshold will be suppressed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        mindspore.Tensor: A tensor containing the indices of the selected bounding boxes after NMS. </span>
<span class="sd">            The shape of the returned tensor is (M,), where M is the number of selected bounding boxes.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If any of the input arguments are not of the expected type.</span>
<span class="sd">        ValueError: If the shape of &#39;boxes&#39; and &#39;scores&#39; tensors are incompatible or if &#39;iou_threshold&#39;</span>
<span class="sd">            is not within the valid range.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">box_with_score</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">boxes</span><span class="p">,</span> <span class="n">scores</span><span class="p">))</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">selected_mask</span> <span class="o">=</span> <span class="n">_get_cache_prim</span><span class="p">(</span><span class="n">mindspore</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">NMSWithMask</span><span class="p">)(</span><span class="n">iou_threshold</span><span class="p">)(</span><span class="n">box_with_score</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">selected_mask</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="mindnlp.transformers.models.sam.modeling_sam" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>MindSpore SAM model.</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamAttention" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamAttention</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamAttention" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>


        <p>SAM's attention layer that allows for downscaling the size of the embedding after projection to queries, keys, and
values.</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    SAM&#39;s attention layer that allows for downscaling the size of the embedding after projection to queries, keys, and</span>
<span class="sd">    values.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>

        <span class="n">downsample_rate</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">attention_downsample_rate</span> <span class="k">if</span> <span class="n">downsample_rate</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">downsample_rate</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="n">downsample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_attention_heads</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_attention_heads must divide hidden_size.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">q_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">internal_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_separate_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">channel</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">c_per_head</span> <span class="o">=</span> <span class="n">channel</span> <span class="o">//</span> <span class="n">num_attention_heads</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch</span> <span class="o">*</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">num_attention_heads</span><span class="p">,</span> <span class="n">c_per_head</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_recombine_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">c_per_head</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch</span> <span class="o">//</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">n_tokens</span><span class="p">,</span> <span class="n">n_heads</span> <span class="o">*</span> <span class="n">c_per_head</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">attention_similarity</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># Input projections</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_proj</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_proj</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_proj</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="n">point_batch_size</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Separate into heads</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_separate_heads</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">)</span>

        <span class="c1"># SamAttention</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">c_per_head</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">query</span> <span class="o">@</span> <span class="n">key</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># batch_size * point_batch_size  x N_heads x N_tokens x N_tokens</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">/</span> <span class="p">(</span><span class="n">c_per_head</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">attention_similarity</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">+</span> <span class="n">attention_similarity</span>
            <span class="n">attn</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Get output</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">@</span> <span class="n">value</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recombine_heads</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamImageSegmentationOutput" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamImageSegmentationOutput</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamImageSegmentationOutput" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.utils.ModelOutput">ModelOutput</span></code></p>


        <p>Base class for Segment-Anything model's output</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>iou_scores</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The iou scores of the predicted masks.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, num_masks)`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pred_masks</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The predicted low resolutions masks. Needs to be post-processed by the processor</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, num_masks, height, width)`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vision_hidden_states</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tuple of <code>mindspore.Tensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the vision model at the output of each layer plus the optional initial embedding outputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code> (`tuple(mindspore.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vision_attentions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tuple of <code>mindspore.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length,
sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code> (`tuple(mindspore.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mask_decoder_attentions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tuple of <code>mindspore.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length,
sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`tuple(mindspore.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SamImageSegmentationOutput</span><span class="p">(</span><span class="n">ModelOutput</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for Segment-Anything model&#39;s output</span>

<span class="sd">    Args:</span>
<span class="sd">        iou_scores (`mindspore.Tensor` of shape `(batch_size, num_masks)`):</span>
<span class="sd">            The iou scores of the predicted masks.</span>
<span class="sd">        pred_masks (`mindspore.Tensor` of shape `(batch_size, num_masks, height, width)`):</span>
<span class="sd">            The predicted low resolutions masks. Needs to be post-processed by the processor</span>
<span class="sd">        vision_hidden_states  (`tuple(mindspore.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):</span>
<span class="sd">            Tuple of `mindspore.Tensor` (one for the output of the embeddings, if the model has an embedding layer, +</span>
<span class="sd">            one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.</span>

<span class="sd">            Hidden-states of the vision model at the output of each layer plus the optional initial embedding outputs.</span>
<span class="sd">        vision_attentions  (`tuple(mindspore.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):</span>
<span class="sd">            Tuple of `mindspore.Tensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,</span>
<span class="sd">            sequence_length)`.</span>

<span class="sd">            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention</span>
<span class="sd">            heads.</span>
<span class="sd">        mask_decoder_attentions (`tuple(mindspore.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):</span>
<span class="sd">            Tuple of `mindspore.Tensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,</span>
<span class="sd">            sequence_length)`.</span>

<span class="sd">            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention</span>
<span class="sd">            heads.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">iou_scores</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">pred_masks</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">vision_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">vision_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">mask_decoder_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamLayerNorm" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamLayerNorm</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamLayerNorm" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>


        <p>LayerNorm that supports two data formats: channels_last (default) or channels_first.
The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch_size, height,
width, channels) while channels_first corresponds to inputs with shape (batch_size, channels, height, width).</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamLayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;LayerNorm that supports two data formats: channels_last (default) or channels_first.</span>
<span class="sd">    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch_size, height,</span>
<span class="sd">    width, channels) while channels_first corresponds to inputs with shape (batch_size, channels, height, width).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;channels_last&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_format</span> <span class="o">=</span> <span class="n">data_format</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;channels_last&quot;</span><span class="p">,</span> <span class="s2">&quot;channels_first&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported data format: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">data_format</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">normalized_shape</span><span class="p">,)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_format</span> <span class="o">==</span> <span class="s2">&quot;channels_last&quot;</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_format</span> <span class="o">==</span> <span class="s2">&quot;channels_first&quot;</span><span class="p">:</span>
            <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span> <span class="o">/</span> <span class="n">ops</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">input_dtype</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamMaskDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">SamMaskDecoderConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_multimask_outputs</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_multimask_outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_mask_tokens</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_multimask_outputs</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iou_token</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_mask_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">SamTwoWayTransformer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># should we create a new class for this?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upscale_conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upscale_conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upscale_layer_norm</span> <span class="o">=</span> <span class="n">SamLayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;channels_first&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>

        <span class="n">mlps_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_mask_tokens</span><span class="p">):</span>
            <span class="n">mlps_list</span> <span class="o">+=</span> <span class="p">[</span><span class="n">SamFeedForward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_hypernetworks_mlps</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">mlps_list</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iou_prediction_head</span> <span class="o">=</span> <span class="n">SamFeedForward</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">iou_head_hidden_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_mask_tokens</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">iou_head_depth</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_embeddings</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">image_positional_embeddings</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sparse_prompt_embeddings</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">dense_prompt_embeddings</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_similarity</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_embedding</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict masks given image and prompt embeddings.</span>

<span class="sd">        Args:</span>
<span class="sd">            image_embeddings (`mindspore.Tensor`):</span>
<span class="sd">                the embeddings from the image encoder</span>
<span class="sd">            image_positional_embedding (`mindspore.Tensor`):</span>
<span class="sd">                positional encoding with the shape of image_embeddings</span>
<span class="sd">            sparse_prompt_embeddings (`mindspore.Tensor`):</span>
<span class="sd">                The embeddings of the points and boxes</span>
<span class="sd">            dense_prompt_embeddings (`mindspore.Tensor`):</span>
<span class="sd">                the embeddings of the mask inputs</span>
<span class="sd">            multimask_output (bool):</span>
<span class="sd">                Whether to return multiple masks or a single mask.</span>
<span class="sd">            output_attentions (bool, *optional*):</span>
<span class="sd">                Whether or not to return the attentions tensors of all attention layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">point_batch_size</span> <span class="o">=</span> <span class="n">sparse_prompt_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Concatenate output tokens</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">iou_token</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="n">output_tokens</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">sparse_prompt_embeddings</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">output_tokens</span><span class="p">,</span> <span class="n">sparse_prompt_embeddings</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">output_tokens</span>
        <span class="n">point_embeddings</span> <span class="o">=</span> <span class="n">tokens</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iou_token</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Expand per-image data in batch direction to be per-point</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">image_embeddings</span> <span class="o">+</span> <span class="n">dense_prompt_embeddings</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">image_positional_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">image_positional_embeddings</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Run the transformer, image_positional_embedding are consumed</span>
        <span class="n">point_embedding</span><span class="p">,</span> <span class="n">image_embeddings</span><span class="p">,</span> <span class="n">attentions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span>
            <span class="n">point_embeddings</span><span class="o">=</span><span class="n">point_embeddings</span><span class="p">,</span>
            <span class="n">image_embeddings</span><span class="o">=</span><span class="n">image_embeddings</span><span class="p">,</span>
            <span class="n">image_positional_embeddings</span><span class="o">=</span><span class="n">image_positional_embeddings</span><span class="p">,</span>
            <span class="n">attention_similarity</span><span class="o">=</span><span class="n">attention_similarity</span><span class="p">,</span>
            <span class="n">target_embedding</span><span class="o">=</span><span class="n">target_embedding</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">iou_token_out</span> <span class="o">=</span> <span class="n">point_embedding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">mask_tokens_out</span> <span class="o">=</span> <span class="n">point_embedding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_mask_tokens</span><span class="p">),</span> <span class="p">:]</span>

        <span class="c1"># Upscale mask embeddings and predict masks using the mask tokens</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">batch_size</span> <span class="o">*</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span>
        <span class="p">)</span>

        <span class="n">upscaled_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upscale_conv1</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">)</span>
        <span class="n">upscaled_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upscale_layer_norm</span><span class="p">(</span><span class="n">upscaled_embedding</span><span class="p">))</span>
        <span class="n">upscaled_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upscale_conv2</span><span class="p">(</span><span class="n">upscaled_embedding</span><span class="p">))</span>

        <span class="n">hyper_in_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_mask_tokens</span><span class="p">):</span>
            <span class="n">current_mlp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_hypernetworks_mlps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">hyper_in_list</span> <span class="o">+=</span> <span class="p">[</span><span class="n">current_mlp</span><span class="p">(</span><span class="n">mask_tokens_out</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:])]</span>
        <span class="n">hyper_in</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">hyper_in_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">upscaled_embedding</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">upscaled_embedding</span> <span class="o">=</span> <span class="n">upscaled_embedding</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">)</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="p">(</span><span class="n">hyper_in</span> <span class="o">@</span> <span class="n">upscaled_embedding</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>

        <span class="c1"># Generate mask quality predictions</span>
        <span class="n">iou_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iou_prediction_head</span><span class="p">(</span><span class="n">iou_token_out</span><span class="p">)</span>

        <span class="c1"># Select the correct mask or masks for output</span>
        <span class="k">if</span> <span class="n">multimask_output</span><span class="p">:</span>
            <span class="n">mask_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mask_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">mask_slice</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">iou_pred</span> <span class="o">=</span> <span class="n">iou_pred</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">mask_slice</span><span class="p">]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">iou_pred</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span> <span class="o">+</span> <span class="p">(</span><span class="n">attentions</span><span class="p">,)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span> <span class="o">+</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span>

        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamMaskDecoder</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">image_positional_embeddings</span><span class="p">,</span> <span class="n">sparse_prompt_embeddings</span><span class="p">,</span> <span class="n">dense_prompt_embeddings</span><span class="p">,</span> <span class="n">multimask_output</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_similarity</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_embedding</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamMaskDecoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Predict masks given image and prompt embeddings.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>the embeddings from the image encoder</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_positional_embedding</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>positional encoding with the shape of image_embeddings</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sparse_prompt_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The embeddings of the points and boxes</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dense_prompt_embeddings</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>the embeddings of the mask inputs</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>multimask_output</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to return multiple masks or a single mask.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_attentions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return the attentions tensors of all attention layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">image_embeddings</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">image_positional_embeddings</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">sparse_prompt_embeddings</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">dense_prompt_embeddings</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_similarity</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">target_embedding</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Predict masks given image and prompt embeddings.</span>

<span class="sd">    Args:</span>
<span class="sd">        image_embeddings (`mindspore.Tensor`):</span>
<span class="sd">            the embeddings from the image encoder</span>
<span class="sd">        image_positional_embedding (`mindspore.Tensor`):</span>
<span class="sd">            positional encoding with the shape of image_embeddings</span>
<span class="sd">        sparse_prompt_embeddings (`mindspore.Tensor`):</span>
<span class="sd">            The embeddings of the points and boxes</span>
<span class="sd">        dense_prompt_embeddings (`mindspore.Tensor`):</span>
<span class="sd">            the embeddings of the mask inputs</span>
<span class="sd">        multimask_output (bool):</span>
<span class="sd">            Whether to return multiple masks or a single mask.</span>
<span class="sd">        output_attentions (bool, *optional*):</span>
<span class="sd">            Whether or not to return the attentions tensors of all attention layers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">point_batch_size</span> <span class="o">=</span> <span class="n">sparse_prompt_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># Concatenate output tokens</span>
    <span class="n">output_tokens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">iou_token</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_tokens</span><span class="o">.</span><span class="n">weight</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">output_tokens</span> <span class="o">=</span> <span class="n">output_tokens</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">sparse_prompt_embeddings</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">output_tokens</span><span class="p">,</span> <span class="n">sparse_prompt_embeddings</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">output_tokens</span>
    <span class="n">point_embeddings</span> <span class="o">=</span> <span class="n">tokens</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iou_token</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># Expand per-image data in batch direction to be per-point</span>
    <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">image_embeddings</span> <span class="o">+</span> <span class="n">dense_prompt_embeddings</span>
    <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">image_positional_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">image_positional_embeddings</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Run the transformer, image_positional_embedding are consumed</span>
    <span class="n">point_embedding</span><span class="p">,</span> <span class="n">image_embeddings</span><span class="p">,</span> <span class="n">attentions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span>
        <span class="n">point_embeddings</span><span class="o">=</span><span class="n">point_embeddings</span><span class="p">,</span>
        <span class="n">image_embeddings</span><span class="o">=</span><span class="n">image_embeddings</span><span class="p">,</span>
        <span class="n">image_positional_embeddings</span><span class="o">=</span><span class="n">image_positional_embeddings</span><span class="p">,</span>
        <span class="n">attention_similarity</span><span class="o">=</span><span class="n">attention_similarity</span><span class="p">,</span>
        <span class="n">target_embedding</span><span class="o">=</span><span class="n">target_embedding</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">iou_token_out</span> <span class="o">=</span> <span class="n">point_embedding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">mask_tokens_out</span> <span class="o">=</span> <span class="n">point_embedding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_mask_tokens</span><span class="p">),</span> <span class="p">:]</span>

    <span class="c1"># Upscale mask embeddings and predict masks using the mask tokens</span>
    <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">batch_size</span> <span class="o">*</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span>
    <span class="p">)</span>

    <span class="n">upscaled_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upscale_conv1</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">)</span>
    <span class="n">upscaled_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upscale_layer_norm</span><span class="p">(</span><span class="n">upscaled_embedding</span><span class="p">))</span>
    <span class="n">upscaled_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">upscale_conv2</span><span class="p">(</span><span class="n">upscaled_embedding</span><span class="p">))</span>

    <span class="n">hyper_in_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_mask_tokens</span><span class="p">):</span>
        <span class="n">current_mlp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_hypernetworks_mlps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">hyper_in_list</span> <span class="o">+=</span> <span class="p">[</span><span class="n">current_mlp</span><span class="p">(</span><span class="n">mask_tokens_out</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:])]</span>
    <span class="n">hyper_in</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">hyper_in_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">upscaled_embedding</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">upscaled_embedding</span> <span class="o">=</span> <span class="n">upscaled_embedding</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">)</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="p">(</span><span class="n">hyper_in</span> <span class="o">@</span> <span class="n">upscaled_embedding</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>

    <span class="c1"># Generate mask quality predictions</span>
    <span class="n">iou_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iou_prediction_head</span><span class="p">(</span><span class="n">iou_token_out</span><span class="p">)</span>

    <span class="c1"># Select the correct mask or masks for output</span>
    <span class="k">if</span> <span class="n">multimask_output</span><span class="p">:</span>
        <span class="n">mask_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">mask_slice</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">mask_slice</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">iou_pred</span> <span class="o">=</span> <span class="n">iou_pred</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">mask_slice</span><span class="p">]</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">iou_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span> <span class="o">+</span> <span class="p">(</span><span class="n">attentions</span><span class="p">,)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span> <span class="o">+</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span>

    <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamModel" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamModel</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.models.sam.modeling_sam.SamPreTrainedModel">SamPreTrainedModel</span></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamModel</span><span class="p">(</span><span class="n">SamPreTrainedModel</span><span class="p">):</span>
    <span class="n">_tied_weights_keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;prompt_encoder.shared_embedding.positional_embedding&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shared_image_embedding</span> <span class="o">=</span> <span class="n">SamPositionalEmbedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vision_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vision_encoder</span> <span class="o">=</span> <span class="n">SamVisionEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vision_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_encoder</span> <span class="o">=</span> <span class="n">SamPromptEncoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">prompt_encoder_config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_image_embedding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_decoder</span> <span class="o">=</span> <span class="n">SamMaskDecoder</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">mask_decoder_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_input_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_encoder</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_image_wide_positional_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">prompt_encoder_config</span><span class="o">.</span><span class="n">image_embedding_size</span>
        <span class="n">target_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_image_embedding</span><span class="o">.</span><span class="n">positional_embedding</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">grid</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">target_dtype</span><span class="p">)</span>
        <span class="n">y_embed</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
        <span class="n">x_embed</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
        <span class="n">y_embed</span> <span class="o">=</span> <span class="n">y_embed</span> <span class="o">/</span> <span class="n">size</span>
        <span class="n">x_embed</span> <span class="o">=</span> <span class="n">x_embed</span> <span class="o">/</span> <span class="n">size</span>

        <span class="n">positional_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_image_embedding</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x_embed</span><span class="p">,</span> <span class="n">y_embed</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">positional_embedding</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># channel x height x width</span>

    <span class="nd">@no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">get_image_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the image embeddings by passing the pixel values through the vision encoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            pixel_values (`mindspore.Tensor` of shape `(batch_size, num_channels, height, width)`):</span>
<span class="sd">                Input pixel values</span>
<span class="sd">            output_attentions (`bool`, *optional*):</span>
<span class="sd">                Whether or not to return the attentions tensors of all attention layers.</span>
<span class="sd">            output_hidden_states (`bool`, *optional*):</span>
<span class="sd">                Whether or not to return the hidden states of all layers.</span>
<span class="sd">            return_dict (`bool`, *optional*):</span>
<span class="sd">                Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">vision_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_encoder</span><span class="p">(</span>
            <span class="n">pixel_values</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">vision_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">image_embeddings</span>

    <span class="nd">@no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">get_prompt_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_masks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_points (`mindspore.Tensor` of shape `(batch_size, point_batch_size, num_points_per_image, 2)`):</span>
<span class="sd">                Optional input points for the prompt encoder. The padding of the point is automatically done by the</span>
<span class="sd">                processor. `point_batch_size` refers to the number of masks that we want the model to predict per</span>
<span class="sd">                point. The model will output `point_batch_size` times 3 masks in total.</span>
<span class="sd">            input_labels (`mindspore.Tensor` of shape `(batch_size, point_batch_size, num_points_per_image)`):</span>
<span class="sd">                Optional input labels for the prompt encoder. The padding of the labels is automatically done by the</span>
<span class="sd">                processor, or can be fed by the user.</span>
<span class="sd">            input_boxes (`mindspore.Tensor` of shape `(batch_size, num_boxes_per_image, 4)`):</span>
<span class="sd">                Optional input boxes for the prompt encoder. The padding of the boxes is automatically done by the</span>
<span class="sd">                processor. users can also pass manually the input boxes.</span>
<span class="sd">            input_masks (`mindspore.Tensor` of shape `(batch_size, image_size, image_size)`):</span>
<span class="sd">                Optional input masks for the prompt encoder.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prompt_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_encoder</span><span class="p">(</span>
            <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span>
            <span class="n">input_labels</span><span class="o">=</span><span class="n">input_labels</span><span class="p">,</span>
            <span class="n">input_boxes</span><span class="o">=</span><span class="n">input_boxes</span><span class="p">,</span>
            <span class="n">input_masks</span><span class="o">=</span><span class="n">input_masks</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">prompt_output</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_masks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image_embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">attention_similarity</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Example:</span>

<span class="sd">        ```python</span>
<span class="sd">        &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">        &gt;&gt;&gt; import requests</span>
<span class="sd">        &gt;&gt;&gt; from transformers import AutoModel, AutoProcessor</span>

<span class="sd">        &gt;&gt;&gt; model = AutoModel.from_pretrained(&quot;facebook/sam-vit-base&quot;)</span>
<span class="sd">        &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;facebook/sam-vit-base&quot;)</span>

<span class="sd">        &gt;&gt;&gt; img_url = &quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/sam-car.png&quot;</span>
<span class="sd">        &gt;&gt;&gt; raw_image = Image.open(requests.get(img_url, stream=True).raw).convert(&quot;RGB&quot;)</span>
<span class="sd">        &gt;&gt;&gt; input_points = [[[400, 650]]]  # 2D location of a window on the car</span>
<span class="sd">        &gt;&gt;&gt; inputs = processor(images=raw_image, input_points=input_points, return_tensors=&quot;ms&quot;)</span>

<span class="sd">        &gt;&gt;&gt; # Get segmentation mask</span>
<span class="sd">        &gt;&gt;&gt; outputs = model(**inputs)</span>

<span class="sd">        &gt;&gt;&gt; # Postprocess masks</span>
<span class="sd">        &gt;&gt;&gt; masks = processor.post_process_masks(</span>
<span class="sd">        ...     outputs.pred_masks, inputs[&quot;original_sizes&quot;], inputs[&quot;reshaped_input_sizes&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">image_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either pixel_values or image_embeddings must be provided.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">image_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only one of pixel_values and image_embeddings can be provided.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The input_points must be a 4D tensor. Of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.&quot;</span><span class="p">,</span>
                <span class="s2">&quot; got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The input_points must be a 3D tensor. Of shape `batch_size`, `nb_boxes`, `4`.&quot;</span><span class="p">,</span>
                <span class="s2">&quot; got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">point_batch_size</span> <span class="o">=</span> <span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">box_batch_size</span> <span class="o">=</span> <span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">point_batch_size</span> <span class="o">!=</span> <span class="n">box_batch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;You should provide as many bounding boxes as input points per box. Got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">box_batch_size</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="n">image_positional_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_image_wide_positional_embeddings</span><span class="p">()</span>
        <span class="c1"># repeat with batch size</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">pixel_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">image_positional_embeddings</span> <span class="o">=</span> <span class="n">image_positional_embeddings</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">vision_attentions</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">vision_hidden_states</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_encoder</span><span class="p">(</span>
                <span class="n">pixel_values</span><span class="p">,</span>
                <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
                <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
                <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
                <span class="n">vision_hidden_states</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
                <span class="n">vision_attentions</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_labels</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">input_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The batch size of the image embeddings and the input points must be the same. &quot;</span><span class="p">,</span>
                <span class="s2">&quot;Got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2"> respectively.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                <span class="s2">&quot; if you want to pass multiple points for the same image, make sure that you passed &quot;</span><span class="p">,</span>
                <span class="s2">&quot; input_points of shape (batch_size, point_batch_size, num_points_per_image, 3) and &quot;</span><span class="p">,</span>
                <span class="s2">&quot; input_labels of shape (batch_size, point_batch_size, num_points_per_image)&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">sparse_embeddings</span><span class="p">,</span> <span class="n">dense_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_encoder</span><span class="p">(</span>
            <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span>
            <span class="n">input_labels</span><span class="o">=</span><span class="n">input_labels</span><span class="p">,</span>
            <span class="n">input_boxes</span><span class="o">=</span><span class="n">input_boxes</span><span class="p">,</span>
            <span class="n">input_masks</span><span class="o">=</span><span class="n">input_masks</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">low_res_masks</span><span class="p">,</span> <span class="n">iou_predictions</span><span class="p">,</span> <span class="n">mask_decoder_attentions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_decoder</span><span class="p">(</span>
            <span class="n">image_embeddings</span><span class="o">=</span><span class="n">image_embeddings</span><span class="p">,</span>
            <span class="n">image_positional_embeddings</span><span class="o">=</span><span class="n">image_positional_embeddings</span><span class="p">,</span>
            <span class="n">sparse_prompt_embeddings</span><span class="o">=</span><span class="n">sparse_embeddings</span><span class="p">,</span>
            <span class="n">dense_prompt_embeddings</span><span class="o">=</span><span class="n">dense_embeddings</span><span class="p">,</span>
            <span class="n">multimask_output</span><span class="o">=</span><span class="n">multimask_output</span><span class="p">,</span>
            <span class="n">attention_similarity</span><span class="o">=</span><span class="n">attention_similarity</span><span class="p">,</span>
            <span class="n">target_embedding</span><span class="o">=</span><span class="n">target_embedding</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">iou_predictions</span><span class="p">,</span> <span class="n">low_res_masks</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="p">(</span><span class="n">vision_hidden_states</span><span class="p">,)</span>

            <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="p">(</span><span class="n">vision_attentions</span><span class="p">,</span> <span class="n">mask_decoder_attentions</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">output</span>

        <span class="k">return</span> <span class="n">SamImageSegmentationOutput</span><span class="p">(</span>
            <span class="n">iou_scores</span><span class="o">=</span><span class="n">iou_predictions</span><span class="p">,</span>
            <span class="n">pred_masks</span><span class="o">=</span><span class="n">low_res_masks</span><span class="p">,</span>
            <span class="n">vision_hidden_states</span><span class="o">=</span><span class="n">vision_hidden_states</span><span class="p">,</span>
            <span class="n">vision_attentions</span><span class="o">=</span><span class="n">vision_attentions</span><span class="p">,</span>
            <span class="n">mask_decoder_attentions</span><span class="o">=</span><span class="n">mask_decoder_attentions</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamModel.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamModel</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pixel_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image_embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">multimask_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">attention_similarity</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_embedding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.forward" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">requests</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoProcessor</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/sam-vit-base&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/sam-vit-base&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">img_url</span> <span class="o">=</span> <span class="s2">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/sam-car.png&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">raw_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">input_points</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">400</span><span class="p">,</span> <span class="mi">650</span><span class="p">]]]</span>  <span class="c1"># 2D location of a window on the car</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">raw_image</span><span class="p">,</span> <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Get segmentation mask</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Postprocess masks</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">masks</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">post_process_masks</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">outputs</span><span class="o">.</span><span class="n">pred_masks</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;original_sizes&quot;</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;reshaped_input_sizes&quot;</span><span class="p">]</span>
<span class="o">...</span> <span class="p">)</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_masks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image_embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">multimask_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">attention_similarity</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">target_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    &gt;&gt;&gt; from PIL import Image</span>
<span class="sd">    &gt;&gt;&gt; import requests</span>
<span class="sd">    &gt;&gt;&gt; from transformers import AutoModel, AutoProcessor</span>

<span class="sd">    &gt;&gt;&gt; model = AutoModel.from_pretrained(&quot;facebook/sam-vit-base&quot;)</span>
<span class="sd">    &gt;&gt;&gt; processor = AutoProcessor.from_pretrained(&quot;facebook/sam-vit-base&quot;)</span>

<span class="sd">    &gt;&gt;&gt; img_url = &quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/sam-car.png&quot;</span>
<span class="sd">    &gt;&gt;&gt; raw_image = Image.open(requests.get(img_url, stream=True).raw).convert(&quot;RGB&quot;)</span>
<span class="sd">    &gt;&gt;&gt; input_points = [[[400, 650]]]  # 2D location of a window on the car</span>
<span class="sd">    &gt;&gt;&gt; inputs = processor(images=raw_image, input_points=input_points, return_tensors=&quot;ms&quot;)</span>

<span class="sd">    &gt;&gt;&gt; # Get segmentation mask</span>
<span class="sd">    &gt;&gt;&gt; outputs = model(**inputs)</span>

<span class="sd">    &gt;&gt;&gt; # Postprocess masks</span>
<span class="sd">    &gt;&gt;&gt; masks = processor.post_process_masks(</span>
<span class="sd">    ...     outputs.pred_masks, inputs[&quot;original_sizes&quot;], inputs[&quot;reshaped_input_sizes&quot;]</span>
<span class="sd">    ... )</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
    <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
    <span class="p">)</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

    <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">image_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either pixel_values or image_embeddings must be provided.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">image_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only one of pixel_values and image_embeddings can be provided.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The input_points must be a 4D tensor. Of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.&quot;</span><span class="p">,</span>
            <span class="s2">&quot; got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The input_points must be a 3D tensor. Of shape `batch_size`, `nb_boxes`, `4`.&quot;</span><span class="p">,</span>
            <span class="s2">&quot; got </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">point_batch_size</span> <span class="o">=</span> <span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">box_batch_size</span> <span class="o">=</span> <span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">point_batch_size</span> <span class="o">!=</span> <span class="n">box_batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You should provide as many bounding boxes as input points per box. Got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">point_batch_size</span><span class="p">,</span> <span class="n">box_batch_size</span>
                <span class="p">)</span>
            <span class="p">)</span>

    <span class="n">image_positional_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_image_wide_positional_embeddings</span><span class="p">()</span>
    <span class="c1"># repeat with batch size</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">pixel_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">image_positional_embeddings</span> <span class="o">=</span> <span class="n">image_positional_embeddings</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">vision_attentions</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">vision_hidden_states</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">vision_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_encoder</span><span class="p">(</span>
            <span class="n">pixel_values</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
            <span class="n">vision_hidden_states</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
            <span class="n">vision_attentions</span> <span class="o">=</span> <span class="n">vision_outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_labels</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">input_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The batch size of the image embeddings and the input points must be the same. &quot;</span><span class="p">,</span>
            <span class="s2">&quot;Got </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2"> respectively.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="s2">&quot; if you want to pass multiple points for the same image, make sure that you passed &quot;</span><span class="p">,</span>
            <span class="s2">&quot; input_points of shape (batch_size, point_batch_size, num_points_per_image, 3) and &quot;</span><span class="p">,</span>
            <span class="s2">&quot; input_labels of shape (batch_size, point_batch_size, num_points_per_image)&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">sparse_embeddings</span><span class="p">,</span> <span class="n">dense_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_encoder</span><span class="p">(</span>
        <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="o">=</span><span class="n">input_labels</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="o">=</span><span class="n">input_boxes</span><span class="p">,</span>
        <span class="n">input_masks</span><span class="o">=</span><span class="n">input_masks</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">low_res_masks</span><span class="p">,</span> <span class="n">iou_predictions</span><span class="p">,</span> <span class="n">mask_decoder_attentions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_decoder</span><span class="p">(</span>
        <span class="n">image_embeddings</span><span class="o">=</span><span class="n">image_embeddings</span><span class="p">,</span>
        <span class="n">image_positional_embeddings</span><span class="o">=</span><span class="n">image_positional_embeddings</span><span class="p">,</span>
        <span class="n">sparse_prompt_embeddings</span><span class="o">=</span><span class="n">sparse_embeddings</span><span class="p">,</span>
        <span class="n">dense_prompt_embeddings</span><span class="o">=</span><span class="n">dense_embeddings</span><span class="p">,</span>
        <span class="n">multimask_output</span><span class="o">=</span><span class="n">multimask_output</span><span class="p">,</span>
        <span class="n">attention_similarity</span><span class="o">=</span><span class="n">attention_similarity</span><span class="p">,</span>
        <span class="n">target_embedding</span><span class="o">=</span><span class="n">target_embedding</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">iou_predictions</span><span class="p">,</span> <span class="n">low_res_masks</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">output_hidden_states</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="p">(</span><span class="n">vision_hidden_states</span><span class="p">,)</span>

        <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="p">(</span><span class="n">vision_attentions</span><span class="p">,</span> <span class="n">mask_decoder_attentions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">return</span> <span class="n">SamImageSegmentationOutput</span><span class="p">(</span>
        <span class="n">iou_scores</span><span class="o">=</span><span class="n">iou_predictions</span><span class="p">,</span>
        <span class="n">pred_masks</span><span class="o">=</span><span class="n">low_res_masks</span><span class="p">,</span>
        <span class="n">vision_hidden_states</span><span class="o">=</span><span class="n">vision_hidden_states</span><span class="p">,</span>
        <span class="n">vision_attentions</span><span class="o">=</span><span class="n">vision_attentions</span><span class="p">,</span>
        <span class="n">mask_decoder_attentions</span><span class="o">=</span><span class="n">mask_decoder_attentions</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamModel.get_image_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamModel</span><span class="o">.</span><span class="n">get_image_embeddings</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.get_image_embeddings" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Returns the image embeddings by passing the pixel values through the vision encoder.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pixel_values</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Input pixel values</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, num_channels, height, width)`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_attentions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return the attentions tensors of all attention layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>output_hidden_states</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return the hidden states of all layers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_dict</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return a [<code>~utils.ModelOutput</code>] instead of a plain tuple.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">get_image_embeddings</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pixel_values</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the image embeddings by passing the pixel values through the vision encoder.</span>

<span class="sd">    Args:</span>
<span class="sd">        pixel_values (`mindspore.Tensor` of shape `(batch_size, num_channels, height, width)`):</span>
<span class="sd">            Input pixel values</span>
<span class="sd">        output_attentions (`bool`, *optional*):</span>
<span class="sd">            Whether or not to return the attentions tensors of all attention layers.</span>
<span class="sd">        output_hidden_states (`bool`, *optional*):</span>
<span class="sd">            Whether or not to return the hidden states of all layers.</span>
<span class="sd">        return_dict (`bool`, *optional*):</span>
<span class="sd">            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vision_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vision_encoder</span><span class="p">(</span>
        <span class="n">pixel_values</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">vision_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">image_embeddings</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamModel.get_prompt_embeddings" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamModel</span><span class="o">.</span><span class="n">get_prompt_embeddings</span><span class="p">(</span><span class="n">input_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamModel.get_prompt_embeddings" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>input_points</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional input points for the prompt encoder. The padding of the point is automatically done by the
processor. <code>point_batch_size</code> refers to the number of masks that we want the model to predict per
point. The model will output <code>point_batch_size</code> times 3 masks in total.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, point_batch_size, num_points_per_image, 2)`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_labels</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional input labels for the prompt encoder. The padding of the labels is automatically done by the
processor, or can be fed by the user.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, point_batch_size, num_points_per_image)`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_boxes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional input boxes for the prompt encoder. The padding of the boxes is automatically done by the
processor. users can also pass manually the input boxes.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, num_boxes_per_image, 4)`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>input_masks</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Optional input masks for the prompt encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, image_size, image_size)`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">get_prompt_embeddings</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_masks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the prompt embeddings by passing the input points, labels, boxes and masks through the prompt encoder.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_points (`mindspore.Tensor` of shape `(batch_size, point_batch_size, num_points_per_image, 2)`):</span>
<span class="sd">            Optional input points for the prompt encoder. The padding of the point is automatically done by the</span>
<span class="sd">            processor. `point_batch_size` refers to the number of masks that we want the model to predict per</span>
<span class="sd">            point. The model will output `point_batch_size` times 3 masks in total.</span>
<span class="sd">        input_labels (`mindspore.Tensor` of shape `(batch_size, point_batch_size, num_points_per_image)`):</span>
<span class="sd">            Optional input labels for the prompt encoder. The padding of the labels is automatically done by the</span>
<span class="sd">            processor, or can be fed by the user.</span>
<span class="sd">        input_boxes (`mindspore.Tensor` of shape `(batch_size, num_boxes_per_image, 4)`):</span>
<span class="sd">            Optional input boxes for the prompt encoder. The padding of the boxes is automatically done by the</span>
<span class="sd">            processor. users can also pass manually the input boxes.</span>
<span class="sd">        input_masks (`mindspore.Tensor` of shape `(batch_size, image_size, image_size)`):</span>
<span class="sd">            Optional input masks for the prompt encoder.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prompt_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_encoder</span><span class="p">(</span>
        <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="o">=</span><span class="n">input_labels</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="o">=</span><span class="n">input_boxes</span><span class="p">,</span>
        <span class="n">input_masks</span><span class="o">=</span><span class="n">input_masks</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">prompt_output</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamPatchEmbeddings" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamPatchEmbeddings</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamPatchEmbeddings" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>


        <p>This class turns <code>pixel_values</code> of shape <code>(batch_size, num_channels, height, width)</code> into the initial
<code>hidden_states</code> (patch embeddings) of shape <code>(batch_size, seq_length, hidden_size)</code> to be consumed by a
Transformer.</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamPatchEmbeddings</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class turns `pixel_values` of shape `(batch_size, num_channels, height, width)` into the initial</span>
<span class="sd">    `hidden_states` (patch embeddings) of shape `(batch_size, seq_length, hidden_size)` to be consumed by a</span>
<span class="sd">    Transformer.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">image_size</span><span class="p">,</span> <span class="n">patch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">image_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">patch_size</span>
        <span class="n">num_channels</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>
        <span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">)</span>
        <span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="n">num_patches</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pixel_values</span><span class="p">):</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">pixel_values</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">num_channels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Make sure that the channel dimension of the pixel values match with the one set in the configuration.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">height</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">or</span> <span class="n">width</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Input image size (</span><span class="si">{</span><span class="n">height</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="n">width</span><span class="si">}</span><span class="s2">) doesn&#39;t match model (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embeddings</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamPositionalEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;positional_embedding&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">ops</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">num_pos_feats</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_coords</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Positionally encode points that are normalized to [0,1].&quot;&quot;&quot;</span>
        <span class="n">coordinates</span> <span class="o">=</span> <span class="n">input_coords</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">coordinates</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">coordinates</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># assuming coords are in [0, 1]^2 square and have d_1 x ... x d_n x 2 shape</span>
        <span class="n">coordinates</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">coordinates</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">coordinates</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">coordinates</span> <span class="o">=</span> <span class="n">coordinates</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span>
        <span class="n">coordinates</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">coordinates</span>
        <span class="c1"># outputs d_1 x ... x d_n x channel shape</span>
        <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ops</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">coordinates</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">coordinates</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamPositionalEmbedding</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_coords</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamPositionalEmbedding.forward" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Positionally encode points that are normalized to [0,1].</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_coords</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Positionally encode points that are normalized to [0,1].&quot;&quot;&quot;</span>
    <span class="n">coordinates</span> <span class="o">=</span> <span class="n">input_coords</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">coordinates</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">coordinates</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># assuming coords are in [0, 1]^2 square and have d_1 x ... x d_n x 2 shape</span>
    <span class="n">coordinates</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">coordinates</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">coordinates</span> <span class="o">=</span> <span class="n">coordinates</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">coordinates</span> <span class="o">=</span> <span class="n">coordinates</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span>
    <span class="n">coordinates</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">coordinates</span>
    <span class="c1"># outputs d_1 x ... x d_n x channel shape</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ops</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">coordinates</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">coordinates</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamPromptEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">SamPromptEncoderConfig</span><span class="p">,</span> <span class="n">shared_patch_embedding</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shared_embedding</span> <span class="o">=</span> <span class="n">shared_patch_embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_embed</span> <span class="o">=</span> <span class="n">SamMaskEmbedding</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">no_mask_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_embedding_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">image_embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_image_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">image_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">point_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_point_embeddings</span><span class="p">)]</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">not_a_point_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_embed_points</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">points</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">pad</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Embeds point prompts.&quot;&quot;&quot;</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">points</span> <span class="o">+</span> <span class="mf">0.5</span>  <span class="c1"># Shift to center of pixel</span>
        <span class="k">if</span> <span class="n">pad</span><span class="p">:</span>
            <span class="n">target_point_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">target_labels_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">padding_point</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">target_point_shape</span><span class="p">)</span>
            <span class="n">padding_label</span> <span class="o">=</span> <span class="o">-</span><span class="n">ops</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">target_labels_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">points</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">points</span><span class="p">,</span> <span class="n">padding_point</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">labels</span><span class="p">,</span> <span class="n">padding_label</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_image_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_image_size</span><span class="p">)</span>
        <span class="n">point_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_embedding</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

        <span class="c1"># ops.where and expanding the labels tensor is required by the ONNX export</span>
        <span class="n">point_embedding</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">not_a_point_embed</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">point_embedding</span><span class="p">)</span>

        <span class="n">point_embedding</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">point_embedding</span><span class="p">,</span>
            <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">point_embedding</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="n">point_embedding</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span>
            <span class="n">point_embedding</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">point_embed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span>
            <span class="n">point_embedding</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">point_embedding</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span>
            <span class="n">point_embedding</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">point_embed</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span>
            <span class="n">point_embedding</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">point_embedding</span>

    <span class="k">def</span> <span class="nf">_embed_boxes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">boxes</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Embeds box prompts.&quot;&quot;&quot;</span>
        <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span> <span class="o">+</span> <span class="mf">0.5</span>  <span class="c1"># Shift to center of pixel</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">nb_boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">coords</span> <span class="o">=</span> <span class="n">boxes</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">nb_boxes</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_image_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_image_size</span><span class="p">)</span>
        <span class="n">corner_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_embedding</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>
        <span class="n">corner_embedding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">point_embed</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">corner_embedding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">point_embed</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span>
        <span class="k">return</span> <span class="n">corner_embedding</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
        <span class="n">input_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">input_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">input_masks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Embeds different types of prompts, returning both sparse and dense embeddings.</span>

<span class="sd">        Args:</span>
<span class="sd">            points (`mindspore.Tensor`, *optional*):</span>
<span class="sd">                point coordinates and labels to embed.</span>
<span class="sd">            boxes (`mindspore.Tensor`, *optional*):</span>
<span class="sd">                boxes to embed</span>
<span class="sd">            masks (`mindspore.Tensor`, *optional*):</span>
<span class="sd">                masks to embed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span> <span class="o">=</span> <span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">input_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;If points are provided, labels must also be provided.&quot;</span><span class="p">)</span>
            <span class="n">point_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embed_points</span><span class="p">(</span><span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">(</span><span class="n">input_boxes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">))</span>
            <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="n">point_embeddings</span>
        <span class="k">if</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">box_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embed_boxes</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sparse_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="n">box_embeddings</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">sparse_embeddings</span><span class="p">,</span> <span class="n">box_embeddings</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_masks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dense_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_embed</span><span class="p">(</span><span class="n">input_masks</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dense_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_mask_embed</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">sparse_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">sparse_embeddings</span><span class="p">,</span> <span class="n">dense_embeddings</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamPromptEncoder</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">,</span> <span class="n">input_boxes</span><span class="p">,</span> <span class="n">input_masks</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamPromptEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Embeds different types of prompts, returning both sparse and dense embeddings.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>points</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>point coordinates and labels to embed.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>boxes</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>boxes to embed</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>masks</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>masks to embed</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_points</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
    <span class="n">input_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">input_boxes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">input_masks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Embeds different types of prompts, returning both sparse and dense embeddings.</span>

<span class="sd">    Args:</span>
<span class="sd">        points (`mindspore.Tensor`, *optional*):</span>
<span class="sd">            point coordinates and labels to embed.</span>
<span class="sd">        boxes (`mindspore.Tensor`, *optional*):</span>
<span class="sd">            boxes to embed</span>
<span class="sd">        masks (`mindspore.Tensor`, *optional*):</span>
<span class="sd">            masks to embed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">point_batch_size</span> <span class="o">=</span> <span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">input_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;If points are provided, labels must also be provided.&quot;</span><span class="p">)</span>
        <span class="n">point_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embed_points</span><span class="p">(</span><span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">(</span><span class="n">input_boxes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">))</span>
        <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="n">point_embeddings</span>
    <span class="k">if</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">box_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embed_boxes</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sparse_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="n">box_embeddings</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">sparse_embeddings</span><span class="p">,</span> <span class="n">box_embeddings</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">input_masks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dense_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_embed</span><span class="p">(</span><span class="n">input_masks</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dense_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">no_mask_embed</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
            <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">sparse_embeddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sparse_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">sparse_embeddings</span><span class="p">,</span> <span class="n">dense_embeddings</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamTwoWayAttentionBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">skip_first_layer_pe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A transformer block with four layers:</span>
<span class="sd">            (1) self-attention of sparse inputs (2) cross attention of sparse inputs -&gt; dense inputs (3) mlp block on</span>
<span class="sd">            sparse inputs (4) cross attention of dense inputs -&gt; sparse inputs</span>

<span class="sd">        Arguments:</span>
<span class="sd">            config (`SamMaskDecoderConfig`):</span>
<span class="sd">                The configuration file used to instantiate the block</span>
<span class="sd">            attention_downsample_rate (*optionalk*, int, defaults to 2):</span>
<span class="sd">                The downsample ratio of the block used to reduce the inner dim of the attention.</span>
<span class="sd">            skip_first_layer_pe (*optional*, bool, defaults to `False`):</span>
<span class="sd">                Whether or not to skip the addition of the query_point_embedding on the first layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_norm_eps</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">SamAttention</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_token_to_image</span> <span class="o">=</span> <span class="n">SamAttention</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SamMLPBlock</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_image_to_token</span> <span class="o">=</span> <span class="n">SamAttention</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">skip_first_layer_pe</span> <span class="o">=</span> <span class="n">skip_first_layer_pe</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">queries</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">keys</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">query_point_embedding</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">key_point_embedding</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_similarity</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Self attention block</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">skip_first_layer_pe</span><span class="p">:</span>
            <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">queries</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">query</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">query_point_embedding</span>
            <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">queries</span><span class="p">)</span>
            <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">attn_out</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm1</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>

        <span class="c1"># Cross attention block, tokens attending to image embedding</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">query_point_embedding</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">keys</span> <span class="o">+</span> <span class="n">key_point_embedding</span>

        <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_token_to_image</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">keys</span><span class="p">,</span> <span class="n">attention_similarity</span><span class="o">=</span><span class="n">attention_similarity</span>
        <span class="p">)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">attn_out</span>

        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm2</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>

        <span class="c1"># MLP block</span>
        <span class="n">mlp_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">mlp_out</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm3</span><span class="p">(</span><span class="n">queries</span><span class="p">)</span>

        <span class="c1"># Cross attention block, image embedding attending to tokens</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">queries</span> <span class="o">+</span> <span class="n">query_point_embedding</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">keys</span> <span class="o">+</span> <span class="n">key_point_embedding</span>

        <span class="n">attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_image_to_token</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">key</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">queries</span><span class="p">)</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span> <span class="o">+</span> <span class="n">attn_out</span>

        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm4</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span> <span class="o">+</span> <span class="p">(</span><span class="n">attn_out</span><span class="p">,)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span> <span class="o">+</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span>

        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamTwoWayAttentionBlock</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">attention_downsample_rate</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">skip_first_layer_pe</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamTwoWayAttentionBlock.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">



<details class="a-transformer-block-with-four-layers" open>
  <summary>A transformer block with four layers</summary>
  <p>(1) self-attention of sparse inputs (2) cross attention of sparse inputs -&gt; dense inputs (3) mlp block on
sparse inputs (4) cross attention of dense inputs -&gt; sparse inputs</p>
</details>

<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>config</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The configuration file used to instantiate the block</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`SamMaskDecoderConfig`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attention_downsample_rate</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The downsample ratio of the block used to reduce the inner dim of the attention.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>*optionalk*, int, defaults to 2</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>2</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>skip_first_layer_pe</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to skip the addition of the query_point_embedding on the first layer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>*optional*, bool, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">attention_downsample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">skip_first_layer_pe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A transformer block with four layers:</span>
<span class="sd">        (1) self-attention of sparse inputs (2) cross attention of sparse inputs -&gt; dense inputs (3) mlp block on</span>
<span class="sd">        sparse inputs (4) cross attention of dense inputs -&gt; sparse inputs</span>

<span class="sd">    Arguments:</span>
<span class="sd">        config (`SamMaskDecoderConfig`):</span>
<span class="sd">            The configuration file used to instantiate the block</span>
<span class="sd">        attention_downsample_rate (*optionalk*, int, defaults to 2):</span>
<span class="sd">            The downsample ratio of the block used to reduce the inner dim of the attention.</span>
<span class="sd">        skip_first_layer_pe (*optional*, bool, defaults to `False`):</span>
<span class="sd">            Whether or not to skip the addition of the query_point_embedding on the first layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">layer_norm_eps</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">SamAttention</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_token_to_image</span> <span class="o">=</span> <span class="n">SamAttention</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SamMLPBlock</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn_image_to_token</span> <span class="o">=</span> <span class="n">SamAttention</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">downsample_rate</span><span class="o">=</span><span class="n">attention_downsample_rate</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">skip_first_layer_pe</span> <span class="o">=</span> <span class="n">skip_first_layer_pe</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>


        <p>Multi-head Attention block with relative position embeddings.</p>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamVisionAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi-head Attention block with relative position embeddings.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">window_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">input_size</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">image_size</span> <span class="o">//</span> <span class="n">config</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">image_size</span> <span class="o">//</span> <span class="n">config</span><span class="o">.</span><span class="n">patch_size</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">window_size</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">else</span> <span class="p">(</span><span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_attention_heads</span>
        <span class="n">head_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="n">config</span><span class="o">.</span><span class="n">num_attention_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">head_dim</span><span class="o">**-</span><span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">attention_dropout</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">qkv_bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">use_rel_pos</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input size must be provided if using relative positional encoding.&quot;</span><span class="p">)</span>

            <span class="c1"># initialize relative positional embeddings</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">get_rel_pos</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">k_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">rel_pos</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get relative positional embeddings according to the relative positions of</span>
<span class="sd">            query and key sizes.</span>

<span class="sd">        Args:</span>
<span class="sd">            q_size (int):</span>
<span class="sd">                size of the query.</span>
<span class="sd">            k_size (int):</span>
<span class="sd">                size of key k.</span>
<span class="sd">            rel_pos (`mindspore.Tensor`):</span>
<span class="sd">                relative position embeddings (L, channel).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Extracted positional embeddings according to relative positions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">max_rel_dist</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">q_size</span><span class="p">,</span> <span class="n">k_size</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Interpolate rel pos.</span>
        <span class="n">rel_pos_resized</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
            <span class="n">rel_pos</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">rel_pos</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">size</span><span class="o">=</span><span class="n">max_rel_dist</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">rel_pos_resized</span> <span class="o">=</span> <span class="n">rel_pos_resized</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_rel_dist</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Scale the coords with short length if shapes for q and k are different.</span>
        <span class="n">q_coords</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">q_size</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">k_size</span> <span class="o">/</span> <span class="n">q_size</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">k_coords</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k_size</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">q_size</span> <span class="o">/</span> <span class="n">k_size</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">relative_coords</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_coords</span> <span class="o">-</span> <span class="n">k_coords</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">k_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">q_size</span> <span class="o">/</span> <span class="n">k_size</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">rel_pos_resized</span><span class="p">[</span><span class="n">relative_coords</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">add_decomposed_rel_pos</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">attn</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">rel_pos_h</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">rel_pos_w</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">q_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">k_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate decomposed Relative Positional Embeddings from :paper:`mvitv2`.</span>
<span class="sd">        https://github.com/facebookresearch/mvit/blob/19786631e330df9f3622e5402b4a419a263a2c80/mvit/models/attention.py</span>

<span class="sd">        Args:</span>
<span class="sd">            attn (`mindspore.Tensor`):</span>
<span class="sd">                attention map.</span>
<span class="sd">            query (`mindspore.Tensor`):</span>
<span class="sd">                query q in the attention layer with shape (batch_size, query_height * query_width, channel).</span>
<span class="sd">            rel_pos_h (`mindspore.Tensor`):</span>
<span class="sd">                relative position embeddings (Lh, channel) for height axis.</span>
<span class="sd">            rel_pos_w (`mindspore.Tensor`):</span>
<span class="sd">                relative position embeddings (Lw, channel) for width axis.</span>
<span class="sd">            q_size (tuple):</span>
<span class="sd">                spatial sequence size of query q with (query_height, query_width).</span>
<span class="sd">            k_size (tuple):</span>
<span class="sd">                spatial sequence size of key k with (key_height, key_width).</span>

<span class="sd">        Returns:</span>
<span class="sd">            attn (`mindspore.Tensor`):</span>
<span class="sd">                attention map with added relative positional embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">query_height</span><span class="p">,</span> <span class="n">query_width</span> <span class="o">=</span> <span class="n">q_size</span>
        <span class="n">key_height</span><span class="p">,</span> <span class="n">key_width</span> <span class="o">=</span> <span class="n">k_size</span>
        <span class="n">relative_position_height</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_rel_pos</span><span class="p">(</span><span class="n">query_height</span><span class="p">,</span> <span class="n">key_height</span><span class="p">,</span> <span class="n">rel_pos_h</span><span class="p">)</span>
        <span class="n">relative_position_width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_rel_pos</span><span class="p">(</span><span class="n">query_width</span><span class="p">,</span> <span class="n">key_width</span><span class="p">,</span> <span class="n">rel_pos_w</span><span class="p">)</span>

        <span class="n">batch_size</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">reshaped_query</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_height</span><span class="p">,</span> <span class="n">query_width</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="n">rel_h</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;bhwc,hkc-&gt;bhwk&quot;</span><span class="p">,</span> <span class="n">reshaped_query</span><span class="p">,</span> <span class="n">relative_position_height</span><span class="p">)</span>
        <span class="n">rel_w</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;bhwc,wkc-&gt;bhwk&quot;</span><span class="p">,</span> <span class="n">reshaped_query</span><span class="p">,</span> <span class="n">relative_position_width</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_height</span><span class="p">,</span> <span class="n">query_width</span><span class="p">,</span> <span class="n">key_height</span><span class="p">,</span> <span class="n">key_width</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">+</span> <span class="n">rel_h</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">rel_w</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_height</span> <span class="o">*</span> <span class="n">query_width</span><span class="p">,</span> <span class="n">key_height</span> <span class="o">*</span> <span class="n">key_width</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">attn</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># qkv with shape (3, batch_size, nHead, height * width, channel)</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># q, k, v with shape (batch_size * nHead, height * width, channel)</span>
        <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">qkv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="n">height</span> <span class="o">*</span> <span class="n">width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">attn_weights</span> <span class="o">=</span> <span class="p">(</span><span class="n">query</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span> <span class="o">@</span> <span class="n">ops</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rel_pos</span><span class="p">:</span>
            <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_decomposed_rel_pos</span><span class="p">(</span>
                <span class="n">attn_weights</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_w</span><span class="p">,</span> <span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">),</span> <span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">query</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">attn_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>

        <span class="n">attn_output</span> <span class="o">=</span> <span class="p">(</span><span class="n">attn_probs</span> <span class="o">@</span> <span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">attn_output</span> <span class="o">=</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">attn_output</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_weights</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">attn_output</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention.add_decomposed_rel_pos" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamVisionAttention</span><span class="o">.</span><span class="n">add_decomposed_rel_pos</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">rel_pos_h</span><span class="p">,</span> <span class="n">rel_pos_w</span><span class="p">,</span> <span class="n">q_size</span><span class="p">,</span> <span class="n">k_size</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention.add_decomposed_rel_pos" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculate decomposed Relative Positional Embeddings from :paper:<code>mvitv2</code>.
https://github.com/facebookresearch/mvit/blob/19786631e330df9f3622e5402b4a419a263a2c80/mvit/models/attention.py</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>attn</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>attention map.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>query</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>query q in the attention layer with shape (batch_size, query_height * query_width, channel).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rel_pos_h</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>relative position embeddings (Lh, channel) for height axis.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rel_pos_w</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>relative position embeddings (Lw, channel) for width axis.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>q_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>spatial sequence size of query q with (query_height, query_width).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>tuple</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>k_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>spatial sequence size of key k with (key_height, key_width).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>tuple</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>attn</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>attention map with added relative positional embeddings.</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
                </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">add_decomposed_rel_pos</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">attn</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">query</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">rel_pos_h</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">rel_pos_w</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">q_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">k_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate decomposed Relative Positional Embeddings from :paper:`mvitv2`.</span>
<span class="sd">    https://github.com/facebookresearch/mvit/blob/19786631e330df9f3622e5402b4a419a263a2c80/mvit/models/attention.py</span>

<span class="sd">    Args:</span>
<span class="sd">        attn (`mindspore.Tensor`):</span>
<span class="sd">            attention map.</span>
<span class="sd">        query (`mindspore.Tensor`):</span>
<span class="sd">            query q in the attention layer with shape (batch_size, query_height * query_width, channel).</span>
<span class="sd">        rel_pos_h (`mindspore.Tensor`):</span>
<span class="sd">            relative position embeddings (Lh, channel) for height axis.</span>
<span class="sd">        rel_pos_w (`mindspore.Tensor`):</span>
<span class="sd">            relative position embeddings (Lw, channel) for width axis.</span>
<span class="sd">        q_size (tuple):</span>
<span class="sd">            spatial sequence size of query q with (query_height, query_width).</span>
<span class="sd">        k_size (tuple):</span>
<span class="sd">            spatial sequence size of key k with (key_height, key_width).</span>

<span class="sd">    Returns:</span>
<span class="sd">        attn (`mindspore.Tensor`):</span>
<span class="sd">            attention map with added relative positional embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">query_height</span><span class="p">,</span> <span class="n">query_width</span> <span class="o">=</span> <span class="n">q_size</span>
    <span class="n">key_height</span><span class="p">,</span> <span class="n">key_width</span> <span class="o">=</span> <span class="n">k_size</span>
    <span class="n">relative_position_height</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_rel_pos</span><span class="p">(</span><span class="n">query_height</span><span class="p">,</span> <span class="n">key_height</span><span class="p">,</span> <span class="n">rel_pos_h</span><span class="p">)</span>
    <span class="n">relative_position_width</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_rel_pos</span><span class="p">(</span><span class="n">query_width</span><span class="p">,</span> <span class="n">key_width</span><span class="p">,</span> <span class="n">rel_pos_w</span><span class="p">)</span>

    <span class="n">batch_size</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">reshaped_query</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_height</span><span class="p">,</span> <span class="n">query_width</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
    <span class="n">rel_h</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;bhwc,hkc-&gt;bhwk&quot;</span><span class="p">,</span> <span class="n">reshaped_query</span><span class="p">,</span> <span class="n">relative_position_height</span><span class="p">)</span>
    <span class="n">rel_w</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;bhwc,wkc-&gt;bhwk&quot;</span><span class="p">,</span> <span class="n">reshaped_query</span><span class="p">,</span> <span class="n">relative_position_width</span><span class="p">)</span>
    <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_height</span><span class="p">,</span> <span class="n">query_width</span><span class="p">,</span> <span class="n">key_height</span><span class="p">,</span> <span class="n">key_width</span><span class="p">)</span>
    <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">+</span> <span class="n">rel_h</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">rel_w</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">query_height</span> <span class="o">*</span> <span class="n">query_width</span><span class="p">,</span> <span class="n">key_height</span> <span class="o">*</span> <span class="n">key_width</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">attn</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention.get_rel_pos" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamVisionAttention</span><span class="o">.</span><span class="n">get_rel_pos</span><span class="p">(</span><span class="n">q_size</span><span class="p">,</span> <span class="n">k_size</span><span class="p">,</span> <span class="n">rel_pos</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionAttention.get_rel_pos" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Get relative positional embeddings according to the relative positions of
    query and key sizes.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>q_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>size of the query.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>k_size</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>size of key k.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rel_pos</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>relative position embeddings (L, channel).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindspore.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>Extracted positional embeddings according to relative positions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_rel_pos</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">k_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">rel_pos</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get relative positional embeddings according to the relative positions of</span>
<span class="sd">        query and key sizes.</span>

<span class="sd">    Args:</span>
<span class="sd">        q_size (int):</span>
<span class="sd">            size of the query.</span>
<span class="sd">        k_size (int):</span>
<span class="sd">            size of key k.</span>
<span class="sd">        rel_pos (`mindspore.Tensor`):</span>
<span class="sd">            relative position embeddings (L, channel).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Extracted positional embeddings according to relative positions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_rel_dist</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">q_size</span><span class="p">,</span> <span class="n">k_size</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Interpolate rel pos.</span>
    <span class="n">rel_pos_resized</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
        <span class="n">rel_pos</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">rel_pos</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">size</span><span class="o">=</span><span class="n">max_rel_dist</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">rel_pos_resized</span> <span class="o">=</span> <span class="n">rel_pos_resized</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_rel_dist</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Scale the coords with short length if shapes for q and k are different.</span>
    <span class="n">q_coords</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">q_size</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">k_size</span> <span class="o">/</span> <span class="n">q_size</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">k_coords</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k_size</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">q_size</span> <span class="o">/</span> <span class="n">k_size</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">relative_coords</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_coords</span> <span class="o">-</span> <span class="n">k_coords</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">k_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">q_size</span> <span class="o">/</span> <span class="n">k_size</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">rel_pos_resized</span><span class="p">[</span><span class="n">relative_coords</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamVisionEncoderOutput" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamVisionEncoderOutput</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionEncoderOutput" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.utils.ModelOutput">ModelOutput</span></code></p>


        <p>Base class for sam vision model's outputs that also contains image embeddings obtained by applying the projection
layer to the pooler_output.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image_embeds</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The image embeddings obtained by applying the projection layer to the pooler_output.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, output_dim)` *optional* returned when model is initialized with `with_projection=True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>last_hidden_state</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Sequence of hidden-states at the output of the last layer of the model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`mindspore.Tensor` of shape `(batch_size, sequence_length, hidden_size)`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hidden_states</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tuple of <code>mindspore.Tensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`tuple(mindspore.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>attentions</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tuple of <code>mindspore.Tensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length,
sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`tuple(mindspore.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SamVisionEncoderOutput</span><span class="p">(</span><span class="n">ModelOutput</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for sam vision model&#39;s outputs that also contains image embeddings obtained by applying the projection</span>
<span class="sd">    layer to the pooler_output.</span>

<span class="sd">    Args:</span>
<span class="sd">        image_embeds (`mindspore.Tensor` of shape `(batch_size, output_dim)` *optional* returned when model is initialized with `with_projection=True`):</span>
<span class="sd">            The image embeddings obtained by applying the projection layer to the pooler_output.</span>
<span class="sd">        last_hidden_state (`mindspore.Tensor` of shape `(batch_size, sequence_length, hidden_size)`):</span>
<span class="sd">            Sequence of hidden-states at the output of the last layer of the model.</span>
<span class="sd">        hidden_states (`tuple(mindspore.Tensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):</span>
<span class="sd">            Tuple of `mindspore.Tensor` (one for the output of the embeddings, if the model has an embedding layer, +</span>
<span class="sd">            one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.</span>

<span class="sd">            Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</span>
<span class="sd">        attentions (`tuple(mindspore.Tensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):</span>
<span class="sd">            Tuple of `mindspore.Tensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,</span>
<span class="sd">            sequence_length)`.</span>

<span class="sd">            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention</span>
<span class="sd">            heads.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">image_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">last_hidden_state</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer</code>


<a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.core.nn.Module">Module</span></code></p>







              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamVisionLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">window_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">SamVisionAttention</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SamMLPBlock</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>

    <span class="k">def</span> <span class="nf">window_partition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">        Partition into non-overlapping windows with padding if needed.</span>
<span class="sd">            hidden_states (tensor): input tokens with [batch_size, height, width, channel]. window_size (int): window</span>
<span class="sd">            size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            windows: windows after partition with [batch_size * num_windows, window_size, window_size, channel].</span>
<span class="sd">            (pad_height, pad_width): padded height and width before partition</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">channel</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">pad_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">window_size</span> <span class="o">-</span> <span class="n">height</span> <span class="o">%</span> <span class="n">window_size</span><span class="p">)</span> <span class="o">%</span> <span class="n">window_size</span>
        <span class="n">pad_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">window_size</span> <span class="o">-</span> <span class="n">width</span> <span class="o">%</span> <span class="n">window_size</span><span class="p">)</span> <span class="o">%</span> <span class="n">window_size</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pad_w</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pad_h</span><span class="p">))</span>
        <span class="n">pad_height</span><span class="p">,</span> <span class="n">pad_width</span> <span class="o">=</span> <span class="n">height</span> <span class="o">+</span> <span class="n">pad_h</span><span class="p">,</span> <span class="n">width</span> <span class="o">+</span> <span class="n">pad_w</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">pad_height</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">pad_width</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">channel</span>
        <span class="p">)</span>
        <span class="n">windows</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">channel</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">windows</span><span class="p">,</span> <span class="p">(</span><span class="n">pad_height</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">window_unpartition</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">windows</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">padding_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">original_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">        Window unpartition into original sequences and removing padding.</span>
<span class="sd">            hidden_states (tensor):</span>
<span class="sd">                input tokens with [batch_size * num_windows, window_size, window_size, channel].</span>
<span class="sd">            window_size (int):</span>
<span class="sd">                window size.</span>
<span class="sd">            padding_shape (Tuple):</span>
<span class="sd">                padded height and width (pad_height, pad_width).</span>
<span class="sd">            original_shape (Tuple): original height and width (height, width) before padding.</span>

<span class="sd">        Returns:</span>
<span class="sd">            hidden_states: unpartitioned sequences with [batch_size, height, width, channel].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pad_height</span><span class="p">,</span> <span class="n">pad_width</span> <span class="o">=</span> <span class="n">padding_shape</span>
        <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">original_shape</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">windows</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="p">(</span><span class="n">pad_height</span> <span class="o">*</span> <span class="n">pad_width</span> <span class="o">//</span> <span class="n">window_size</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">windows</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">pad_height</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">pad_width</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">hidden_states</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">pad_height</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:,</span> <span class="p">:</span><span class="n">height</span><span class="p">,</span> <span class="p">:</span><span class="n">width</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="n">hidden_states</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_states</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">hidden_states</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm1</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="c1"># Window partition</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">hidden_states</span><span class="p">,</span> <span class="n">padding_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_partition</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">)</span>

        <span class="n">hidden_states</span><span class="p">,</span> <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Reverse window partition</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_unpartition</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">,</span> <span class="n">padding_shape</span><span class="p">,</span> <span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">))</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">residual</span> <span class="o">+</span> <span class="n">hidden_states</span>
        <span class="n">layernorm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm2</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">layernorm_output</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">hidden_states</span><span class="p">,)</span>
        <span class="k">if</span> <span class="n">output_attentions</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">+=</span> <span class="p">(</span><span class="n">attn_weights</span><span class="p">,)</span>

        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer.window_partition" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamVisionLayer</span><span class="o">.</span><span class="n">window_partition</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">window_size</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer.window_partition" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Partition into non-overlapping windows with padding if needed.
    hidden_states (tensor): input tokens with [batch_size, height, width, channel]. window_size (int): window
    size.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>windows</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>windows after partition with [batch_size * num_windows, window_size, window_size, channel].</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.Tensor">Tensor</span></code>
                  </span>
                </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code>(pad_height, pad_width)</code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>padded height and width before partition</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">window_partition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">    Partition into non-overlapping windows with padding if needed.</span>
<span class="sd">        hidden_states (tensor): input tokens with [batch_size, height, width, channel]. window_size (int): window</span>
<span class="sd">        size.</span>

<span class="sd">    Returns:</span>
<span class="sd">        windows: windows after partition with [batch_size * num_windows, window_size, window_size, channel].</span>
<span class="sd">        (pad_height, pad_width): padded height and width before partition</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">channel</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">pad_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">window_size</span> <span class="o">-</span> <span class="n">height</span> <span class="o">%</span> <span class="n">window_size</span><span class="p">)</span> <span class="o">%</span> <span class="n">window_size</span>
    <span class="n">pad_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">window_size</span> <span class="o">-</span> <span class="n">width</span> <span class="o">%</span> <span class="n">window_size</span><span class="p">)</span> <span class="o">%</span> <span class="n">window_size</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pad_w</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pad_h</span><span class="p">))</span>
    <span class="n">pad_height</span><span class="p">,</span> <span class="n">pad_width</span> <span class="o">=</span> <span class="n">height</span> <span class="o">+</span> <span class="n">pad_h</span><span class="p">,</span> <span class="n">width</span> <span class="o">+</span> <span class="n">pad_w</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">pad_height</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">pad_width</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">channel</span>
    <span class="p">)</span>
    <span class="n">windows</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">channel</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">windows</span><span class="p">,</span> <span class="p">(</span><span class="n">pad_height</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer.window_unpartition" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">modeling_sam</span><span class="o">.</span><span class="n">SamVisionLayer</span><span class="o">.</span><span class="n">window_unpartition</span><span class="p">(</span><span class="n">windows</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">padding_shape</span><span class="p">,</span> <span class="n">original_shape</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.modeling_sam.SamVisionLayer.window_unpartition" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Window unpartition into original sequences and removing padding.
    hidden_states (tensor):
        input tokens with [batch_size * num_windows, window_size, window_size, channel].
    window_size (int):
        window size.
    padding_shape (Tuple):
        padded height and width (pad_height, pad_width).
    original_shape (Tuple): original height and width (height, width) before padding.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hidden_states</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>unpartitioned sequences with [batch_size, height, width, channel].</p>
              </div>
                <p>
                  <span class="doc-returns-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.Tensor">Tensor</span></code>
                  </span>
                </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\modeling_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">window_unpartition</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">windows</span><span class="p">:</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">window_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">padding_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">original_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">    Window unpartition into original sequences and removing padding.</span>
<span class="sd">        hidden_states (tensor):</span>
<span class="sd">            input tokens with [batch_size * num_windows, window_size, window_size, channel].</span>
<span class="sd">        window_size (int):</span>
<span class="sd">            window size.</span>
<span class="sd">        padding_shape (Tuple):</span>
<span class="sd">            padded height and width (pad_height, pad_width).</span>
<span class="sd">        original_shape (Tuple): original height and width (height, width) before padding.</span>

<span class="sd">    Returns:</span>
<span class="sd">        hidden_states: unpartitioned sequences with [batch_size, height, width, channel].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pad_height</span><span class="p">,</span> <span class="n">pad_width</span> <span class="o">=</span> <span class="n">padding_shape</span>
    <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">original_shape</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">windows</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="p">(</span><span class="n">pad_height</span> <span class="o">*</span> <span class="n">pad_width</span> <span class="o">//</span> <span class="n">window_size</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">)</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">windows</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">pad_height</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">pad_width</span> <span class="o">//</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
    <span class="p">)</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">hidden_states</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">pad_height</span><span class="p">,</span> <span class="n">pad_width</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:,</span> <span class="p">:</span><span class="n">height</span><span class="p">,</span> <span class="p">:</span><span class="n">width</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">hidden_states</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="mindnlp.transformers.models.sam.processing_sam" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.processing_sam</code>


<a href="#mindnlp.transformers.models.sam.processing_sam" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

        <p>Processor class for SAM.</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="mindnlp.transformers.models.sam.processing_sam.SamProcessor" class="doc doc-heading">
            <code>mindnlp.transformers.models.sam.processing_sam.SamProcessor</code>


<a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindnlp.transformers.processing_utils.ProcessorMixin">ProcessorMixin</span></code></p>


        <p>Constructs a SAM processor which wraps a SAM image processor and an 2D points &amp; Bounding boxes processor into a
single processor.</p>
<p>[<code>SamProcessor</code>] offers all the functionalities of [<code>SamImageProcessor</code>]. See the docstring of
[<code>~SamImageProcessor.__call__</code>] for more information.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>image_processor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An instance of [<code>SamImageProcessor</code>]. The image processor is a required input.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`SamImageProcessor`</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>mindnlp\transformers\models\sam\processing_sam.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SamProcessor</span><span class="p">(</span><span class="n">ProcessorMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs a SAM processor which wraps a SAM image processor and an 2D points &amp; Bounding boxes processor into a</span>
<span class="sd">    single processor.</span>

<span class="sd">    [`SamProcessor`] offers all the functionalities of [`SamImageProcessor`]. See the docstring of</span>
<span class="sd">    [`~SamImageProcessor.__call__`] for more information.</span>

<span class="sd">    Args:</span>
<span class="sd">        image_processor (`SamImageProcessor`):</span>
<span class="sd">            An instance of [`SamImageProcessor`]. The image processor is a required input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;image_processor&quot;</span><span class="p">]</span>
    <span class="n">image_processor_class</span> <span class="o">=</span> <span class="s2">&quot;SamImageProcessor&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_processor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a new instance of the SamProcessor class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the SamProcessor class.</span>
<span class="sd">            image_processor: An image processor object used for image processing operations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">image_processor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_processor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">point_pad_value</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&quot;longest_edge&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">segmentation_maps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchEncoding</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method uses [`SamImageProcessor.__call__`] method to prepare image(s) for the model. It also prepares 2D</span>
<span class="sd">        points and bounding boxes for the model if they are provided.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoding_image_processor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="p">(</span>
            <span class="n">images</span><span class="p">,</span>
            <span class="n">segmentation_maps</span><span class="o">=</span><span class="n">segmentation_maps</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># pop arguments that are not used in the foward but used nevertheless</span>
        <span class="n">original_sizes</span> <span class="o">=</span> <span class="n">encoding_image_processor</span><span class="p">[</span><span class="s2">&quot;original_sizes&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">original_sizes</span><span class="p">,</span> <span class="s2">&quot;asnumpy&quot;</span><span class="p">):</span>  <span class="c1"># Checks if MindSpore tensor</span>
            <span class="n">original_sizes</span> <span class="o">=</span> <span class="n">original_sizes</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

        <span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">,</span> <span class="n">input_boxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_and_preprocess_points</span><span class="p">(</span>
            <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span>
            <span class="n">input_labels</span><span class="o">=</span><span class="n">input_labels</span><span class="p">,</span>
            <span class="n">input_boxes</span><span class="o">=</span><span class="n">input_boxes</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">encoding_image_processor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_and_convert</span><span class="p">(</span>
            <span class="n">encoding_image_processor</span><span class="p">,</span>
            <span class="n">original_sizes</span><span class="p">,</span>
            <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span>
            <span class="n">input_labels</span><span class="o">=</span><span class="n">input_labels</span><span class="p">,</span>
            <span class="n">input_boxes</span><span class="o">=</span><span class="n">input_boxes</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">encoding_image_processor</span>

    <span class="k">def</span> <span class="nf">_normalize_and_convert</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">encoding_image_processor</span><span class="p">,</span>
        <span class="n">original_sizes</span><span class="p">,</span>
        <span class="n">input_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Normalize and convert input data for encoding image processing.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: SamProcessor</span>
<span class="sd">                The instance of the SamProcessor class.</span>
<span class="sd">            encoding_image_processor: object</span>
<span class="sd">                The encoding image processor object.</span>
<span class="sd">            original_sizes: list</span>
<span class="sd">                A list containing the original sizes of the input data.</span>
<span class="sd">            input_points: list, optional</span>
<span class="sd">                A list of input points to be processed. Defaults to None.</span>
<span class="sd">            input_labels: list, optional</span>
<span class="sd">                A list of input labels to be processed. Defaults to None.</span>
<span class="sd">            input_boxes: list, optional</span>
<span class="sd">                A list of input boxes to be processed. Defaults to None.</span>
<span class="sd">            return_tensors: str</span>
<span class="sd">                A string indicating the type of return tensors. Allowed values are: &#39;ms&#39; for MindSpore tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None: This method does not return a value. The input encoding_image_processor is updated with</span>
<span class="sd">                the processed input data.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If the length of original_sizes does not match the length of input_points or input_boxes.</span>
<span class="sd">            ValueError: If input_points and input_labels are not of the same shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_sizes</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_points</span><span class="p">):</span>
                <span class="n">input_points</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_size</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">original_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">input_points</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_points</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_size</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">original_size</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">point</span><span class="p">,</span> <span class="n">original_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_points</span><span class="p">,</span> <span class="n">original_sizes</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="c1"># check that all arrays have the same shape</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">point</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">input_points</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">input_points</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">input_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pad_points_and_labels</span><span class="p">(</span><span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">)</span>

            <span class="n">input_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">input_points</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_sizes</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">):</span>
                <span class="n">input_boxes</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_size</span><span class="p">,</span> <span class="n">box</span><span class="p">,</span> <span class="n">original_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">is_bounding_box</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">box</span> <span class="ow">in</span> <span class="n">input_boxes</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_boxes</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_coordinates</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_size</span><span class="p">,</span> <span class="n">box</span><span class="p">,</span> <span class="n">original_size</span><span class="p">,</span> <span class="n">is_bounding_box</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">box</span><span class="p">,</span> <span class="n">original_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">,</span> <span class="n">original_sizes</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="n">input_boxes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
                <span class="n">input_boxes</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">)</span>
                <span class="c1"># boxes batch size of 1 by default</span>
                <span class="n">input_boxes</span> <span class="o">=</span> <span class="n">input_boxes</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span> <span class="k">else</span> <span class="n">input_boxes</span>
            <span class="n">encoding_image_processor</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;input_boxes&quot;</span><span class="p">:</span> <span class="n">input_boxes</span><span class="p">})</span>
        <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
                <span class="n">input_points</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_points</span><span class="p">,</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="c1"># point batch size of 1 by default</span>
                <span class="n">input_points</span> <span class="o">=</span> <span class="n">input_points</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_points</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">4</span> <span class="k">else</span> <span class="n">input_points</span>
            <span class="n">encoding_image_processor</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;input_points&quot;</span><span class="p">:</span> <span class="n">input_points</span><span class="p">})</span>
        <span class="k">if</span> <span class="n">input_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">return_tensors</span> <span class="o">==</span> <span class="s2">&quot;ms&quot;</span><span class="p">:</span>
                <span class="n">input_labels</span> <span class="o">=</span> <span class="n">mindspore</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span>
                <span class="c1"># point batch size of 1 by default</span>
                <span class="n">input_labels</span> <span class="o">=</span> <span class="n">input_labels</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span> <span class="k">else</span> <span class="n">input_labels</span>
            <span class="n">encoding_image_processor</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;input_labels&quot;</span><span class="p">:</span> <span class="n">input_labels</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">encoding_image_processor</span>

    <span class="k">def</span> <span class="nf">_pad_points_and_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The method pads the 2D points and labels to the maximum number of points in the batch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">expected_nb_points</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">point</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">input_points</span><span class="p">)</span>
        <span class="n">processed_input_points</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">point</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_points</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">point</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">expected_nb_points</span><span class="p">:</span>
                <span class="n">point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">point</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">expected_nb_points</span> <span class="o">-</span> <span class="n">point</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">point_pad_value</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
                <span class="p">)</span>
                <span class="n">input_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">point_pad_value</span><span class="p">])</span>
            <span class="n">processed_input_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
        <span class="n">input_points</span> <span class="o">=</span> <span class="n">processed_input_points</span>
        <span class="k">return</span> <span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span>

    <span class="k">def</span> <span class="nf">_normalize_coordinates</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">target_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">coords</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">original_size</span><span class="p">,</span> <span class="n">is_bounding_box</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Expects a numpy array of length 2 in the final dimension. Requires the original image size in (H, W) format.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">old_h</span><span class="p">,</span> <span class="n">old_w</span> <span class="o">=</span> <span class="n">original_size</span>
        <span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">_get_preprocess_shape</span><span class="p">(</span><span class="n">original_size</span><span class="p">,</span> <span class="n">longest_edge</span><span class="o">=</span><span class="n">target_size</span><span class="p">)</span>
        <span class="n">coords</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">coords</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_bounding_box</span><span class="p">:</span>
            <span class="n">coords</span> <span class="o">=</span> <span class="n">coords</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">coords</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">coords</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">new_w</span> <span class="o">/</span> <span class="n">old_w</span><span class="p">)</span>
        <span class="n">coords</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">coords</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">new_h</span> <span class="o">/</span> <span class="n">old_h</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_bounding_box</span><span class="p">:</span>
            <span class="n">coords</span> <span class="o">=</span> <span class="n">coords</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">coords</span>

    <span class="k">def</span> <span class="nf">_check_and_preprocess_points</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check and preprocesses the 2D points, labels and bounding boxes. It checks if the input is valid and if they</span>
<span class="sd">        are, it converts the coordinates of the points and bounding boxes. If a user passes directly a `torch.Tensor`,</span>
<span class="sd">        it is converted to a `numpy.ndarray` and then to a `list`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">input_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">input_points</span><span class="p">,</span> <span class="s2">&quot;asnumpy&quot;</span><span class="p">):</span>  <span class="c1"># Checks for MindSpore tensor</span>
                <span class="n">input_points</span> <span class="o">=</span> <span class="n">input_points</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_points</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_points</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input points must be a list of list of floating points.&quot;</span><span class="p">)</span>
            <span class="n">input_points</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">input_point</span><span class="p">)</span> <span class="k">for</span> <span class="n">input_point</span> <span class="ow">in</span> <span class="n">input_points</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_points</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">input_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">input_labels</span><span class="p">,</span> <span class="s2">&quot;numpy&quot;</span><span class="p">):</span>
                <span class="n">input_labels</span> <span class="o">=</span> <span class="n">input_labels</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_labels</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input labels must be a list of list integers.&quot;</span><span class="p">)</span>
            <span class="n">input_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">input_labels</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_labels</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">input_boxes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">,</span> <span class="s2">&quot;numpy&quot;</span><span class="p">):</span>
                <span class="n">input_boxes</span> <span class="o">=</span> <span class="n">input_boxes</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

            <span class="k">if</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">)</span>
                <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_boxes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input boxes must be a list of list of list of floating points.&quot;</span><span class="p">)</span>
            <span class="n">input_boxes</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">box</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">box</span> <span class="ow">in</span> <span class="n">input_boxes</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_boxes</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">,</span> <span class="n">input_boxes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_input_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method returns a list of unique model input names used in the SamProcessor class.</span>

<span class="sd">        Args:</span>
<span class="sd">            self (SamProcessor): The instance of the SamProcessor class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: A list of unique model input names extracted from the image processor.</span>

<span class="sd">        Raises:</span>
<span class="sd">            None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">image_processor_input_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">model_input_names</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">image_processor_input_names</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">post_process_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Post-processes masks using the image processor.</span>

<span class="sd">        Args:</span>
<span class="sd">            self: The instance of the SamProcessor class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            Any exceptions raised by the image_processor.post_process_masks method may be propagated from this method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">post_process_masks</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="mindnlp.transformers.models.sam.processing_sam.SamProcessor.model_input_names" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">processing_sam</span><span class="o">.</span><span class="n">SamProcessor</span><span class="o">.</span><span class="n">model_input_names</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.model_input_names" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>This method returns a list of unique model input names used in the SamProcessor class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the SamProcessor class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><a class="autorefs autorefs-internal" title="mindnlp.transformers.models.sam.processing_sam.SamProcessor" href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor">SamProcessor</a></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>list</code>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>A list of unique model input names extracted from the image processor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
    </div>

</div>



<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.processing_sam.SamProcessor.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">processing_sam</span><span class="o">.</span><span class="n">SamProcessor</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">segmentation_maps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>This method uses [<code>SamImageProcessor.__call__</code>] method to prepare image(s) for the model. It also prepares 2D
points and bounding boxes for the model if they are provided.</p>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">segmentation_maps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">input_points</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">input_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">input_boxes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BatchEncoding</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method uses [`SamImageProcessor.__call__`] method to prepare image(s) for the model. It also prepares 2D</span>
<span class="sd">    points and bounding boxes for the model if they are provided.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoding_image_processor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="p">(</span>
        <span class="n">images</span><span class="p">,</span>
        <span class="n">segmentation_maps</span><span class="o">=</span><span class="n">segmentation_maps</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># pop arguments that are not used in the foward but used nevertheless</span>
    <span class="n">original_sizes</span> <span class="o">=</span> <span class="n">encoding_image_processor</span><span class="p">[</span><span class="s2">&quot;original_sizes&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">original_sizes</span><span class="p">,</span> <span class="s2">&quot;asnumpy&quot;</span><span class="p">):</span>  <span class="c1"># Checks if MindSpore tensor</span>
        <span class="n">original_sizes</span> <span class="o">=</span> <span class="n">original_sizes</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

    <span class="n">input_points</span><span class="p">,</span> <span class="n">input_labels</span><span class="p">,</span> <span class="n">input_boxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_and_preprocess_points</span><span class="p">(</span>
        <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="o">=</span><span class="n">input_labels</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="o">=</span><span class="n">input_boxes</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">encoding_image_processor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_normalize_and_convert</span><span class="p">(</span>
        <span class="n">encoding_image_processor</span><span class="p">,</span>
        <span class="n">original_sizes</span><span class="p">,</span>
        <span class="n">input_points</span><span class="o">=</span><span class="n">input_points</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="o">=</span><span class="n">input_labels</span><span class="p">,</span>
        <span class="n">input_boxes</span><span class="o">=</span><span class="n">input_boxes</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="n">return_tensors</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">encoding_image_processor</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.processing_sam.SamProcessor.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">processing_sam</span><span class="o">.</span><span class="n">SamProcessor</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">image_processor</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Initializes a new instance of the SamProcessor class.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the SamProcessor class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_processor</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>An image processor object used for image processing operations.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_processor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a new instance of the SamProcessor class.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The instance of the SamProcessor class.</span>
<span class="sd">        image_processor: An image processor object used for image processing operations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">image_processor</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_processor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">point_pad_value</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&quot;longest_edge&quot;</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindnlp.transformers.models.sam.processing_sam.SamProcessor.post_process_masks" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindnlp</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">sam</span><span class="o">.</span><span class="n">processing_sam</span><span class="o">.</span><span class="n">SamProcessor</span><span class="o">.</span><span class="n">post_process_masks</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindnlp.transformers.models.sam.processing_sam.SamProcessor.post_process_masks" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Post-processes masks using the image processor.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>self</code>
            </td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The instance of the SamProcessor class.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>None.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindnlp\transformers\models\sam\processing_sam.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">post_process_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Post-processes masks using the image processor.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The instance of the SamProcessor class.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        Any exceptions raised by the image_processor.post_process_masks method may be propagated from this method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">post_process_masks</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../rwkv/" class="md-footer__link md-footer__link--prev" aria-label="Previous: rwkv">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                rwkv
              </div>
            </div>
          </a>
        
        
          
          <a href="../seamless_m4t/" class="md-footer__link md-footer__link--next" aria-label="Next: seamless_m4t">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                seamless_m4t
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 - 2024 MindSpore Lab and CQU NLP Team.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:lvyufeng@cqu.edu.cn" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindnlp" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/lu-yu-feng-46-1" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top", "navigation.footer", "navigation.path", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>